{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "import numpy as np\n",
    "from keras.callbacks import Callback\n",
    "from scipy.io import loadmat\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization,Activation\n",
    "from keras.optimizers import Adam,Nadam\n",
    "from numpy import linalg as la\n",
    "from sklearn import preprocessing\n",
    "from keras import regularizers\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "import tensorflow as tf\n",
    "import matplotlib.ticker as plticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(cm,n):\n",
    "    if n != 72:\n",
    "        fig = plt.figure(figsize=(6.5,6.5))\n",
    "        ax = fig.add_subplot()\n",
    "        plt.imshow(cm,cmap='Blues', interpolation='nearest')\n",
    "        plt.colorbar()\n",
    "        \n",
    "        loc = plticker.MultipleLocator(base=1.0)\n",
    "        ax.xaxis.set_major_locator(loc)\n",
    "        ax.yaxis.set_major_locator(loc)\n",
    "\n",
    "        if n == 6 :\n",
    "            ax.set_xticklabels([''] + [\"HB\", \"HF\", \"AB\", \"AF\", \"FV\", \"IO\"])\n",
    "            ax.set_yticklabels([''] + [\"HB\", \"HF\", \"AB\", \"AF\", \"FV\", \"IO\"])\n",
    "        elif n == 12 :\n",
    "            ax.set_xticklabels([''] + [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\"])\n",
    "            ax.set_yticklabels([''] + [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \"11\", \"12\"])\n",
    "        elif n == 2 :\n",
    "            ax.set_xticklabels([''] + [\"HF\", \"IO\"])\n",
    "            ax.set_yticklabels([''] + [\"HF\", \"IO\"])\n",
    "    \n",
    "        thresh = cm.max() / 2.\n",
    "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "            plt.text(j, i, cm[i, j], horizontalalignment=\"center\",color=\"white\" if cm[i, j] > thresh else \"black\");\n",
    "    \n",
    "    else:\n",
    "        fig = plt.figure(figsize=(12,12))\n",
    "        ax = fig.add_subplot()\n",
    "        plt.imshow(cm,cmap='Blues', interpolation='nearest')\n",
    "        plt.colorbar()\n",
    "            \n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.ylabel('True')\n",
    "    plt.xlabel('Predicted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple CNN\n",
    "\n",
    "Τρέχουμε ένα απλό cnn για όλες τις 6 κλάσεις. Το κάθε μοντέλο το τρέχουμε ξεχωριστά για τον κάθε συμμετέχοντα και στη συνέχεια παίρνουμε τα τελικά αποτελέσματα. Δηλαδή, παίρνουμε τη μέση τιμή της ακρίβειας για κάθε συμμετέχοντα, ενώ αθροίζουμε όλους τους confusion matrices και ύστερα τους κανονικοποιούμε. Η διαδικασία αυτή εφαρμόζεται σε όλα τα μοντέλα νευρωνικών δικτύων που δοκιμάσαμε."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4150 samples, validate on 1038 samples\n",
      "Epoch 1/50\n",
      "4150/4150 [==============================] - 5s 1ms/step - loss: 2.1439 - accuracy: 0.2508 - val_loss: 1.9378 - val_accuracy: 0.2890\n",
      "Epoch 2/50\n",
      "4150/4150 [==============================] - 2s 596us/step - loss: 1.9096 - accuracy: 0.3284 - val_loss: 1.9067 - val_accuracy: 0.3632\n",
      "Epoch 3/50\n",
      "4150/4150 [==============================] - 3s 630us/step - loss: 1.8655 - accuracy: 0.3957 - val_loss: 1.9492 - val_accuracy: 0.3295\n",
      "Epoch 4/50\n",
      "4150/4150 [==============================] - 3s 635us/step - loss: 1.7930 - accuracy: 0.4537 - val_loss: 1.9561 - val_accuracy: 0.3738\n",
      "Epoch 5/50\n",
      "4150/4150 [==============================] - 3s 636us/step - loss: 1.6664 - accuracy: 0.4829 - val_loss: 1.8745 - val_accuracy: 0.4056\n",
      "Epoch 6/50\n",
      "4150/4150 [==============================] - 3s 674us/step - loss: 1.5465 - accuracy: 0.5566 - val_loss: 1.8985 - val_accuracy: 0.3988\n",
      "Epoch 7/50\n",
      "4150/4150 [==============================] - 3s 674us/step - loss: 1.4812 - accuracy: 0.6000 - val_loss: 2.0064 - val_accuracy: 0.4152\n",
      "Epoch 8/50\n",
      "4150/4150 [==============================] - 3s 679us/step - loss: 1.4996 - accuracy: 0.6402 - val_loss: 2.0506 - val_accuracy: 0.4085\n",
      "Epoch 9/50\n",
      "4150/4150 [==============================] - 3s 661us/step - loss: 1.2936 - accuracy: 0.6834 - val_loss: 2.1813 - val_accuracy: 0.4008\n",
      "Epoch 10/50\n",
      "4150/4150 [==============================] - 3s 642us/step - loss: 1.2154 - accuracy: 0.7272 - val_loss: 2.0807 - val_accuracy: 0.4287\n",
      "Epoch 11/50\n",
      "4150/4150 [==============================] - 3s 630us/step - loss: 1.2406 - accuracy: 0.7434 - val_loss: 2.1690 - val_accuracy: 0.4191\n",
      "Epoch 12/50\n",
      "4150/4150 [==============================] - 3s 611us/step - loss: 1.1385 - accuracy: 0.7805 - val_loss: 2.2489 - val_accuracy: 0.4085\n",
      "Epoch 13/50\n",
      "4150/4150 [==============================] - 2s 597us/step - loss: 1.0661 - accuracy: 0.8017 - val_loss: 2.4780 - val_accuracy: 0.3969\n",
      "Epoch 14/50\n",
      "4150/4150 [==============================] - 2s 600us/step - loss: 1.0314 - accuracy: 0.8159 - val_loss: 2.3774 - val_accuracy: 0.3998\n",
      "Epoch 15/50\n",
      "4150/4150 [==============================] - 2s 599us/step - loss: 0.9941 - accuracy: 0.8335 - val_loss: 2.4655 - val_accuracy: 0.4066\n",
      "Epoch 16/50\n",
      "4150/4150 [==============================] - 2s 598us/step - loss: 1.0274 - accuracy: 0.8306 - val_loss: 2.5835 - val_accuracy: 0.3873\n",
      "Epoch 17/50\n",
      "4150/4150 [==============================] - 2s 599us/step - loss: 0.9616 - accuracy: 0.8414 - val_loss: 2.5537 - val_accuracy: 0.3979\n",
      "Epoch 18/50\n",
      "4150/4150 [==============================] - 2s 599us/step - loss: 0.9245 - accuracy: 0.8569 - val_loss: 2.7650 - val_accuracy: 0.3805\n",
      "Epoch 19/50\n",
      "4150/4150 [==============================] - 2s 600us/step - loss: 0.8967 - accuracy: 0.8569 - val_loss: 2.6428 - val_accuracy: 0.4085\n",
      "Epoch 20/50\n",
      "4150/4150 [==============================] - 2s 602us/step - loss: 0.8559 - accuracy: 0.8827 - val_loss: 2.7262 - val_accuracy: 0.4046\n",
      "Epoch 21/50\n",
      "4150/4150 [==============================] - 2s 601us/step - loss: 0.7981 - accuracy: 0.8884 - val_loss: 2.7492 - val_accuracy: 0.4114\n",
      "Epoch 22/50\n",
      "4150/4150 [==============================] - 2s 597us/step - loss: 0.8672 - accuracy: 0.8848 - val_loss: 2.6857 - val_accuracy: 0.3911\n",
      "Epoch 23/50\n",
      "4150/4150 [==============================] - 2s 595us/step - loss: 0.8146 - accuracy: 0.8918 - val_loss: 2.9094 - val_accuracy: 0.3931\n",
      "Epoch 24/50\n",
      "4150/4150 [==============================] - 2s 596us/step - loss: 0.7708 - accuracy: 0.8920 - val_loss: 2.8109 - val_accuracy: 0.4008\n",
      "Epoch 25/50\n",
      "4150/4150 [==============================] - 2s 599us/step - loss: 0.7319 - accuracy: 0.9007 - val_loss: 2.9258 - val_accuracy: 0.4075\n",
      "Epoch 26/50\n",
      "4150/4150 [==============================] - 2s 598us/step - loss: 0.7869 - accuracy: 0.8875 - val_loss: 2.8797 - val_accuracy: 0.4017\n",
      "Epoch 27/50\n",
      "4150/4150 [==============================] - 2s 598us/step - loss: 0.8137 - accuracy: 0.8851 - val_loss: 2.7563 - val_accuracy: 0.3719\n",
      "Epoch 28/50\n",
      "4150/4150 [==============================] - 2s 597us/step - loss: 0.7408 - accuracy: 0.8966 - val_loss: 2.6832 - val_accuracy: 0.4075\n",
      "Epoch 29/50\n",
      "4150/4150 [==============================] - 2s 596us/step - loss: 0.7780 - accuracy: 0.8930 - val_loss: 2.8354 - val_accuracy: 0.4046\n",
      "Epoch 30/50\n",
      "4150/4150 [==============================] - 2s 596us/step - loss: 0.7682 - accuracy: 0.8904 - val_loss: 2.7502 - val_accuracy: 0.4162\n",
      "Epoch 31/50\n",
      "4150/4150 [==============================] - 2s 599us/step - loss: 0.7507 - accuracy: 0.9012 - val_loss: 2.9945 - val_accuracy: 0.3882\n",
      "Epoch 32/50\n",
      "4150/4150 [==============================] - 2s 601us/step - loss: 0.7564 - accuracy: 0.9019 - val_loss: 2.9437 - val_accuracy: 0.4046\n",
      "Epoch 33/50\n",
      "4150/4150 [==============================] - 3s 634us/step - loss: 0.7213 - accuracy: 0.9017 - val_loss: 3.2368 - val_accuracy: 0.4075\n",
      "Epoch 34/50\n",
      "4150/4150 [==============================] - 3s 664us/step - loss: 0.7742 - accuracy: 0.8966 - val_loss: 3.3070 - val_accuracy: 0.3873\n",
      "Epoch 35/50\n",
      "4150/4150 [==============================] - 2s 598us/step - loss: 0.7572 - accuracy: 0.8961 - val_loss: 3.1863 - val_accuracy: 0.3834\n",
      "Epoch 36/50\n",
      "4150/4150 [==============================] - 3s 682us/step - loss: 0.7719 - accuracy: 0.9048 - val_loss: 3.1312 - val_accuracy: 0.3805\n",
      "Epoch 37/50\n",
      "4150/4150 [==============================] - 3s 682us/step - loss: 0.7565 - accuracy: 0.9055 - val_loss: 3.1873 - val_accuracy: 0.3690\n",
      "Epoch 38/50\n",
      "4150/4150 [==============================] - 3s 625us/step - loss: 0.7241 - accuracy: 0.9024 - val_loss: 3.1501 - val_accuracy: 0.4027\n",
      "Epoch 39/50\n",
      "4150/4150 [==============================] - 3s 624us/step - loss: 0.7210 - accuracy: 0.9022 - val_loss: 2.9980 - val_accuracy: 0.4056\n",
      "Epoch 40/50\n",
      "4150/4150 [==============================] - 3s 605us/step - loss: 0.6995 - accuracy: 0.9046 - val_loss: 3.4748 - val_accuracy: 0.4066\n",
      "Epoch 41/50\n",
      "4150/4150 [==============================] - 3s 620us/step - loss: 0.9018 - accuracy: 0.8870 - val_loss: 3.1985 - val_accuracy: 0.3931\n",
      "Epoch 42/50\n",
      "4150/4150 [==============================] - 3s 620us/step - loss: 0.7655 - accuracy: 0.8947 - val_loss: 3.2806 - val_accuracy: 0.4027\n",
      "Epoch 43/50\n",
      "4150/4150 [==============================] - 3s 614us/step - loss: 0.7030 - accuracy: 0.9118 - val_loss: 3.3578 - val_accuracy: 0.3844\n",
      "Epoch 44/50\n",
      "4150/4150 [==============================] - 3s 617us/step - loss: 0.6639 - accuracy: 0.9147 - val_loss: 2.9531 - val_accuracy: 0.3834\n",
      "Epoch 45/50\n",
      "4150/4150 [==============================] - 3s 622us/step - loss: 0.6770 - accuracy: 0.9106 - val_loss: 3.2445 - val_accuracy: 0.3844\n",
      "Epoch 46/50\n",
      "4150/4150 [==============================] - 3s 631us/step - loss: 0.6686 - accuracy: 0.9152 - val_loss: 2.9951 - val_accuracy: 0.3882\n",
      "Epoch 47/50\n",
      "4150/4150 [==============================] - 3s 618us/step - loss: 0.6940 - accuracy: 0.9157 - val_loss: 3.4344 - val_accuracy: 0.3882\n",
      "Epoch 48/50\n",
      "4150/4150 [==============================] - 3s 615us/step - loss: 0.6769 - accuracy: 0.9166 - val_loss: 3.0297 - val_accuracy: 0.3873\n",
      "Epoch 49/50\n",
      "4150/4150 [==============================] - 3s 614us/step - loss: 0.6317 - accuracy: 0.9239 - val_loss: 3.2093 - val_accuracy: 0.3825\n",
      "Epoch 50/50\n",
      "4150/4150 [==============================] - 3s 614us/step - loss: 0.6785 - accuracy: 0.9075 - val_loss: 3.2872 - val_accuracy: 0.3854\n",
      "1038/1038 [==============================] - 0s 135us/step\n",
      "1038/1038 [==============================] - 0s 166us/step\n",
      " \n",
      "Train on 4148 samples, validate on 1037 samples\n",
      "Epoch 1/50\n",
      "4148/4148 [==============================] - 3s 764us/step - loss: 2.0441 - accuracy: 0.2399 - val_loss: 1.8680 - val_accuracy: 0.2999\n",
      "Epoch 2/50\n",
      "4148/4148 [==============================] - 3s 608us/step - loss: 1.8867 - accuracy: 0.3380 - val_loss: 1.8908 - val_accuracy: 0.3462\n",
      "Epoch 3/50\n",
      "4148/4148 [==============================] - 3s 623us/step - loss: 1.8224 - accuracy: 0.4041 - val_loss: 1.9193 - val_accuracy: 0.3616\n",
      "Epoch 4/50\n",
      "4148/4148 [==============================] - 3s 611us/step - loss: 1.7404 - accuracy: 0.4658 - val_loss: 1.8895 - val_accuracy: 0.3963\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4148/4148 [==============================] - 2s 595us/step - loss: 1.6231 - accuracy: 0.5178 - val_loss: 1.9371 - val_accuracy: 0.3722\n",
      "Epoch 6/50\n",
      "4148/4148 [==============================] - 2s 591us/step - loss: 1.5246 - accuracy: 0.5885 - val_loss: 2.1449 - val_accuracy: 0.3664\n",
      "Epoch 7/50\n",
      "4148/4148 [==============================] - 2s 588us/step - loss: 1.3958 - accuracy: 0.6345 - val_loss: 2.2766 - val_accuracy: 0.3472\n",
      "Epoch 8/50\n",
      "4148/4148 [==============================] - 3s 612us/step - loss: 1.2956 - accuracy: 0.7042 - val_loss: 2.4513 - val_accuracy: 0.3365\n",
      "Epoch 9/50\n",
      "4148/4148 [==============================] - 3s 651us/step - loss: 1.1550 - accuracy: 0.7476 - val_loss: 2.3933 - val_accuracy: 0.3655\n",
      "Epoch 10/50\n",
      "4148/4148 [==============================] - 3s 638us/step - loss: 1.1223 - accuracy: 0.7686 - val_loss: 2.7339 - val_accuracy: 0.3635\n",
      "Epoch 11/50\n",
      "4148/4148 [==============================] - 3s 622us/step - loss: 1.1671 - accuracy: 0.8103 - val_loss: 2.5634 - val_accuracy: 0.3587\n",
      "Epoch 12/50\n",
      "4148/4148 [==============================] - 3s 612us/step - loss: 1.0065 - accuracy: 0.8462 - val_loss: 2.6146 - val_accuracy: 0.3761\n",
      "Epoch 13/50\n",
      "4148/4148 [==============================] - 3s 608us/step - loss: 0.9555 - accuracy: 0.8392 - val_loss: 2.6648 - val_accuracy: 0.3713\n",
      "Epoch 14/50\n",
      "4148/4148 [==============================] - 3s 609us/step - loss: 0.9258 - accuracy: 0.8488 - val_loss: 3.0714 - val_accuracy: 0.3481\n",
      "Epoch 15/50\n",
      "4148/4148 [==============================] - 3s 608us/step - loss: 0.8742 - accuracy: 0.8607 - val_loss: 3.1326 - val_accuracy: 0.3375\n",
      "Epoch 16/50\n",
      "4148/4148 [==============================] - 3s 611us/step - loss: 0.8238 - accuracy: 0.8703 - val_loss: 2.9252 - val_accuracy: 0.3558\n",
      "Epoch 17/50\n",
      "4148/4148 [==============================] - 3s 613us/step - loss: 0.8284 - accuracy: 0.8696 - val_loss: 3.0611 - val_accuracy: 0.3664\n",
      "Epoch 18/50\n",
      "4148/4148 [==============================] - 3s 613us/step - loss: 0.8007 - accuracy: 0.8756 - val_loss: 3.1845 - val_accuracy: 0.3500\n",
      "Epoch 19/50\n",
      "4148/4148 [==============================] - 3s 609us/step - loss: 0.8070 - accuracy: 0.8809 - val_loss: 2.9923 - val_accuracy: 0.3770\n",
      "Epoch 20/50\n",
      "4148/4148 [==============================] - 3s 611us/step - loss: 0.7897 - accuracy: 0.8920 - val_loss: 3.2894 - val_accuracy: 0.3452\n",
      "Epoch 21/50\n",
      "4148/4148 [==============================] - 3s 608us/step - loss: 0.7561 - accuracy: 0.8949 - val_loss: 3.2508 - val_accuracy: 0.3529\n",
      "Epoch 22/50\n",
      "4148/4148 [==============================] - 3s 611us/step - loss: 0.8119 - accuracy: 0.8865 - val_loss: 3.1048 - val_accuracy: 0.3443\n",
      "Epoch 23/50\n",
      "4148/4148 [==============================] - 3s 613us/step - loss: 0.7624 - accuracy: 0.9012 - val_loss: 3.2907 - val_accuracy: 0.3655\n",
      "Epoch 24/50\n",
      "4148/4148 [==============================] - 3s 613us/step - loss: 0.7707 - accuracy: 0.8990 - val_loss: 3.5835 - val_accuracy: 0.3539\n",
      "Epoch 25/50\n",
      "4148/4148 [==============================] - 3s 611us/step - loss: 0.7194 - accuracy: 0.8956 - val_loss: 3.4063 - val_accuracy: 0.3481\n",
      "Epoch 26/50\n",
      "4148/4148 [==============================] - 3s 610us/step - loss: 0.7097 - accuracy: 0.9081 - val_loss: 3.3252 - val_accuracy: 0.3645\n",
      "Epoch 27/50\n",
      "4148/4148 [==============================] - 3s 609us/step - loss: 0.6961 - accuracy: 0.9057 - val_loss: 3.6175 - val_accuracy: 0.3385\n",
      "Epoch 28/50\n",
      "4148/4148 [==============================] - 3s 624us/step - loss: 0.7451 - accuracy: 0.9081 - val_loss: 3.8935 - val_accuracy: 0.3394\n",
      "Epoch 29/50\n",
      "4148/4148 [==============================] - 3s 619us/step - loss: 0.7049 - accuracy: 0.9101 - val_loss: 3.7394 - val_accuracy: 0.3269\n",
      "Epoch 30/50\n",
      "4148/4148 [==============================] - 3s 612us/step - loss: 0.7111 - accuracy: 0.9053 - val_loss: 3.8409 - val_accuracy: 0.3230\n",
      "Epoch 31/50\n",
      "4148/4148 [==============================] - 3s 610us/step - loss: 0.7047 - accuracy: 0.9050 - val_loss: 3.4991 - val_accuracy: 0.3481\n",
      "Epoch 32/50\n",
      "4148/4148 [==============================] - 3s 608us/step - loss: 0.6907 - accuracy: 0.9106 - val_loss: 3.7535 - val_accuracy: 0.3182\n",
      "Epoch 33/50\n",
      "4148/4148 [==============================] - 3s 608us/step - loss: 0.6915 - accuracy: 0.9050 - val_loss: 3.6052 - val_accuracy: 0.3375\n",
      "Epoch 34/50\n",
      "4148/4148 [==============================] - 3s 609us/step - loss: 0.6596 - accuracy: 0.9171 - val_loss: 3.7338 - val_accuracy: 0.3414\n",
      "Epoch 35/50\n",
      "4148/4148 [==============================] - 3s 611us/step - loss: 0.6336 - accuracy: 0.9188 - val_loss: 3.5584 - val_accuracy: 0.3298\n",
      "Epoch 36/50\n",
      "4148/4148 [==============================] - 3s 611us/step - loss: 0.6115 - accuracy: 0.9195 - val_loss: 3.6585 - val_accuracy: 0.3182\n",
      "Epoch 37/50\n",
      "4148/4148 [==============================] - 3s 629us/step - loss: 0.6771 - accuracy: 0.9086 - val_loss: 3.5182 - val_accuracy: 0.3317\n",
      "Epoch 38/50\n",
      "4148/4148 [==============================] - 3s 626us/step - loss: 0.6273 - accuracy: 0.9216 - val_loss: 3.7235 - val_accuracy: 0.3317\n",
      "Epoch 39/50\n",
      "4148/4148 [==============================] - 3s 618us/step - loss: 0.6210 - accuracy: 0.9171 - val_loss: 3.9241 - val_accuracy: 0.3510\n",
      "Epoch 40/50\n",
      "4148/4148 [==============================] - 3s 610us/step - loss: 0.6263 - accuracy: 0.9171 - val_loss: 3.7442 - val_accuracy: 0.3491\n",
      "Epoch 41/50\n",
      "4148/4148 [==============================] - 3s 616us/step - loss: 0.6161 - accuracy: 0.9151 - val_loss: 3.6418 - val_accuracy: 0.3385\n",
      "Epoch 42/50\n",
      "4148/4148 [==============================] - 3s 619us/step - loss: 0.6054 - accuracy: 0.9195 - val_loss: 3.9354 - val_accuracy: 0.3202\n",
      "Epoch 43/50\n",
      "4148/4148 [==============================] - 3s 613us/step - loss: 0.6118 - accuracy: 0.9238 - val_loss: 3.9816 - val_accuracy: 0.3394\n",
      "Epoch 44/50\n",
      "4148/4148 [==============================] - 3s 611us/step - loss: 0.6395 - accuracy: 0.9135 - val_loss: 4.0857 - val_accuracy: 0.3259\n",
      "Epoch 45/50\n",
      "4148/4148 [==============================] - 3s 610us/step - loss: 0.6724 - accuracy: 0.9106 - val_loss: 3.8520 - val_accuracy: 0.3259\n",
      "Epoch 46/50\n",
      "4148/4148 [==============================] - 3s 606us/step - loss: 0.6200 - accuracy: 0.9173 - val_loss: 3.7206 - val_accuracy: 0.3462\n",
      "Epoch 47/50\n",
      "4148/4148 [==============================] - 3s 611us/step - loss: 0.5793 - accuracy: 0.9284 - val_loss: 3.8923 - val_accuracy: 0.3346\n",
      "Epoch 48/50\n",
      "4148/4148 [==============================] - 3s 610us/step - loss: 0.5434 - accuracy: 0.9421 - val_loss: 3.7442 - val_accuracy: 0.3385\n",
      "Epoch 49/50\n",
      "4148/4148 [==============================] - 3s 610us/step - loss: 0.5456 - accuracy: 0.9368 - val_loss: 4.0293 - val_accuracy: 0.3365\n",
      "Epoch 50/50\n",
      "4148/4148 [==============================] - 3s 612us/step - loss: 0.5505 - accuracy: 0.9323 - val_loss: 4.0438 - val_accuracy: 0.3337\n",
      "1037/1037 [==============================] - 0s 136us/step\n",
      "1037/1037 [==============================] - 0s 166us/step\n",
      " \n",
      "Train on 4148 samples, validate on 1038 samples\n",
      "Epoch 1/50\n",
      "4148/4148 [==============================] - 3s 772us/step - loss: 2.1212 - accuracy: 0.2895 - val_loss: 1.9021 - val_accuracy: 0.3304\n",
      "Epoch 2/50\n",
      "4148/4148 [==============================] - 3s 612us/step - loss: 1.8428 - accuracy: 0.3942 - val_loss: 1.9068 - val_accuracy: 0.3998\n",
      "Epoch 3/50\n",
      "4148/4148 [==============================] - 3s 611us/step - loss: 1.7816 - accuracy: 0.4568 - val_loss: 1.9267 - val_accuracy: 0.4133\n",
      "Epoch 4/50\n",
      "4148/4148 [==============================] - 3s 610us/step - loss: 1.7286 - accuracy: 0.5063 - val_loss: 1.9238 - val_accuracy: 0.4085\n",
      "Epoch 5/50\n",
      "4148/4148 [==============================] - 3s 611us/step - loss: 1.5840 - accuracy: 0.5685 - val_loss: 2.0353 - val_accuracy: 0.4104\n",
      "Epoch 6/50\n",
      "4148/4148 [==============================] - 3s 611us/step - loss: 1.5142 - accuracy: 0.6162 - val_loss: 2.2094 - val_accuracy: 0.3757\n",
      "Epoch 7/50\n",
      "4148/4148 [==============================] - 3s 615us/step - loss: 1.4711 - accuracy: 0.6651 - val_loss: 2.2088 - val_accuracy: 0.4480\n",
      "Epoch 8/50\n",
      "4148/4148 [==============================] - 3s 615us/step - loss: 1.3954 - accuracy: 0.6986 - val_loss: 2.3304 - val_accuracy: 0.4123\n",
      "Epoch 9/50\n",
      "4148/4148 [==============================] - 3s 614us/step - loss: 1.3255 - accuracy: 0.7406 - val_loss: 2.4636 - val_accuracy: 0.4335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50\n",
      "4148/4148 [==============================] - 2s 592us/step - loss: 1.1918 - accuracy: 0.7775 - val_loss: 2.6446 - val_accuracy: 0.4133\n",
      "Epoch 11/50\n",
      "4148/4148 [==============================] - 2s 592us/step - loss: 1.1800 - accuracy: 0.8035 - val_loss: 2.5923 - val_accuracy: 0.4287\n",
      "Epoch 12/50\n",
      "4148/4148 [==============================] - 2s 590us/step - loss: 1.1109 - accuracy: 0.8303 - val_loss: 2.7105 - val_accuracy: 0.4075\n",
      "Epoch 13/50\n",
      "4148/4148 [==============================] - 2s 593us/step - loss: 0.9935 - accuracy: 0.8443 - val_loss: 2.6042 - val_accuracy: 0.4461\n",
      "Epoch 14/50\n",
      "4148/4148 [==============================] - 2s 593us/step - loss: 0.9948 - accuracy: 0.8496 - val_loss: 2.9066 - val_accuracy: 0.4345\n",
      "Epoch 15/50\n",
      "4148/4148 [==============================] - 2s 593us/step - loss: 0.9878 - accuracy: 0.8602 - val_loss: 2.8819 - val_accuracy: 0.4306\n",
      "Epoch 16/50\n",
      "4148/4148 [==============================] - 2s 594us/step - loss: 0.9684 - accuracy: 0.8703 - val_loss: 2.9326 - val_accuracy: 0.4123\n",
      "Epoch 17/50\n",
      "4148/4148 [==============================] - 2s 593us/step - loss: 0.9553 - accuracy: 0.8717 - val_loss: 2.9839 - val_accuracy: 0.4335\n",
      "Epoch 18/50\n",
      "4148/4148 [==============================] - 2s 592us/step - loss: 0.9930 - accuracy: 0.8611 - val_loss: 3.5037 - val_accuracy: 0.3854\n",
      "Epoch 19/50\n",
      "4148/4148 [==============================] - 2s 595us/step - loss: 0.9208 - accuracy: 0.8679 - val_loss: 3.2615 - val_accuracy: 0.4027\n",
      "Epoch 20/50\n",
      "4148/4148 [==============================] - 2s 595us/step - loss: 0.8366 - accuracy: 0.8987 - val_loss: 3.1347 - val_accuracy: 0.4239\n",
      "Epoch 21/50\n",
      "4148/4148 [==============================] - 2s 598us/step - loss: 0.8280 - accuracy: 0.8959 - val_loss: 3.2920 - val_accuracy: 0.4364\n",
      "Epoch 22/50\n",
      "4148/4148 [==============================] - 2s 594us/step - loss: 0.8071 - accuracy: 0.9050 - val_loss: 3.1145 - val_accuracy: 0.4152\n",
      "Epoch 23/50\n",
      "4148/4148 [==============================] - 2s 591us/step - loss: 0.7992 - accuracy: 0.9028 - val_loss: 3.0979 - val_accuracy: 0.4306\n",
      "Epoch 24/50\n",
      "4148/4148 [==============================] - 2s 594us/step - loss: 0.8066 - accuracy: 0.9000 - val_loss: 2.9281 - val_accuracy: 0.4412\n",
      "Epoch 25/50\n",
      "4148/4148 [==============================] - 2s 592us/step - loss: 0.8199 - accuracy: 0.9043 - val_loss: 3.4458 - val_accuracy: 0.4422\n",
      "Epoch 26/50\n",
      "4148/4148 [==============================] - 2s 592us/step - loss: 0.7703 - accuracy: 0.9081 - val_loss: 3.2586 - val_accuracy: 0.4210\n",
      "Epoch 27/50\n",
      "4148/4148 [==============================] - 2s 594us/step - loss: 0.8528 - accuracy: 0.8734 - val_loss: 3.1939 - val_accuracy: 0.4229\n",
      "Epoch 28/50\n",
      "4148/4148 [==============================] - 2s 593us/step - loss: 0.8908 - accuracy: 0.8824 - val_loss: 3.1245 - val_accuracy: 0.4287\n",
      "Epoch 29/50\n",
      "4148/4148 [==============================] - 2s 590us/step - loss: 0.7954 - accuracy: 0.9021 - val_loss: 3.2537 - val_accuracy: 0.4152\n",
      "Epoch 30/50\n",
      "4148/4148 [==============================] - 2s 588us/step - loss: 0.7525 - accuracy: 0.9060 - val_loss: 3.3688 - val_accuracy: 0.4277\n",
      "Epoch 31/50\n",
      "4148/4148 [==============================] - 2s 588us/step - loss: 0.7458 - accuracy: 0.9115 - val_loss: 3.5592 - val_accuracy: 0.3950\n",
      "Epoch 32/50\n",
      "4148/4148 [==============================] - 2s 591us/step - loss: 0.7032 - accuracy: 0.9224 - val_loss: 3.4852 - val_accuracy: 0.4239\n",
      "Epoch 33/50\n",
      "4148/4148 [==============================] - 2s 594us/step - loss: 0.6920 - accuracy: 0.9351 - val_loss: 3.5519 - val_accuracy: 0.4066\n",
      "Epoch 34/50\n",
      "4148/4148 [==============================] - 2s 594us/step - loss: 0.7204 - accuracy: 0.9139 - val_loss: 3.6154 - val_accuracy: 0.4181\n",
      "Epoch 35/50\n",
      "4148/4148 [==============================] - 2s 594us/step - loss: 0.7150 - accuracy: 0.9200 - val_loss: 3.5979 - val_accuracy: 0.4104\n",
      "Epoch 36/50\n",
      "4148/4148 [==============================] - 2s 593us/step - loss: 0.6968 - accuracy: 0.9245 - val_loss: 3.4857 - val_accuracy: 0.3988\n",
      "Epoch 37/50\n",
      "4148/4148 [==============================] - 2s 599us/step - loss: 0.7742 - accuracy: 0.9159 - val_loss: 3.8637 - val_accuracy: 0.3911\n",
      "Epoch 38/50\n",
      "4148/4148 [==============================] - 2s 598us/step - loss: 0.6619 - accuracy: 0.9323 - val_loss: 3.7076 - val_accuracy: 0.4104\n",
      "Epoch 39/50\n",
      "4148/4148 [==============================] - 2s 596us/step - loss: 0.6696 - accuracy: 0.9238 - val_loss: 3.8030 - val_accuracy: 0.4191\n",
      "Epoch 40/50\n",
      "4148/4148 [==============================] - 2s 596us/step - loss: 0.6245 - accuracy: 0.9344 - val_loss: 3.8924 - val_accuracy: 0.4085\n",
      "Epoch 41/50\n",
      "4148/4148 [==============================] - 2s 597us/step - loss: 0.6037 - accuracy: 0.9385 - val_loss: 3.8089 - val_accuracy: 0.4133\n",
      "Epoch 42/50\n",
      "4148/4148 [==============================] - 2s 591us/step - loss: 0.6295 - accuracy: 0.9332 - val_loss: 3.8493 - val_accuracy: 0.4200\n",
      "Epoch 43/50\n",
      "4148/4148 [==============================] - 2s 590us/step - loss: 0.6205 - accuracy: 0.9361 - val_loss: 3.7853 - val_accuracy: 0.4258\n",
      "Epoch 44/50\n",
      "4148/4148 [==============================] - 2s 588us/step - loss: 0.6337 - accuracy: 0.9286 - val_loss: 3.7601 - val_accuracy: 0.4171\n",
      "Epoch 45/50\n",
      "4148/4148 [==============================] - 2s 592us/step - loss: 0.6524 - accuracy: 0.9327 - val_loss: 3.8107 - val_accuracy: 0.3960\n",
      "Epoch 46/50\n",
      "4148/4148 [==============================] - 2s 594us/step - loss: 0.6413 - accuracy: 0.9272 - val_loss: 3.8179 - val_accuracy: 0.4143\n",
      "Epoch 47/50\n",
      "4148/4148 [==============================] - 2s 594us/step - loss: 0.6236 - accuracy: 0.9272 - val_loss: 3.8654 - val_accuracy: 0.4094\n",
      "Epoch 48/50\n",
      "4148/4148 [==============================] - 2s 593us/step - loss: 0.5736 - accuracy: 0.9351 - val_loss: 4.3305 - val_accuracy: 0.4162\n",
      "Epoch 49/50\n",
      "4148/4148 [==============================] - 2s 592us/step - loss: 0.6170 - accuracy: 0.9320 - val_loss: 4.1451 - val_accuracy: 0.4162\n",
      "Epoch 50/50\n",
      "4148/4148 [==============================] - 2s 592us/step - loss: 0.6491 - accuracy: 0.9255 - val_loss: 4.1662 - val_accuracy: 0.4162\n",
      "1038/1038 [==============================] - 0s 131us/step\n",
      "1038/1038 [==============================] - 0s 162us/step\n",
      " \n",
      "Train on 4148 samples, validate on 1038 samples\n",
      "Epoch 1/50\n",
      "4148/4148 [==============================] - 3s 737us/step - loss: 2.1367 - accuracy: 0.2310 - val_loss: 1.9821 - val_accuracy: 0.2697\n",
      "Epoch 2/50\n",
      "4148/4148 [==============================] - 2s 590us/step - loss: 1.9902 - accuracy: 0.3030 - val_loss: 1.9892 - val_accuracy: 0.3170\n",
      "Epoch 3/50\n",
      "4148/4148 [==============================] - 2s 593us/step - loss: 1.9378 - accuracy: 0.3467 - val_loss: 1.9537 - val_accuracy: 0.3170\n",
      "Epoch 4/50\n",
      "4148/4148 [==============================] - 2s 593us/step - loss: 1.8315 - accuracy: 0.3905 - val_loss: 1.9464 - val_accuracy: 0.3083\n",
      "Epoch 5/50\n",
      "4148/4148 [==============================] - 2s 595us/step - loss: 1.7423 - accuracy: 0.4354 - val_loss: 1.9886 - val_accuracy: 0.3266\n",
      "Epoch 6/50\n",
      "4148/4148 [==============================] - 2s 596us/step - loss: 1.6785 - accuracy: 0.4795 - val_loss: 2.0654 - val_accuracy: 0.2948\n",
      "Epoch 7/50\n",
      "4148/4148 [==============================] - 2s 591us/step - loss: 1.6620 - accuracy: 0.5292 - val_loss: 2.1315 - val_accuracy: 0.3295\n",
      "Epoch 8/50\n",
      "4148/4148 [==============================] - 2s 591us/step - loss: 1.5906 - accuracy: 0.5673 - val_loss: 2.2032 - val_accuracy: 0.3333\n",
      "Epoch 9/50\n",
      "4148/4148 [==============================] - 2s 590us/step - loss: 1.5942 - accuracy: 0.5887 - val_loss: 2.2442 - val_accuracy: 0.3208\n",
      "Epoch 10/50\n",
      "4148/4148 [==============================] - 2s 589us/step - loss: 1.4173 - accuracy: 0.6439 - val_loss: 2.4810 - val_accuracy: 0.3092\n",
      "Epoch 11/50\n",
      "4148/4148 [==============================] - 2s 587us/step - loss: 1.4024 - accuracy: 0.6680 - val_loss: 2.6341 - val_accuracy: 0.3131\n",
      "Epoch 12/50\n",
      "4148/4148 [==============================] - 2s 593us/step - loss: 1.4276 - accuracy: 0.7081 - val_loss: 2.7816 - val_accuracy: 0.3285\n",
      "Epoch 13/50\n",
      "4148/4148 [==============================] - 2s 593us/step - loss: 1.3491 - accuracy: 0.7314 - val_loss: 2.6432 - val_accuracy: 0.3170\n",
      "Epoch 14/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4148/4148 [==============================] - 2s 594us/step - loss: 1.1590 - accuracy: 0.7847 - val_loss: 3.0022 - val_accuracy: 0.3198\n",
      "Epoch 15/50\n",
      "4148/4148 [==============================] - 2s 591us/step - loss: 1.1399 - accuracy: 0.7948 - val_loss: 2.8247 - val_accuracy: 0.3372\n",
      "Epoch 16/50\n",
      "4148/4148 [==============================] - 2s 591us/step - loss: 1.0378 - accuracy: 0.8115 - val_loss: 2.8904 - val_accuracy: 0.3459\n",
      "Epoch 17/50\n",
      "4148/4148 [==============================] - 2s 590us/step - loss: 1.0675 - accuracy: 0.8243 - val_loss: 3.2424 - val_accuracy: 0.3121\n",
      "Epoch 18/50\n",
      "4148/4148 [==============================] - 2s 593us/step - loss: 1.1384 - accuracy: 0.8310 - val_loss: 2.9362 - val_accuracy: 0.3189\n",
      "Epoch 19/50\n",
      "4148/4148 [==============================] - 2s 596us/step - loss: 1.0017 - accuracy: 0.8503 - val_loss: 3.2708 - val_accuracy: 0.3266\n",
      "Epoch 20/50\n",
      "4148/4148 [==============================] - 2s 596us/step - loss: 0.9550 - accuracy: 0.8604 - val_loss: 3.1470 - val_accuracy: 0.3208\n",
      "Epoch 21/50\n",
      "4148/4148 [==============================] - 2s 592us/step - loss: 0.9030 - accuracy: 0.8773 - val_loss: 3.4862 - val_accuracy: 0.3131\n",
      "Epoch 22/50\n",
      "4148/4148 [==============================] - 2s 590us/step - loss: 0.9095 - accuracy: 0.8684 - val_loss: 3.6612 - val_accuracy: 0.3430\n",
      "Epoch 23/50\n",
      "4148/4148 [==============================] - 2s 589us/step - loss: 0.8915 - accuracy: 0.8787 - val_loss: 3.6763 - val_accuracy: 0.3324\n",
      "Epoch 24/50\n",
      "4148/4148 [==============================] - 2s 590us/step - loss: 0.8860 - accuracy: 0.8824 - val_loss: 3.6099 - val_accuracy: 0.3333\n",
      "Epoch 25/50\n",
      "4148/4148 [==============================] - 2s 592us/step - loss: 0.9993 - accuracy: 0.8720 - val_loss: 3.8645 - val_accuracy: 0.2909\n",
      "Epoch 26/50\n",
      "4148/4148 [==============================] - 2s 593us/step - loss: 0.9654 - accuracy: 0.8831 - val_loss: 3.9312 - val_accuracy: 0.3227\n",
      "Epoch 27/50\n",
      "4148/4148 [==============================] - 2s 590us/step - loss: 0.8790 - accuracy: 0.8985 - val_loss: 4.0517 - val_accuracy: 0.3401\n",
      "Epoch 28/50\n",
      "4148/4148 [==============================] - 2s 590us/step - loss: 0.9419 - accuracy: 0.8889 - val_loss: 4.0198 - val_accuracy: 0.3362\n",
      "Epoch 29/50\n",
      "4148/4148 [==============================] - 2s 591us/step - loss: 0.9421 - accuracy: 0.8973 - val_loss: 3.8384 - val_accuracy: 0.3276\n",
      "Epoch 30/50\n",
      "4148/4148 [==============================] - 2s 592us/step - loss: 0.8596 - accuracy: 0.9048 - val_loss: 3.9165 - val_accuracy: 0.3121\n",
      "Epoch 31/50\n",
      "4148/4148 [==============================] - 2s 593us/step - loss: 0.8530 - accuracy: 0.9098 - val_loss: 4.0000 - val_accuracy: 0.3314\n",
      "Epoch 32/50\n",
      "4148/4148 [==============================] - 3s 613us/step - loss: 0.9456 - accuracy: 0.8930 - val_loss: 4.2712 - val_accuracy: 0.2929\n",
      "Epoch 33/50\n",
      "4148/4148 [==============================] - 2s 596us/step - loss: 0.8986 - accuracy: 0.8946 - val_loss: 4.2530 - val_accuracy: 0.3102\n",
      "Epoch 34/50\n",
      "4148/4148 [==============================] - 3s 608us/step - loss: 0.9060 - accuracy: 0.9038 - val_loss: 3.9191 - val_accuracy: 0.3198\n",
      "Epoch 35/50\n",
      "4148/4148 [==============================] - 2s 591us/step - loss: 0.8606 - accuracy: 0.9120 - val_loss: 4.2063 - val_accuracy: 0.3256\n",
      "Epoch 36/50\n",
      "4148/4148 [==============================] - 2s 592us/step - loss: 0.8399 - accuracy: 0.8995 - val_loss: 3.6449 - val_accuracy: 0.3304\n",
      "Epoch 37/50\n",
      "4148/4148 [==============================] - 2s 594us/step - loss: 0.7666 - accuracy: 0.9180 - val_loss: 4.0365 - val_accuracy: 0.3391\n",
      "Epoch 38/50\n",
      "4148/4148 [==============================] - 2s 594us/step - loss: 0.7976 - accuracy: 0.9069 - val_loss: 3.9999 - val_accuracy: 0.3237\n",
      "Epoch 39/50\n",
      "4148/4148 [==============================] - 2s 593us/step - loss: 0.8270 - accuracy: 0.9024 - val_loss: 4.0534 - val_accuracy: 0.3189\n",
      "Epoch 40/50\n",
      "4148/4148 [==============================] - 2s 592us/step - loss: 0.7275 - accuracy: 0.9262 - val_loss: 3.8932 - val_accuracy: 0.3247\n",
      "Epoch 41/50\n",
      "4148/4148 [==============================] - 3s 609us/step - loss: 0.7427 - accuracy: 0.9139 - val_loss: 4.1169 - val_accuracy: 0.3391\n",
      "Epoch 42/50\n",
      "4148/4148 [==============================] - 2s 593us/step - loss: 0.8084 - accuracy: 0.9050 - val_loss: 4.3406 - val_accuracy: 0.2871\n",
      "Epoch 43/50\n",
      "4148/4148 [==============================] - 2s 589us/step - loss: 0.8312 - accuracy: 0.9045 - val_loss: 4.1377 - val_accuracy: 0.3092\n",
      "Epoch 44/50\n",
      "4148/4148 [==============================] - 2s 593us/step - loss: 0.7147 - accuracy: 0.9282 - val_loss: 4.3185 - val_accuracy: 0.3256\n",
      "Epoch 45/50\n",
      "4148/4148 [==============================] - 3s 606us/step - loss: 0.7520 - accuracy: 0.9168 - val_loss: 4.4231 - val_accuracy: 0.3276\n",
      "Epoch 46/50\n",
      "4148/4148 [==============================] - 2s 599us/step - loss: 0.8410 - accuracy: 0.9016 - val_loss: 4.1676 - val_accuracy: 0.3353\n",
      "Epoch 47/50\n",
      "4148/4148 [==============================] - 2s 593us/step - loss: 0.8367 - accuracy: 0.9069 - val_loss: 4.0798 - val_accuracy: 0.3141\n",
      "Epoch 48/50\n",
      "4148/4148 [==============================] - 2s 593us/step - loss: 0.7816 - accuracy: 0.9178 - val_loss: 4.3580 - val_accuracy: 0.3160\n",
      "Epoch 49/50\n",
      "4148/4148 [==============================] - 2s 591us/step - loss: 0.8345 - accuracy: 0.9190 - val_loss: 4.3418 - val_accuracy: 0.3131\n",
      "Epoch 50/50\n",
      "4148/4148 [==============================] - 2s 592us/step - loss: 0.8111 - accuracy: 0.9197 - val_loss: 4.1965 - val_accuracy: 0.3420\n",
      "1038/1038 [==============================] - 0s 143us/step\n",
      "1038/1038 [==============================] - 0s 168us/step\n",
      " \n",
      "Train on 4148 samples, validate on 1037 samples\n",
      "Epoch 1/50\n",
      "4148/4148 [==============================] - 3s 730us/step - loss: 2.0531 - accuracy: 0.2924 - val_loss: 2.0133 - val_accuracy: 0.2989\n",
      "Epoch 2/50\n",
      "4148/4148 [==============================] - 2s 591us/step - loss: 1.8159 - accuracy: 0.4135 - val_loss: 1.9067 - val_accuracy: 0.4137\n",
      "Epoch 3/50\n",
      "4148/4148 [==============================] - 2s 591us/step - loss: 1.7155 - accuracy: 0.5116 - val_loss: 2.0332 - val_accuracy: 0.4089\n",
      "Epoch 4/50\n",
      "4148/4148 [==============================] - 2s 595us/step - loss: 1.6016 - accuracy: 0.5796 - val_loss: 2.0469 - val_accuracy: 0.4542\n",
      "Epoch 5/50\n",
      "4148/4148 [==============================] - 2s 594us/step - loss: 1.5333 - accuracy: 0.6352 - val_loss: 2.1246 - val_accuracy: 0.4484\n",
      "Epoch 6/50\n",
      "4148/4148 [==============================] - 2s 599us/step - loss: 1.4468 - accuracy: 0.6835 - val_loss: 2.2995 - val_accuracy: 0.4407\n",
      "Epoch 7/50\n",
      "4148/4148 [==============================] - 2s 589us/step - loss: 1.3201 - accuracy: 0.7401 - val_loss: 2.6304 - val_accuracy: 0.4147\n",
      "Epoch 8/50\n",
      "4148/4148 [==============================] - 2s 591us/step - loss: 1.2583 - accuracy: 0.7768 - val_loss: 2.3259 - val_accuracy: 0.4561\n",
      "Epoch 9/50\n",
      "4148/4148 [==============================] - 2s 591us/step - loss: 1.0822 - accuracy: 0.8139 - val_loss: 2.4186 - val_accuracy: 0.4532\n",
      "Epoch 10/50\n",
      "4148/4148 [==============================] - 2s 596us/step - loss: 1.0941 - accuracy: 0.8264 - val_loss: 2.8621 - val_accuracy: 0.4243\n",
      "Epoch 11/50\n",
      "4148/4148 [==============================] - 2s 596us/step - loss: 1.1369 - accuracy: 0.8271 - val_loss: 2.5207 - val_accuracy: 0.4330\n",
      "Epoch 12/50\n",
      "4148/4148 [==============================] - 2s 597us/step - loss: 1.0244 - accuracy: 0.8722 - val_loss: 2.9707 - val_accuracy: 0.4339\n",
      "Epoch 13/50\n",
      "4148/4148 [==============================] - 2s 594us/step - loss: 1.0134 - accuracy: 0.8676 - val_loss: 2.8882 - val_accuracy: 0.4195\n",
      "Epoch 14/50\n",
      "4148/4148 [==============================] - 2s 592us/step - loss: 1.0463 - accuracy: 0.8693 - val_loss: 2.7017 - val_accuracy: 0.4359\n",
      "Epoch 15/50\n",
      "4148/4148 [==============================] - 2s 593us/step - loss: 0.8766 - accuracy: 0.8937 - val_loss: 2.9577 - val_accuracy: 0.4214\n",
      "Epoch 16/50\n",
      "4148/4148 [==============================] - 2s 595us/step - loss: 0.8408 - accuracy: 0.8990 - val_loss: 3.0132 - val_accuracy: 0.4446\n",
      "Epoch 17/50\n",
      "4148/4148 [==============================] - 2s 596us/step - loss: 0.7921 - accuracy: 0.9163 - val_loss: 3.1845 - val_accuracy: 0.4359\n",
      "Epoch 18/50\n",
      "4148/4148 [==============================] - 2s 594us/step - loss: 0.7779 - accuracy: 0.9065 - val_loss: 3.1256 - val_accuracy: 0.4378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50\n",
      "4148/4148 [==============================] - 2s 593us/step - loss: 0.7893 - accuracy: 0.9045 - val_loss: 2.8909 - val_accuracy: 0.4571\n",
      "Epoch 20/50\n",
      "4148/4148 [==============================] - 2s 592us/step - loss: 0.8303 - accuracy: 0.9014 - val_loss: 3.1529 - val_accuracy: 0.4253\n",
      "Epoch 21/50\n",
      "4148/4148 [==============================] - 2s 591us/step - loss: 0.7900 - accuracy: 0.9084 - val_loss: 3.6693 - val_accuracy: 0.4301\n",
      "Epoch 22/50\n",
      "4148/4148 [==============================] - 2s 590us/step - loss: 0.7697 - accuracy: 0.9122 - val_loss: 3.1520 - val_accuracy: 0.4484\n",
      "Epoch 23/50\n",
      "4148/4148 [==============================] - 2s 593us/step - loss: 0.7625 - accuracy: 0.9204 - val_loss: 2.9982 - val_accuracy: 0.4513\n",
      "Epoch 24/50\n",
      "4148/4148 [==============================] - 2s 594us/step - loss: 0.7137 - accuracy: 0.9296 - val_loss: 3.2362 - val_accuracy: 0.4426\n",
      "Epoch 25/50\n",
      "4148/4148 [==============================] - 2s 594us/step - loss: 0.7338 - accuracy: 0.9209 - val_loss: 3.1261 - val_accuracy: 0.4368\n",
      "Epoch 26/50\n",
      "4148/4148 [==============================] - 2s 593us/step - loss: 0.7666 - accuracy: 0.9096 - val_loss: 3.1789 - val_accuracy: 0.4233\n",
      "Epoch 27/50\n",
      "4148/4148 [==============================] - 3s 615us/step - loss: 0.7697 - accuracy: 0.9147 - val_loss: 3.2438 - val_accuracy: 0.4262\n",
      "Epoch 28/50\n",
      "4148/4148 [==============================] - 3s 666us/step - loss: 0.7385 - accuracy: 0.9159 - val_loss: 3.0797 - val_accuracy: 0.4426\n",
      "Epoch 29/50\n",
      "4148/4148 [==============================] - 3s 662us/step - loss: 0.6957 - accuracy: 0.9279 - val_loss: 3.2543 - val_accuracy: 0.4397\n",
      "Epoch 30/50\n",
      "4148/4148 [==============================] - 3s 674us/step - loss: 0.6629 - accuracy: 0.9323 - val_loss: 3.0612 - val_accuracy: 0.4368\n",
      "Epoch 31/50\n",
      "4148/4148 [==============================] - 3s 658us/step - loss: 0.7162 - accuracy: 0.9233 - val_loss: 3.4434 - val_accuracy: 0.4147\n",
      "Epoch 32/50\n",
      "4148/4148 [==============================] - 3s 611us/step - loss: 0.6494 - accuracy: 0.9424 - val_loss: 3.2191 - val_accuracy: 0.4388\n",
      "Epoch 33/50\n",
      "4148/4148 [==============================] - 3s 611us/step - loss: 0.6751 - accuracy: 0.9289 - val_loss: 3.2639 - val_accuracy: 0.4185\n",
      "Epoch 34/50\n",
      "4148/4148 [==============================] - 3s 611us/step - loss: 0.6582 - accuracy: 0.9279 - val_loss: 3.3502 - val_accuracy: 0.4378\n",
      "Epoch 35/50\n",
      "4148/4148 [==============================] - 3s 610us/step - loss: 0.6753 - accuracy: 0.9260 - val_loss: 3.3764 - val_accuracy: 0.4156\n",
      "Epoch 36/50\n",
      "4148/4148 [==============================] - 3s 613us/step - loss: 0.6445 - accuracy: 0.9294 - val_loss: 3.2015 - val_accuracy: 0.4407\n",
      "Epoch 37/50\n",
      "4148/4148 [==============================] - 3s 613us/step - loss: 0.7092 - accuracy: 0.9192 - val_loss: 3.8665 - val_accuracy: 0.4098\n",
      "Epoch 38/50\n",
      "4148/4148 [==============================] - 3s 613us/step - loss: 0.6738 - accuracy: 0.9306 - val_loss: 3.4314 - val_accuracy: 0.4349\n",
      "Epoch 39/50\n",
      "4148/4148 [==============================] - 3s 611us/step - loss: 0.6411 - accuracy: 0.9337 - val_loss: 3.2735 - val_accuracy: 0.4320\n",
      "Epoch 40/50\n",
      "4148/4148 [==============================] - 3s 611us/step - loss: 0.5903 - accuracy: 0.9424 - val_loss: 3.2911 - val_accuracy: 0.4455\n",
      "Epoch 41/50\n",
      "4148/4148 [==============================] - 3s 613us/step - loss: 0.5896 - accuracy: 0.9417 - val_loss: 3.4621 - val_accuracy: 0.4224\n",
      "Epoch 42/50\n",
      "4148/4148 [==============================] - 3s 613us/step - loss: 0.5563 - accuracy: 0.9515 - val_loss: 3.3336 - val_accuracy: 0.4513\n",
      "Epoch 43/50\n",
      "4148/4148 [==============================] - 3s 613us/step - loss: 0.5630 - accuracy: 0.9402 - val_loss: 3.2316 - val_accuracy: 0.4359\n",
      "Epoch 44/50\n",
      "4148/4148 [==============================] - 3s 613us/step - loss: 0.5974 - accuracy: 0.9356 - val_loss: 3.4832 - val_accuracy: 0.4455\n",
      "Epoch 45/50\n",
      "4148/4148 [==============================] - 3s 612us/step - loss: 0.5848 - accuracy: 0.9327 - val_loss: 3.3858 - val_accuracy: 0.4301\n",
      "Epoch 46/50\n",
      "4148/4148 [==============================] - 3s 612us/step - loss: 0.6333 - accuracy: 0.9325 - val_loss: 3.4475 - val_accuracy: 0.4156\n",
      "Epoch 47/50\n",
      "4148/4148 [==============================] - 3s 610us/step - loss: 0.6218 - accuracy: 0.9255 - val_loss: 3.6070 - val_accuracy: 0.4204\n",
      "Epoch 48/50\n",
      "4148/4148 [==============================] - 3s 612us/step - loss: 0.5937 - accuracy: 0.9366 - val_loss: 3.4961 - val_accuracy: 0.4388\n",
      "Epoch 49/50\n",
      "4148/4148 [==============================] - 3s 612us/step - loss: 0.5999 - accuracy: 0.9390 - val_loss: 3.5202 - val_accuracy: 0.4330\n",
      "Epoch 50/50\n",
      "4148/4148 [==============================] - 3s 613us/step - loss: 0.5563 - accuracy: 0.9405 - val_loss: 3.6254 - val_accuracy: 0.4407\n",
      "1037/1037 [==============================] - 0s 138us/step\n",
      "1037/1037 [==============================] - 0s 172us/step\n",
      " \n",
      "Train on 4148 samples, validate on 1038 samples\n",
      "Epoch 1/50\n",
      "4148/4148 [==============================] - 3s 756us/step - loss: 1.9400 - accuracy: 0.3392 - val_loss: 2.0838 - val_accuracy: 0.3536\n",
      "Epoch 2/50\n",
      "4148/4148 [==============================] - 3s 614us/step - loss: 1.7922 - accuracy: 0.4778 - val_loss: 1.9141 - val_accuracy: 0.4422\n",
      "Epoch 3/50\n",
      "4148/4148 [==============================] - 3s 613us/step - loss: 1.6941 - accuracy: 0.5465 - val_loss: 1.9444 - val_accuracy: 0.4615\n",
      "Epoch 4/50\n",
      "4148/4148 [==============================] - 3s 612us/step - loss: 1.5728 - accuracy: 0.6087 - val_loss: 1.9315 - val_accuracy: 0.4547\n",
      "Epoch 5/50\n",
      "4148/4148 [==============================] - 3s 612us/step - loss: 1.4263 - accuracy: 0.6726 - val_loss: 2.1340 - val_accuracy: 0.4692\n",
      "Epoch 6/50\n",
      "4148/4148 [==============================] - 3s 611us/step - loss: 1.3263 - accuracy: 0.7160 - val_loss: 2.0785 - val_accuracy: 0.4730\n",
      "Epoch 7/50\n",
      "4148/4148 [==============================] - 3s 611us/step - loss: 1.2516 - accuracy: 0.7686 - val_loss: 2.3818 - val_accuracy: 0.4489\n",
      "Epoch 8/50\n",
      "4148/4148 [==============================] - 3s 614us/step - loss: 1.1659 - accuracy: 0.8153 - val_loss: 2.5085 - val_accuracy: 0.4316\n",
      "Epoch 9/50\n",
      "4148/4148 [==============================] - 3s 613us/step - loss: 1.1002 - accuracy: 0.8390 - val_loss: 2.6476 - val_accuracy: 0.4345\n",
      "Epoch 10/50\n",
      "4148/4148 [==============================] - 3s 613us/step - loss: 1.0493 - accuracy: 0.8585 - val_loss: 3.0074 - val_accuracy: 0.3882\n",
      "Epoch 11/50\n",
      "4148/4148 [==============================] - 3s 612us/step - loss: 1.0683 - accuracy: 0.8679 - val_loss: 2.5784 - val_accuracy: 0.4528\n",
      "Epoch 12/50\n",
      "4148/4148 [==============================] - 3s 611us/step - loss: 0.9010 - accuracy: 0.9120 - val_loss: 2.9400 - val_accuracy: 0.4114\n",
      "Epoch 13/50\n",
      "4148/4148 [==============================] - 3s 612us/step - loss: 0.8736 - accuracy: 0.9118 - val_loss: 2.7404 - val_accuracy: 0.4721\n",
      "Epoch 14/50\n",
      "4148/4148 [==============================] - 3s 614us/step - loss: 0.8206 - accuracy: 0.9212 - val_loss: 2.8253 - val_accuracy: 0.4316\n",
      "Epoch 15/50\n",
      "4148/4148 [==============================] - 3s 612us/step - loss: 0.8317 - accuracy: 0.9115 - val_loss: 2.9139 - val_accuracy: 0.4249\n",
      "Epoch 16/50\n",
      "4148/4148 [==============================] - 3s 611us/step - loss: 0.8573 - accuracy: 0.9159 - val_loss: 2.8289 - val_accuracy: 0.4451\n",
      "Epoch 17/50\n",
      "4148/4148 [==============================] - 3s 611us/step - loss: 0.7580 - accuracy: 0.9359 - val_loss: 2.8963 - val_accuracy: 0.4335\n",
      "Epoch 18/50\n",
      "4148/4148 [==============================] - 3s 611us/step - loss: 0.7845 - accuracy: 0.9233 - val_loss: 2.8683 - val_accuracy: 0.4595\n",
      "Epoch 19/50\n",
      "4148/4148 [==============================] - 3s 613us/step - loss: 0.7089 - accuracy: 0.9426 - val_loss: 6.9159 - val_accuracy: 0.2707\n",
      "Epoch 20/50\n",
      "4148/4148 [==============================] - 3s 613us/step - loss: 1.0024 - accuracy: 0.8975 - val_loss: 3.1033 - val_accuracy: 0.4374\n",
      "Epoch 21/50\n",
      "4148/4148 [==============================] - 3s 615us/step - loss: 0.8054 - accuracy: 0.9311 - val_loss: 3.4960 - val_accuracy: 0.4133\n",
      "Epoch 22/50\n",
      "4148/4148 [==============================] - 3s 613us/step - loss: 0.7432 - accuracy: 0.9482 - val_loss: 3.5776 - val_accuracy: 0.4191\n",
      "Epoch 23/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4148/4148 [==============================] - 2s 594us/step - loss: 0.7019 - accuracy: 0.9462 - val_loss: 3.2313 - val_accuracy: 0.4355\n",
      "Epoch 24/50\n",
      "4148/4148 [==============================] - 2s 593us/step - loss: 0.7435 - accuracy: 0.9474 - val_loss: 3.4873 - val_accuracy: 0.4470\n",
      "Epoch 25/50\n",
      "4148/4148 [==============================] - 2s 599us/step - loss: 0.6726 - accuracy: 0.9491 - val_loss: 3.4350 - val_accuracy: 0.4451\n",
      "Epoch 26/50\n",
      "4148/4148 [==============================] - 3s 605us/step - loss: 0.6594 - accuracy: 0.9453 - val_loss: 3.0992 - val_accuracy: 0.4489\n",
      "Epoch 27/50\n",
      "4148/4148 [==============================] - 2s 594us/step - loss: 0.6322 - accuracy: 0.9477 - val_loss: 2.9642 - val_accuracy: 0.4393\n",
      "Epoch 28/50\n",
      "4148/4148 [==============================] - 2s 594us/step - loss: 0.6464 - accuracy: 0.9443 - val_loss: 3.4115 - val_accuracy: 0.4210\n",
      "Epoch 29/50\n",
      "4148/4148 [==============================] - 2s 594us/step - loss: 0.6142 - accuracy: 0.9547 - val_loss: 3.1976 - val_accuracy: 0.4268\n",
      "Epoch 30/50\n",
      "4148/4148 [==============================] - 2s 592us/step - loss: 0.6178 - accuracy: 0.9561 - val_loss: 3.7586 - val_accuracy: 0.3854\n",
      "Epoch 31/50\n",
      "4148/4148 [==============================] - 2s 592us/step - loss: 0.6703 - accuracy: 0.9405 - val_loss: 3.6185 - val_accuracy: 0.4306\n",
      "Epoch 32/50\n",
      "4148/4148 [==============================] - 2s 593us/step - loss: 0.7158 - accuracy: 0.9248 - val_loss: 3.2347 - val_accuracy: 0.4306\n",
      "Epoch 33/50\n",
      "4148/4148 [==============================] - 2s 594us/step - loss: 0.6551 - accuracy: 0.9474 - val_loss: 3.3534 - val_accuracy: 0.4239\n",
      "Epoch 34/50\n",
      "4148/4148 [==============================] - 2s 593us/step - loss: 0.6663 - accuracy: 0.9448 - val_loss: 3.1411 - val_accuracy: 0.4277\n",
      "Epoch 35/50\n",
      "4148/4148 [==============================] - 2s 596us/step - loss: 0.6275 - accuracy: 0.9477 - val_loss: 3.2039 - val_accuracy: 0.4412\n",
      "Epoch 36/50\n",
      "4148/4148 [==============================] - 2s 592us/step - loss: 0.5757 - accuracy: 0.9554 - val_loss: 3.2070 - val_accuracy: 0.4364\n",
      "Epoch 37/50\n",
      "4148/4148 [==============================] - 2s 594us/step - loss: 0.5671 - accuracy: 0.9568 - val_loss: 3.3893 - val_accuracy: 0.4528\n",
      "Epoch 38/50\n",
      "4148/4148 [==============================] - 2s 592us/step - loss: 0.5754 - accuracy: 0.9542 - val_loss: 3.4408 - val_accuracy: 0.4538\n",
      "Epoch 39/50\n",
      "4148/4148 [==============================] - 2s 596us/step - loss: 0.6260 - accuracy: 0.9429 - val_loss: 3.6824 - val_accuracy: 0.4364\n",
      "Epoch 40/50\n",
      "4148/4148 [==============================] - 2s 596us/step - loss: 0.6499 - accuracy: 0.9414 - val_loss: 3.6317 - val_accuracy: 0.4297\n",
      "Epoch 41/50\n",
      "4148/4148 [==============================] - 2s 596us/step - loss: 0.6476 - accuracy: 0.9433 - val_loss: 4.0780 - val_accuracy: 0.4355\n",
      "Epoch 42/50\n",
      "4148/4148 [==============================] - 2s 592us/step - loss: 0.6201 - accuracy: 0.9460 - val_loss: 3.6571 - val_accuracy: 0.4422\n",
      "Epoch 43/50\n",
      "4148/4148 [==============================] - 2s 592us/step - loss: 0.5388 - accuracy: 0.9672 - val_loss: 3.3449 - val_accuracy: 0.4403\n",
      "Epoch 44/50\n",
      "4148/4148 [==============================] - 2s 591us/step - loss: 0.6209 - accuracy: 0.9506 - val_loss: 3.4825 - val_accuracy: 0.4412\n",
      "Epoch 45/50\n",
      "4148/4148 [==============================] - 2s 592us/step - loss: 0.5580 - accuracy: 0.9576 - val_loss: 3.7187 - val_accuracy: 0.4287\n",
      "Epoch 46/50\n",
      "4148/4148 [==============================] - 2s 593us/step - loss: 0.5319 - accuracy: 0.9609 - val_loss: 3.4267 - val_accuracy: 0.4615\n",
      "Epoch 47/50\n",
      "4148/4148 [==============================] - 2s 594us/step - loss: 0.5320 - accuracy: 0.9643 - val_loss: 3.4471 - val_accuracy: 0.4528\n",
      "Epoch 48/50\n",
      "4148/4148 [==============================] - 2s 593us/step - loss: 0.5541 - accuracy: 0.9576 - val_loss: 3.6697 - val_accuracy: 0.4489\n",
      "Epoch 49/50\n",
      "4148/4148 [==============================] - 2s 591us/step - loss: 0.5590 - accuracy: 0.9552 - val_loss: 3.8935 - val_accuracy: 0.4268\n",
      "Epoch 50/50\n",
      "4148/4148 [==============================] - 2s 592us/step - loss: 0.6523 - accuracy: 0.9421 - val_loss: 3.4020 - val_accuracy: 0.4306\n",
      "1038/1038 [==============================] - 0s 129us/step\n",
      "1038/1038 [==============================] - 0s 159us/step\n",
      " \n",
      "Train on 4150 samples, validate on 1038 samples\n",
      "Epoch 1/50\n",
      "4150/4150 [==============================] - 3s 730us/step - loss: 2.1165 - accuracy: 0.3212 - val_loss: 1.8249 - val_accuracy: 0.4114\n",
      "Epoch 2/50\n",
      "4150/4150 [==============================] - 2s 588us/step - loss: 1.7841 - accuracy: 0.4455 - val_loss: 2.0431 - val_accuracy: 0.3295\n",
      "Epoch 3/50\n",
      "4150/4150 [==============================] - 2s 588us/step - loss: 1.7161 - accuracy: 0.4920 - val_loss: 1.8169 - val_accuracy: 0.4605\n",
      "Epoch 4/50\n",
      "4150/4150 [==============================] - 2s 588us/step - loss: 1.6308 - accuracy: 0.5511 - val_loss: 1.9385 - val_accuracy: 0.4451\n",
      "Epoch 5/50\n",
      "4150/4150 [==============================] - 2s 590us/step - loss: 1.5082 - accuracy: 0.6111 - val_loss: 1.9879 - val_accuracy: 0.4480\n",
      "Epoch 6/50\n",
      "4150/4150 [==============================] - 2s 591us/step - loss: 1.4097 - accuracy: 0.6622 - val_loss: 1.9557 - val_accuracy: 0.4489\n",
      "Epoch 7/50\n",
      "4150/4150 [==============================] - 2s 590us/step - loss: 1.2713 - accuracy: 0.7164 - val_loss: 2.1469 - val_accuracy: 0.4393\n",
      "Epoch 8/50\n",
      "4150/4150 [==============================] - 2s 590us/step - loss: 1.2148 - accuracy: 0.7540 - val_loss: 2.1622 - val_accuracy: 0.4672\n",
      "Epoch 9/50\n",
      "4150/4150 [==============================] - 2s 591us/step - loss: 1.1229 - accuracy: 0.7945 - val_loss: 2.1754 - val_accuracy: 0.4547\n",
      "Epoch 10/50\n",
      "4150/4150 [==============================] - 2s 590us/step - loss: 1.0593 - accuracy: 0.8311 - val_loss: 2.3303 - val_accuracy: 0.4528\n",
      "Epoch 11/50\n",
      "4150/4150 [==============================] - 2s 590us/step - loss: 1.0606 - accuracy: 0.8429 - val_loss: 2.5778 - val_accuracy: 0.4393\n",
      "Epoch 12/50\n",
      "4150/4150 [==============================] - 2s 592us/step - loss: 0.9758 - accuracy: 0.8629 - val_loss: 2.4504 - val_accuracy: 0.4721\n",
      "Epoch 13/50\n",
      "4150/4150 [==============================] - 2s 592us/step - loss: 0.9092 - accuracy: 0.8846 - val_loss: 2.4735 - val_accuracy: 0.4566\n",
      "Epoch 14/50\n",
      "4150/4150 [==============================] - 2s 591us/step - loss: 0.8594 - accuracy: 0.8995 - val_loss: 2.6763 - val_accuracy: 0.4538\n",
      "Epoch 15/50\n",
      "4150/4150 [==============================] - 2s 588us/step - loss: 0.8453 - accuracy: 0.9002 - val_loss: 2.5847 - val_accuracy: 0.4383\n",
      "Epoch 16/50\n",
      "4150/4150 [==============================] - 2s 587us/step - loss: 0.8113 - accuracy: 0.9099 - val_loss: 2.6647 - val_accuracy: 0.4441\n",
      "Epoch 17/50\n",
      "4150/4150 [==============================] - 2s 588us/step - loss: 0.7895 - accuracy: 0.9118 - val_loss: 2.4668 - val_accuracy: 0.4595\n",
      "Epoch 18/50\n",
      "4150/4150 [==============================] - 2s 588us/step - loss: 0.8244 - accuracy: 0.9108 - val_loss: 2.6906 - val_accuracy: 0.4586\n",
      "Epoch 19/50\n",
      "4150/4150 [==============================] - 2s 590us/step - loss: 0.7863 - accuracy: 0.9099 - val_loss: 2.5618 - val_accuracy: 0.4566\n",
      "Epoch 20/50\n",
      "4150/4150 [==============================] - 2s 589us/step - loss: 0.7203 - accuracy: 0.9323 - val_loss: 2.6028 - val_accuracy: 0.4403\n",
      "Epoch 21/50\n",
      "4150/4150 [==============================] - 2s 588us/step - loss: 0.7072 - accuracy: 0.9328 - val_loss: 3.0479 - val_accuracy: 0.4326\n",
      "Epoch 22/50\n",
      "4150/4150 [==============================] - 2s 595us/step - loss: 0.7236 - accuracy: 0.9275 - val_loss: 2.5080 - val_accuracy: 0.4393\n",
      "Epoch 23/50\n",
      "4150/4150 [==============================] - 2s 593us/step - loss: 0.6968 - accuracy: 0.9282 - val_loss: 2.9021 - val_accuracy: 0.4383\n",
      "Epoch 24/50\n",
      "4150/4150 [==============================] - 3s 614us/step - loss: 0.6695 - accuracy: 0.9320 - val_loss: 2.8063 - val_accuracy: 0.4383\n",
      "Epoch 25/50\n",
      "4150/4150 [==============================] - 2s 591us/step - loss: 0.6656 - accuracy: 0.9354 - val_loss: 2.7754 - val_accuracy: 0.4692\n",
      "Epoch 26/50\n",
      "4150/4150 [==============================] - 2s 589us/step - loss: 0.7046 - accuracy: 0.9248 - val_loss: 2.9659 - val_accuracy: 0.4499\n",
      "Epoch 27/50\n",
      "4150/4150 [==============================] - 2s 588us/step - loss: 0.6753 - accuracy: 0.9335 - val_loss: 2.8489 - val_accuracy: 0.4316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50\n",
      "4150/4150 [==============================] - 2s 586us/step - loss: 0.6548 - accuracy: 0.9386 - val_loss: 2.8569 - val_accuracy: 0.4297\n",
      "Epoch 29/50\n",
      "4150/4150 [==============================] - 2s 584us/step - loss: 0.6409 - accuracy: 0.9429 - val_loss: 3.0548 - val_accuracy: 0.4432\n",
      "Epoch 30/50\n",
      "4150/4150 [==============================] - 2s 587us/step - loss: 0.6682 - accuracy: 0.9311 - val_loss: 2.8856 - val_accuracy: 0.4441\n",
      "Epoch 31/50\n",
      "4150/4150 [==============================] - 2s 588us/step - loss: 0.6635 - accuracy: 0.9419 - val_loss: 2.9641 - val_accuracy: 0.4624\n",
      "Epoch 32/50\n",
      "4150/4150 [==============================] - 2s 593us/step - loss: 0.6245 - accuracy: 0.9463 - val_loss: 2.9145 - val_accuracy: 0.4345\n",
      "Epoch 33/50\n",
      "4150/4150 [==============================] - 2s 589us/step - loss: 0.6250 - accuracy: 0.9407 - val_loss: 3.0259 - val_accuracy: 0.4528\n",
      "Epoch 34/50\n",
      "4150/4150 [==============================] - 2s 587us/step - loss: 0.6013 - accuracy: 0.9429 - val_loss: 3.1808 - val_accuracy: 0.4383\n",
      "Epoch 35/50\n",
      "4150/4150 [==============================] - 2s 587us/step - loss: 0.6017 - accuracy: 0.9434 - val_loss: 3.2153 - val_accuracy: 0.4316\n",
      "Epoch 36/50\n",
      "4150/4150 [==============================] - 2s 585us/step - loss: 0.5742 - accuracy: 0.9528 - val_loss: 2.9733 - val_accuracy: 0.4306\n",
      "Epoch 37/50\n",
      "4150/4150 [==============================] - 2s 589us/step - loss: 0.6367 - accuracy: 0.9294 - val_loss: 3.1936 - val_accuracy: 0.4355\n",
      "Epoch 38/50\n",
      "4150/4150 [==============================] - 2s 588us/step - loss: 0.6337 - accuracy: 0.9414 - val_loss: 2.9360 - val_accuracy: 0.4364\n",
      "Epoch 39/50\n",
      "4150/4150 [==============================] - 2s 590us/step - loss: 0.6189 - accuracy: 0.9434 - val_loss: 3.1586 - val_accuracy: 0.4451\n",
      "Epoch 40/50\n",
      "4150/4150 [==============================] - 2s 588us/step - loss: 0.6178 - accuracy: 0.9386 - val_loss: 3.1930 - val_accuracy: 0.4200\n",
      "Epoch 41/50\n",
      "4150/4150 [==============================] - 2s 586us/step - loss: 0.6265 - accuracy: 0.9417 - val_loss: 3.1463 - val_accuracy: 0.4528\n",
      "Epoch 42/50\n",
      "4150/4150 [==============================] - 2s 588us/step - loss: 0.5931 - accuracy: 0.9467 - val_loss: 3.2091 - val_accuracy: 0.4489\n",
      "Epoch 43/50\n",
      "4150/4150 [==============================] - 2s 586us/step - loss: 0.5927 - accuracy: 0.9441 - val_loss: 3.1872 - val_accuracy: 0.4432\n",
      "Epoch 44/50\n",
      "4150/4150 [==============================] - 2s 588us/step - loss: 0.5872 - accuracy: 0.9467 - val_loss: 3.2829 - val_accuracy: 0.4393\n",
      "Epoch 45/50\n",
      "4150/4150 [==============================] - 2s 589us/step - loss: 0.5981 - accuracy: 0.9513 - val_loss: 3.2373 - val_accuracy: 0.4297\n",
      "Epoch 46/50\n",
      "4150/4150 [==============================] - 2s 591us/step - loss: 0.5814 - accuracy: 0.9494 - val_loss: 3.2234 - val_accuracy: 0.4220\n",
      "Epoch 47/50\n",
      "4150/4150 [==============================] - 2s 588us/step - loss: 0.5546 - accuracy: 0.9489 - val_loss: 3.1733 - val_accuracy: 0.4412\n",
      "Epoch 48/50\n",
      "4150/4150 [==============================] - 2s 587us/step - loss: 0.5611 - accuracy: 0.9453 - val_loss: 3.0377 - val_accuracy: 0.4730\n",
      "Epoch 49/50\n",
      "4150/4150 [==============================] - 2s 585us/step - loss: 0.5607 - accuracy: 0.9499 - val_loss: 3.3214 - val_accuracy: 0.4470\n",
      "Epoch 50/50\n",
      "4150/4150 [==============================] - 2s 588us/step - loss: 0.5455 - accuracy: 0.9552 - val_loss: 3.5407 - val_accuracy: 0.4355\n",
      "1038/1038 [==============================] - 0s 135us/step\n",
      "1038/1038 [==============================] - 0s 163us/step\n",
      " \n",
      "Train on 4147 samples, validate on 1037 samples\n",
      "Epoch 1/50\n",
      "4147/4147 [==============================] - 3s 741us/step - loss: 2.0770 - accuracy: 0.2327 - val_loss: 1.9425 - val_accuracy: 0.2825\n",
      "Epoch 2/50\n",
      "4147/4147 [==============================] - 2s 590us/step - loss: 2.0057 - accuracy: 0.2990 - val_loss: 2.0219 - val_accuracy: 0.2536\n",
      "Epoch 3/50\n",
      "4147/4147 [==============================] - 2s 592us/step - loss: 1.9456 - accuracy: 0.3410 - val_loss: 2.0484 - val_accuracy: 0.2816\n",
      "Epoch 4/50\n",
      "4147/4147 [==============================] - 2s 592us/step - loss: 1.8970 - accuracy: 0.3890 - val_loss: 2.1102 - val_accuracy: 0.2729\n",
      "Epoch 5/50\n",
      "4147/4147 [==============================] - 2s 591us/step - loss: 1.8243 - accuracy: 0.4406 - val_loss: 2.1735 - val_accuracy: 0.3067\n",
      "Epoch 6/50\n",
      "4147/4147 [==============================] - 2s 592us/step - loss: 1.7224 - accuracy: 0.5040 - val_loss: 2.2262 - val_accuracy: 0.3124\n",
      "Epoch 7/50\n",
      "4147/4147 [==============================] - 2s 588us/step - loss: 1.6033 - accuracy: 0.5814 - val_loss: 2.4572 - val_accuracy: 0.3163\n",
      "Epoch 8/50\n",
      "4147/4147 [==============================] - 2s 591us/step - loss: 1.6043 - accuracy: 0.6388 - val_loss: 2.8398 - val_accuracy: 0.2854\n",
      "Epoch 9/50\n",
      "4147/4147 [==============================] - 2s 590us/step - loss: 1.4079 - accuracy: 0.7256 - val_loss: 2.8528 - val_accuracy: 0.2825\n",
      "Epoch 10/50\n",
      "4147/4147 [==============================] - 2s 590us/step - loss: 1.2961 - accuracy: 0.7791 - val_loss: 3.0833 - val_accuracy: 0.3086\n",
      "Epoch 11/50\n",
      "4147/4147 [==============================] - 2s 592us/step - loss: 1.1598 - accuracy: 0.8153 - val_loss: 3.2877 - val_accuracy: 0.2883\n",
      "Epoch 12/50\n",
      "4147/4147 [==============================] - 2s 593us/step - loss: 1.0617 - accuracy: 0.8541 - val_loss: 3.3861 - val_accuracy: 0.2748\n",
      "Epoch 13/50\n",
      "4147/4147 [==============================] - 2s 593us/step - loss: 0.9948 - accuracy: 0.8748 - val_loss: 3.3214 - val_accuracy: 0.2777\n",
      "Epoch 14/50\n",
      "4147/4147 [==============================] - 2s 591us/step - loss: 0.9882 - accuracy: 0.8859 - val_loss: 3.5469 - val_accuracy: 0.2903\n",
      "Epoch 15/50\n",
      "4147/4147 [==============================] - 2s 591us/step - loss: 0.9384 - accuracy: 0.9076 - val_loss: 3.6651 - val_accuracy: 0.2912\n",
      "Epoch 16/50\n",
      "4147/4147 [==============================] - 2s 591us/step - loss: 0.9467 - accuracy: 0.9048 - val_loss: 3.6384 - val_accuracy: 0.3057\n",
      "Epoch 17/50\n",
      "4147/4147 [==============================] - 2s 592us/step - loss: 0.9688 - accuracy: 0.9166 - val_loss: 3.8749 - val_accuracy: 0.2941\n",
      "Epoch 18/50\n",
      "4147/4147 [==============================] - 2s 594us/step - loss: 0.8540 - accuracy: 0.9296 - val_loss: 3.8845 - val_accuracy: 0.2787\n",
      "Epoch 19/50\n",
      "4147/4147 [==============================] - 2s 602us/step - loss: 0.8302 - accuracy: 0.9281 - val_loss: 4.2732 - val_accuracy: 0.2989\n",
      "Epoch 20/50\n",
      "4147/4147 [==============================] - 2s 598us/step - loss: 0.7789 - accuracy: 0.9359 - val_loss: 4.1244 - val_accuracy: 0.3115\n",
      "Epoch 21/50\n",
      "4147/4147 [==============================] - 2s 592us/step - loss: 0.7454 - accuracy: 0.9416 - val_loss: 4.0172 - val_accuracy: 0.2932\n",
      "Epoch 22/50\n",
      "4147/4147 [==============================] - 2s 591us/step - loss: 0.7241 - accuracy: 0.9424 - val_loss: 4.3881 - val_accuracy: 0.2816\n",
      "Epoch 23/50\n",
      "4147/4147 [==============================] - 2s 593us/step - loss: 0.7377 - accuracy: 0.9380 - val_loss: 4.1826 - val_accuracy: 0.2903\n",
      "Epoch 24/50\n",
      "4147/4147 [==============================] - 2s 595us/step - loss: 0.7224 - accuracy: 0.9424 - val_loss: 4.4478 - val_accuracy: 0.2960\n",
      "Epoch 25/50\n",
      "4147/4147 [==============================] - 2s 594us/step - loss: 0.7875 - accuracy: 0.9361 - val_loss: 4.5515 - val_accuracy: 0.2816\n",
      "Epoch 26/50\n",
      "4147/4147 [==============================] - 2s 593us/step - loss: 0.7773 - accuracy: 0.9349 - val_loss: 4.5093 - val_accuracy: 0.2883\n",
      "Epoch 27/50\n",
      "4147/4147 [==============================] - 2s 593us/step - loss: 0.7866 - accuracy: 0.9209 - val_loss: 3.9521 - val_accuracy: 0.2864\n",
      "Epoch 28/50\n",
      "4147/4147 [==============================] - 2s 591us/step - loss: 0.7878 - accuracy: 0.9277 - val_loss: 4.6373 - val_accuracy: 0.2854\n",
      "Epoch 29/50\n",
      "4147/4147 [==============================] - 2s 592us/step - loss: 0.7587 - accuracy: 0.9344 - val_loss: 4.3566 - val_accuracy: 0.2864\n",
      "Epoch 30/50\n",
      "4147/4147 [==============================] - 2s 594us/step - loss: 0.7351 - accuracy: 0.9457 - val_loss: 4.7677 - val_accuracy: 0.2719\n",
      "Epoch 31/50\n",
      "4147/4147 [==============================] - 2s 595us/step - loss: 0.7100 - accuracy: 0.9472 - val_loss: 4.5346 - val_accuracy: 0.2825\n",
      "Epoch 32/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4147/4147 [==============================] - 2s 594us/step - loss: 0.7119 - accuracy: 0.9445 - val_loss: 4.3206 - val_accuracy: 0.2777\n",
      "Epoch 33/50\n",
      "4147/4147 [==============================] - 2s 593us/step - loss: 0.6893 - accuracy: 0.9474 - val_loss: 4.9900 - val_accuracy: 0.2806\n",
      "Epoch 34/50\n",
      "4147/4147 [==============================] - 2s 591us/step - loss: 0.6613 - accuracy: 0.9501 - val_loss: 4.7674 - val_accuracy: 0.2768\n",
      "Epoch 35/50\n",
      "4147/4147 [==============================] - 2s 592us/step - loss: 0.6800 - accuracy: 0.9469 - val_loss: 4.3282 - val_accuracy: 0.2864\n",
      "Epoch 36/50\n",
      "4147/4147 [==============================] - 2s 591us/step - loss: 0.6723 - accuracy: 0.9438 - val_loss: 4.5750 - val_accuracy: 0.2777\n",
      "Epoch 37/50\n",
      "4147/4147 [==============================] - 2s 592us/step - loss: 0.7099 - accuracy: 0.9416 - val_loss: 4.4904 - val_accuracy: 0.2681\n",
      "Epoch 38/50\n",
      "4147/4147 [==============================] - 2s 593us/step - loss: 0.6857 - accuracy: 0.9445 - val_loss: 5.1808 - val_accuracy: 0.2700\n",
      "Epoch 39/50\n",
      "4147/4147 [==============================] - 2s 591us/step - loss: 0.6480 - accuracy: 0.9482 - val_loss: 4.8638 - val_accuracy: 0.2642\n",
      "Epoch 40/50\n",
      "4147/4147 [==============================] - 2s 590us/step - loss: 0.6577 - accuracy: 0.9462 - val_loss: 4.9549 - val_accuracy: 0.2748\n",
      "Epoch 41/50\n",
      "4147/4147 [==============================] - 2s 591us/step - loss: 0.6941 - accuracy: 0.9457 - val_loss: 4.3226 - val_accuracy: 0.2719\n",
      "Epoch 42/50\n",
      "4147/4147 [==============================] - 2s 592us/step - loss: 0.6581 - accuracy: 0.9547 - val_loss: 4.9801 - val_accuracy: 0.2555\n",
      "Epoch 43/50\n",
      "4147/4147 [==============================] - 2s 593us/step - loss: 0.6780 - accuracy: 0.9525 - val_loss: 5.1514 - val_accuracy: 0.2748\n",
      "Epoch 44/50\n",
      "4147/4147 [==============================] - 2s 594us/step - loss: 0.6533 - accuracy: 0.9513 - val_loss: 4.8109 - val_accuracy: 0.2777\n",
      "Epoch 45/50\n",
      "4147/4147 [==============================] - 2s 594us/step - loss: 0.6386 - accuracy: 0.9491 - val_loss: 5.0218 - val_accuracy: 0.2797\n",
      "Epoch 46/50\n",
      "4147/4147 [==============================] - 2s 593us/step - loss: 0.6517 - accuracy: 0.9506 - val_loss: 4.5736 - val_accuracy: 0.2845\n",
      "Epoch 47/50\n",
      "4147/4147 [==============================] - 2s 593us/step - loss: 0.6507 - accuracy: 0.9530 - val_loss: 5.0351 - val_accuracy: 0.2806\n",
      "Epoch 48/50\n",
      "4147/4147 [==============================] - 2s 592us/step - loss: 0.6261 - accuracy: 0.9530 - val_loss: 5.5340 - val_accuracy: 0.2980\n",
      "Epoch 49/50\n",
      "4147/4147 [==============================] - 2s 593us/step - loss: 0.6492 - accuracy: 0.9460 - val_loss: 5.2468 - val_accuracy: 0.2681\n",
      "Epoch 50/50\n",
      "4147/4147 [==============================] - 2s 594us/step - loss: 0.6658 - accuracy: 0.9414 - val_loss: 5.4458 - val_accuracy: 0.2594\n",
      "1037/1037 [==============================] - 0s 129us/step\n",
      "1037/1037 [==============================] - 0s 155us/step\n",
      " \n",
      "Train on 4148 samples, validate on 1037 samples\n",
      "Epoch 1/50\n",
      "4148/4148 [==============================] - 3s 727us/step - loss: 2.0398 - accuracy: 0.2695 - val_loss: 1.9382 - val_accuracy: 0.3684\n",
      "Epoch 2/50\n",
      "4148/4148 [==============================] - 2s 590us/step - loss: 1.9338 - accuracy: 0.3652 - val_loss: 1.9515 - val_accuracy: 0.3857\n",
      "Epoch 3/50\n",
      "4148/4148 [==============================] - 2s 592us/step - loss: 1.8429 - accuracy: 0.4327 - val_loss: 1.9426 - val_accuracy: 0.4021\n",
      "Epoch 4/50\n",
      "4148/4148 [==============================] - 2s 593us/step - loss: 1.7730 - accuracy: 0.4949 - val_loss: 1.9277 - val_accuracy: 0.4619\n",
      "Epoch 5/50\n",
      "4148/4148 [==============================] - 2s 594us/step - loss: 1.6397 - accuracy: 0.5400 - val_loss: 2.0299 - val_accuracy: 0.4388\n",
      "Epoch 6/50\n",
      "4148/4148 [==============================] - 2s 589us/step - loss: 1.5105 - accuracy: 0.6251 - val_loss: 2.2443 - val_accuracy: 0.4291\n",
      "Epoch 7/50\n",
      "4148/4148 [==============================] - 2s 591us/step - loss: 1.3865 - accuracy: 0.6914 - val_loss: 2.3232 - val_accuracy: 0.4523\n",
      "Epoch 8/50\n",
      "4148/4148 [==============================] - 2s 590us/step - loss: 1.2612 - accuracy: 0.7575 - val_loss: 2.2195 - val_accuracy: 0.4301\n",
      "Epoch 9/50\n",
      "4148/4148 [==============================] - 2s 592us/step - loss: 1.1729 - accuracy: 0.7958 - val_loss: 2.3961 - val_accuracy: 0.4561\n",
      "Epoch 10/50\n",
      "4148/4148 [==============================] - 2s 593us/step - loss: 1.0570 - accuracy: 0.8474 - val_loss: 2.6483 - val_accuracy: 0.4320\n",
      "Epoch 11/50\n",
      "4148/4148 [==============================] - 2s 593us/step - loss: 1.0098 - accuracy: 0.8597 - val_loss: 2.7131 - val_accuracy: 0.4426\n",
      "Epoch 12/50\n",
      "4148/4148 [==============================] - 2s 591us/step - loss: 0.9743 - accuracy: 0.8828 - val_loss: 2.7472 - val_accuracy: 0.4272\n",
      "Epoch 13/50\n",
      "4148/4148 [==============================] - 2s 590us/step - loss: 0.9042 - accuracy: 0.9014 - val_loss: 2.9794 - val_accuracy: 0.4301\n",
      "Epoch 14/50\n",
      "4148/4148 [==============================] - 2s 590us/step - loss: 0.8723 - accuracy: 0.9000 - val_loss: 3.0145 - val_accuracy: 0.4339\n",
      "Epoch 15/50\n",
      "4148/4148 [==============================] - 2s 591us/step - loss: 0.8328 - accuracy: 0.9156 - val_loss: 2.9827 - val_accuracy: 0.4330\n",
      "Epoch 16/50\n",
      "4148/4148 [==============================] - 3s 604us/step - loss: 0.8630 - accuracy: 0.9096 - val_loss: 3.4622 - val_accuracy: 0.4195\n",
      "Epoch 17/50\n",
      "4148/4148 [==============================] - 2s 592us/step - loss: 0.8757 - accuracy: 0.9098 - val_loss: 3.1512 - val_accuracy: 0.4320\n",
      "Epoch 18/50\n",
      "4148/4148 [==============================] - 2s 589us/step - loss: 0.7826 - accuracy: 0.9243 - val_loss: 3.2345 - val_accuracy: 0.4243\n",
      "Epoch 19/50\n",
      "4148/4148 [==============================] - 2s 589us/step - loss: 0.7648 - accuracy: 0.9330 - val_loss: 3.3594 - val_accuracy: 0.4349\n",
      "Epoch 20/50\n",
      "4148/4148 [==============================] - 2s 590us/step - loss: 0.7299 - accuracy: 0.9366 - val_loss: 3.3453 - val_accuracy: 0.4147\n",
      "Epoch 21/50\n",
      "4148/4148 [==============================] - 2s 589us/step - loss: 0.7067 - accuracy: 0.9354 - val_loss: 3.3854 - val_accuracy: 0.4320\n",
      "Epoch 22/50\n",
      "4148/4148 [==============================] - 2s 590us/step - loss: 0.6909 - accuracy: 0.9397 - val_loss: 3.4780 - val_accuracy: 0.4330\n",
      "Epoch 23/50\n",
      "4148/4148 [==============================] - 2s 591us/step - loss: 0.7259 - accuracy: 0.9267 - val_loss: 3.5020 - val_accuracy: 0.4262\n",
      "Epoch 24/50\n",
      "4148/4148 [==============================] - 2s 590us/step - loss: 0.7428 - accuracy: 0.9303 - val_loss: 3.4793 - val_accuracy: 0.4243\n",
      "Epoch 25/50\n",
      "4148/4148 [==============================] - 2s 590us/step - loss: 0.7067 - accuracy: 0.9347 - val_loss: 3.4015 - val_accuracy: 0.4291\n",
      "Epoch 26/50\n",
      "4148/4148 [==============================] - 2s 589us/step - loss: 0.6925 - accuracy: 0.9337 - val_loss: 3.6896 - val_accuracy: 0.4002\n",
      "Epoch 27/50\n",
      "4148/4148 [==============================] - 2s 597us/step - loss: 0.7113 - accuracy: 0.9354 - val_loss: 3.6081 - val_accuracy: 0.4224\n",
      "Epoch 28/50\n",
      "4148/4148 [==============================] - 2s 592us/step - loss: 0.7229 - accuracy: 0.9364 - val_loss: 3.5489 - val_accuracy: 0.4166\n",
      "Epoch 29/50\n",
      "4148/4148 [==============================] - 2s 592us/step - loss: 0.7244 - accuracy: 0.9383 - val_loss: 3.8465 - val_accuracy: 0.4147\n",
      "Epoch 30/50\n",
      "4148/4148 [==============================] - 2s 590us/step - loss: 0.6632 - accuracy: 0.9552 - val_loss: 3.6191 - val_accuracy: 0.3992\n",
      "Epoch 31/50\n",
      "4148/4148 [==============================] - 2s 590us/step - loss: 0.6591 - accuracy: 0.9431 - val_loss: 3.8223 - val_accuracy: 0.4089\n",
      "Epoch 32/50\n",
      "4148/4148 [==============================] - 2s 589us/step - loss: 0.7664 - accuracy: 0.9376 - val_loss: 4.2801 - val_accuracy: 0.4079\n",
      "Epoch 33/50\n",
      "4148/4148 [==============================] - 2s 589us/step - loss: 0.6623 - accuracy: 0.9482 - val_loss: 4.1816 - val_accuracy: 0.4079\n",
      "Epoch 34/50\n",
      "4148/4148 [==============================] - 2s 592us/step - loss: 0.6454 - accuracy: 0.9477 - val_loss: 4.2010 - val_accuracy: 0.4079\n",
      "Epoch 35/50\n",
      "4148/4148 [==============================] - 2s 591us/step - loss: 0.6625 - accuracy: 0.9405 - val_loss: 3.8746 - val_accuracy: 0.4108\n",
      "Epoch 36/50\n",
      "4148/4148 [==============================] - 2s 592us/step - loss: 0.6404 - accuracy: 0.9499 - val_loss: 4.2725 - val_accuracy: 0.4118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50\n",
      "4148/4148 [==============================] - 2s 591us/step - loss: 0.6727 - accuracy: 0.9455 - val_loss: 4.5109 - val_accuracy: 0.4127\n",
      "Epoch 38/50\n",
      "4148/4148 [==============================] - 2s 588us/step - loss: 0.6547 - accuracy: 0.9433 - val_loss: 4.1827 - val_accuracy: 0.4069\n",
      "Epoch 39/50\n",
      "4148/4148 [==============================] - 2s 587us/step - loss: 0.6439 - accuracy: 0.9460 - val_loss: 4.1312 - val_accuracy: 0.4224\n",
      "Epoch 40/50\n",
      "4148/4148 [==============================] - 2s 587us/step - loss: 0.6177 - accuracy: 0.9508 - val_loss: 4.1350 - val_accuracy: 0.4089\n",
      "Epoch 41/50\n",
      "4148/4148 [==============================] - 2s 588us/step - loss: 0.5958 - accuracy: 0.9523 - val_loss: 4.1863 - val_accuracy: 0.4021\n",
      "Epoch 42/50\n",
      "4148/4148 [==============================] - 2s 590us/step - loss: 0.6089 - accuracy: 0.9525 - val_loss: 4.2099 - val_accuracy: 0.3992\n",
      "Epoch 43/50\n",
      "4148/4148 [==============================] - 2s 589us/step - loss: 0.5879 - accuracy: 0.9549 - val_loss: 3.9988 - val_accuracy: 0.3867\n",
      "Epoch 44/50\n",
      "4148/4148 [==============================] - 2s 589us/step - loss: 0.5849 - accuracy: 0.9532 - val_loss: 4.2854 - val_accuracy: 0.4031\n",
      "Epoch 45/50\n",
      "4148/4148 [==============================] - 2s 587us/step - loss: 0.5804 - accuracy: 0.9542 - val_loss: 4.2293 - val_accuracy: 0.3896\n",
      "Epoch 46/50\n",
      "4148/4148 [==============================] - 2s 588us/step - loss: 0.5773 - accuracy: 0.9527 - val_loss: 4.3064 - val_accuracy: 0.4147\n",
      "Epoch 47/50\n",
      "4148/4148 [==============================] - 2s 588us/step - loss: 0.5731 - accuracy: 0.9489 - val_loss: 4.1036 - val_accuracy: 0.3905\n",
      "Epoch 48/50\n",
      "4148/4148 [==============================] - 2s 589us/step - loss: 0.6044 - accuracy: 0.9484 - val_loss: 4.3849 - val_accuracy: 0.3983\n",
      "Epoch 49/50\n",
      "4148/4148 [==============================] - 2s 588us/step - loss: 0.6031 - accuracy: 0.9441 - val_loss: 4.0044 - val_accuracy: 0.4031\n",
      "Epoch 50/50\n",
      "4148/4148 [==============================] - 2s 592us/step - loss: 0.6042 - accuracy: 0.9520 - val_loss: 4.3588 - val_accuracy: 0.3857\n",
      "1037/1037 [==============================] - 0s 134us/step\n",
      "1037/1037 [==============================] - 0s 167us/step\n",
      " \n",
      "Train on 4147 samples, validate on 1037 samples\n",
      "Epoch 1/50\n",
      "4147/4147 [==============================] - 3s 784us/step - loss: 2.1164 - accuracy: 0.2845 - val_loss: 1.9824 - val_accuracy: 0.3751\n",
      "Epoch 2/50\n",
      "4147/4147 [==============================] - 3s 666us/step - loss: 1.8900 - accuracy: 0.4343 - val_loss: 1.9400 - val_accuracy: 0.3867\n",
      "Epoch 3/50\n",
      "4147/4147 [==============================] - 3s 695us/step - loss: 1.7696 - accuracy: 0.5018 - val_loss: 2.0519 - val_accuracy: 0.4060\n",
      "Epoch 4/50\n",
      "4147/4147 [==============================] - 3s 718us/step - loss: 1.6666 - accuracy: 0.5628 - val_loss: 1.8121 - val_accuracy: 0.4696\n",
      "Epoch 5/50\n",
      "4147/4147 [==============================] - 3s 715us/step - loss: 1.5064 - accuracy: 0.6151 - val_loss: 1.8657 - val_accuracy: 0.4735\n",
      "Epoch 6/50\n",
      "4147/4147 [==============================] - 3s 675us/step - loss: 1.3889 - accuracy: 0.6694 - val_loss: 2.0108 - val_accuracy: 0.4494\n",
      "Epoch 7/50\n",
      "4147/4147 [==============================] - 3s 633us/step - loss: 1.3091 - accuracy: 0.7150 - val_loss: 2.3563 - val_accuracy: 0.3877\n",
      "Epoch 8/50\n",
      "4147/4147 [==============================] - 3s 647us/step - loss: 1.1566 - accuracy: 0.7830 - val_loss: 2.0410 - val_accuracy: 0.4879\n",
      "Epoch 9/50\n",
      "4147/4147 [==============================] - 3s 651us/step - loss: 1.0893 - accuracy: 0.8129 - val_loss: 2.3439 - val_accuracy: 0.4552\n",
      "Epoch 10/50\n",
      "4147/4147 [==============================] - 3s 615us/step - loss: 1.0382 - accuracy: 0.8317 - val_loss: 2.3682 - val_accuracy: 0.4590\n",
      "Epoch 11/50\n",
      "4147/4147 [==============================] - 2s 590us/step - loss: 0.9999 - accuracy: 0.8570 - val_loss: 2.3225 - val_accuracy: 0.4561\n",
      "Epoch 12/50\n",
      "4147/4147 [==============================] - 2s 593us/step - loss: 0.9194 - accuracy: 0.8799 - val_loss: 2.5219 - val_accuracy: 0.4552\n",
      "Epoch 13/50\n",
      "4147/4147 [==============================] - 3s 620us/step - loss: 0.8958 - accuracy: 0.8826 - val_loss: 2.4992 - val_accuracy: 0.4571\n",
      "Epoch 14/50\n",
      "4147/4147 [==============================] - 2s 596us/step - loss: 0.8292 - accuracy: 0.9002 - val_loss: 2.6206 - val_accuracy: 0.4687\n",
      "Epoch 15/50\n",
      "4147/4147 [==============================] - 3s 649us/step - loss: 0.7975 - accuracy: 0.9088 - val_loss: 2.6665 - val_accuracy: 0.4407\n",
      "Epoch 16/50\n",
      "4147/4147 [==============================] - 3s 614us/step - loss: 0.7829 - accuracy: 0.9149 - val_loss: 2.8945 - val_accuracy: 0.4638\n",
      "Epoch 17/50\n",
      "4147/4147 [==============================] - 3s 658us/step - loss: 0.8181 - accuracy: 0.9183 - val_loss: 2.6589 - val_accuracy: 0.4735\n",
      "Epoch 18/50\n",
      "4147/4147 [==============================] - 3s 656us/step - loss: 0.7880 - accuracy: 0.9134 - val_loss: 2.7301 - val_accuracy: 0.4783\n",
      "Epoch 19/50\n",
      "4147/4147 [==============================] - 3s 657us/step - loss: 0.7700 - accuracy: 0.9233 - val_loss: 2.9276 - val_accuracy: 0.4311\n",
      "Epoch 20/50\n",
      "4147/4147 [==============================] - 3s 640us/step - loss: 0.8465 - accuracy: 0.9086 - val_loss: 2.9384 - val_accuracy: 0.4667\n",
      "Epoch 21/50\n",
      "4147/4147 [==============================] - 3s 619us/step - loss: 0.7696 - accuracy: 0.9255 - val_loss: 2.9655 - val_accuracy: 0.4658\n",
      "Epoch 22/50\n",
      "4147/4147 [==============================] - 3s 646us/step - loss: 0.7349 - accuracy: 0.9320 - val_loss: 2.8738 - val_accuracy: 0.4561\n",
      "Epoch 23/50\n",
      "4147/4147 [==============================] - 3s 617us/step - loss: 0.7480 - accuracy: 0.9279 - val_loss: 2.9350 - val_accuracy: 0.4658\n",
      "Epoch 24/50\n",
      "4147/4147 [==============================] - 3s 617us/step - loss: 0.7422 - accuracy: 0.9291 - val_loss: 2.6661 - val_accuracy: 0.4571\n",
      "Epoch 25/50\n",
      "4147/4147 [==============================] - 3s 662us/step - loss: 0.6856 - accuracy: 0.9378 - val_loss: 3.0929 - val_accuracy: 0.4253\n",
      "Epoch 26/50\n",
      "4147/4147 [==============================] - 3s 608us/step - loss: 0.6735 - accuracy: 0.9407 - val_loss: 2.9142 - val_accuracy: 0.4503\n",
      "Epoch 27/50\n",
      "4147/4147 [==============================] - 3s 603us/step - loss: 0.6855 - accuracy: 0.9339 - val_loss: 2.9602 - val_accuracy: 0.4532\n",
      "Epoch 28/50\n",
      "4147/4147 [==============================] - 2s 601us/step - loss: 0.6732 - accuracy: 0.9354 - val_loss: 3.0344 - val_accuracy: 0.4600\n",
      "Epoch 29/50\n",
      "4147/4147 [==============================] - 2s 601us/step - loss: 0.6673 - accuracy: 0.9368 - val_loss: 3.0902 - val_accuracy: 0.4561\n",
      "Epoch 30/50\n",
      "4147/4147 [==============================] - 2s 600us/step - loss: 0.7607 - accuracy: 0.9248 - val_loss: 3.9836 - val_accuracy: 0.3915\n",
      "Epoch 31/50\n",
      "4147/4147 [==============================] - 2s 601us/step - loss: 0.7128 - accuracy: 0.9286 - val_loss: 3.0564 - val_accuracy: 0.4455\n",
      "Epoch 32/50\n",
      "4147/4147 [==============================] - 2s 600us/step - loss: 0.6886 - accuracy: 0.9330 - val_loss: 2.9200 - val_accuracy: 0.4388\n",
      "Epoch 33/50\n",
      "4147/4147 [==============================] - 3s 611us/step - loss: 0.6766 - accuracy: 0.9421 - val_loss: 2.9416 - val_accuracy: 0.4629\n",
      "Epoch 34/50\n",
      "4147/4147 [==============================] - 3s 612us/step - loss: 0.6062 - accuracy: 0.9544 - val_loss: 2.9991 - val_accuracy: 0.4590\n",
      "Epoch 35/50\n",
      "4147/4147 [==============================] - 3s 610us/step - loss: 0.6002 - accuracy: 0.9535 - val_loss: 3.1195 - val_accuracy: 0.4658\n",
      "Epoch 36/50\n",
      "4147/4147 [==============================] - 3s 624us/step - loss: 0.6156 - accuracy: 0.9438 - val_loss: 3.0759 - val_accuracy: 0.4455\n",
      "Epoch 37/50\n",
      "4147/4147 [==============================] - 3s 633us/step - loss: 0.6004 - accuracy: 0.9501 - val_loss: 3.2242 - val_accuracy: 0.4532\n",
      "Epoch 38/50\n",
      "4147/4147 [==============================] - 3s 604us/step - loss: 0.6264 - accuracy: 0.9424 - val_loss: 3.2154 - val_accuracy: 0.4523\n",
      "Epoch 39/50\n",
      "4147/4147 [==============================] - 3s 605us/step - loss: 0.6105 - accuracy: 0.9520 - val_loss: 3.2180 - val_accuracy: 0.4532\n",
      "Epoch 40/50\n",
      "4147/4147 [==============================] - 2s 601us/step - loss: 0.6770 - accuracy: 0.9351 - val_loss: 3.3414 - val_accuracy: 0.4282\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4147/4147 [==============================] - 3s 605us/step - loss: 0.7505 - accuracy: 0.9183 - val_loss: 3.1746 - val_accuracy: 0.4552\n",
      "Epoch 42/50\n",
      "4147/4147 [==============================] - 3s 607us/step - loss: 0.6694 - accuracy: 0.9392 - val_loss: 3.2631 - val_accuracy: 0.4494\n",
      "Epoch 43/50\n",
      "4147/4147 [==============================] - 3s 608us/step - loss: 0.6351 - accuracy: 0.9486 - val_loss: 3.2850 - val_accuracy: 0.4542\n",
      "Epoch 44/50\n",
      "4147/4147 [==============================] - 2s 592us/step - loss: 0.6216 - accuracy: 0.9501 - val_loss: 3.5259 - val_accuracy: 0.4484\n",
      "Epoch 45/50\n",
      "4147/4147 [==============================] - 2s 593us/step - loss: 0.6174 - accuracy: 0.9445 - val_loss: 3.2900 - val_accuracy: 0.4725\n",
      "Epoch 46/50\n",
      "4147/4147 [==============================] - 2s 594us/step - loss: 0.6007 - accuracy: 0.9496 - val_loss: 3.4751 - val_accuracy: 0.4301\n",
      "Epoch 47/50\n",
      "4147/4147 [==============================] - 2s 592us/step - loss: 0.6406 - accuracy: 0.9388 - val_loss: 3.5320 - val_accuracy: 0.4359\n",
      "Epoch 48/50\n",
      "4147/4147 [==============================] - 2s 590us/step - loss: 0.6212 - accuracy: 0.9445 - val_loss: 3.1863 - val_accuracy: 0.4330\n",
      "Epoch 49/50\n",
      "4147/4147 [==============================] - 2s 591us/step - loss: 0.5935 - accuracy: 0.9498 - val_loss: 3.5548 - val_accuracy: 0.4397\n",
      "Epoch 50/50\n",
      "4147/4147 [==============================] - 2s 594us/step - loss: 0.5686 - accuracy: 0.9554 - val_loss: 3.5515 - val_accuracy: 0.4532\n",
      "1037/1037 [==============================] - 0s 131us/step\n",
      "1037/1037 [==============================] - 0s 158us/step\n",
      " \n",
      "Accuracy: 38.82\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 468x468 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_cv1 = np.zeros((6,6))         # simple cnn\n",
    "cm_cv2 = np.zeros((6,6))         # pca and simple cnn\n",
    "cm_cv3 = np.zeros((6,6))         # pca, deep cnn\n",
    "cm_cv4 = np.zeros((2,2))         # binary, pca, dfnn\n",
    "cm_cv5 = np.zeros((2,2))         # binary, simple cnn\n",
    "cm_cv6 = np.zeros((12,12))       # hf, exemplar, simple cnn\n",
    "cm_cv7 = np.zeros((72,72))       # deep cnn\n",
    "    \n",
    "files = [\"data/S1.mat\", \"data/S2.mat\",\"data/S3.mat\",\"data/S4.mat\",\"data/S5.mat\",\"data/S6.mat\", \n",
    "         \"data/S7.mat\",\"data/S8.mat\",\"data/S9.mat\",\"data/S10.mat\"]\n",
    "N = 32\n",
    "electrodes = 124\n",
    "keep_accuracy = np.zeros((10))\n",
    "j = 0\n",
    "\n",
    "for participant in files:\n",
    "    mat = loadmat(participant)\n",
    "    X_2D = np.array(mat[\"X_2D\"])\n",
    "\n",
    "    X = X_2D\n",
    "    y = np.array(mat[\"categoryLabels\"]).ravel()         # get labels\n",
    "\n",
    "    X_training = X[:int(0.8*len(X))]                    # create train and test sets\n",
    "    X_validation = X[int(0.8*len(X)):]\n",
    "\n",
    "    y_training = y[:int(0.8*len(X))]\n",
    "    y_validation = y[int(0.8*len(X)):]\n",
    "\n",
    "    num_classes = 6\n",
    "    y_training1hot = keras.utils.to_categorical(y_training - 1, num_classes)      # subtract 1 to convert to 0-index\n",
    "    y_validation1hot = keras.utils.to_categorical(y_validation - 1, num_classes)\n",
    "\n",
    "    # reshape to treat the data like images (124x32)\n",
    "    X_training = np.reshape(X_training, (-1, electrodes, N, 1))     \n",
    "    X_validation = np.reshape(X_validation, (-1, electrodes, N, 1))\n",
    "    \n",
    "    # cnn model\n",
    "    model = Sequential()                                                 \n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=X_training.shape[1:], activation = \"relu\"))\n",
    "    model.add(Flatten())  \n",
    "    model.add(Dense(128,kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "                    bias_regularizer=regularizers.l2(1e-7),\n",
    "                    activity_regularizer=regularizers.l2(1e-7),\n",
    "                    activation = \"relu\"))\n",
    "    model.add(Dropout(0.15))\n",
    "    model.add(Dense(num_classes,activity_regularizer=regularizers.l2(1e-6), activation = \"softmax\"))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='nadam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_training, y_training1hot,                                 # train the model\n",
    "              epochs=50, \n",
    "              validation_data=(X_validation, y_validation1hot), \n",
    "              shuffle=True)\n",
    "\n",
    "    y_validation_predictions = model.predict(X_validation, verbose=1)     # make predictions\n",
    "\n",
    "    # create the comfusion matrix\n",
    "    cnf_matrix1 = confusion_matrix(y_validation-1, np.argmax(y_validation_predictions, axis=1))\n",
    "    cm_cv1 += cnf_matrix1                                                 # add together all the confusion matrices\n",
    "    \n",
    "    _, accuracy = model.evaluate(X_validation, y_validation1hot)          # find accuracy\n",
    "    keep_accuracy[j] = accuracy\n",
    "    j = j + 1\n",
    "    print(\" \")\n",
    "    \n",
    "print('Accuracy: %.2f' % (np.mean(keep_accuracy)*100))                    # print mean accuracy\n",
    "\n",
    "sum_by_row = np.sum(cm_cv1, 1)                                            # normalize the final confusion matrix\n",
    "for i in range(0,6):\n",
    "    cm_cv1[i,:] = cm_cv1[i,:] / sum_by_row[i]\n",
    "\n",
    "plot_cm(np.round(cm_cv1, 4),6)                                            # plot the final confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.30178881, 0.10271206, 0.12117715, 0.17657242, 0.13848817,\n",
       "        0.1592614 ],\n",
       "       [0.09698026, 0.55400697, 0.08246225, 0.11033682, 0.08072009,\n",
       "        0.07549361],\n",
       "       [0.12709417, 0.073368  , 0.40439053, 0.14904679, 0.12593876,\n",
       "        0.12016176],\n",
       "       [0.1391455 , 0.11489607, 0.14491917, 0.40819861, 0.1073903 ,\n",
       "        0.08545035],\n",
       "       [0.12413395, 0.06466513, 0.147806  , 0.13337182, 0.31581986,\n",
       "        0.21420323],\n",
       "       [0.12753623, 0.0684058 , 0.14202899, 0.08      , 0.23594203,\n",
       "        0.34608696]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_cv1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA with Simple CNN\n",
    "\n",
    "Εφαρμόζουμε το ίδιο cnn με πριν για  τις 6 κλάσεις, ωστόσο τώρα κάνουμε και PCA με svd πριν, χρησιμοποιώντας k=180, καθώς από τη συνάρτηση lda που έχουμε φτιάξει, το βέλτιστο k έβγαινε πολλές φορές γύρω στο 180."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4150 samples, validate on 1038 samples\n",
      "Epoch 1/50\n",
      "4150/4150 [==============================] - 1s 279us/step - loss: 1.8714 - accuracy: 0.2171 - val_loss: 1.8291 - val_accuracy: 0.2505\n",
      "Epoch 2/50\n",
      "4150/4150 [==============================] - 1s 150us/step - loss: 1.7763 - accuracy: 0.3094 - val_loss: 1.7772 - val_accuracy: 0.2996\n",
      "Epoch 3/50\n",
      "4150/4150 [==============================] - 1s 147us/step - loss: 1.6828 - accuracy: 0.3814 - val_loss: 1.7365 - val_accuracy: 0.3295\n",
      "Epoch 4/50\n",
      "4150/4150 [==============================] - 1s 145us/step - loss: 1.5817 - accuracy: 0.4492 - val_loss: 1.7442 - val_accuracy: 0.3536\n",
      "Epoch 5/50\n",
      "4150/4150 [==============================] - 1s 146us/step - loss: 1.4829 - accuracy: 0.5005 - val_loss: 1.7652 - val_accuracy: 0.3719\n",
      "Epoch 6/50\n",
      "4150/4150 [==============================] - 1s 145us/step - loss: 1.3855 - accuracy: 0.5537 - val_loss: 1.8592 - val_accuracy: 0.3555\n",
      "Epoch 7/50\n",
      "4150/4150 [==============================] - 1s 146us/step - loss: 1.2805 - accuracy: 0.6034 - val_loss: 1.8270 - val_accuracy: 0.3536\n",
      "Epoch 8/50\n",
      "4150/4150 [==============================] - 1s 144us/step - loss: 1.1728 - accuracy: 0.6566 - val_loss: 1.9140 - val_accuracy: 0.3468\n",
      "Epoch 9/50\n",
      "4150/4150 [==============================] - 1s 146us/step - loss: 1.0719 - accuracy: 0.7089 - val_loss: 1.9354 - val_accuracy: 0.3565\n",
      "Epoch 10/50\n",
      "4150/4150 [==============================] - 1s 146us/step - loss: 0.9975 - accuracy: 0.7463 - val_loss: 2.0839 - val_accuracy: 0.3410\n",
      "Epoch 11/50\n",
      "4150/4150 [==============================] - 1s 147us/step - loss: 0.9377 - accuracy: 0.7829 - val_loss: 2.1883 - val_accuracy: 0.3420\n",
      "Epoch 12/50\n",
      "4150/4150 [==============================] - 1s 146us/step - loss: 0.8543 - accuracy: 0.8176 - val_loss: 2.2171 - val_accuracy: 0.3401\n",
      "Epoch 13/50\n",
      "4150/4150 [==============================] - 1s 145us/step - loss: 0.8113 - accuracy: 0.8410 - val_loss: 2.2942 - val_accuracy: 0.3324\n",
      "Epoch 14/50\n",
      "4150/4150 [==============================] - 1s 145us/step - loss: 0.7670 - accuracy: 0.8622 - val_loss: 2.3595 - val_accuracy: 0.3247\n",
      "Epoch 15/50\n",
      "4150/4150 [==============================] - 1s 143us/step - loss: 0.7621 - accuracy: 0.8588 - val_loss: 2.3169 - val_accuracy: 0.3410\n",
      "Epoch 16/50\n",
      "4150/4150 [==============================] - 1s 144us/step - loss: 0.7088 - accuracy: 0.8728 - val_loss: 2.3383 - val_accuracy: 0.3237\n",
      "Epoch 17/50\n",
      "4150/4150 [==============================] - 1s 142us/step - loss: 0.7024 - accuracy: 0.8819 - val_loss: 2.3902 - val_accuracy: 0.3391\n",
      "Epoch 18/50\n",
      "4150/4150 [==============================] - 1s 143us/step - loss: 0.6436 - accuracy: 0.9010 - val_loss: 2.5574 - val_accuracy: 0.3266\n",
      "Epoch 19/50\n",
      "4150/4150 [==============================] - 1s 143us/step - loss: 0.6553 - accuracy: 0.8957 - val_loss: 2.5064 - val_accuracy: 0.3227\n",
      "Epoch 20/50\n",
      "4150/4150 [==============================] - 1s 143us/step - loss: 0.6293 - accuracy: 0.9027 - val_loss: 2.6533 - val_accuracy: 0.3391\n",
      "Epoch 21/50\n",
      "4150/4150 [==============================] - 1s 141us/step - loss: 0.6043 - accuracy: 0.9145 - val_loss: 2.5367 - val_accuracy: 0.3285\n",
      "Epoch 22/50\n",
      "4150/4150 [==============================] - ETA: 0s - loss: 0.5931 - accuracy: 0.90 - 1s 141us/step - loss: 0.6015 - accuracy: 0.9092 - val_loss: 2.5922 - val_accuracy: 0.3208\n",
      "Epoch 23/50\n",
      "4150/4150 [==============================] - 1s 141us/step - loss: 0.5745 - accuracy: 0.9152 - val_loss: 2.6591 - val_accuracy: 0.3276\n",
      "Epoch 24/50\n",
      "4150/4150 [==============================] - 1s 142us/step - loss: 0.6112 - accuracy: 0.9123 - val_loss: 2.6320 - val_accuracy: 0.3064\n",
      "Epoch 25/50\n",
      "4150/4150 [==============================] - 1s 141us/step - loss: 0.5853 - accuracy: 0.9133 - val_loss: 2.5692 - val_accuracy: 0.3121\n",
      "Epoch 26/50\n",
      "4150/4150 [==============================] - 1s 141us/step - loss: 0.5663 - accuracy: 0.9130 - val_loss: 2.7077 - val_accuracy: 0.3256\n",
      "Epoch 27/50\n",
      "4150/4150 [==============================] - 1s 142us/step - loss: 0.5613 - accuracy: 0.9193 - val_loss: 2.7557 - val_accuracy: 0.3150\n",
      "Epoch 28/50\n",
      "4150/4150 [==============================] - 1s 143us/step - loss: 0.5550 - accuracy: 0.9248 - val_loss: 2.8514 - val_accuracy: 0.3179\n",
      "Epoch 29/50\n",
      "4150/4150 [==============================] - 1s 140us/step - loss: 0.5407 - accuracy: 0.9188 - val_loss: 2.7500 - val_accuracy: 0.3218\n",
      "Epoch 30/50\n",
      "4150/4150 [==============================] - 1s 141us/step - loss: 0.5475 - accuracy: 0.9152 - val_loss: 2.8968 - val_accuracy: 0.3247\n",
      "Epoch 31/50\n",
      "4150/4150 [==============================] - 1s 141us/step - loss: 0.5349 - accuracy: 0.9251 - val_loss: 2.8291 - val_accuracy: 0.3333\n",
      "Epoch 32/50\n",
      "4150/4150 [==============================] - 1s 141us/step - loss: 0.5083 - accuracy: 0.9258 - val_loss: 2.8194 - val_accuracy: 0.3324\n",
      "Epoch 33/50\n",
      "4150/4150 [==============================] - 1s 142us/step - loss: 0.5348 - accuracy: 0.9227 - val_loss: 2.7655 - val_accuracy: 0.3208\n",
      "Epoch 34/50\n",
      "4150/4150 [==============================] - 1s 143us/step - loss: 0.5362 - accuracy: 0.9214 - val_loss: 2.7667 - val_accuracy: 0.3131\n",
      "Epoch 35/50\n",
      "4150/4150 [==============================] - 1s 141us/step - loss: 0.5400 - accuracy: 0.9120 - val_loss: 2.9020 - val_accuracy: 0.3198\n",
      "Epoch 36/50\n",
      "4150/4150 [==============================] - 1s 140us/step - loss: 0.5127 - accuracy: 0.9205 - val_loss: 2.7947 - val_accuracy: 0.3295\n",
      "Epoch 37/50\n",
      "4150/4150 [==============================] - 1s 141us/step - loss: 0.5100 - accuracy: 0.9234 - val_loss: 2.9501 - val_accuracy: 0.3227\n",
      "Epoch 38/50\n",
      "4150/4150 [==============================] - 1s 139us/step - loss: 0.5183 - accuracy: 0.9212 - val_loss: 2.8164 - val_accuracy: 0.2967\n",
      "Epoch 39/50\n",
      "4150/4150 [==============================] - 1s 140us/step - loss: 0.5019 - accuracy: 0.9272 - val_loss: 2.9444 - val_accuracy: 0.3102\n",
      "Epoch 40/50\n",
      "4150/4150 [==============================] - 1s 139us/step - loss: 0.4831 - accuracy: 0.9345 - val_loss: 2.9657 - val_accuracy: 0.3160\n",
      "Epoch 41/50\n",
      "4150/4150 [==============================] - 1s 140us/step - loss: 0.4817 - accuracy: 0.9323 - val_loss: 2.9647 - val_accuracy: 0.3237\n",
      "Epoch 42/50\n",
      "4150/4150 [==============================] - 1s 139us/step - loss: 0.5390 - accuracy: 0.9104 - val_loss: 2.8082 - val_accuracy: 0.3160\n",
      "Epoch 43/50\n",
      "4150/4150 [==============================] - 1s 139us/step - loss: 0.5653 - accuracy: 0.9084 - val_loss: 3.1284 - val_accuracy: 0.3208\n",
      "Epoch 44/50\n",
      "4150/4150 [==============================] - 1s 142us/step - loss: 0.5316 - accuracy: 0.9089 - val_loss: 3.1529 - val_accuracy: 0.3015\n",
      "Epoch 45/50\n",
      "4150/4150 [==============================] - 1s 143us/step - loss: 0.5515 - accuracy: 0.9178 - val_loss: 2.9626 - val_accuracy: 0.2996\n",
      "Epoch 46/50\n",
      "4150/4150 [==============================] - 1s 142us/step - loss: 0.5351 - accuracy: 0.9108 - val_loss: 3.1645 - val_accuracy: 0.3131\n",
      "Epoch 47/50\n",
      "4150/4150 [==============================] - 1s 144us/step - loss: 0.5103 - accuracy: 0.9272 - val_loss: 3.1060 - val_accuracy: 0.3237\n",
      "Epoch 48/50\n",
      "4150/4150 [==============================] - 1s 141us/step - loss: 0.4961 - accuracy: 0.9251 - val_loss: 3.2080 - val_accuracy: 0.3131\n",
      "Epoch 49/50\n",
      "4150/4150 [==============================] - 1s 141us/step - loss: 0.5008 - accuracy: 0.9258 - val_loss: 3.0738 - val_accuracy: 0.3179\n",
      "Epoch 50/50\n",
      "4150/4150 [==============================] - 1s 143us/step - loss: 0.4816 - accuracy: 0.9258 - val_loss: 3.2110 - val_accuracy: 0.3295\n",
      "1038/1038 [==============================] - 0s 66us/step\n",
      "1038/1038 [==============================] - 0s 72us/step\n",
      " \n",
      "Train on 4148 samples, validate on 1037 samples\n",
      "Epoch 1/50\n",
      "4148/4148 [==============================] - 1s 270us/step - loss: 1.8542 - accuracy: 0.2365 - val_loss: 1.7951 - val_accuracy: 0.2980\n",
      "Epoch 2/50\n",
      "4148/4148 [==============================] - 1s 158us/step - loss: 1.7282 - accuracy: 0.3450 - val_loss: 1.7982 - val_accuracy: 0.2604\n",
      "Epoch 3/50\n",
      "4148/4148 [==============================] - 1s 147us/step - loss: 1.6297 - accuracy: 0.4122 - val_loss: 1.8119 - val_accuracy: 0.3095\n",
      "Epoch 4/50\n",
      "4148/4148 [==============================] - 1s 148us/step - loss: 1.5272 - accuracy: 0.4805 - val_loss: 1.8430 - val_accuracy: 0.3134\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4148/4148 [==============================] - 1s 147us/step - loss: 1.4238 - accuracy: 0.5378 - val_loss: 1.8371 - val_accuracy: 0.3144\n",
      "Epoch 6/50\n",
      "4148/4148 [==============================] - 1s 157us/step - loss: 1.3040 - accuracy: 0.6189 - val_loss: 1.9961 - val_accuracy: 0.3067\n",
      "Epoch 7/50\n",
      "4148/4148 [==============================] - 1s 153us/step - loss: 1.1808 - accuracy: 0.6815 - val_loss: 2.0658 - val_accuracy: 0.3067\n",
      "Epoch 8/50\n",
      "4148/4148 [==============================] - 1s 144us/step - loss: 1.0675 - accuracy: 0.7551 - val_loss: 2.1840 - val_accuracy: 0.2980\n",
      "Epoch 9/50\n",
      "4148/4148 [==============================] - 1s 143us/step - loss: 0.9419 - accuracy: 0.8199 - val_loss: 2.3758 - val_accuracy: 0.2960\n",
      "Epoch 10/50\n",
      "4148/4148 [==============================] - 1s 143us/step - loss: 0.8546 - accuracy: 0.8498 - val_loss: 2.4071 - val_accuracy: 0.2932\n",
      "Epoch 11/50\n",
      "4148/4148 [==============================] - 1s 143us/step - loss: 0.7668 - accuracy: 0.8966 - val_loss: 2.5063 - val_accuracy: 0.2941\n",
      "Epoch 12/50\n",
      "4148/4148 [==============================] - 1s 144us/step - loss: 0.7030 - accuracy: 0.9192 - val_loss: 2.5721 - val_accuracy: 0.2777\n",
      "Epoch 13/50\n",
      "4148/4148 [==============================] - ETA: 0s - loss: 0.6834 - accuracy: 0.92 - 1s 142us/step - loss: 0.6855 - accuracy: 0.9265 - val_loss: 2.6770 - val_accuracy: 0.2825\n",
      "Epoch 14/50\n",
      "4148/4148 [==============================] - 1s 142us/step - loss: 0.6392 - accuracy: 0.9407 - val_loss: 2.7319 - val_accuracy: 0.2748\n",
      "Epoch 15/50\n",
      "4148/4148 [==============================] - 1s 142us/step - loss: 0.6132 - accuracy: 0.9433 - val_loss: 2.7493 - val_accuracy: 0.2623\n",
      "Epoch 16/50\n",
      "4148/4148 [==============================] - 1s 148us/step - loss: 0.5907 - accuracy: 0.9465 - val_loss: 2.8384 - val_accuracy: 0.2893\n",
      "Epoch 17/50\n",
      "4148/4148 [==============================] - 1s 144us/step - loss: 0.5644 - accuracy: 0.9535 - val_loss: 2.7922 - val_accuracy: 0.3028\n",
      "Epoch 18/50\n",
      "4148/4148 [==============================] - 1s 143us/step - loss: 0.5562 - accuracy: 0.9520 - val_loss: 2.8597 - val_accuracy: 0.2825\n",
      "Epoch 19/50\n",
      "4148/4148 [==============================] - 1s 146us/step - loss: 0.5582 - accuracy: 0.9552 - val_loss: 2.8946 - val_accuracy: 0.2690\n",
      "Epoch 20/50\n",
      "4148/4148 [==============================] - 1s 143us/step - loss: 0.5309 - accuracy: 0.9588 - val_loss: 2.8923 - val_accuracy: 0.2903\n",
      "Epoch 21/50\n",
      "4148/4148 [==============================] - 1s 143us/step - loss: 0.5296 - accuracy: 0.9576 - val_loss: 2.8947 - val_accuracy: 0.3086\n",
      "Epoch 22/50\n",
      "4148/4148 [==============================] - 1s 144us/step - loss: 0.4996 - accuracy: 0.9619 - val_loss: 2.8620 - val_accuracy: 0.2797\n",
      "Epoch 23/50\n",
      "4148/4148 [==============================] - 1s 144us/step - loss: 0.4885 - accuracy: 0.9622 - val_loss: 3.0408 - val_accuracy: 0.2825\n",
      "Epoch 24/50\n",
      "4148/4148 [==============================] - 1s 144us/step - loss: 0.4885 - accuracy: 0.9614 - val_loss: 3.0697 - val_accuracy: 0.2710\n",
      "Epoch 25/50\n",
      "4148/4148 [==============================] - 1s 145us/step - loss: 0.4917 - accuracy: 0.9593 - val_loss: 3.0319 - val_accuracy: 0.2903\n",
      "Epoch 26/50\n",
      "4148/4148 [==============================] - 1s 144us/step - loss: 0.5134 - accuracy: 0.9525 - val_loss: 3.0407 - val_accuracy: 0.2768\n",
      "Epoch 27/50\n",
      "4148/4148 [==============================] - 1s 147us/step - loss: 0.5290 - accuracy: 0.9530 - val_loss: 3.2013 - val_accuracy: 0.2787\n",
      "Epoch 28/50\n",
      "4148/4148 [==============================] - 1s 145us/step - loss: 0.4861 - accuracy: 0.9602 - val_loss: 3.1405 - val_accuracy: 0.2729\n",
      "Epoch 29/50\n",
      "4148/4148 [==============================] - 1s 143us/step - loss: 0.4711 - accuracy: 0.9614 - val_loss: 3.0878 - val_accuracy: 0.2729\n",
      "Epoch 30/50\n",
      "4148/4148 [==============================] - 1s 141us/step - loss: 0.4827 - accuracy: 0.9622 - val_loss: 3.2014 - val_accuracy: 0.2594\n",
      "Epoch 31/50\n",
      "4148/4148 [==============================] - 1s 140us/step - loss: 0.4822 - accuracy: 0.9566 - val_loss: 3.2189 - val_accuracy: 0.2797\n",
      "Epoch 32/50\n",
      "4148/4148 [==============================] - 1s 142us/step - loss: 0.5020 - accuracy: 0.9513 - val_loss: 3.5104 - val_accuracy: 0.2739\n",
      "Epoch 33/50\n",
      "4148/4148 [==============================] - 1s 143us/step - loss: 0.4800 - accuracy: 0.9595 - val_loss: 3.3044 - val_accuracy: 0.2575\n",
      "Epoch 34/50\n",
      "4148/4148 [==============================] - 1s 144us/step - loss: 0.4894 - accuracy: 0.9552 - val_loss: 3.2449 - val_accuracy: 0.2719\n",
      "Epoch 35/50\n",
      "4148/4148 [==============================] - 1s 142us/step - loss: 0.4655 - accuracy: 0.9655 - val_loss: 3.2879 - val_accuracy: 0.2758\n",
      "Epoch 36/50\n",
      "4148/4148 [==============================] - 1s 143us/step - loss: 0.4520 - accuracy: 0.9638 - val_loss: 3.2666 - val_accuracy: 0.2671\n",
      "Epoch 37/50\n",
      "4148/4148 [==============================] - 1s 143us/step - loss: 0.4333 - accuracy: 0.9687 - val_loss: 3.2944 - val_accuracy: 0.2700\n",
      "Epoch 38/50\n",
      "4148/4148 [==============================] - 1s 143us/step - loss: 0.4237 - accuracy: 0.9691 - val_loss: 3.3988 - val_accuracy: 0.2671\n",
      "Epoch 39/50\n",
      "4148/4148 [==============================] - 1s 143us/step - loss: 0.4297 - accuracy: 0.9646 - val_loss: 3.4088 - val_accuracy: 0.2642\n",
      "Epoch 40/50\n",
      "4148/4148 [==============================] - 1s 142us/step - loss: 0.4421 - accuracy: 0.9626 - val_loss: 3.4883 - val_accuracy: 0.2729\n",
      "Epoch 41/50\n",
      "4148/4148 [==============================] - 1s 143us/step - loss: 0.4664 - accuracy: 0.9542 - val_loss: 3.2747 - val_accuracy: 0.2681\n",
      "Epoch 42/50\n",
      "4148/4148 [==============================] - 1s 145us/step - loss: 0.4875 - accuracy: 0.9472 - val_loss: 3.6063 - val_accuracy: 0.2671\n",
      "Epoch 43/50\n",
      "4148/4148 [==============================] - 1s 164us/step - loss: 0.5006 - accuracy: 0.9479 - val_loss: 3.2384 - val_accuracy: 0.2700\n",
      "Epoch 44/50\n",
      "4148/4148 [==============================] - 1s 155us/step - loss: 0.4879 - accuracy: 0.9477 - val_loss: 3.5192 - val_accuracy: 0.2633\n",
      "Epoch 45/50\n",
      "4148/4148 [==============================] - 1s 166us/step - loss: 0.4933 - accuracy: 0.9494 - val_loss: 3.4071 - val_accuracy: 0.2642\n",
      "Epoch 46/50\n",
      "4148/4148 [==============================] - 1s 158us/step - loss: 0.5052 - accuracy: 0.9491 - val_loss: 3.5744 - val_accuracy: 0.2710\n",
      "Epoch 47/50\n",
      "4148/4148 [==============================] - 1s 152us/step - loss: 0.4465 - accuracy: 0.9626 - val_loss: 3.3422 - val_accuracy: 0.2768\n",
      "Epoch 48/50\n",
      "4148/4148 [==============================] - 1s 161us/step - loss: 0.4241 - accuracy: 0.9677 - val_loss: 3.3691 - val_accuracy: 0.2787\n",
      "Epoch 49/50\n",
      "4148/4148 [==============================] - 1s 148us/step - loss: 0.4250 - accuracy: 0.9638 - val_loss: 3.3060 - val_accuracy: 0.2536\n",
      "Epoch 50/50\n",
      "4148/4148 [==============================] - 1s 179us/step - loss: 0.4032 - accuracy: 0.9718 - val_loss: 3.3711 - val_accuracy: 0.2575\n",
      "1037/1037 [==============================] - 0s 80us/step\n",
      "1037/1037 [==============================] - 0s 83us/step\n",
      " \n",
      "Train on 4148 samples, validate on 1038 samples\n",
      "Epoch 1/50\n",
      "4148/4148 [==============================] - 1s 266us/step - loss: 1.8494 - accuracy: 0.2840 - val_loss: 1.7759 - val_accuracy: 0.3295\n",
      "Epoch 2/50\n",
      "4148/4148 [==============================] - 1s 178us/step - loss: 1.6844 - accuracy: 0.3787 - val_loss: 1.6910 - val_accuracy: 0.3738\n",
      "Epoch 3/50\n",
      "4148/4148 [==============================] - 1s 176us/step - loss: 1.5842 - accuracy: 0.4260 - val_loss: 1.6855 - val_accuracy: 0.3516\n",
      "Epoch 4/50\n",
      "4148/4148 [==============================] - 1s 176us/step - loss: 1.4904 - accuracy: 0.4829 - val_loss: 1.6669 - val_accuracy: 0.3622\n",
      "Epoch 5/50\n",
      "4148/4148 [==============================] - 1s 165us/step - loss: 1.4218 - accuracy: 0.5104 - val_loss: 1.6945 - val_accuracy: 0.3574\n",
      "Epoch 6/50\n",
      "4148/4148 [==============================] - 1s 164us/step - loss: 1.3492 - accuracy: 0.5504 - val_loss: 1.7234 - val_accuracy: 0.3613\n",
      "Epoch 7/50\n",
      "4148/4148 [==============================] - 1s 163us/step - loss: 1.2799 - accuracy: 0.5849 - val_loss: 1.7724 - val_accuracy: 0.3353\n",
      "Epoch 8/50\n",
      "4148/4148 [==============================] - 1s 177us/step - loss: 1.1895 - accuracy: 0.6345 - val_loss: 1.8711 - val_accuracy: 0.3449\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4148/4148 [==============================] - 1s 161us/step - loss: 1.1373 - accuracy: 0.6610 - val_loss: 1.8789 - val_accuracy: 0.3372\n",
      "Epoch 10/50\n",
      "4148/4148 [==============================] - 1s 158us/step - loss: 1.0644 - accuracy: 0.7020 - val_loss: 1.9158 - val_accuracy: 0.3459\n",
      "Epoch 11/50\n",
      "4148/4148 [==============================] - 1s 163us/step - loss: 1.0236 - accuracy: 0.7254 - val_loss: 1.9792 - val_accuracy: 0.3468\n",
      "Epoch 12/50\n",
      "4148/4148 [==============================] - 1s 158us/step - loss: 0.9725 - accuracy: 0.7476 - val_loss: 2.3159 - val_accuracy: 0.3449\n",
      "Epoch 13/50\n",
      "4148/4148 [==============================] - 1s 170us/step - loss: 0.9193 - accuracy: 0.7715 - val_loss: 2.2191 - val_accuracy: 0.3256\n",
      "Epoch 14/50\n",
      "4148/4148 [==============================] - 1s 159us/step - loss: 0.8872 - accuracy: 0.7840 - val_loss: 2.5598 - val_accuracy: 0.3160\n",
      "Epoch 15/50\n",
      "4148/4148 [==============================] - 1s 158us/step - loss: 0.8970 - accuracy: 0.7886 - val_loss: 2.2988 - val_accuracy: 0.3410\n",
      "Epoch 16/50\n",
      "4148/4148 [==============================] - 1s 147us/step - loss: 0.8337 - accuracy: 0.8091 - val_loss: 2.4022 - val_accuracy: 0.3314\n",
      "Epoch 17/50\n",
      "4148/4148 [==============================] - 1s 156us/step - loss: 0.7962 - accuracy: 0.8189 - val_loss: 2.4325 - val_accuracy: 0.3208\n",
      "Epoch 18/50\n",
      "4148/4148 [==============================] - 1s 148us/step - loss: 0.7774 - accuracy: 0.8305 - val_loss: 2.5968 - val_accuracy: 0.3208\n",
      "Epoch 19/50\n",
      "4148/4148 [==============================] - 1s 156us/step - loss: 0.7546 - accuracy: 0.8356 - val_loss: 2.3602 - val_accuracy: 0.3208\n",
      "Epoch 20/50\n",
      "4148/4148 [==============================] - 1s 168us/step - loss: 0.7161 - accuracy: 0.8486 - val_loss: 2.6051 - val_accuracy: 0.3401\n",
      "Epoch 21/50\n",
      "4148/4148 [==============================] - 1s 159us/step - loss: 0.7130 - accuracy: 0.8459 - val_loss: 2.3954 - val_accuracy: 0.3276\n",
      "Epoch 22/50\n",
      "4148/4148 [==============================] - 1s 143us/step - loss: 0.7227 - accuracy: 0.8500 - val_loss: 2.4885 - val_accuracy: 0.3314\n",
      "Epoch 23/50\n",
      "4148/4148 [==============================] - 1s 144us/step - loss: 0.6950 - accuracy: 0.8563 - val_loss: 2.8645 - val_accuracy: 0.3227\n",
      "Epoch 24/50\n",
      "4148/4148 [==============================] - 1s 145us/step - loss: 0.6760 - accuracy: 0.8638 - val_loss: 2.7190 - val_accuracy: 0.3314\n",
      "Epoch 25/50\n",
      "4148/4148 [==============================] - 1s 152us/step - loss: 0.6585 - accuracy: 0.8652 - val_loss: 2.7500 - val_accuracy: 0.3276\n",
      "Epoch 26/50\n",
      "4148/4148 [==============================] - 1s 162us/step - loss: 0.7000 - accuracy: 0.8529 - val_loss: 2.7453 - val_accuracy: 0.3227\n",
      "Epoch 27/50\n",
      "4148/4148 [==============================] - 1s 153us/step - loss: 0.6687 - accuracy: 0.8645 - val_loss: 2.8426 - val_accuracy: 0.3092\n",
      "Epoch 28/50\n",
      "4148/4148 [==============================] - 1s 155us/step - loss: 0.6896 - accuracy: 0.8551 - val_loss: 2.7271 - val_accuracy: 0.3208\n",
      "Epoch 29/50\n",
      "4148/4148 [==============================] - 1s 151us/step - loss: 0.6675 - accuracy: 0.8640 - val_loss: 2.7849 - val_accuracy: 0.3189\n",
      "Epoch 30/50\n",
      "4148/4148 [==============================] - 1s 146us/step - loss: 0.6873 - accuracy: 0.8517 - val_loss: 2.7354 - val_accuracy: 0.3256\n",
      "Epoch 31/50\n",
      "4148/4148 [==============================] - 1s 167us/step - loss: 0.6727 - accuracy: 0.8566 - val_loss: 2.8811 - val_accuracy: 0.3372\n",
      "Epoch 32/50\n",
      "4148/4148 [==============================] - 1s 150us/step - loss: 0.6441 - accuracy: 0.8737 - val_loss: 2.8342 - val_accuracy: 0.3353\n",
      "Epoch 33/50\n",
      "4148/4148 [==============================] - 1s 177us/step - loss: 0.6159 - accuracy: 0.8787 - val_loss: 2.9088 - val_accuracy: 0.3218\n",
      "Epoch 34/50\n",
      "4148/4148 [==============================] - 1s 159us/step - loss: 0.6413 - accuracy: 0.8676 - val_loss: 2.8747 - val_accuracy: 0.3160\n",
      "Epoch 35/50\n",
      "4148/4148 [==============================] - 1s 146us/step - loss: 0.6403 - accuracy: 0.8691 - val_loss: 2.9677 - val_accuracy: 0.3256\n",
      "Epoch 36/50\n",
      "4148/4148 [==============================] - 1s 148us/step - loss: 0.6331 - accuracy: 0.8691 - val_loss: 2.8253 - val_accuracy: 0.3343\n",
      "Epoch 37/50\n",
      "4148/4148 [==============================] - 1s 168us/step - loss: 0.6133 - accuracy: 0.8684 - val_loss: 2.9424 - val_accuracy: 0.3189\n",
      "Epoch 38/50\n",
      "4148/4148 [==============================] - 1s 152us/step - loss: 0.5939 - accuracy: 0.8821 - val_loss: 3.0430 - val_accuracy: 0.3150\n",
      "Epoch 39/50\n",
      "4148/4148 [==============================] - 1s 153us/step - loss: 0.6008 - accuracy: 0.8751 - val_loss: 3.0714 - val_accuracy: 0.3189\n",
      "Epoch 40/50\n",
      "4148/4148 [==============================] - 1s 179us/step - loss: 0.6232 - accuracy: 0.8655 - val_loss: 3.0541 - val_accuracy: 0.3160\n",
      "Epoch 41/50\n",
      "4148/4148 [==============================] - 1s 181us/step - loss: 0.6038 - accuracy: 0.8717 - val_loss: 2.8974 - val_accuracy: 0.3092\n",
      "Epoch 42/50\n",
      "4148/4148 [==============================] - 1s 162us/step - loss: 0.6305 - accuracy: 0.8674 - val_loss: 3.1689 - val_accuracy: 0.3035\n",
      "Epoch 43/50\n",
      "4148/4148 [==============================] - 1s 169us/step - loss: 0.6373 - accuracy: 0.8621 - val_loss: 3.0068 - val_accuracy: 0.3198\n",
      "Epoch 44/50\n",
      "4148/4148 [==============================] - 1s 162us/step - loss: 0.6753 - accuracy: 0.8568 - val_loss: 2.8643 - val_accuracy: 0.3121\n",
      "Epoch 45/50\n",
      "4148/4148 [==============================] - 1s 160us/step - loss: 0.5949 - accuracy: 0.8787 - val_loss: 2.9097 - val_accuracy: 0.3276\n",
      "Epoch 46/50\n",
      "4148/4148 [==============================] - 1s 164us/step - loss: 0.5884 - accuracy: 0.8826 - val_loss: 2.9895 - val_accuracy: 0.3343\n",
      "Epoch 47/50\n",
      "4148/4148 [==============================] - 1s 157us/step - loss: 0.5961 - accuracy: 0.8790 - val_loss: 3.0609 - val_accuracy: 0.3064\n",
      "Epoch 48/50\n",
      "4148/4148 [==============================] - 1s 148us/step - loss: 0.6074 - accuracy: 0.8758 - val_loss: 3.1193 - val_accuracy: 0.3170\n",
      "Epoch 49/50\n",
      "4148/4148 [==============================] - 1s 167us/step - loss: 0.6629 - accuracy: 0.8597 - val_loss: 3.1989 - val_accuracy: 0.3198\n",
      "Epoch 50/50\n",
      "4148/4148 [==============================] - 1s 158us/step - loss: 0.6191 - accuracy: 0.8734 - val_loss: 3.0498 - val_accuracy: 0.3304\n",
      "1038/1038 [==============================] - 0s 67us/step\n",
      "1038/1038 [==============================] - 0s 79us/step\n",
      " \n",
      "Train on 4148 samples, validate on 1038 samples\n",
      "Epoch 1/50\n",
      "4148/4148 [==============================] - 1s 284us/step - loss: 1.8576 - accuracy: 0.2406 - val_loss: 1.8043 - val_accuracy: 0.2437\n",
      "Epoch 2/50\n",
      "4148/4148 [==============================] - 1s 159us/step - loss: 1.7523 - accuracy: 0.3045 - val_loss: 1.7549 - val_accuracy: 0.2813\n",
      "Epoch 3/50\n",
      "4148/4148 [==============================] - 1s 173us/step - loss: 1.6963 - accuracy: 0.3267 - val_loss: 1.7433 - val_accuracy: 0.3044\n",
      "Epoch 4/50\n",
      "4148/4148 [==============================] - 1s 176us/step - loss: 1.6570 - accuracy: 0.3679 - val_loss: 1.7356 - val_accuracy: 0.3247\n",
      "Epoch 5/50\n",
      "4148/4148 [==============================] - 1s 195us/step - loss: 1.6036 - accuracy: 0.4036 - val_loss: 1.7354 - val_accuracy: 0.3218\n",
      "Epoch 6/50\n",
      "4148/4148 [==============================] - 1s 150us/step - loss: 1.5504 - accuracy: 0.4373 - val_loss: 1.7815 - val_accuracy: 0.3150\n",
      "Epoch 7/50\n",
      "4148/4148 [==============================] - 1s 150us/step - loss: 1.4978 - accuracy: 0.4706 - val_loss: 1.7984 - val_accuracy: 0.3343\n",
      "Epoch 8/50\n",
      "4148/4148 [==============================] - 1s 153us/step - loss: 1.4473 - accuracy: 0.4882 - val_loss: 1.9124 - val_accuracy: 0.3083\n",
      "Epoch 9/50\n",
      "4148/4148 [==============================] - 1s 149us/step - loss: 1.3927 - accuracy: 0.5277 - val_loss: 1.9249 - val_accuracy: 0.3227\n",
      "Epoch 10/50\n",
      "4148/4148 [==============================] - 1s 164us/step - loss: 1.3319 - accuracy: 0.5574 - val_loss: 1.9510 - val_accuracy: 0.3218\n",
      "Epoch 11/50\n",
      "4148/4148 [==============================] - 1s 168us/step - loss: 1.2748 - accuracy: 0.5817 - val_loss: 2.0604 - val_accuracy: 0.3160\n",
      "Epoch 12/50\n",
      "4148/4148 [==============================] - 1s 155us/step - loss: 1.2031 - accuracy: 0.6174 - val_loss: 2.0876 - val_accuracy: 0.2929\n",
      "Epoch 13/50\n",
      "4148/4148 [==============================] - 1s 145us/step - loss: 1.1559 - accuracy: 0.6471 - val_loss: 2.1524 - val_accuracy: 0.2987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50\n",
      "4148/4148 [==============================] - 1s 159us/step - loss: 1.1374 - accuracy: 0.6586 - val_loss: 2.1923 - val_accuracy: 0.2852\n",
      "Epoch 15/50\n",
      "4148/4148 [==============================] - 1s 142us/step - loss: 1.0803 - accuracy: 0.6849 - val_loss: 2.2469 - val_accuracy: 0.2987\n",
      "Epoch 16/50\n",
      "4148/4148 [==============================] - 1s 152us/step - loss: 1.0562 - accuracy: 0.6991 - val_loss: 2.2182 - val_accuracy: 0.2852\n",
      "Epoch 17/50\n",
      "4148/4148 [==============================] - 1s 155us/step - loss: 0.9889 - accuracy: 0.7261 - val_loss: 2.2989 - val_accuracy: 0.2977\n",
      "Epoch 18/50\n",
      "4148/4148 [==============================] - 1s 149us/step - loss: 1.0010 - accuracy: 0.7264 - val_loss: 2.3367 - val_accuracy: 0.2900\n",
      "Epoch 19/50\n",
      "4148/4148 [==============================] - 1s 163us/step - loss: 0.9430 - accuracy: 0.7408 - val_loss: 2.4343 - val_accuracy: 0.3015\n",
      "Epoch 20/50\n",
      "4148/4148 [==============================] - 1s 153us/step - loss: 0.9033 - accuracy: 0.7568 - val_loss: 2.4642 - val_accuracy: 0.3112\n",
      "Epoch 21/50\n",
      "4148/4148 [==============================] - 1s 169us/step - loss: 0.8842 - accuracy: 0.7698 - val_loss: 2.4847 - val_accuracy: 0.2929\n",
      "Epoch 22/50\n",
      "4148/4148 [==============================] - 1s 159us/step - loss: 0.8588 - accuracy: 0.7842 - val_loss: 2.5936 - val_accuracy: 0.3035\n",
      "Epoch 23/50\n",
      "4148/4148 [==============================] - 1s 153us/step - loss: 0.8810 - accuracy: 0.7907 - val_loss: 2.6645 - val_accuracy: 0.3141\n",
      "Epoch 24/50\n",
      "4148/4148 [==============================] - 1s 168us/step - loss: 0.8361 - accuracy: 0.8016 - val_loss: 2.5993 - val_accuracy: 0.2929\n",
      "Epoch 25/50\n",
      "4148/4148 [==============================] - 1s 163us/step - loss: 0.8009 - accuracy: 0.8079 - val_loss: 2.7107 - val_accuracy: 0.3064\n",
      "Epoch 26/50\n",
      "4148/4148 [==============================] - 1s 141us/step - loss: 0.8033 - accuracy: 0.8156 - val_loss: 2.5366 - val_accuracy: 0.2996\n",
      "Epoch 27/50\n",
      "4148/4148 [==============================] - 1s 139us/step - loss: 0.8087 - accuracy: 0.7992 - val_loss: 2.5971 - val_accuracy: 0.2967\n",
      "Epoch 28/50\n",
      "4148/4148 [==============================] - 1s 142us/step - loss: 0.8041 - accuracy: 0.8057 - val_loss: 2.6473 - val_accuracy: 0.2909\n",
      "Epoch 29/50\n",
      "4148/4148 [==============================] - 1s 143us/step - loss: 0.7929 - accuracy: 0.8146 - val_loss: 2.7463 - val_accuracy: 0.2967\n",
      "Epoch 30/50\n",
      "4148/4148 [==============================] - 1s 139us/step - loss: 0.7598 - accuracy: 0.8180 - val_loss: 2.8710 - val_accuracy: 0.2929\n",
      "Epoch 31/50\n",
      "4148/4148 [==============================] - 1s 139us/step - loss: 0.7320 - accuracy: 0.8286 - val_loss: 2.7952 - val_accuracy: 0.2929\n",
      "Epoch 32/50\n",
      "4148/4148 [==============================] - 1s 139us/step - loss: 0.7153 - accuracy: 0.8435 - val_loss: 2.8161 - val_accuracy: 0.2726\n",
      "Epoch 33/50\n",
      "4148/4148 [==============================] - 1s 140us/step - loss: 0.7266 - accuracy: 0.8363 - val_loss: 3.0163 - val_accuracy: 0.2842\n",
      "Epoch 34/50\n",
      "4148/4148 [==============================] - 1s 141us/step - loss: 0.7395 - accuracy: 0.8375 - val_loss: 2.9189 - val_accuracy: 0.2871\n",
      "Epoch 35/50\n",
      "4148/4148 [==============================] - 1s 141us/step - loss: 0.7172 - accuracy: 0.8327 - val_loss: 3.0694 - val_accuracy: 0.2852\n",
      "Epoch 36/50\n",
      "4148/4148 [==============================] - 1s 138us/step - loss: 0.7496 - accuracy: 0.8353 - val_loss: 2.9273 - val_accuracy: 0.2697\n",
      "Epoch 37/50\n",
      "4148/4148 [==============================] - 1s 139us/step - loss: 0.6932 - accuracy: 0.8488 - val_loss: 2.9597 - val_accuracy: 0.2987\n",
      "Epoch 38/50\n",
      "4148/4148 [==============================] - 1s 138us/step - loss: 0.7022 - accuracy: 0.8426 - val_loss: 3.0513 - val_accuracy: 0.2842\n",
      "Epoch 39/50\n",
      "4148/4148 [==============================] - 1s 138us/step - loss: 0.7057 - accuracy: 0.8455 - val_loss: 2.9149 - val_accuracy: 0.2909\n",
      "Epoch 40/50\n",
      "4148/4148 [==============================] - 1s 139us/step - loss: 0.6733 - accuracy: 0.8539 - val_loss: 3.0227 - val_accuracy: 0.2919\n",
      "Epoch 41/50\n",
      "4148/4148 [==============================] - 1s 139us/step - loss: 0.6602 - accuracy: 0.8573 - val_loss: 2.9846 - val_accuracy: 0.2919\n",
      "Epoch 42/50\n",
      "4148/4148 [==============================] - 1s 139us/step - loss: 0.6547 - accuracy: 0.8628 - val_loss: 3.1226 - val_accuracy: 0.2803\n",
      "Epoch 43/50\n",
      "4148/4148 [==============================] - 1s 141us/step - loss: 0.6781 - accuracy: 0.8498 - val_loss: 3.0559 - val_accuracy: 0.2919\n",
      "Epoch 44/50\n",
      "4148/4148 [==============================] - 1s 141us/step - loss: 0.6670 - accuracy: 0.8513 - val_loss: 3.1238 - val_accuracy: 0.3025\n",
      "Epoch 45/50\n",
      "4148/4148 [==============================] - 1s 141us/step - loss: 0.6648 - accuracy: 0.8532 - val_loss: 2.9879 - val_accuracy: 0.3015\n",
      "Epoch 46/50\n",
      "4148/4148 [==============================] - 1s 140us/step - loss: 0.6677 - accuracy: 0.8476 - val_loss: 3.2220 - val_accuracy: 0.2958\n",
      "Epoch 47/50\n",
      "4148/4148 [==============================] - 1s 139us/step - loss: 0.6468 - accuracy: 0.8693 - val_loss: 3.1486 - val_accuracy: 0.2852\n",
      "Epoch 48/50\n",
      "4148/4148 [==============================] - 1s 138us/step - loss: 0.6808 - accuracy: 0.8481 - val_loss: 3.2478 - val_accuracy: 0.3035\n",
      "Epoch 49/50\n",
      "4148/4148 [==============================] - 1s 142us/step - loss: 0.6703 - accuracy: 0.8570 - val_loss: 3.2854 - val_accuracy: 0.2842\n",
      "Epoch 50/50\n",
      "4148/4148 [==============================] - 1s 144us/step - loss: 0.6707 - accuracy: 0.8462 - val_loss: 3.1691 - val_accuracy: 0.3083\n",
      "1038/1038 [==============================] - 0s 66us/step\n",
      "1038/1038 [==============================] - 0s 67us/step\n",
      " \n",
      "Train on 4148 samples, validate on 1037 samples\n",
      "Epoch 1/50\n",
      "4148/4148 [==============================] - 1s 266us/step - loss: 1.8127 - accuracy: 0.3071 - val_loss: 1.7831 - val_accuracy: 0.3047\n",
      "Epoch 2/50\n",
      "4148/4148 [==============================] - 1s 146us/step - loss: 1.6482 - accuracy: 0.4004 - val_loss: 1.7741 - val_accuracy: 0.3346\n",
      "Epoch 3/50\n",
      "4148/4148 [==============================] - 1s 146us/step - loss: 1.5333 - accuracy: 0.4744 - val_loss: 1.7608 - val_accuracy: 0.3346\n",
      "Epoch 4/50\n",
      "4148/4148 [==============================] - 1s 144us/step - loss: 1.4265 - accuracy: 0.5350 - val_loss: 1.8604 - val_accuracy: 0.3298\n",
      "Epoch 5/50\n",
      "4148/4148 [==============================] - 1s 144us/step - loss: 1.3184 - accuracy: 0.5885 - val_loss: 1.9954 - val_accuracy: 0.3317\n",
      "Epoch 6/50\n",
      "4148/4148 [==============================] - 1s 144us/step - loss: 1.2017 - accuracy: 0.6430 - val_loss: 1.9982 - val_accuracy: 0.3414\n",
      "Epoch 7/50\n",
      "4148/4148 [==============================] - 1s 144us/step - loss: 1.0836 - accuracy: 0.7083 - val_loss: 2.1272 - val_accuracy: 0.3472\n",
      "Epoch 8/50\n",
      "4148/4148 [==============================] - 1s 145us/step - loss: 0.9934 - accuracy: 0.7582 - val_loss: 2.1486 - val_accuracy: 0.3472\n",
      "Epoch 9/50\n",
      "4148/4148 [==============================] - 1s 145us/step - loss: 0.9067 - accuracy: 0.7989 - val_loss: 2.2531 - val_accuracy: 0.3481\n",
      "Epoch 10/50\n",
      "4148/4148 [==============================] - 1s 151us/step - loss: 0.8191 - accuracy: 0.8443 - val_loss: 2.4299 - val_accuracy: 0.3385\n",
      "Epoch 11/50\n",
      "4148/4148 [==============================] - 1s 156us/step - loss: 0.7471 - accuracy: 0.8792 - val_loss: 2.6019 - val_accuracy: 0.3288\n",
      "Epoch 12/50\n",
      "4148/4148 [==============================] - 1s 181us/step - loss: 0.6872 - accuracy: 0.8963 - val_loss: 2.5936 - val_accuracy: 0.3481\n",
      "Epoch 13/50\n",
      "4148/4148 [==============================] - 1s 166us/step - loss: 0.6613 - accuracy: 0.9026 - val_loss: 2.6032 - val_accuracy: 0.3337\n",
      "Epoch 14/50\n",
      "4148/4148 [==============================] - 1s 154us/step - loss: 0.6200 - accuracy: 0.9248 - val_loss: 2.7756 - val_accuracy: 0.3433\n",
      "Epoch 15/50\n",
      "4148/4148 [==============================] - 1s 174us/step - loss: 0.6129 - accuracy: 0.9274 - val_loss: 2.7363 - val_accuracy: 0.3327\n",
      "Epoch 16/50\n",
      "4148/4148 [==============================] - 1s 151us/step - loss: 0.5721 - accuracy: 0.9347 - val_loss: 2.7169 - val_accuracy: 0.3298\n",
      "Epoch 17/50\n",
      "4148/4148 [==============================] - 1s 175us/step - loss: 0.5728 - accuracy: 0.9388 - val_loss: 2.7644 - val_accuracy: 0.3105\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4148/4148 [==============================] - 1s 169us/step - loss: 0.5647 - accuracy: 0.9347 - val_loss: 2.7321 - val_accuracy: 0.3414\n",
      "Epoch 19/50\n",
      "4148/4148 [==============================] - 1s 168us/step - loss: 0.5622 - accuracy: 0.9371 - val_loss: 2.8325 - val_accuracy: 0.3221\n",
      "Epoch 20/50\n",
      "4148/4148 [==============================] - 1s 156us/step - loss: 0.5533 - accuracy: 0.9412 - val_loss: 2.8740 - val_accuracy: 0.3356\n",
      "Epoch 21/50\n",
      "4148/4148 [==============================] - 1s 162us/step - loss: 0.5561 - accuracy: 0.9320 - val_loss: 2.8609 - val_accuracy: 0.3124\n",
      "Epoch 22/50\n",
      "4148/4148 [==============================] - 1s 176us/step - loss: 0.5140 - accuracy: 0.9441 - val_loss: 2.8065 - val_accuracy: 0.3404\n",
      "Epoch 23/50\n",
      "4148/4148 [==============================] - 1s 180us/step - loss: 0.5027 - accuracy: 0.9458 - val_loss: 2.8962 - val_accuracy: 0.3269\n",
      "Epoch 24/50\n",
      "4148/4148 [==============================] - 1s 149us/step - loss: 0.5152 - accuracy: 0.9460 - val_loss: 2.9821 - val_accuracy: 0.3298\n",
      "Epoch 25/50\n",
      "4148/4148 [==============================] - 1s 151us/step - loss: 0.5109 - accuracy: 0.9467 - val_loss: 3.0850 - val_accuracy: 0.3076\n",
      "Epoch 26/50\n",
      "4148/4148 [==============================] - 1s 145us/step - loss: 0.5163 - accuracy: 0.9431 - val_loss: 3.0076 - val_accuracy: 0.3269\n",
      "Epoch 27/50\n",
      "4148/4148 [==============================] - 1s 146us/step - loss: 0.5035 - accuracy: 0.9407 - val_loss: 3.0044 - val_accuracy: 0.3365\n",
      "Epoch 28/50\n",
      "4148/4148 [==============================] - 1s 146us/step - loss: 0.4775 - accuracy: 0.9576 - val_loss: 2.9422 - val_accuracy: 0.3394\n",
      "Epoch 29/50\n",
      "4148/4148 [==============================] - 1s 149us/step - loss: 0.4955 - accuracy: 0.9503 - val_loss: 2.9105 - val_accuracy: 0.3192\n",
      "Epoch 30/50\n",
      "4148/4148 [==============================] - 1s 147us/step - loss: 0.4561 - accuracy: 0.9479 - val_loss: 3.0531 - val_accuracy: 0.3202\n",
      "Epoch 31/50\n",
      "4148/4148 [==============================] - 1s 145us/step - loss: 0.4812 - accuracy: 0.9438 - val_loss: 2.9352 - val_accuracy: 0.3240\n",
      "Epoch 32/50\n",
      "4148/4148 [==============================] - 1s 147us/step - loss: 0.5076 - accuracy: 0.9407 - val_loss: 3.1738 - val_accuracy: 0.3250\n",
      "Epoch 33/50\n",
      "4148/4148 [==============================] - 1s 147us/step - loss: 0.5630 - accuracy: 0.9190 - val_loss: 2.9562 - val_accuracy: 0.3067\n",
      "Epoch 34/50\n",
      "4148/4148 [==============================] - 1s 150us/step - loss: 0.5495 - accuracy: 0.9163 - val_loss: 3.1691 - val_accuracy: 0.3365\n",
      "Epoch 35/50\n",
      "4148/4148 [==============================] - 1s 149us/step - loss: 0.5266 - accuracy: 0.9282 - val_loss: 3.2076 - val_accuracy: 0.3269\n",
      "Epoch 36/50\n",
      "4148/4148 [==============================] - 1s 148us/step - loss: 0.5013 - accuracy: 0.9419 - val_loss: 3.1445 - val_accuracy: 0.3211\n",
      "Epoch 37/50\n",
      "4148/4148 [==============================] - 1s 148us/step - loss: 0.4801 - accuracy: 0.9496 - val_loss: 3.2218 - val_accuracy: 0.3308\n",
      "Epoch 38/50\n",
      "4148/4148 [==============================] - 1s 148us/step - loss: 0.4709 - accuracy: 0.9503 - val_loss: 3.1521 - val_accuracy: 0.3259\n",
      "Epoch 39/50\n",
      "4148/4148 [==============================] - 1s 149us/step - loss: 0.4357 - accuracy: 0.9585 - val_loss: 3.1041 - val_accuracy: 0.3202\n",
      "Epoch 40/50\n",
      "4148/4148 [==============================] - 1s 149us/step - loss: 0.4497 - accuracy: 0.9571 - val_loss: 3.2779 - val_accuracy: 0.3144\n",
      "Epoch 41/50\n",
      "4148/4148 [==============================] - 1s 151us/step - loss: 0.4306 - accuracy: 0.9585 - val_loss: 3.0718 - val_accuracy: 0.3259\n",
      "Epoch 42/50\n",
      "4148/4148 [==============================] - 1s 149us/step - loss: 0.4273 - accuracy: 0.9595 - val_loss: 3.2383 - val_accuracy: 0.3173\n",
      "Epoch 43/50\n",
      "4148/4148 [==============================] - 1s 150us/step - loss: 0.4239 - accuracy: 0.9585 - val_loss: 3.2639 - val_accuracy: 0.3308\n",
      "Epoch 44/50\n",
      "4148/4148 [==============================] - 1s 150us/step - loss: 0.4066 - accuracy: 0.9609 - val_loss: 3.3763 - val_accuracy: 0.3221\n",
      "Epoch 45/50\n",
      "4148/4148 [==============================] - 1s 149us/step - loss: 0.4444 - accuracy: 0.9465 - val_loss: 3.1767 - val_accuracy: 0.3221\n",
      "Epoch 46/50\n",
      "4148/4148 [==============================] - 1s 150us/step - loss: 0.4245 - accuracy: 0.9561 - val_loss: 3.4198 - val_accuracy: 0.3288\n",
      "Epoch 47/50\n",
      "4148/4148 [==============================] - 1s 149us/step - loss: 0.4252 - accuracy: 0.9561 - val_loss: 3.2953 - val_accuracy: 0.3182\n",
      "Epoch 48/50\n",
      "4148/4148 [==============================] - 1s 147us/step - loss: 0.4198 - accuracy: 0.9559 - val_loss: 3.3890 - val_accuracy: 0.3211\n",
      "Epoch 49/50\n",
      "4148/4148 [==============================] - 1s 149us/step - loss: 0.4905 - accuracy: 0.9337 - val_loss: 3.4392 - val_accuracy: 0.3095\n",
      "Epoch 50/50\n",
      "4148/4148 [==============================] - 1s 149us/step - loss: 0.4941 - accuracy: 0.9330 - val_loss: 3.2907 - val_accuracy: 0.3356\n",
      "1037/1037 [==============================] - 0s 67us/step\n",
      "1037/1037 [==============================] - 0s 73us/step\n",
      " \n",
      "Train on 4148 samples, validate on 1038 samples\n",
      "Epoch 1/50\n",
      "4148/4148 [==============================] - 1s 223us/step - loss: 1.7772 - accuracy: 0.3570 - val_loss: 1.7071 - val_accuracy: 0.4066\n",
      "Epoch 2/50\n",
      "4148/4148 [==============================] - 1s 140us/step - loss: 1.5404 - accuracy: 0.4771 - val_loss: 1.7807 - val_accuracy: 0.3632\n",
      "Epoch 3/50\n",
      "4148/4148 [==============================] - 1s 128us/step - loss: 1.4067 - accuracy: 0.5407 - val_loss: 1.6634 - val_accuracy: 0.4393\n",
      "Epoch 4/50\n",
      "4148/4148 [==============================] - 1s 125us/step - loss: 1.2938 - accuracy: 0.6056 - val_loss: 1.7966 - val_accuracy: 0.3873\n",
      "Epoch 5/50\n",
      "4148/4148 [==============================] - 1s 125us/step - loss: 1.1902 - accuracy: 0.6487 - val_loss: 1.7833 - val_accuracy: 0.4085\n",
      "Epoch 6/50\n",
      "4148/4148 [==============================] - 1s 126us/step - loss: 1.0760 - accuracy: 0.7138 - val_loss: 1.9252 - val_accuracy: 0.3998\n",
      "Epoch 7/50\n",
      "4148/4148 [==============================] - 1s 124us/step - loss: 1.0023 - accuracy: 0.7601 - val_loss: 1.9564 - val_accuracy: 0.3998\n",
      "Epoch 8/50\n",
      "4148/4148 [==============================] - 1s 124us/step - loss: 0.8936 - accuracy: 0.8127 - val_loss: 2.1387 - val_accuracy: 0.3844\n",
      "Epoch 9/50\n",
      "4148/4148 [==============================] - 1s 125us/step - loss: 0.8279 - accuracy: 0.8539 - val_loss: 2.2355 - val_accuracy: 0.3863\n",
      "Epoch 10/50\n",
      "4148/4148 [==============================] - 1s 125us/step - loss: 0.7573 - accuracy: 0.8908 - val_loss: 2.1294 - val_accuracy: 0.3911\n",
      "Epoch 11/50\n",
      "4148/4148 [==============================] - 1s 124us/step - loss: 0.6877 - accuracy: 0.9125 - val_loss: 2.3056 - val_accuracy: 0.3642\n",
      "Epoch 12/50\n",
      "4148/4148 [==============================] - 1s 122us/step - loss: 0.6362 - accuracy: 0.9303 - val_loss: 2.2670 - val_accuracy: 0.3863\n",
      "Epoch 13/50\n",
      "4148/4148 [==============================] - 1s 122us/step - loss: 0.6228 - accuracy: 0.9378 - val_loss: 2.3932 - val_accuracy: 0.3651\n",
      "Epoch 14/50\n",
      "4148/4148 [==============================] - 1s 123us/step - loss: 0.5766 - accuracy: 0.9503 - val_loss: 2.3391 - val_accuracy: 0.3709\n",
      "Epoch 15/50\n",
      "4148/4148 [==============================] - 1s 124us/step - loss: 0.5429 - accuracy: 0.9552 - val_loss: 2.3760 - val_accuracy: 0.3863\n",
      "Epoch 16/50\n",
      "4148/4148 [==============================] - 1s 125us/step - loss: 0.5381 - accuracy: 0.9537 - val_loss: 2.5225 - val_accuracy: 0.3487\n",
      "Epoch 17/50\n",
      "4148/4148 [==============================] - 1s 122us/step - loss: 0.5493 - accuracy: 0.9561 - val_loss: 2.5391 - val_accuracy: 0.3651\n",
      "Epoch 18/50\n",
      "4148/4148 [==============================] - 1s 123us/step - loss: 0.5166 - accuracy: 0.9585 - val_loss: 2.5448 - val_accuracy: 0.3738\n",
      "Epoch 19/50\n",
      "4148/4148 [==============================] - 1s 122us/step - loss: 0.4966 - accuracy: 0.9617 - val_loss: 2.6469 - val_accuracy: 0.3613\n",
      "Epoch 20/50\n",
      "4148/4148 [==============================] - 1s 124us/step - loss: 0.5056 - accuracy: 0.9547 - val_loss: 2.6319 - val_accuracy: 0.3603\n",
      "Epoch 21/50\n",
      "4148/4148 [==============================] - 1s 123us/step - loss: 0.4910 - accuracy: 0.9583 - val_loss: 2.6038 - val_accuracy: 0.3719\n",
      "Epoch 22/50\n",
      "4148/4148 [==============================] - 1s 125us/step - loss: 0.4763 - accuracy: 0.9672 - val_loss: 2.6314 - val_accuracy: 0.3709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50\n",
      "4148/4148 [==============================] - 1s 132us/step - loss: 0.4498 - accuracy: 0.9670 - val_loss: 2.7228 - val_accuracy: 0.3844\n",
      "Epoch 24/50\n",
      "4148/4148 [==============================] - 1s 139us/step - loss: 0.4322 - accuracy: 0.9694 - val_loss: 2.6225 - val_accuracy: 0.3497\n",
      "Epoch 25/50\n",
      "4148/4148 [==============================] - 1s 122us/step - loss: 0.4999 - accuracy: 0.9484 - val_loss: 2.6825 - val_accuracy: 0.3439\n",
      "Epoch 26/50\n",
      "4148/4148 [==============================] - 1s 133us/step - loss: 0.5237 - accuracy: 0.9438 - val_loss: 2.6965 - val_accuracy: 0.3545\n",
      "Epoch 27/50\n",
      "4148/4148 [==============================] - 1s 165us/step - loss: 0.5192 - accuracy: 0.9385 - val_loss: 2.7572 - val_accuracy: 0.3767\n",
      "Epoch 28/50\n",
      "4148/4148 [==============================] - 1s 153us/step - loss: 0.5249 - accuracy: 0.9366 - val_loss: 2.6339 - val_accuracy: 0.3651\n",
      "Epoch 29/50\n",
      "4148/4148 [==============================] - 1s 144us/step - loss: 0.4727 - accuracy: 0.9576 - val_loss: 2.8649 - val_accuracy: 0.3343\n",
      "Epoch 30/50\n",
      "4148/4148 [==============================] - 1s 156us/step - loss: 0.4671 - accuracy: 0.9600 - val_loss: 2.8371 - val_accuracy: 0.3671\n",
      "Epoch 31/50\n",
      "4148/4148 [==============================] - 1s 142us/step - loss: 0.4910 - accuracy: 0.9537 - val_loss: 2.9325 - val_accuracy: 0.3632\n",
      "Epoch 32/50\n",
      "4148/4148 [==============================] - 1s 146us/step - loss: 0.4891 - accuracy: 0.9511 - val_loss: 2.6842 - val_accuracy: 0.3593\n",
      "Epoch 33/50\n",
      "4148/4148 [==============================] - 1s 141us/step - loss: 0.4658 - accuracy: 0.9518 - val_loss: 2.7839 - val_accuracy: 0.3680\n",
      "Epoch 34/50\n",
      "4148/4148 [==============================] - 1s 141us/step - loss: 0.4627 - accuracy: 0.9602 - val_loss: 2.9187 - val_accuracy: 0.3468\n",
      "Epoch 35/50\n",
      "4148/4148 [==============================] - 1s 144us/step - loss: 0.4128 - accuracy: 0.9691 - val_loss: 2.7722 - val_accuracy: 0.3545\n",
      "Epoch 36/50\n",
      "4148/4148 [==============================] - 1s 142us/step - loss: 0.4608 - accuracy: 0.9576 - val_loss: 2.8277 - val_accuracy: 0.3757\n",
      "Epoch 37/50\n",
      "4148/4148 [==============================] - 1s 141us/step - loss: 0.4934 - accuracy: 0.9477 - val_loss: 2.8527 - val_accuracy: 0.3497\n",
      "Epoch 38/50\n",
      "4148/4148 [==============================] - 1s 139us/step - loss: 0.4554 - accuracy: 0.9518 - val_loss: 2.9508 - val_accuracy: 0.3497\n",
      "Epoch 39/50\n",
      "4148/4148 [==============================] - 1s 139us/step - loss: 0.4605 - accuracy: 0.9491 - val_loss: 2.9099 - val_accuracy: 0.3565\n",
      "Epoch 40/50\n",
      "4148/4148 [==============================] - 1s 139us/step - loss: 0.4471 - accuracy: 0.9540 - val_loss: 2.9830 - val_accuracy: 0.3555\n",
      "Epoch 41/50\n",
      "4148/4148 [==============================] - 1s 138us/step - loss: 0.4512 - accuracy: 0.9607 - val_loss: 2.9389 - val_accuracy: 0.3593\n",
      "Epoch 42/50\n",
      "4148/4148 [==============================] - 1s 139us/step - loss: 0.4385 - accuracy: 0.9581 - val_loss: 3.0567 - val_accuracy: 0.3497\n",
      "Epoch 43/50\n",
      "4148/4148 [==============================] - 1s 152us/step - loss: 0.4762 - accuracy: 0.9467 - val_loss: 2.8098 - val_accuracy: 0.3642\n",
      "Epoch 44/50\n",
      "4148/4148 [==============================] - 1s 156us/step - loss: 0.4573 - accuracy: 0.9561 - val_loss: 3.0252 - val_accuracy: 0.3642\n",
      "Epoch 45/50\n",
      "4148/4148 [==============================] - 1s 149us/step - loss: 0.4331 - accuracy: 0.9595 - val_loss: 3.0551 - val_accuracy: 0.3449\n",
      "Epoch 46/50\n",
      "4148/4148 [==============================] - 1s 156us/step - loss: 0.4319 - accuracy: 0.9597 - val_loss: 3.0627 - val_accuracy: 0.3526\n",
      "Epoch 47/50\n",
      "4148/4148 [==============================] - 1s 166us/step - loss: 0.4186 - accuracy: 0.9634 - val_loss: 2.9349 - val_accuracy: 0.3526\n",
      "Epoch 48/50\n",
      "4148/4148 [==============================] - 1s 145us/step - loss: 0.4088 - accuracy: 0.9631 - val_loss: 3.0619 - val_accuracy: 0.3362\n",
      "Epoch 49/50\n",
      "4148/4148 [==============================] - 1s 180us/step - loss: 0.4262 - accuracy: 0.9581 - val_loss: 3.0629 - val_accuracy: 0.3642\n",
      "Epoch 50/50\n",
      "4148/4148 [==============================] - 1s 178us/step - loss: 0.3965 - accuracy: 0.9595 - val_loss: 3.0262 - val_accuracy: 0.3776\n",
      "1038/1038 [==============================] - 0s 73us/step\n",
      "1038/1038 [==============================] - 0s 78us/step\n",
      " \n",
      "Train on 4150 samples, validate on 1038 samples\n",
      "Epoch 1/50\n",
      "4150/4150 [==============================] - 1s 247us/step - loss: 1.7798 - accuracy: 0.3227 - val_loss: 1.7038 - val_accuracy: 0.3776\n",
      "Epoch 2/50\n",
      "4150/4150 [==============================] - 1s 146us/step - loss: 1.5743 - accuracy: 0.4564 - val_loss: 1.6033 - val_accuracy: 0.4335\n",
      "Epoch 3/50\n",
      "4150/4150 [==============================] - 1s 147us/step - loss: 1.4375 - accuracy: 0.5217 - val_loss: 1.5589 - val_accuracy: 0.4489\n",
      "Epoch 4/50\n",
      "4150/4150 [==============================] - 1s 147us/step - loss: 1.3244 - accuracy: 0.5737 - val_loss: 1.5931 - val_accuracy: 0.4461\n",
      "Epoch 5/50\n",
      "4150/4150 [==============================] - 1s 151us/step - loss: 1.2276 - accuracy: 0.6270 - val_loss: 1.6323 - val_accuracy: 0.4538\n",
      "Epoch 6/50\n",
      "4150/4150 [==============================] - 1s 145us/step - loss: 1.1352 - accuracy: 0.6863 - val_loss: 1.6900 - val_accuracy: 0.4461\n",
      "Epoch 7/50\n",
      "4150/4150 [==============================] - 1s 146us/step - loss: 1.0238 - accuracy: 0.7475 - val_loss: 1.7258 - val_accuracy: 0.4403\n",
      "Epoch 8/50\n",
      "4150/4150 [==============================] - 1s 144us/step - loss: 0.9357 - accuracy: 0.7906 - val_loss: 1.8367 - val_accuracy: 0.4162\n",
      "Epoch 9/50\n",
      "4150/4150 [==============================] - 1s 145us/step - loss: 0.8715 - accuracy: 0.8330 - val_loss: 1.9018 - val_accuracy: 0.4171\n",
      "Epoch 10/50\n",
      "4150/4150 [==============================] - 1s 144us/step - loss: 0.7813 - accuracy: 0.8733 - val_loss: 2.0321 - val_accuracy: 0.4258\n",
      "Epoch 11/50\n",
      "4150/4150 [==============================] - 1s 144us/step - loss: 0.7318 - accuracy: 0.8937 - val_loss: 2.0818 - val_accuracy: 0.4133\n",
      "Epoch 12/50\n",
      "4150/4150 [==============================] - 1s 145us/step - loss: 0.6680 - accuracy: 0.9190 - val_loss: 2.1484 - val_accuracy: 0.4181\n",
      "Epoch 13/50\n",
      "4150/4150 [==============================] - 1s 145us/step - loss: 0.6255 - accuracy: 0.9304 - val_loss: 2.1411 - val_accuracy: 0.4104\n",
      "Epoch 14/50\n",
      "4150/4150 [==============================] - 1s 145us/step - loss: 0.5971 - accuracy: 0.9410 - val_loss: 2.1917 - val_accuracy: 0.4181\n",
      "Epoch 15/50\n",
      "4150/4150 [==============================] - 1s 145us/step - loss: 0.5724 - accuracy: 0.9422 - val_loss: 2.2050 - val_accuracy: 0.4066\n",
      "Epoch 16/50\n",
      "4150/4150 [==============================] - 1s 143us/step - loss: 0.5648 - accuracy: 0.9434 - val_loss: 2.2758 - val_accuracy: 0.4027\n",
      "Epoch 17/50\n",
      "4150/4150 [==============================] - 1s 144us/step - loss: 0.5564 - accuracy: 0.9516 - val_loss: 2.2329 - val_accuracy: 0.3950\n",
      "Epoch 18/50\n",
      "4150/4150 [==============================] - 1s 147us/step - loss: 0.5372 - accuracy: 0.9487 - val_loss: 2.3207 - val_accuracy: 0.3969\n",
      "Epoch 19/50\n",
      "4150/4150 [==============================] - 1s 148us/step - loss: 0.5370 - accuracy: 0.9520 - val_loss: 2.3822 - val_accuracy: 0.3988\n",
      "Epoch 20/50\n",
      "4150/4150 [==============================] - 1s 146us/step - loss: 0.4953 - accuracy: 0.9578 - val_loss: 2.4793 - val_accuracy: 0.4046\n",
      "Epoch 21/50\n",
      "4150/4150 [==============================] - 1s 148us/step - loss: 0.5116 - accuracy: 0.9612 - val_loss: 2.4797 - val_accuracy: 0.4123\n",
      "Epoch 22/50\n",
      "4150/4150 [==============================] - 1s 148us/step - loss: 0.4917 - accuracy: 0.9586 - val_loss: 2.2977 - val_accuracy: 0.4017\n",
      "Epoch 23/50\n",
      "4150/4150 [==============================] - 1s 155us/step - loss: 0.5314 - accuracy: 0.9525 - val_loss: 2.3551 - val_accuracy: 0.4143\n",
      "Epoch 24/50\n",
      "4150/4150 [==============================] - 1s 156us/step - loss: 0.5269 - accuracy: 0.9540 - val_loss: 2.5102 - val_accuracy: 0.4152\n",
      "Epoch 25/50\n",
      "4150/4150 [==============================] - 1s 148us/step - loss: 0.4792 - accuracy: 0.9617 - val_loss: 2.5908 - val_accuracy: 0.3969\n",
      "Epoch 26/50\n",
      "4150/4150 [==============================] - 1s 155us/step - loss: 0.4696 - accuracy: 0.9612 - val_loss: 2.6048 - val_accuracy: 0.3969\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4150/4150 [==============================] - 1s 146us/step - loss: 0.4683 - accuracy: 0.9610 - val_loss: 2.4210 - val_accuracy: 0.3988\n",
      "Epoch 28/50\n",
      "4150/4150 [==============================] - 1s 147us/step - loss: 0.4734 - accuracy: 0.9528 - val_loss: 2.5215 - val_accuracy: 0.3911\n",
      "Epoch 29/50\n",
      "4150/4150 [==============================] - 1s 144us/step - loss: 0.4742 - accuracy: 0.9566 - val_loss: 2.4453 - val_accuracy: 0.3998\n",
      "Epoch 30/50\n",
      "4150/4150 [==============================] - 1s 145us/step - loss: 0.4445 - accuracy: 0.9622 - val_loss: 2.5149 - val_accuracy: 0.4075\n",
      "Epoch 31/50\n",
      "4150/4150 [==============================] - 1s 144us/step - loss: 0.4451 - accuracy: 0.9631 - val_loss: 2.6540 - val_accuracy: 0.3950\n",
      "Epoch 32/50\n",
      "4150/4150 [==============================] - 1s 144us/step - loss: 0.4253 - accuracy: 0.9672 - val_loss: 2.6025 - val_accuracy: 0.4075\n",
      "Epoch 33/50\n",
      "4150/4150 [==============================] - 1s 146us/step - loss: 0.4192 - accuracy: 0.9670 - val_loss: 2.6786 - val_accuracy: 0.3738\n",
      "Epoch 34/50\n",
      "4150/4150 [==============================] - 1s 146us/step - loss: 0.4426 - accuracy: 0.9614 - val_loss: 2.7127 - val_accuracy: 0.3873\n",
      "Epoch 35/50\n",
      "4150/4150 [==============================] - 1s 145us/step - loss: 0.4456 - accuracy: 0.9627 - val_loss: 2.5983 - val_accuracy: 0.3931\n",
      "Epoch 36/50\n",
      "4150/4150 [==============================] - 1s 145us/step - loss: 0.4813 - accuracy: 0.9516 - val_loss: 2.6742 - val_accuracy: 0.3950\n",
      "Epoch 37/50\n",
      "4150/4150 [==============================] - 1s 145us/step - loss: 0.5038 - accuracy: 0.9482 - val_loss: 2.5365 - val_accuracy: 0.4104\n",
      "Epoch 38/50\n",
      "4150/4150 [==============================] - 1s 147us/step - loss: 0.4449 - accuracy: 0.9610 - val_loss: 2.6866 - val_accuracy: 0.3873\n",
      "Epoch 39/50\n",
      "4150/4150 [==============================] - 1s 144us/step - loss: 0.4258 - accuracy: 0.9610 - val_loss: 2.7069 - val_accuracy: 0.3979\n",
      "Epoch 40/50\n",
      "4150/4150 [==============================] - 1s 144us/step - loss: 0.4022 - accuracy: 0.9720 - val_loss: 2.6783 - val_accuracy: 0.4037\n",
      "Epoch 41/50\n",
      "4150/4150 [==============================] - 1s 145us/step - loss: 0.3905 - accuracy: 0.9713 - val_loss: 2.7105 - val_accuracy: 0.3911\n",
      "Epoch 42/50\n",
      "4150/4150 [==============================] - 1s 145us/step - loss: 0.3766 - accuracy: 0.9737 - val_loss: 2.6339 - val_accuracy: 0.3902\n",
      "Epoch 43/50\n",
      "4150/4150 [==============================] - 1s 143us/step - loss: 0.3629 - accuracy: 0.9745 - val_loss: 2.7421 - val_accuracy: 0.3940\n",
      "Epoch 44/50\n",
      "4150/4150 [==============================] - 1s 144us/step - loss: 0.4036 - accuracy: 0.9641 - val_loss: 2.5299 - val_accuracy: 0.3940\n",
      "Epoch 45/50\n",
      "4150/4150 [==============================] - 1s 144us/step - loss: 0.4495 - accuracy: 0.9499 - val_loss: 2.7457 - val_accuracy: 0.3786\n",
      "Epoch 46/50\n",
      "4150/4150 [==============================] - 1s 146us/step - loss: 0.4716 - accuracy: 0.9402 - val_loss: 2.8954 - val_accuracy: 0.3776\n",
      "Epoch 47/50\n",
      "4150/4150 [==============================] - 1s 145us/step - loss: 0.4976 - accuracy: 0.9376 - val_loss: 2.8416 - val_accuracy: 0.3719\n",
      "Epoch 48/50\n",
      "4150/4150 [==============================] - 1s 145us/step - loss: 0.4189 - accuracy: 0.9629 - val_loss: 2.8961 - val_accuracy: 0.3680\n",
      "Epoch 49/50\n",
      "4150/4150 [==============================] - 1s 144us/step - loss: 0.4017 - accuracy: 0.9660 - val_loss: 2.9398 - val_accuracy: 0.3815\n",
      "Epoch 50/50\n",
      "4150/4150 [==============================] - 1s 143us/step - loss: 0.4036 - accuracy: 0.9675 - val_loss: 2.8976 - val_accuracy: 0.3825\n",
      "1038/1038 [==============================] - 0s 66us/step\n",
      "1038/1038 [==============================] - 0s 70us/step\n",
      " \n",
      "Train on 4147 samples, validate on 1037 samples\n",
      "Epoch 1/50\n",
      "4147/4147 [==============================] - 1s 210us/step - loss: 1.8620 - accuracy: 0.2206 - val_loss: 1.8180 - val_accuracy: 0.2469\n",
      "Epoch 2/50\n",
      "4147/4147 [==============================] - 1s 153us/step - loss: 1.7741 - accuracy: 0.2894 - val_loss: 1.7813 - val_accuracy: 0.2507\n",
      "Epoch 3/50\n",
      "4147/4147 [==============================] - 1s 146us/step - loss: 1.7189 - accuracy: 0.3395 - val_loss: 1.8052 - val_accuracy: 0.2633\n",
      "Epoch 4/50\n",
      "4147/4147 [==============================] - 1s 145us/step - loss: 1.6641 - accuracy: 0.3902 - val_loss: 1.8306 - val_accuracy: 0.2729\n",
      "Epoch 5/50\n",
      "4147/4147 [==============================] - 1s 144us/step - loss: 1.5961 - accuracy: 0.4297 - val_loss: 1.8584 - val_accuracy: 0.2739\n",
      "Epoch 6/50\n",
      "4147/4147 [==============================] - 1s 146us/step - loss: 1.5014 - accuracy: 0.4939 - val_loss: 2.0433 - val_accuracy: 0.2623\n",
      "Epoch 7/50\n",
      "4147/4147 [==============================] - 1s 146us/step - loss: 1.4112 - accuracy: 0.5575 - val_loss: 2.0204 - val_accuracy: 0.2960\n",
      "Epoch 8/50\n",
      "4147/4147 [==============================] - 1s 145us/step - loss: 1.2988 - accuracy: 0.6197 - val_loss: 2.1145 - val_accuracy: 0.2912\n",
      "Epoch 9/50\n",
      "4147/4147 [==============================] - 1s 145us/step - loss: 1.1938 - accuracy: 0.6805 - val_loss: 2.3629 - val_accuracy: 0.2797\n",
      "Epoch 10/50\n",
      "4147/4147 [==============================] - 1s 144us/step - loss: 1.0931 - accuracy: 0.7270 - val_loss: 2.3130 - val_accuracy: 0.2739\n",
      "Epoch 11/50\n",
      "4147/4147 [==============================] - 1s 144us/step - loss: 1.0030 - accuracy: 0.7762 - val_loss: 2.3835 - val_accuracy: 0.2642\n",
      "Epoch 12/50\n",
      "4147/4147 [==============================] - 1s 146us/step - loss: 0.9437 - accuracy: 0.8100 - val_loss: 2.6176 - val_accuracy: 0.2671\n",
      "Epoch 13/50\n",
      "4147/4147 [==============================] - 1s 144us/step - loss: 0.8800 - accuracy: 0.8437 - val_loss: 2.5870 - val_accuracy: 0.2797\n",
      "Epoch 14/50\n",
      "4147/4147 [==============================] - 1s 144us/step - loss: 0.8267 - accuracy: 0.8712 - val_loss: 2.6803 - val_accuracy: 0.2729\n",
      "Epoch 15/50\n",
      "4147/4147 [==============================] - 1s 145us/step - loss: 0.7624 - accuracy: 0.8905 - val_loss: 3.0155 - val_accuracy: 0.2642\n",
      "Epoch 16/50\n",
      "4147/4147 [==============================] - 1s 144us/step - loss: 0.7377 - accuracy: 0.8997 - val_loss: 2.9018 - val_accuracy: 0.2449\n",
      "Epoch 17/50\n",
      "4147/4147 [==============================] - 1s 145us/step - loss: 0.6869 - accuracy: 0.9183 - val_loss: 2.9114 - val_accuracy: 0.2584\n",
      "Epoch 18/50\n",
      "4147/4147 [==============================] - 1s 145us/step - loss: 0.6699 - accuracy: 0.9228 - val_loss: 2.9371 - val_accuracy: 0.2748\n",
      "Epoch 19/50\n",
      "4147/4147 [==============================] - 1s 145us/step - loss: 0.6212 - accuracy: 0.9306 - val_loss: 3.0620 - val_accuracy: 0.2546\n",
      "Epoch 20/50\n",
      "4147/4147 [==============================] - 1s 144us/step - loss: 0.6413 - accuracy: 0.9250 - val_loss: 2.9852 - val_accuracy: 0.2652\n",
      "Epoch 21/50\n",
      "4147/4147 [==============================] - 1s 145us/step - loss: 0.6002 - accuracy: 0.9313 - val_loss: 3.1023 - val_accuracy: 0.2681\n",
      "Epoch 22/50\n",
      "4147/4147 [==============================] - 1s 144us/step - loss: 0.6210 - accuracy: 0.9308 - val_loss: 3.1720 - val_accuracy: 0.2575\n",
      "Epoch 23/50\n",
      "4147/4147 [==============================] - 1s 144us/step - loss: 0.6165 - accuracy: 0.9315 - val_loss: 3.2375 - val_accuracy: 0.2642\n",
      "Epoch 24/50\n",
      "4147/4147 [==============================] - 1s 143us/step - loss: 0.5998 - accuracy: 0.9277 - val_loss: 3.1501 - val_accuracy: 0.2642\n",
      "Epoch 25/50\n",
      "4147/4147 [==============================] - 1s 144us/step - loss: 0.5941 - accuracy: 0.9308 - val_loss: 3.4982 - val_accuracy: 0.2459\n",
      "Epoch 26/50\n",
      "4147/4147 [==============================] - 1s 144us/step - loss: 0.5915 - accuracy: 0.9310 - val_loss: 3.2369 - val_accuracy: 0.2498\n",
      "Epoch 27/50\n",
      "4147/4147 [==============================] - 1s 143us/step - loss: 0.5655 - accuracy: 0.9322 - val_loss: 3.2656 - val_accuracy: 0.2565\n",
      "Epoch 28/50\n",
      "4147/4147 [==============================] - 1s 145us/step - loss: 0.5665 - accuracy: 0.9354 - val_loss: 3.3297 - val_accuracy: 0.2546\n",
      "Epoch 29/50\n",
      "4147/4147 [==============================] - 1s 143us/step - loss: 0.5649 - accuracy: 0.9395 - val_loss: 3.3792 - val_accuracy: 0.2498\n",
      "Epoch 30/50\n",
      "4147/4147 [==============================] - 1s 142us/step - loss: 0.5455 - accuracy: 0.9438 - val_loss: 3.5233 - val_accuracy: 0.2411\n",
      "Epoch 31/50\n",
      "4147/4147 [==============================] - 1s 143us/step - loss: 0.5587 - accuracy: 0.9371 - val_loss: 3.4470 - val_accuracy: 0.2478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50\n",
      "4147/4147 [==============================] - 1s 143us/step - loss: 0.5278 - accuracy: 0.9424 - val_loss: 3.3160 - val_accuracy: 0.2459\n",
      "Epoch 33/50\n",
      "4147/4147 [==============================] - 1s 142us/step - loss: 0.5145 - accuracy: 0.9448 - val_loss: 3.4168 - val_accuracy: 0.2401\n",
      "Epoch 34/50\n",
      "4147/4147 [==============================] - 1s 143us/step - loss: 0.4963 - accuracy: 0.9482 - val_loss: 3.5679 - val_accuracy: 0.2334\n",
      "Epoch 35/50\n",
      "4147/4147 [==============================] - 1s 143us/step - loss: 0.5021 - accuracy: 0.9419 - val_loss: 3.4408 - val_accuracy: 0.2411\n",
      "Epoch 36/50\n",
      "4147/4147 [==============================] - 1s 143us/step - loss: 0.5446 - accuracy: 0.9301 - val_loss: 3.4587 - val_accuracy: 0.2314\n",
      "Epoch 37/50\n",
      "4147/4147 [==============================] - 1s 145us/step - loss: 0.5121 - accuracy: 0.9409 - val_loss: 3.4612 - val_accuracy: 0.2382\n",
      "Epoch 38/50\n",
      "4147/4147 [==============================] - 1s 147us/step - loss: 0.5051 - accuracy: 0.9436 - val_loss: 3.5009 - val_accuracy: 0.2430\n",
      "Epoch 39/50\n",
      "4147/4147 [==============================] - 1s 143us/step - loss: 0.4894 - accuracy: 0.9450 - val_loss: 3.6283 - val_accuracy: 0.2459\n",
      "Epoch 40/50\n",
      "4147/4147 [==============================] - 1s 143us/step - loss: 0.5107 - accuracy: 0.9366 - val_loss: 3.6001 - val_accuracy: 0.2575\n",
      "Epoch 41/50\n",
      "4147/4147 [==============================] - 1s 144us/step - loss: 0.5482 - accuracy: 0.9327 - val_loss: 3.5494 - val_accuracy: 0.2517\n",
      "Epoch 42/50\n",
      "4147/4147 [==============================] - 1s 142us/step - loss: 0.5124 - accuracy: 0.9419 - val_loss: 3.5327 - val_accuracy: 0.2469\n",
      "Epoch 43/50\n",
      "4147/4147 [==============================] - 1s 143us/step - loss: 0.5205 - accuracy: 0.9388 - val_loss: 3.6232 - val_accuracy: 0.2488\n",
      "Epoch 44/50\n",
      "4147/4147 [==============================] - 1s 142us/step - loss: 0.5069 - accuracy: 0.9409 - val_loss: 3.5403 - val_accuracy: 0.2478\n",
      "Epoch 45/50\n",
      "4147/4147 [==============================] - 1s 143us/step - loss: 0.5060 - accuracy: 0.9421 - val_loss: 3.6305 - val_accuracy: 0.2324\n",
      "Epoch 46/50\n",
      "4147/4147 [==============================] - 1s 142us/step - loss: 0.5080 - accuracy: 0.9375 - val_loss: 3.4984 - val_accuracy: 0.2546\n",
      "Epoch 47/50\n",
      "4147/4147 [==============================] - 1s 144us/step - loss: 0.5235 - accuracy: 0.9373 - val_loss: 3.7737 - val_accuracy: 0.2343\n",
      "Epoch 48/50\n",
      "4147/4147 [==============================] - 1s 141us/step - loss: 0.4873 - accuracy: 0.9457 - val_loss: 3.5008 - val_accuracy: 0.2459\n",
      "Epoch 49/50\n",
      "4147/4147 [==============================] - 1s 144us/step - loss: 0.4824 - accuracy: 0.9496 - val_loss: 3.6922 - val_accuracy: 0.2372\n",
      "Epoch 50/50\n",
      "4147/4147 [==============================] - 1s 142us/step - loss: 0.4713 - accuracy: 0.9460 - val_loss: 3.8647 - val_accuracy: 0.2498\n",
      "1037/1037 [==============================] - 0s 67us/step\n",
      "1037/1037 [==============================] - 0s 69us/step\n",
      " \n",
      "Train on 4148 samples, validate on 1037 samples\n",
      "Epoch 1/50\n",
      "4148/4148 [==============================] - 1s 156us/step - loss: 1.8323 - accuracy: 0.2780 - val_loss: 1.7457 - val_accuracy: 0.3645\n",
      "Epoch 2/50\n",
      "4148/4148 [==============================] - 0s 95us/step - loss: 1.6795 - accuracy: 0.3710 - val_loss: 1.6562 - val_accuracy: 0.3703\n",
      "Epoch 3/50\n",
      "4148/4148 [==============================] - 0s 105us/step - loss: 1.5893 - accuracy: 0.4298 - val_loss: 1.6388 - val_accuracy: 0.3848\n",
      "Epoch 4/50\n",
      "4148/4148 [==============================] - 1s 121us/step - loss: 1.5150 - accuracy: 0.4776 - val_loss: 1.6560 - val_accuracy: 0.4041\n",
      "Epoch 5/50\n",
      "4148/4148 [==============================] - 0s 119us/step - loss: 1.4370 - accuracy: 0.5234 - val_loss: 1.6665 - val_accuracy: 0.4262\n",
      "Epoch 6/50\n",
      "4148/4148 [==============================] - 0s 111us/step - loss: 1.3370 - accuracy: 0.5735 - val_loss: 1.7500 - val_accuracy: 0.4060\n",
      "Epoch 7/50\n",
      "4148/4148 [==============================] - 0s 107us/step - loss: 1.2550 - accuracy: 0.6205 - val_loss: 1.8016 - val_accuracy: 0.4002\n",
      "Epoch 8/50\n",
      "4148/4148 [==============================] - 1s 136us/step - loss: 1.1515 - accuracy: 0.6726 - val_loss: 1.9135 - val_accuracy: 0.4050\n",
      "Epoch 9/50\n",
      "4148/4148 [==============================] - 1s 148us/step - loss: 1.0659 - accuracy: 0.7206 - val_loss: 1.9739 - val_accuracy: 0.3963\n",
      "Epoch 10/50\n",
      "4148/4148 [==============================] - 1s 175us/step - loss: 0.9832 - accuracy: 0.7674 - val_loss: 2.1157 - val_accuracy: 0.4012\n",
      "Epoch 11/50\n",
      "4148/4148 [==============================] - 1s 146us/step - loss: 0.9266 - accuracy: 0.7982 - val_loss: 2.2383 - val_accuracy: 0.3877\n",
      "Epoch 12/50\n",
      "4148/4148 [==============================] - 1s 153us/step - loss: 0.8544 - accuracy: 0.8387 - val_loss: 2.2783 - val_accuracy: 0.4002\n",
      "Epoch 13/50\n",
      "4148/4148 [==============================] - 1s 163us/step - loss: 0.8120 - accuracy: 0.8558 - val_loss: 2.3686 - val_accuracy: 0.3799\n",
      "Epoch 14/50\n",
      "4148/4148 [==============================] - 1s 153us/step - loss: 0.7401 - accuracy: 0.8799 - val_loss: 2.4356 - val_accuracy: 0.3809\n",
      "Epoch 15/50\n",
      "4148/4148 [==============================] - 1s 158us/step - loss: 0.7343 - accuracy: 0.8879 - val_loss: 2.4597 - val_accuracy: 0.3925\n",
      "Epoch 16/50\n",
      "4148/4148 [==============================] - 1s 154us/step - loss: 0.6840 - accuracy: 0.9045 - val_loss: 2.4332 - val_accuracy: 0.3809\n",
      "Epoch 17/50\n",
      "4148/4148 [==============================] - 1s 157us/step - loss: 0.6547 - accuracy: 0.9067 - val_loss: 2.4635 - val_accuracy: 0.3828\n",
      "Epoch 18/50\n",
      "4148/4148 [==============================] - 1s 155us/step - loss: 0.6337 - accuracy: 0.9180 - val_loss: 2.5110 - val_accuracy: 0.3770\n",
      "Epoch 19/50\n",
      "4148/4148 [==============================] - 1s 155us/step - loss: 0.6049 - accuracy: 0.9241 - val_loss: 2.6703 - val_accuracy: 0.3751\n",
      "Epoch 20/50\n",
      "4148/4148 [==============================] - 1s 159us/step - loss: 0.5976 - accuracy: 0.9221 - val_loss: 2.6578 - val_accuracy: 0.3828\n",
      "Epoch 21/50\n",
      "4148/4148 [==============================] - 1s 156us/step - loss: 0.5957 - accuracy: 0.9204 - val_loss: 2.7664 - val_accuracy: 0.3867\n",
      "Epoch 22/50\n",
      "4148/4148 [==============================] - 1s 157us/step - loss: 0.5971 - accuracy: 0.9192 - val_loss: 2.6609 - val_accuracy: 0.3819\n",
      "Epoch 23/50\n",
      "4148/4148 [==============================] - 1s 147us/step - loss: 0.5955 - accuracy: 0.9243 - val_loss: 2.7114 - val_accuracy: 0.3954\n",
      "Epoch 24/50\n",
      "4148/4148 [==============================] - 1s 148us/step - loss: 0.5778 - accuracy: 0.9274 - val_loss: 2.8261 - val_accuracy: 0.3963\n",
      "Epoch 25/50\n",
      "4148/4148 [==============================] - 1s 150us/step - loss: 0.5419 - accuracy: 0.9318 - val_loss: 2.8910 - val_accuracy: 0.3838\n",
      "Epoch 26/50\n",
      "4148/4148 [==============================] - 1s 148us/step - loss: 0.5511 - accuracy: 0.9371 - val_loss: 2.8137 - val_accuracy: 0.3867\n",
      "Epoch 27/50\n",
      "4148/4148 [==============================] - 1s 147us/step - loss: 0.5044 - accuracy: 0.9417 - val_loss: 2.9019 - val_accuracy: 0.3799\n",
      "Epoch 28/50\n",
      "4148/4148 [==============================] - 1s 149us/step - loss: 0.5337 - accuracy: 0.9332 - val_loss: 2.8545 - val_accuracy: 0.3770\n",
      "Epoch 29/50\n",
      "4148/4148 [==============================] - 1s 150us/step - loss: 0.5126 - accuracy: 0.9388 - val_loss: 3.1666 - val_accuracy: 0.3809\n",
      "Epoch 30/50\n",
      "4148/4148 [==============================] - 1s 148us/step - loss: 0.5280 - accuracy: 0.9339 - val_loss: 3.0866 - val_accuracy: 0.3915\n",
      "Epoch 31/50\n",
      "4148/4148 [==============================] - 1s 150us/step - loss: 0.5341 - accuracy: 0.9313 - val_loss: 3.1558 - val_accuracy: 0.3915\n",
      "Epoch 32/50\n",
      "4148/4148 [==============================] - 1s 150us/step - loss: 0.5295 - accuracy: 0.9395 - val_loss: 3.0951 - val_accuracy: 0.3790\n",
      "Epoch 33/50\n",
      "4148/4148 [==============================] - 1s 149us/step - loss: 0.5198 - accuracy: 0.9356 - val_loss: 3.1187 - val_accuracy: 0.3751\n",
      "Epoch 34/50\n",
      "4148/4148 [==============================] - 1s 150us/step - loss: 0.5534 - accuracy: 0.9250 - val_loss: 2.9789 - val_accuracy: 0.3780\n",
      "Epoch 35/50\n",
      "4148/4148 [==============================] - 1s 148us/step - loss: 0.5246 - accuracy: 0.9371 - val_loss: 3.0275 - val_accuracy: 0.3857\n",
      "Epoch 36/50\n",
      "4148/4148 [==============================] - 1s 150us/step - loss: 0.4972 - accuracy: 0.9390 - val_loss: 3.0882 - val_accuracy: 0.3761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50\n",
      "4148/4148 [==============================] - 1s 142us/step - loss: 0.4754 - accuracy: 0.9453 - val_loss: 3.0623 - val_accuracy: 0.3963\n",
      "Epoch 38/50\n",
      "4148/4148 [==============================] - 1s 141us/step - loss: 0.4833 - accuracy: 0.9455 - val_loss: 3.2391 - val_accuracy: 0.3674\n",
      "Epoch 39/50\n",
      "4148/4148 [==============================] - 1s 140us/step - loss: 0.4865 - accuracy: 0.9462 - val_loss: 3.2109 - val_accuracy: 0.3751\n",
      "Epoch 40/50\n",
      "4148/4148 [==============================] - 1s 143us/step - loss: 0.5009 - accuracy: 0.9347 - val_loss: 3.2320 - val_accuracy: 0.3626\n",
      "Epoch 41/50\n",
      "4148/4148 [==============================] - 1s 141us/step - loss: 0.5135 - accuracy: 0.9298 - val_loss: 3.1147 - val_accuracy: 0.3703\n",
      "Epoch 42/50\n",
      "4148/4148 [==============================] - 1s 140us/step - loss: 0.4988 - accuracy: 0.9339 - val_loss: 3.1789 - val_accuracy: 0.3578\n",
      "Epoch 43/50\n",
      "4148/4148 [==============================] - 1s 142us/step - loss: 0.4967 - accuracy: 0.9513 - val_loss: 3.0146 - val_accuracy: 0.3780\n",
      "Epoch 44/50\n",
      "4148/4148 [==============================] - 1s 149us/step - loss: 0.4685 - accuracy: 0.9458 - val_loss: 3.2297 - val_accuracy: 0.3693\n",
      "Epoch 45/50\n",
      "4148/4148 [==============================] - 1s 142us/step - loss: 0.4745 - accuracy: 0.9426 - val_loss: 3.3818 - val_accuracy: 0.3828\n",
      "Epoch 46/50\n",
      "4148/4148 [==============================] - 1s 148us/step - loss: 0.4806 - accuracy: 0.9450 - val_loss: 3.1294 - val_accuracy: 0.3693\n",
      "Epoch 47/50\n",
      "4148/4148 [==============================] - 1s 143us/step - loss: 0.4591 - accuracy: 0.9446 - val_loss: 3.0964 - val_accuracy: 0.3799\n",
      "Epoch 48/50\n",
      "4148/4148 [==============================] - 1s 149us/step - loss: 0.4354 - accuracy: 0.9518 - val_loss: 3.1997 - val_accuracy: 0.3838\n",
      "Epoch 49/50\n",
      "4148/4148 [==============================] - 1s 147us/step - loss: 0.4218 - accuracy: 0.9568 - val_loss: 3.3153 - val_accuracy: 0.3828\n",
      "Epoch 50/50\n",
      "4148/4148 [==============================] - 1s 142us/step - loss: 0.4592 - accuracy: 0.9511 - val_loss: 3.3459 - val_accuracy: 0.3799\n",
      "1037/1037 [==============================] - 0s 69us/step\n",
      "1037/1037 [==============================] - 0s 71us/step\n",
      " \n",
      "Train on 4147 samples, validate on 1037 samples\n",
      "Epoch 1/50\n",
      "4147/4147 [==============================] - 1s 256us/step - loss: 1.8370 - accuracy: 0.2780 - val_loss: 1.7944 - val_accuracy: 0.3211\n",
      "Epoch 2/50\n",
      "4147/4147 [==============================] - 1s 147us/step - loss: 1.6660 - accuracy: 0.3928 - val_loss: 1.6792 - val_accuracy: 0.3809\n",
      "Epoch 3/50\n",
      "4147/4147 [==============================] - 1s 144us/step - loss: 1.5434 - accuracy: 0.4693 - val_loss: 1.6727 - val_accuracy: 0.3973\n",
      "Epoch 4/50\n",
      "4147/4147 [==============================] - 1s 144us/step - loss: 1.4465 - accuracy: 0.5093 - val_loss: 1.6922 - val_accuracy: 0.3963\n",
      "Epoch 5/50\n",
      "4147/4147 [==============================] - 1s 143us/step - loss: 1.3555 - accuracy: 0.5462 - val_loss: 1.7584 - val_accuracy: 0.3896\n",
      "Epoch 6/50\n",
      "4147/4147 [==============================] - 1s 144us/step - loss: 1.2722 - accuracy: 0.5966 - val_loss: 1.7426 - val_accuracy: 0.3905\n",
      "Epoch 7/50\n",
      "4147/4147 [==============================] - 1s 144us/step - loss: 1.1919 - accuracy: 0.6422 - val_loss: 1.8422 - val_accuracy: 0.3655\n",
      "Epoch 8/50\n",
      "4147/4147 [==============================] - 1s 142us/step - loss: 1.1087 - accuracy: 0.6752 - val_loss: 1.8783 - val_accuracy: 0.3799\n",
      "Epoch 9/50\n",
      "4147/4147 [==============================] - 1s 144us/step - loss: 1.0463 - accuracy: 0.7075 - val_loss: 1.9570 - val_accuracy: 0.3703\n",
      "Epoch 10/50\n",
      "4147/4147 [==============================] - 1s 144us/step - loss: 0.9571 - accuracy: 0.7560 - val_loss: 2.0141 - val_accuracy: 0.3722\n",
      "Epoch 11/50\n",
      "4147/4147 [==============================] - 1s 143us/step - loss: 0.9057 - accuracy: 0.7794 - val_loss: 2.0289 - val_accuracy: 0.3635\n",
      "Epoch 12/50\n",
      "4147/4147 [==============================] - 1s 144us/step - loss: 0.8488 - accuracy: 0.7974 - val_loss: 2.1877 - val_accuracy: 0.3635\n",
      "Epoch 13/50\n",
      "4147/4147 [==============================] - 1s 143us/step - loss: 0.7899 - accuracy: 0.8271 - val_loss: 2.1125 - val_accuracy: 0.3674\n",
      "Epoch 14/50\n",
      "4147/4147 [==============================] - 1s 143us/step - loss: 0.7594 - accuracy: 0.8392 - val_loss: 2.2584 - val_accuracy: 0.3635\n",
      "Epoch 15/50\n",
      "4147/4147 [==============================] - 1s 143us/step - loss: 0.7413 - accuracy: 0.8389 - val_loss: 2.3327 - val_accuracy: 0.3472\n",
      "Epoch 16/50\n",
      "4147/4147 [==============================] - 1s 144us/step - loss: 0.7273 - accuracy: 0.8522 - val_loss: 2.4781 - val_accuracy: 0.3578\n",
      "Epoch 17/50\n",
      "4147/4147 [==============================] - 1s 145us/step - loss: 0.6608 - accuracy: 0.8847 - val_loss: 2.5692 - val_accuracy: 0.3414\n",
      "Epoch 18/50\n",
      "4147/4147 [==============================] - 1s 143us/step - loss: 0.6409 - accuracy: 0.8879 - val_loss: 2.5497 - val_accuracy: 0.3645\n",
      "Epoch 19/50\n",
      "4147/4147 [==============================] - 1s 143us/step - loss: 0.6462 - accuracy: 0.8794 - val_loss: 2.5411 - val_accuracy: 0.3365\n",
      "Epoch 20/50\n",
      "4147/4147 [==============================] - 1s 144us/step - loss: 0.6134 - accuracy: 0.8896 - val_loss: 2.5771 - val_accuracy: 0.3520\n",
      "Epoch 21/50\n",
      "4147/4147 [==============================] - 1s 144us/step - loss: 0.6192 - accuracy: 0.8922 - val_loss: 2.7168 - val_accuracy: 0.3462\n",
      "Epoch 22/50\n",
      "4147/4147 [==============================] - 1s 145us/step - loss: 0.6289 - accuracy: 0.8908 - val_loss: 2.7731 - val_accuracy: 0.3578\n",
      "Epoch 23/50\n",
      "4147/4147 [==============================] - 1s 145us/step - loss: 0.5922 - accuracy: 0.9067 - val_loss: 2.6196 - val_accuracy: 0.3500\n",
      "Epoch 24/50\n",
      "4147/4147 [==============================] - 1s 145us/step - loss: 0.5836 - accuracy: 0.9033 - val_loss: 2.6642 - val_accuracy: 0.3356\n",
      "Epoch 25/50\n",
      "4147/4147 [==============================] - 1s 144us/step - loss: 0.5757 - accuracy: 0.9055 - val_loss: 2.7890 - val_accuracy: 0.3327\n",
      "Epoch 26/50\n",
      "4147/4147 [==============================] - 1s 144us/step - loss: 0.5563 - accuracy: 0.9064 - val_loss: 2.6150 - val_accuracy: 0.3365\n",
      "Epoch 27/50\n",
      "4147/4147 [==============================] - 1s 145us/step - loss: 0.5350 - accuracy: 0.9120 - val_loss: 2.7264 - val_accuracy: 0.3500\n",
      "Epoch 28/50\n",
      "4147/4147 [==============================] - 1s 143us/step - loss: 0.5526 - accuracy: 0.9023 - val_loss: 2.7895 - val_accuracy: 0.3346\n",
      "Epoch 29/50\n",
      "4147/4147 [==============================] - 1s 144us/step - loss: 0.5241 - accuracy: 0.9180 - val_loss: 2.8027 - val_accuracy: 0.3317\n",
      "Epoch 30/50\n",
      "4147/4147 [==============================] - 1s 144us/step - loss: 0.5242 - accuracy: 0.9146 - val_loss: 2.9137 - val_accuracy: 0.3385\n",
      "Epoch 31/50\n",
      "4147/4147 [==============================] - 1s 143us/step - loss: 0.5127 - accuracy: 0.9192 - val_loss: 3.0262 - val_accuracy: 0.3394\n",
      "Epoch 32/50\n",
      "4147/4147 [==============================] - 1s 143us/step - loss: 0.5497 - accuracy: 0.9045 - val_loss: 2.8656 - val_accuracy: 0.3375\n",
      "Epoch 33/50\n",
      "4147/4147 [==============================] - 1s 142us/step - loss: 0.5295 - accuracy: 0.9170 - val_loss: 3.0629 - val_accuracy: 0.3250\n",
      "Epoch 34/50\n",
      "4147/4147 [==============================] - 1s 143us/step - loss: 0.5410 - accuracy: 0.9081 - val_loss: 3.2266 - val_accuracy: 0.3240\n",
      "Epoch 35/50\n",
      "4147/4147 [==============================] - 1s 144us/step - loss: 0.4961 - accuracy: 0.9281 - val_loss: 2.9729 - val_accuracy: 0.3211\n",
      "Epoch 36/50\n",
      "4147/4147 [==============================] - 1s 143us/step - loss: 0.4955 - accuracy: 0.9211 - val_loss: 2.9338 - val_accuracy: 0.3317\n",
      "Epoch 37/50\n",
      "4147/4147 [==============================] - 1s 142us/step - loss: 0.4912 - accuracy: 0.9226 - val_loss: 2.9621 - val_accuracy: 0.3250\n",
      "Epoch 38/50\n",
      "4147/4147 [==============================] - 1s 143us/step - loss: 0.4729 - accuracy: 0.9274 - val_loss: 2.8418 - val_accuracy: 0.3404\n",
      "Epoch 39/50\n",
      "4147/4147 [==============================] - 1s 141us/step - loss: 0.4741 - accuracy: 0.9308 - val_loss: 2.8655 - val_accuracy: 0.3481\n",
      "Epoch 40/50\n",
      "4147/4147 [==============================] - 1s 142us/step - loss: 0.4736 - accuracy: 0.9238 - val_loss: 2.9753 - val_accuracy: 0.3327\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4147/4147 [==============================] - 1s 143us/step - loss: 0.4809 - accuracy: 0.9286 - val_loss: 3.1803 - val_accuracy: 0.3298\n",
      "Epoch 42/50\n",
      "4147/4147 [==============================] - 1s 143us/step - loss: 0.4893 - accuracy: 0.9207 - val_loss: 3.0862 - val_accuracy: 0.3327\n",
      "Epoch 43/50\n",
      "4147/4147 [==============================] - 1s 144us/step - loss: 0.5023 - accuracy: 0.9122 - val_loss: 3.1594 - val_accuracy: 0.3317\n",
      "Epoch 44/50\n",
      "4147/4147 [==============================] - 1s 143us/step - loss: 0.4836 - accuracy: 0.9151 - val_loss: 3.1032 - val_accuracy: 0.3404\n",
      "Epoch 45/50\n",
      "4147/4147 [==============================] - 1s 145us/step - loss: 0.5126 - accuracy: 0.9093 - val_loss: 3.2201 - val_accuracy: 0.3337\n",
      "Epoch 46/50\n",
      "4147/4147 [==============================] - 1s 144us/step - loss: 0.4882 - accuracy: 0.9286 - val_loss: 3.4056 - val_accuracy: 0.3375\n",
      "Epoch 47/50\n",
      "4147/4147 [==============================] - 1s 144us/step - loss: 0.5029 - accuracy: 0.9211 - val_loss: 3.1483 - val_accuracy: 0.3337\n",
      "Epoch 48/50\n",
      "4147/4147 [==============================] - 1s 144us/step - loss: 0.4570 - accuracy: 0.9380 - val_loss: 3.1522 - val_accuracy: 0.3481\n",
      "Epoch 49/50\n",
      "4147/4147 [==============================] - 1s 144us/step - loss: 0.4435 - accuracy: 0.9388 - val_loss: 3.3166 - val_accuracy: 0.3472\n",
      "Epoch 50/50\n",
      "4147/4147 [==============================] - 1s 142us/step - loss: 0.4483 - accuracy: 0.9363 - val_loss: 3.1012 - val_accuracy: 0.3462\n",
      "1037/1037 [==============================] - 0s 68us/step\n",
      "1037/1037 [==============================] - 0s 70us/step\n",
      " \n",
      "Accuracy: 32.97\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 468x468 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "keep_accuracy = np.zeros((10))\n",
    "j = 0\n",
    "\n",
    "for participant in files:\n",
    "    mat = loadmat(participant)\n",
    "    X_2D = np.array(mat[\"X_2D\"])\n",
    "    categoryLabels = np.array(mat[\"categoryLabels\"])     # get labels\n",
    "\n",
    "    k = 180\n",
    "    X = X_2D.copy()\n",
    "    y = categoryLabels.ravel()\n",
    "    X -= np.mean(X, axis=0)\n",
    "\n",
    "    [u,s,v] = la.svd(X)                                   # pca with svd, using an optimum k\n",
    "    v = v.transpose() \n",
    "    v_new = v[:,:k]\n",
    "    X_pca = np.dot(X, v_new)\n",
    "\n",
    "\n",
    "    X_training = X_pca[:int(0.8*len(X_pca))]              # create train and test sets\n",
    "    X_validation = X_pca[int(0.8*len(X_pca)):]\n",
    "\n",
    "    y_training = y[:int(0.8*len(X_pca))]\n",
    "    y_validation = y[int(0.8*len(X_pca)):]\n",
    "\n",
    "    X_training = np.reshape(X_training, (-1, 30, 6, 1))\n",
    "    X_validation = np.reshape(X_validation, (-1, 30, 6, 1))\n",
    "\n",
    "    num_classes = 6\n",
    "    y_training1hot = keras.utils.to_categorical(y_training - 1, num_classes)      # subtract 1 to convert to 0-index\n",
    "    y_validation1hot = keras.utils.to_categorical(y_validation - 1, num_classes)\n",
    "\n",
    "    # cnn model\n",
    "    model = Sequential()                                                        \n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=X_training.shape[1:],  activation = \"relu\"))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=128,kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "                    bias_regularizer=regularizers.l2(1e-3),\n",
    "                    activity_regularizer=regularizers.l2(1e-3),\n",
    "                    activation = \"relu\"))\n",
    "    model.add(Dropout(0.15))\n",
    "    model.add(Dense(units=num_classes,activity_regularizer=regularizers.l2(1e-5),  activation = \"softmax\"))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='nadam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_training, y_training1hot,                                       # train the model\n",
    "              epochs=50, \n",
    "              validation_data=(X_validation, y_validation1hot), \n",
    "              shuffle=True)\n",
    "    \n",
    "    y_validation_predictions = model.predict(X_validation, verbose=1)           # make predictions\n",
    "    \n",
    "    # create the confusion matrix\n",
    "    cnf_matrix2 = confusion_matrix(y_validation-1, np.argmax(y_validation_predictions, axis=1))\n",
    "    cm_cv2 += cnf_matrix2                                                      # add together all the confusion matrices\n",
    "    \n",
    "    _, accuracy = model.evaluate(X_validation, y_validation1hot)               # find accuracy\n",
    "    keep_accuracy[j] = accuracy\n",
    "    j = j + 1\n",
    "    print(\" \")\n",
    "    \n",
    "print('Accuracy: %.2f' % (np.mean(keep_accuracy)*100))                         # print mean accuracy\n",
    "\n",
    "sum_by_row = np.sum(cm_cv2, 1)                                                 # normalize the final confusion matrix\n",
    "for i in range(0,6):\n",
    "    cm_cv2[i,:] = cm_cv2[i,:] / sum_by_row[i]\n",
    "\n",
    "plot_cm(np.round(cm_cv2, 4),6)                                                 # plot the final confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.26601269, 0.1050202 , 0.16330063, 0.17599538, 0.13618003,\n",
       "        0.15349106],\n",
       "       [0.10511034, 0.49186992, 0.11149826, 0.1155633 , 0.09407666,\n",
       "        0.08188153],\n",
       "       [0.14442519, 0.08954362, 0.31484691, 0.16233391, 0.14095898,\n",
       "        0.14789139],\n",
       "       [0.11778291, 0.11893764, 0.17205543, 0.34872979, 0.12413395,\n",
       "        0.11836028],\n",
       "       [0.14838337, 0.07505774, 0.15704388, 0.12759815, 0.28637413,\n",
       "        0.20554273],\n",
       "       [0.15188406, 0.09275362, 0.17275362, 0.11188406, 0.19942029,\n",
       "        0.27130435]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA with Deep CNN\n",
    "\n",
    "Φτιάχνουμε ένα Deep CNN και το τρέχουμε πάλι για τις 6 κλάσεις, ενώ κάνουμε PCA με svd πριν, χρησιμοποιώντας k=180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4150 samples, validate on 1038 samples\n",
      "Epoch 1/50\n",
      "4150/4150 [==============================] - 3s 720us/step - loss: 1.8824 - accuracy: 0.1728 - val_loss: 4.4969 - val_accuracy: 0.1763\n",
      "Epoch 2/50\n",
      "4150/4150 [==============================] - 2s 385us/step - loss: 1.7989 - accuracy: 0.1988 - val_loss: 8.6101 - val_accuracy: 0.1599\n",
      "Epoch 3/50\n",
      "4150/4150 [==============================] - 2s 397us/step - loss: 1.7467 - accuracy: 0.2472 - val_loss: 3.9619 - val_accuracy: 0.1859\n",
      "Epoch 4/50\n",
      "4150/4150 [==============================] - 2s 397us/step - loss: 1.6966 - accuracy: 0.2805 - val_loss: 1.8843 - val_accuracy: 0.2669\n",
      "Epoch 5/50\n",
      "4150/4150 [==============================] - 2s 393us/step - loss: 1.6259 - accuracy: 0.3157 - val_loss: 1.6718 - val_accuracy: 0.2852\n",
      "Epoch 6/50\n",
      "4150/4150 [==============================] - 2s 394us/step - loss: 1.5466 - accuracy: 0.3530 - val_loss: 1.7091 - val_accuracy: 0.2582\n",
      "Epoch 7/50\n",
      "4150/4150 [==============================] - 2s 394us/step - loss: 1.4598 - accuracy: 0.3884 - val_loss: 1.6710 - val_accuracy: 0.3285\n",
      "Epoch 8/50\n",
      "4150/4150 [==============================] - 2s 392us/step - loss: 1.3429 - accuracy: 0.4407 - val_loss: 1.7735 - val_accuracy: 0.3333\n",
      "Epoch 9/50\n",
      "4150/4150 [==============================] - 2s 393us/step - loss: 1.2217 - accuracy: 0.5012 - val_loss: 1.7947 - val_accuracy: 0.3208\n",
      "Epoch 10/50\n",
      "4150/4150 [==============================] - 2s 393us/step - loss: 1.0831 - accuracy: 0.5670 - val_loss: 2.3518 - val_accuracy: 0.3304\n",
      "Epoch 11/50\n",
      "4150/4150 [==============================] - 2s 390us/step - loss: 0.9336 - accuracy: 0.6311 - val_loss: 1.9497 - val_accuracy: 0.3304\n",
      "Epoch 12/50\n",
      "4150/4150 [==============================] - 2s 389us/step - loss: 0.8103 - accuracy: 0.6805 - val_loss: 2.1207 - val_accuracy: 0.3247\n",
      "Epoch 13/50\n",
      "4150/4150 [==============================] - 2s 378us/step - loss: 0.6876 - accuracy: 0.7427 - val_loss: 2.3868 - val_accuracy: 0.3343\n",
      "Epoch 14/50\n",
      "4150/4150 [==============================] - 2s 376us/step - loss: 0.5706 - accuracy: 0.7814 - val_loss: 2.7935 - val_accuracy: 0.3218\n",
      "Epoch 15/50\n",
      "4150/4150 [==============================] - 2s 375us/step - loss: 0.4958 - accuracy: 0.8178 - val_loss: 2.6446 - val_accuracy: 0.3256\n",
      "Epoch 16/50\n",
      "4150/4150 [==============================] - 2s 376us/step - loss: 0.4200 - accuracy: 0.8504 - val_loss: 2.8202 - val_accuracy: 0.3314\n",
      "Epoch 17/50\n",
      "4150/4150 [==============================] - 2s 375us/step - loss: 0.3833 - accuracy: 0.8648 - val_loss: 3.1088 - val_accuracy: 0.3565\n",
      "Epoch 18/50\n",
      "4150/4150 [==============================] - 2s 377us/step - loss: 0.3520 - accuracy: 0.8742 - val_loss: 3.2143 - val_accuracy: 0.3574\n",
      "Epoch 19/50\n",
      "4150/4150 [==============================] - 2s 380us/step - loss: 0.2822 - accuracy: 0.9007 - val_loss: 3.2821 - val_accuracy: 0.3295\n",
      "Epoch 20/50\n",
      "4150/4150 [==============================] - 2s 378us/step - loss: 0.2411 - accuracy: 0.9157 - val_loss: 3.6612 - val_accuracy: 0.3150\n",
      "Epoch 21/50\n",
      "4150/4150 [==============================] - 2s 379us/step - loss: 0.2721 - accuracy: 0.9051 - val_loss: 3.5200 - val_accuracy: 0.3459\n",
      "Epoch 22/50\n",
      "4150/4150 [==============================] - 2s 380us/step - loss: 0.2389 - accuracy: 0.9207 - val_loss: 3.3984 - val_accuracy: 0.3247\n",
      "Epoch 23/50\n",
      "4150/4150 [==============================] - 2s 383us/step - loss: 0.1893 - accuracy: 0.9337 - val_loss: 4.2878 - val_accuracy: 0.3179\n",
      "Epoch 24/50\n",
      "4150/4150 [==============================] - 2s 381us/step - loss: 0.1589 - accuracy: 0.9448 - val_loss: 4.3434 - val_accuracy: 0.3516\n",
      "Epoch 25/50\n",
      "4150/4150 [==============================] - 2s 379us/step - loss: 0.1641 - accuracy: 0.9441 - val_loss: 5.6365 - val_accuracy: 0.3256\n",
      "Epoch 26/50\n",
      "4150/4150 [==============================] - 2s 383us/step - loss: 0.2112 - accuracy: 0.9318 - val_loss: 4.2313 - val_accuracy: 0.3343\n",
      "Epoch 27/50\n",
      "4150/4150 [==============================] - 2s 379us/step - loss: 0.2020 - accuracy: 0.9349 - val_loss: 3.5478 - val_accuracy: 0.3353\n",
      "Epoch 28/50\n",
      "4150/4150 [==============================] - 2s 429us/step - loss: 0.1614 - accuracy: 0.9434 - val_loss: 4.0301 - val_accuracy: 0.3285\n",
      "Epoch 29/50\n",
      "4150/4150 [==============================] - 2s 418us/step - loss: 0.1372 - accuracy: 0.9525 - val_loss: 4.7280 - val_accuracy: 0.3439\n",
      "Epoch 30/50\n",
      "4150/4150 [==============================] - 2s 434us/step - loss: 0.1328 - accuracy: 0.9554 - val_loss: 4.6596 - val_accuracy: 0.3526\n",
      "Epoch 31/50\n",
      "4150/4150 [==============================] - 2s 388us/step - loss: 0.1230 - accuracy: 0.9576 - val_loss: 4.3278 - val_accuracy: 0.3507\n",
      "Epoch 32/50\n",
      "4150/4150 [==============================] - 2s 378us/step - loss: 0.1408 - accuracy: 0.9588 - val_loss: 4.4026 - val_accuracy: 0.3719\n",
      "Epoch 33/50\n",
      "4150/4150 [==============================] - 2s 375us/step - loss: 0.1413 - accuracy: 0.9537 - val_loss: 4.5014 - val_accuracy: 0.3584\n",
      "Epoch 34/50\n",
      "4150/4150 [==============================] - 2s 402us/step - loss: 0.1150 - accuracy: 0.9634 - val_loss: 4.1756 - val_accuracy: 0.3430\n",
      "Epoch 35/50\n",
      "4150/4150 [==============================] - 2s 408us/step - loss: 0.1028 - accuracy: 0.9680 - val_loss: 4.7573 - val_accuracy: 0.3382\n",
      "Epoch 36/50\n",
      "4150/4150 [==============================] - 2s 417us/step - loss: 0.0985 - accuracy: 0.9639 - val_loss: 4.8837 - val_accuracy: 0.3593\n",
      "Epoch 37/50\n",
      "4150/4150 [==============================] - 2s 375us/step - loss: 0.0987 - accuracy: 0.9704 - val_loss: 4.8958 - val_accuracy: 0.3304\n",
      "Epoch 38/50\n",
      "4150/4150 [==============================] - 2s 422us/step - loss: 0.0882 - accuracy: 0.9694 - val_loss: 5.1020 - val_accuracy: 0.3324\n",
      "Epoch 39/50\n",
      "4150/4150 [==============================] - 2s 403us/step - loss: 0.0799 - accuracy: 0.9735 - val_loss: 5.4788 - val_accuracy: 0.3401\n",
      "Epoch 40/50\n",
      "4150/4150 [==============================] - 2s 423us/step - loss: 0.0828 - accuracy: 0.9725 - val_loss: 6.0602 - val_accuracy: 0.3680\n",
      "Epoch 41/50\n",
      "4150/4150 [==============================] - 2s 431us/step - loss: 0.0800 - accuracy: 0.9737 - val_loss: 5.8478 - val_accuracy: 0.3468\n",
      "Epoch 42/50\n",
      "4150/4150 [==============================] - 2s 380us/step - loss: 0.1016 - accuracy: 0.9699 - val_loss: 5.7992 - val_accuracy: 0.3478\n",
      "Epoch 43/50\n",
      "4150/4150 [==============================] - 2s 382us/step - loss: 0.1445 - accuracy: 0.9528 - val_loss: 5.0212 - val_accuracy: 0.3593\n",
      "Epoch 44/50\n",
      "4150/4150 [==============================] - 2s 395us/step - loss: 0.1422 - accuracy: 0.9542 - val_loss: 6.8614 - val_accuracy: 0.3661\n",
      "Epoch 45/50\n",
      "4150/4150 [==============================] - 2s 387us/step - loss: 0.1316 - accuracy: 0.9588 - val_loss: 4.3694 - val_accuracy: 0.3516\n",
      "Epoch 46/50\n",
      "4150/4150 [==============================] - 2s 383us/step - loss: 0.0566 - accuracy: 0.9795 - val_loss: 4.8783 - val_accuracy: 0.3478\n",
      "Epoch 47/50\n",
      "4150/4150 [==============================] - 2s 383us/step - loss: 0.0744 - accuracy: 0.9786 - val_loss: 5.4098 - val_accuracy: 0.3545\n",
      "Epoch 48/50\n",
      "4150/4150 [==============================] - 2s 387us/step - loss: 0.0626 - accuracy: 0.9805 - val_loss: 5.1181 - val_accuracy: 0.3545\n",
      "Epoch 49/50\n",
      "4150/4150 [==============================] - 2s 387us/step - loss: 0.0739 - accuracy: 0.9764 - val_loss: 4.8952 - val_accuracy: 0.3295\n",
      "Epoch 50/50\n",
      "4150/4150 [==============================] - 2s 386us/step - loss: 0.0846 - accuracy: 0.9795 - val_loss: 5.2507 - val_accuracy: 0.3372\n",
      "1038/1038 [==============================] - 0s 197us/step\n",
      "1038/1038 [==============================] - 0s 114us/step\n",
      " \n",
      "Train on 4148 samples, validate on 1037 samples\n",
      "Epoch 1/50\n",
      "4148/4148 [==============================] - 3s 699us/step - loss: 1.8417 - accuracy: 0.1996 - val_loss: 2.3449 - val_accuracy: 0.1659\n",
      "Epoch 2/50\n",
      "4148/4148 [==============================] - 2s 401us/step - loss: 1.7298 - accuracy: 0.2502 - val_loss: 3.2422 - val_accuracy: 0.2083\n",
      "Epoch 3/50\n",
      "4148/4148 [==============================] - 2s 400us/step - loss: 1.6578 - accuracy: 0.3100 - val_loss: 5.1781 - val_accuracy: 0.1765\n",
      "Epoch 4/50\n",
      "4148/4148 [==============================] - 2s 427us/step - loss: 1.5460 - accuracy: 0.3662 - val_loss: 2.9699 - val_accuracy: 0.2392\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4148/4148 [==============================] - 2s 405us/step - loss: 1.4496 - accuracy: 0.4163 - val_loss: 1.8086 - val_accuracy: 0.3086\n",
      "Epoch 6/50\n",
      "4148/4148 [==============================] - 2s 368us/step - loss: 1.3227 - accuracy: 0.4675 - val_loss: 1.7344 - val_accuracy: 0.3385\n",
      "Epoch 7/50\n",
      "4148/4148 [==============================] - 2s 370us/step - loss: 1.1880 - accuracy: 0.5304 - val_loss: 1.8278 - val_accuracy: 0.3153\n",
      "Epoch 8/50\n",
      "4148/4148 [==============================] - 2s 376us/step - loss: 1.0465 - accuracy: 0.5841 - val_loss: 2.0568 - val_accuracy: 0.3028\n",
      "Epoch 9/50\n",
      "4148/4148 [==============================] - 2s 384us/step - loss: 0.8716 - accuracy: 0.6649 - val_loss: 2.1804 - val_accuracy: 0.3182\n",
      "Epoch 10/50\n",
      "4148/4148 [==============================] - 2s 424us/step - loss: 0.7575 - accuracy: 0.7081 - val_loss: 2.4189 - val_accuracy: 0.3182\n",
      "Epoch 11/50\n",
      "4148/4148 [==============================] - 2s 403us/step - loss: 0.6809 - accuracy: 0.7322 - val_loss: 3.0393 - val_accuracy: 0.3095\n",
      "Epoch 12/50\n",
      "4148/4148 [==============================] - 2s 394us/step - loss: 0.6031 - accuracy: 0.7739 - val_loss: 2.6912 - val_accuracy: 0.3124\n",
      "Epoch 13/50\n",
      "4148/4148 [==============================] - 2s 387us/step - loss: 0.5444 - accuracy: 0.7975 - val_loss: 2.2909 - val_accuracy: 0.3144\n",
      "Epoch 14/50\n",
      "4148/4148 [==============================] - 2s 386us/step - loss: 0.5015 - accuracy: 0.8151 - val_loss: 2.3994 - val_accuracy: 0.2700\n",
      "Epoch 15/50\n",
      "4148/4148 [==============================] - 2s 382us/step - loss: 0.4778 - accuracy: 0.8274 - val_loss: 3.0866 - val_accuracy: 0.3057\n",
      "Epoch 16/50\n",
      "4148/4148 [==============================] - 2s 411us/step - loss: 0.4480 - accuracy: 0.8385 - val_loss: 2.9622 - val_accuracy: 0.3076\n",
      "Epoch 17/50\n",
      "4148/4148 [==============================] - 2s 400us/step - loss: 0.3937 - accuracy: 0.8592 - val_loss: 3.1693 - val_accuracy: 0.3047\n",
      "Epoch 18/50\n",
      "4148/4148 [==============================] - 2s 416us/step - loss: 0.3671 - accuracy: 0.8626 - val_loss: 4.4052 - val_accuracy: 0.3105\n",
      "Epoch 19/50\n",
      "4148/4148 [==============================] - 2s 405us/step - loss: 0.3641 - accuracy: 0.8676 - val_loss: 2.6224 - val_accuracy: 0.3105\n",
      "Epoch 20/50\n",
      "4148/4148 [==============================] - 2s 399us/step - loss: 0.3415 - accuracy: 0.8737 - val_loss: 2.9947 - val_accuracy: 0.3038\n",
      "Epoch 21/50\n",
      "4148/4148 [==============================] - 2s 410us/step - loss: 0.2977 - accuracy: 0.8889 - val_loss: 2.9142 - val_accuracy: 0.3018\n",
      "Epoch 22/50\n",
      "4148/4148 [==============================] - 2s 417us/step - loss: 0.3134 - accuracy: 0.8903 - val_loss: 2.9251 - val_accuracy: 0.2980\n",
      "Epoch 23/50\n",
      "4148/4148 [==============================] - 2s 391us/step - loss: 0.3305 - accuracy: 0.8795 - val_loss: 4.1054 - val_accuracy: 0.2932\n",
      "Epoch 24/50\n",
      "4148/4148 [==============================] - 2s 377us/step - loss: 0.3370 - accuracy: 0.8790 - val_loss: 3.6790 - val_accuracy: 0.3124\n",
      "Epoch 25/50\n",
      "4148/4148 [==============================] - 2s 406us/step - loss: 0.2996 - accuracy: 0.8862 - val_loss: 3.1703 - val_accuracy: 0.3086\n",
      "Epoch 26/50\n",
      "4148/4148 [==============================] - 2s 390us/step - loss: 0.2629 - accuracy: 0.9069 - val_loss: 2.9261 - val_accuracy: 0.3230\n",
      "Epoch 27/50\n",
      "4148/4148 [==============================] - 2s 435us/step - loss: 0.2477 - accuracy: 0.9043 - val_loss: 3.7467 - val_accuracy: 0.3076\n",
      "Epoch 28/50\n",
      "4148/4148 [==============================] - 2s 387us/step - loss: 0.2410 - accuracy: 0.9132 - val_loss: 3.8957 - val_accuracy: 0.3346\n",
      "Epoch 29/50\n",
      "4148/4148 [==============================] - 2s 388us/step - loss: 0.2495 - accuracy: 0.9091 - val_loss: 3.6777 - val_accuracy: 0.3076\n",
      "Epoch 30/50\n",
      "4148/4148 [==============================] - 2s 404us/step - loss: 0.2695 - accuracy: 0.8973 - val_loss: 4.9517 - val_accuracy: 0.2980\n",
      "Epoch 31/50\n",
      "4148/4148 [==============================] - 2s 469us/step - loss: 0.2573 - accuracy: 0.9057 - val_loss: 3.4387 - val_accuracy: 0.2816\n",
      "Epoch 32/50\n",
      "4148/4148 [==============================] - 2s 430us/step - loss: 0.2421 - accuracy: 0.9101 - val_loss: 4.2351 - val_accuracy: 0.3009\n",
      "Epoch 33/50\n",
      "4148/4148 [==============================] - 2s 404us/step - loss: 0.2196 - accuracy: 0.9180 - val_loss: 4.4382 - val_accuracy: 0.2883\n",
      "Epoch 34/50\n",
      "4148/4148 [==============================] - 2s 388us/step - loss: 0.2174 - accuracy: 0.9236 - val_loss: 4.0234 - val_accuracy: 0.2932\n",
      "Epoch 35/50\n",
      "4148/4148 [==============================] - 2s 433us/step - loss: 0.2239 - accuracy: 0.9279 - val_loss: 3.3424 - val_accuracy: 0.3018\n",
      "Epoch 36/50\n",
      "4148/4148 [==============================] - 2s 405us/step - loss: 0.2113 - accuracy: 0.9255 - val_loss: 4.1410 - val_accuracy: 0.3057\n",
      "Epoch 37/50\n",
      "4148/4148 [==============================] - 2s 387us/step - loss: 0.2195 - accuracy: 0.9197 - val_loss: 5.3458 - val_accuracy: 0.3095\n",
      "Epoch 38/50\n",
      "4148/4148 [==============================] - 2s 387us/step - loss: 0.2264 - accuracy: 0.9253 - val_loss: 4.1972 - val_accuracy: 0.2864\n",
      "Epoch 39/50\n",
      "4148/4148 [==============================] - 2s 400us/step - loss: 0.1822 - accuracy: 0.9294 - val_loss: 4.0056 - val_accuracy: 0.2941\n",
      "Epoch 40/50\n",
      "4148/4148 [==============================] - 2s 365us/step - loss: 0.1839 - accuracy: 0.9388 - val_loss: 5.3206 - val_accuracy: 0.3086\n",
      "Epoch 41/50\n",
      "4148/4148 [==============================] - 2s 411us/step - loss: 0.1818 - accuracy: 0.9337 - val_loss: 3.5835 - val_accuracy: 0.2989\n",
      "Epoch 42/50\n",
      "4148/4148 [==============================] - 2s 365us/step - loss: 0.1700 - accuracy: 0.9412 - val_loss: 3.9253 - val_accuracy: 0.3038\n",
      "Epoch 43/50\n",
      "4148/4148 [==============================] - 2s 370us/step - loss: 0.1649 - accuracy: 0.9405 - val_loss: 4.7667 - val_accuracy: 0.2729\n",
      "Epoch 44/50\n",
      "4148/4148 [==============================] - 2s 372us/step - loss: 0.1601 - accuracy: 0.9458 - val_loss: 4.3245 - val_accuracy: 0.2970\n",
      "Epoch 45/50\n",
      "4148/4148 [==============================] - 2s 368us/step - loss: 0.1540 - accuracy: 0.9462 - val_loss: 4.7570 - val_accuracy: 0.3018\n",
      "Epoch 46/50\n",
      "4148/4148 [==============================] - 2s 368us/step - loss: 0.1655 - accuracy: 0.9424 - val_loss: 4.2946 - val_accuracy: 0.2845\n",
      "Epoch 47/50\n",
      "4148/4148 [==============================] - 2s 370us/step - loss: 0.1458 - accuracy: 0.9499 - val_loss: 4.2797 - val_accuracy: 0.3163\n",
      "Epoch 48/50\n",
      "4148/4148 [==============================] - 2s 369us/step - loss: 0.1599 - accuracy: 0.9438 - val_loss: 4.1382 - val_accuracy: 0.3086\n",
      "Epoch 49/50\n",
      "4148/4148 [==============================] - 2s 373us/step - loss: 0.1511 - accuracy: 0.9455 - val_loss: 4.9016 - val_accuracy: 0.3009\n",
      "Epoch 50/50\n",
      "4148/4148 [==============================] - 2s 369us/step - loss: 0.1658 - accuracy: 0.9441 - val_loss: 5.5833 - val_accuracy: 0.3018\n",
      "1037/1037 [==============================] - 0s 203us/step\n",
      "1037/1037 [==============================] - 0s 111us/step\n",
      " \n",
      "Train on 4148 samples, validate on 1038 samples\n",
      "Epoch 1/50\n",
      "4148/4148 [==============================] - 3s 734us/step - loss: 1.8051 - accuracy: 0.2457 - val_loss: 2.2202 - val_accuracy: 0.1657\n",
      "Epoch 2/50\n",
      "4148/4148 [==============================] - 2s 409us/step - loss: 1.5784 - accuracy: 0.3474 - val_loss: 3.1445 - val_accuracy: 0.1686\n",
      "Epoch 3/50\n",
      "4148/4148 [==============================] - 2s 367us/step - loss: 1.3990 - accuracy: 0.4342 - val_loss: 2.8557 - val_accuracy: 0.2071\n",
      "Epoch 4/50\n",
      "4148/4148 [==============================] - 2s 382us/step - loss: 1.2202 - accuracy: 0.5116 - val_loss: 1.6792 - val_accuracy: 0.3834\n",
      "Epoch 5/50\n",
      "4148/4148 [==============================] - 2s 366us/step - loss: 1.0118 - accuracy: 0.6010 - val_loss: 1.6037 - val_accuracy: 0.4037\n",
      "Epoch 6/50\n",
      "4148/4148 [==============================] - 2s 407us/step - loss: 0.7924 - accuracy: 0.6984 - val_loss: 2.0375 - val_accuracy: 0.3767\n",
      "Epoch 7/50\n",
      "4148/4148 [==============================] - 2s 410us/step - loss: 0.6058 - accuracy: 0.7724 - val_loss: 1.9924 - val_accuracy: 0.4008\n",
      "Epoch 8/50\n",
      "4148/4148 [==============================] - 2s 402us/step - loss: 0.4784 - accuracy: 0.8274 - val_loss: 2.2565 - val_accuracy: 0.4066\n",
      "Epoch 9/50\n",
      "4148/4148 [==============================] - 2s 395us/step - loss: 0.3601 - accuracy: 0.8713 - val_loss: 2.7178 - val_accuracy: 0.3728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50\n",
      "4148/4148 [==============================] - 2s 422us/step - loss: 0.3421 - accuracy: 0.8790 - val_loss: 2.6448 - val_accuracy: 0.3902\n",
      "Epoch 11/50\n",
      "4148/4148 [==============================] - 2s 418us/step - loss: 0.2531 - accuracy: 0.9139 - val_loss: 3.3126 - val_accuracy: 0.3728\n",
      "Epoch 12/50\n",
      "4148/4148 [==============================] - 2s 390us/step - loss: 0.1882 - accuracy: 0.9320 - val_loss: 3.0330 - val_accuracy: 0.4210\n",
      "Epoch 13/50\n",
      "4148/4148 [==============================] - 2s 413us/step - loss: 0.1876 - accuracy: 0.9376 - val_loss: 3.6636 - val_accuracy: 0.3844\n",
      "Epoch 14/50\n",
      "4148/4148 [==============================] - 2s 415us/step - loss: 0.1725 - accuracy: 0.9385 - val_loss: 3.4421 - val_accuracy: 0.4239\n",
      "Epoch 15/50\n",
      "4148/4148 [==============================] - 2s 387us/step - loss: 0.1434 - accuracy: 0.9530 - val_loss: 3.7598 - val_accuracy: 0.3863\n",
      "Epoch 16/50\n",
      "4148/4148 [==============================] - 2s 416us/step - loss: 0.1561 - accuracy: 0.9472 - val_loss: 3.5574 - val_accuracy: 0.3931\n",
      "Epoch 17/50\n",
      "4148/4148 [==============================] - 2s 393us/step - loss: 0.1407 - accuracy: 0.9520 - val_loss: 3.6869 - val_accuracy: 0.3998\n",
      "Epoch 18/50\n",
      "4148/4148 [==============================] - 2s 432us/step - loss: 0.1504 - accuracy: 0.9470 - val_loss: 3.6221 - val_accuracy: 0.3892\n",
      "Epoch 19/50\n",
      "4148/4148 [==============================] - 2s 398us/step - loss: 0.1214 - accuracy: 0.9573 - val_loss: 3.7548 - val_accuracy: 0.3998\n",
      "Epoch 20/50\n",
      "4148/4148 [==============================] - 2s 387us/step - loss: 0.0593 - accuracy: 0.9807 - val_loss: 4.0802 - val_accuracy: 0.4056\n",
      "Epoch 21/50\n",
      "4148/4148 [==============================] - 2s 378us/step - loss: 0.0767 - accuracy: 0.9737 - val_loss: 4.2003 - val_accuracy: 0.3844\n",
      "Epoch 22/50\n",
      "4148/4148 [==============================] - 2s 381us/step - loss: 0.0713 - accuracy: 0.9747 - val_loss: 4.5569 - val_accuracy: 0.3719\n",
      "Epoch 23/50\n",
      "4148/4148 [==============================] - 2s 381us/step - loss: 0.0869 - accuracy: 0.9689 - val_loss: 4.8311 - val_accuracy: 0.3825\n",
      "Epoch 24/50\n",
      "4148/4148 [==============================] - 2s 390us/step - loss: 0.1651 - accuracy: 0.9491 - val_loss: 4.3502 - val_accuracy: 0.3748\n",
      "Epoch 25/50\n",
      "4148/4148 [==============================] - 2s 389us/step - loss: 0.1660 - accuracy: 0.9506 - val_loss: 3.4659 - val_accuracy: 0.4229\n",
      "Epoch 26/50\n",
      "4148/4148 [==============================] - 2s 381us/step - loss: 0.0986 - accuracy: 0.9658 - val_loss: 4.0828 - val_accuracy: 0.4066\n",
      "Epoch 27/50\n",
      "4148/4148 [==============================] - 2s 389us/step - loss: 0.0767 - accuracy: 0.9769 - val_loss: 3.8549 - val_accuracy: 0.3825\n",
      "Epoch 28/50\n",
      "4148/4148 [==============================] - 2s 385us/step - loss: 0.0435 - accuracy: 0.9865 - val_loss: 4.3027 - val_accuracy: 0.4046\n",
      "Epoch 29/50\n",
      "4148/4148 [==============================] - 2s 379us/step - loss: 0.0300 - accuracy: 0.9896 - val_loss: 4.6283 - val_accuracy: 0.3863\n",
      "Epoch 30/50\n",
      "4148/4148 [==============================] - 2s 381us/step - loss: 0.0358 - accuracy: 0.9865 - val_loss: 4.9597 - val_accuracy: 0.4056\n",
      "Epoch 31/50\n",
      "4148/4148 [==============================] - 2s 381us/step - loss: 0.1116 - accuracy: 0.9650 - val_loss: 3.7290 - val_accuracy: 0.3921\n",
      "Epoch 32/50\n",
      "4148/4148 [==============================] - 2s 384us/step - loss: 0.1248 - accuracy: 0.9597 - val_loss: 4.0662 - val_accuracy: 0.3844\n",
      "Epoch 33/50\n",
      "4148/4148 [==============================] - 2s 380us/step - loss: 0.0868 - accuracy: 0.9730 - val_loss: 4.4619 - val_accuracy: 0.3805\n",
      "Epoch 34/50\n",
      "4148/4148 [==============================] - 2s 383us/step - loss: 0.0672 - accuracy: 0.9764 - val_loss: 4.5830 - val_accuracy: 0.4133\n",
      "Epoch 35/50\n",
      "4148/4148 [==============================] - 2s 380us/step - loss: 0.0598 - accuracy: 0.9831 - val_loss: 4.6685 - val_accuracy: 0.3825\n",
      "Epoch 36/50\n",
      "4148/4148 [==============================] - 2s 376us/step - loss: 0.0831 - accuracy: 0.9718 - val_loss: 5.2457 - val_accuracy: 0.3728\n",
      "Epoch 37/50\n",
      "4148/4148 [==============================] - 2s 376us/step - loss: 0.0723 - accuracy: 0.9764 - val_loss: 4.6896 - val_accuracy: 0.3844\n",
      "Epoch 38/50\n",
      "4148/4148 [==============================] - 2s 375us/step - loss: 0.0635 - accuracy: 0.9817 - val_loss: 5.0036 - val_accuracy: 0.3805\n",
      "Epoch 39/50\n",
      "4148/4148 [==============================] - 2s 380us/step - loss: 0.0431 - accuracy: 0.9851 - val_loss: 4.7839 - val_accuracy: 0.3998\n",
      "Epoch 40/50\n",
      "4148/4148 [==============================] - 2s 378us/step - loss: 0.0435 - accuracy: 0.9838 - val_loss: 5.1494 - val_accuracy: 0.3815\n",
      "Epoch 41/50\n",
      "4148/4148 [==============================] - 2s 377us/step - loss: 0.0328 - accuracy: 0.9899 - val_loss: 5.3305 - val_accuracy: 0.4181\n",
      "Epoch 42/50\n",
      "4148/4148 [==============================] - 2s 372us/step - loss: 0.0406 - accuracy: 0.9875 - val_loss: 5.1665 - val_accuracy: 0.3998\n",
      "Epoch 43/50\n",
      "4148/4148 [==============================] - 2s 373us/step - loss: 0.0529 - accuracy: 0.9826 - val_loss: 4.6595 - val_accuracy: 0.4046\n",
      "Epoch 44/50\n",
      "4148/4148 [==============================] - 2s 374us/step - loss: 0.0604 - accuracy: 0.9817 - val_loss: 5.0608 - val_accuracy: 0.4008\n",
      "Epoch 45/50\n",
      "4148/4148 [==============================] - 2s 378us/step - loss: 0.1034 - accuracy: 0.9711 - val_loss: 4.3432 - val_accuracy: 0.3882\n",
      "Epoch 46/50\n",
      "4148/4148 [==============================] - 2s 377us/step - loss: 0.0662 - accuracy: 0.9790 - val_loss: 5.1453 - val_accuracy: 0.3834\n",
      "Epoch 47/50\n",
      "4148/4148 [==============================] - 2s 372us/step - loss: 0.0295 - accuracy: 0.9918 - val_loss: 4.5980 - val_accuracy: 0.4094\n",
      "Epoch 48/50\n",
      "4148/4148 [==============================] - 2s 375us/step - loss: 0.0214 - accuracy: 0.9928 - val_loss: 4.7441 - val_accuracy: 0.4017\n",
      "Epoch 49/50\n",
      "4148/4148 [==============================] - 2s 375us/step - loss: 0.0344 - accuracy: 0.9892 - val_loss: 5.0335 - val_accuracy: 0.3960\n",
      "Epoch 50/50\n",
      "4148/4148 [==============================] - 2s 372us/step - loss: 0.0413 - accuracy: 0.9913 - val_loss: 4.6556 - val_accuracy: 0.3902\n",
      "1038/1038 [==============================] - 0s 195us/step\n",
      "1038/1038 [==============================] - 0s 108us/step\n",
      " \n",
      "Train on 4148 samples, validate on 1038 samples\n",
      "Epoch 1/50\n",
      "4148/4148 [==============================] - 3s 695us/step - loss: 1.8661 - accuracy: 0.1832 - val_loss: 1.9932 - val_accuracy: 0.1821\n",
      "Epoch 2/50\n",
      "4148/4148 [==============================] - 2s 374us/step - loss: 1.7593 - accuracy: 0.2293 - val_loss: 1.7956 - val_accuracy: 0.1667\n",
      "Epoch 3/50\n",
      "4148/4148 [==============================] - 2s 379us/step - loss: 1.6683 - accuracy: 0.2625 - val_loss: 1.8272 - val_accuracy: 0.2225\n",
      "Epoch 4/50\n",
      "4148/4148 [==============================] - 2s 382us/step - loss: 1.6063 - accuracy: 0.3136 - val_loss: 1.7695 - val_accuracy: 0.2476\n",
      "Epoch 5/50\n",
      "4148/4148 [==============================] - 2s 376us/step - loss: 1.5211 - accuracy: 0.3587 - val_loss: 1.8237 - val_accuracy: 0.2187\n",
      "Epoch 6/50\n",
      "4148/4148 [==============================] - 2s 376us/step - loss: 1.4442 - accuracy: 0.4060 - val_loss: 1.8845 - val_accuracy: 0.2919\n",
      "Epoch 7/50\n",
      "4148/4148 [==============================] - 2s 375us/step - loss: 1.3136 - accuracy: 0.4561 - val_loss: 1.7602 - val_accuracy: 0.3044\n",
      "Epoch 8/50\n",
      "4148/4148 [==============================] - 2s 374us/step - loss: 1.1842 - accuracy: 0.5200 - val_loss: 2.1577 - val_accuracy: 0.2630\n",
      "Epoch 9/50\n",
      "4148/4148 [==============================] - 2s 379us/step - loss: 1.0589 - accuracy: 0.5682 - val_loss: 2.1514 - val_accuracy: 0.3035\n",
      "Epoch 10/50\n",
      "4148/4148 [==============================] - 2s 378us/step - loss: 0.9129 - accuracy: 0.6249 - val_loss: 2.6302 - val_accuracy: 0.2958\n",
      "Epoch 11/50\n",
      "4148/4148 [==============================] - 2s 376us/step - loss: 0.8380 - accuracy: 0.6586 - val_loss: 2.5671 - val_accuracy: 0.3112\n",
      "Epoch 12/50\n",
      "4148/4148 [==============================] - 2s 374us/step - loss: 0.7141 - accuracy: 0.7155 - val_loss: 2.7538 - val_accuracy: 0.2958\n",
      "Epoch 13/50\n",
      "4148/4148 [==============================] - 2s 374us/step - loss: 0.6554 - accuracy: 0.7466 - val_loss: 2.7991 - val_accuracy: 0.3218\n",
      "Epoch 14/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4148/4148 [==============================] - 2s 367us/step - loss: 0.5493 - accuracy: 0.7888 - val_loss: 3.4369 - val_accuracy: 0.2803\n",
      "Epoch 15/50\n",
      "4148/4148 [==============================] - 2s 367us/step - loss: 0.4639 - accuracy: 0.8202 - val_loss: 3.6770 - val_accuracy: 0.3035\n",
      "Epoch 16/50\n",
      "4148/4148 [==============================] - 2s 366us/step - loss: 0.4408 - accuracy: 0.8337 - val_loss: 3.6138 - val_accuracy: 0.3179\n",
      "Epoch 17/50\n",
      "4148/4148 [==============================] - 2s 367us/step - loss: 0.4073 - accuracy: 0.8433 - val_loss: 3.9315 - val_accuracy: 0.3150\n",
      "Epoch 18/50\n",
      "4148/4148 [==============================] - 2s 368us/step - loss: 0.3419 - accuracy: 0.8720 - val_loss: 4.1017 - val_accuracy: 0.2832\n",
      "Epoch 19/50\n",
      "4148/4148 [==============================] - 2s 371us/step - loss: 0.3073 - accuracy: 0.8889 - val_loss: 4.2017 - val_accuracy: 0.2900\n",
      "Epoch 20/50\n",
      "4148/4148 [==============================] - 2s 371us/step - loss: 0.2723 - accuracy: 0.8983 - val_loss: 4.6833 - val_accuracy: 0.3035\n",
      "Epoch 21/50\n",
      "4148/4148 [==============================] - 2s 370us/step - loss: 0.2169 - accuracy: 0.9176 - val_loss: 4.9744 - val_accuracy: 0.2977\n",
      "Epoch 22/50\n",
      "4148/4148 [==============================] - 2s 372us/step - loss: 0.2035 - accuracy: 0.9272 - val_loss: 5.2460 - val_accuracy: 0.3073\n",
      "Epoch 23/50\n",
      "4148/4148 [==============================] - 2s 368us/step - loss: 0.2644 - accuracy: 0.9094 - val_loss: 4.6041 - val_accuracy: 0.3015\n",
      "Epoch 24/50\n",
      "4148/4148 [==============================] - 2s 374us/step - loss: 0.2850 - accuracy: 0.8997 - val_loss: 5.7283 - val_accuracy: 0.2697\n",
      "Epoch 25/50\n",
      "4148/4148 [==============================] - 2s 369us/step - loss: 0.2102 - accuracy: 0.9272 - val_loss: 5.3734 - val_accuracy: 0.3044\n",
      "Epoch 26/50\n",
      "4148/4148 [==============================] - 2s 373us/step - loss: 0.1635 - accuracy: 0.9419 - val_loss: 4.9382 - val_accuracy: 0.2929\n",
      "Epoch 27/50\n",
      "4148/4148 [==============================] - 2s 372us/step - loss: 0.1641 - accuracy: 0.9438 - val_loss: 5.8708 - val_accuracy: 0.2803\n",
      "Epoch 28/50\n",
      "4148/4148 [==============================] - 2s 373us/step - loss: 0.1740 - accuracy: 0.9421 - val_loss: 5.9142 - val_accuracy: 0.3102\n",
      "Epoch 29/50\n",
      "4148/4148 [==============================] - 2s 374us/step - loss: 0.1435 - accuracy: 0.9537 - val_loss: 5.5295 - val_accuracy: 0.2900\n",
      "Epoch 30/50\n",
      "4148/4148 [==============================] - 2s 373us/step - loss: 0.1826 - accuracy: 0.9409 - val_loss: 5.7342 - val_accuracy: 0.2852\n",
      "Epoch 31/50\n",
      "4148/4148 [==============================] - 2s 369us/step - loss: 0.1435 - accuracy: 0.9511 - val_loss: 5.6498 - val_accuracy: 0.2803\n",
      "Epoch 32/50\n",
      "4148/4148 [==============================] - 2s 370us/step - loss: 0.1550 - accuracy: 0.9491 - val_loss: 6.0478 - val_accuracy: 0.3035\n",
      "Epoch 33/50\n",
      "4148/4148 [==============================] - 2s 374us/step - loss: 0.1714 - accuracy: 0.9431 - val_loss: 6.2033 - val_accuracy: 0.2938\n",
      "Epoch 34/50\n",
      "4148/4148 [==============================] - 2s 383us/step - loss: 0.1871 - accuracy: 0.9433 - val_loss: 5.4158 - val_accuracy: 0.3054\n",
      "Epoch 35/50\n",
      "4148/4148 [==============================] - 2s 377us/step - loss: 0.1376 - accuracy: 0.9578 - val_loss: 5.5668 - val_accuracy: 0.2967\n",
      "Epoch 36/50\n",
      "4148/4148 [==============================] - 2s 370us/step - loss: 0.0874 - accuracy: 0.9694 - val_loss: 6.4729 - val_accuracy: 0.3112\n",
      "Epoch 37/50\n",
      "4148/4148 [==============================] - 2s 372us/step - loss: 0.0632 - accuracy: 0.9785 - val_loss: 5.7674 - val_accuracy: 0.3121\n",
      "Epoch 38/50\n",
      "4148/4148 [==============================] - 2s 372us/step - loss: 0.0759 - accuracy: 0.9776 - val_loss: 6.5116 - val_accuracy: 0.2794\n",
      "Epoch 39/50\n",
      "4148/4148 [==============================] - 2s 375us/step - loss: 0.0836 - accuracy: 0.9723 - val_loss: 6.8740 - val_accuracy: 0.2794\n",
      "Epoch 40/50\n",
      "4148/4148 [==============================] - 2s 375us/step - loss: 0.0885 - accuracy: 0.9675 - val_loss: 6.8901 - val_accuracy: 0.3073\n",
      "Epoch 41/50\n",
      "4148/4148 [==============================] - 2s 373us/step - loss: 0.1251 - accuracy: 0.9595 - val_loss: 6.9387 - val_accuracy: 0.3131\n",
      "Epoch 42/50\n",
      "4148/4148 [==============================] - 2s 373us/step - loss: 0.1445 - accuracy: 0.9576 - val_loss: 6.0016 - val_accuracy: 0.2929\n",
      "Epoch 43/50\n",
      "4148/4148 [==============================] - 2s 374us/step - loss: 0.1321 - accuracy: 0.9573 - val_loss: 5.8012 - val_accuracy: 0.2987\n",
      "Epoch 44/50\n",
      "4148/4148 [==============================] - 2s 397us/step - loss: 0.1160 - accuracy: 0.9643 - val_loss: 6.4139 - val_accuracy: 0.2948\n",
      "Epoch 45/50\n",
      "4148/4148 [==============================] - 2s 391us/step - loss: 0.0769 - accuracy: 0.9735 - val_loss: 6.7611 - val_accuracy: 0.3035\n",
      "Epoch 46/50\n",
      "4148/4148 [==============================] - 2s 402us/step - loss: 0.0810 - accuracy: 0.9747 - val_loss: 6.3175 - val_accuracy: 0.3044\n",
      "Epoch 47/50\n",
      "4148/4148 [==============================] - 2s 380us/step - loss: 0.0629 - accuracy: 0.9764 - val_loss: 6.2537 - val_accuracy: 0.3044\n",
      "Epoch 48/50\n",
      "4148/4148 [==============================] - 2s 385us/step - loss: 0.0519 - accuracy: 0.9812 - val_loss: 6.9430 - val_accuracy: 0.2987\n",
      "Epoch 49/50\n",
      "4148/4148 [==============================] - 2s 387us/step - loss: 0.0646 - accuracy: 0.9764 - val_loss: 7.4116 - val_accuracy: 0.2967\n",
      "Epoch 50/50\n",
      "4148/4148 [==============================] - 2s 397us/step - loss: 0.1144 - accuracy: 0.9691 - val_loss: 7.1540 - val_accuracy: 0.2909\n",
      "1038/1038 [==============================] - 0s 195us/step\n",
      "1038/1038 [==============================] - 0s 112us/step\n",
      " \n",
      "Train on 4148 samples, validate on 1037 samples\n",
      "Epoch 1/50\n",
      "4148/4148 [==============================] - 3s 713us/step - loss: 1.7979 - accuracy: 0.2464 - val_loss: 2.5323 - val_accuracy: 0.1668\n",
      "Epoch 2/50\n",
      "4148/4148 [==============================] - 2s 407us/step - loss: 1.5561 - accuracy: 0.3633 - val_loss: 7.2570 - val_accuracy: 0.1967\n",
      "Epoch 3/50\n",
      "4148/4148 [==============================] - 2s 408us/step - loss: 1.3909 - accuracy: 0.4279 - val_loss: 1.7441 - val_accuracy: 0.3423\n",
      "Epoch 4/50\n",
      "4148/4148 [==============================] - 2s 409us/step - loss: 1.2490 - accuracy: 0.4865 - val_loss: 1.9837 - val_accuracy: 0.3269\n",
      "Epoch 5/50\n",
      "4148/4148 [==============================] - 2s 406us/step - loss: 1.1039 - accuracy: 0.5439 - val_loss: 1.6727 - val_accuracy: 0.3645\n",
      "Epoch 6/50\n",
      "4148/4148 [==============================] - 2s 405us/step - loss: 0.9040 - accuracy: 0.6184 - val_loss: 1.8911 - val_accuracy: 0.3645\n",
      "Epoch 7/50\n",
      "4148/4148 [==============================] - 2s 406us/step - loss: 0.7874 - accuracy: 0.6791 - val_loss: 2.2337 - val_accuracy: 0.3703\n",
      "Epoch 8/50\n",
      "4148/4148 [==============================] - 2s 408us/step - loss: 0.6739 - accuracy: 0.7281 - val_loss: 2.2981 - val_accuracy: 0.3664\n",
      "Epoch 9/50\n",
      "4148/4148 [==============================] - 2s 406us/step - loss: 0.5774 - accuracy: 0.7751 - val_loss: 2.6507 - val_accuracy: 0.3944\n",
      "Epoch 10/50\n",
      "4148/4148 [==============================] - 2s 405us/step - loss: 0.4615 - accuracy: 0.8264 - val_loss: 2.6925 - val_accuracy: 0.3443\n",
      "Epoch 11/50\n",
      "4148/4148 [==============================] - 2s 407us/step - loss: 0.3819 - accuracy: 0.8513 - val_loss: 3.0472 - val_accuracy: 0.3896\n",
      "Epoch 12/50\n",
      "4148/4148 [==============================] - 2s 386us/step - loss: 0.3049 - accuracy: 0.8857 - val_loss: 3.4337 - val_accuracy: 0.3877\n",
      "Epoch 13/50\n",
      "4148/4148 [==============================] - 2s 400us/step - loss: 0.2543 - accuracy: 0.9060 - val_loss: 3.4595 - val_accuracy: 0.4060\n",
      "Epoch 14/50\n",
      "4148/4148 [==============================] - 2s 411us/step - loss: 0.1918 - accuracy: 0.9301 - val_loss: 3.9253 - val_accuracy: 0.3780\n",
      "Epoch 15/50\n",
      "4148/4148 [==============================] - 2s 431us/step - loss: 0.1813 - accuracy: 0.9356 - val_loss: 4.3655 - val_accuracy: 0.3867\n",
      "Epoch 16/50\n",
      "4148/4148 [==============================] - 2s 405us/step - loss: 0.1856 - accuracy: 0.9414 - val_loss: 3.6539 - val_accuracy: 0.3944\n",
      "Epoch 17/50\n",
      "4148/4148 [==============================] - 2s 387us/step - loss: 0.1472 - accuracy: 0.9515 - val_loss: 4.8344 - val_accuracy: 0.3713\n",
      "Epoch 18/50\n",
      "4148/4148 [==============================] - 2s 382us/step - loss: 0.0866 - accuracy: 0.9694 - val_loss: 4.5382 - val_accuracy: 0.3992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50\n",
      "4148/4148 [==============================] - 2s 376us/step - loss: 0.1024 - accuracy: 0.9624 - val_loss: 5.0962 - val_accuracy: 0.3944\n",
      "Epoch 20/50\n",
      "4148/4148 [==============================] - 2s 376us/step - loss: 0.1090 - accuracy: 0.9617 - val_loss: 4.6333 - val_accuracy: 0.3780\n",
      "Epoch 21/50\n",
      "4148/4148 [==============================] - 2s 373us/step - loss: 0.1187 - accuracy: 0.9602 - val_loss: 4.6310 - val_accuracy: 0.3828\n",
      "Epoch 22/50\n",
      "4148/4148 [==============================] - 2s 373us/step - loss: 0.1155 - accuracy: 0.9605 - val_loss: 4.7690 - val_accuracy: 0.3992\n",
      "Epoch 23/50\n",
      "4148/4148 [==============================] - 2s 375us/step - loss: 0.1143 - accuracy: 0.9626 - val_loss: 5.5099 - val_accuracy: 0.3664\n",
      "Epoch 24/50\n",
      "4148/4148 [==============================] - 2s 372us/step - loss: 0.1265 - accuracy: 0.9585 - val_loss: 4.3659 - val_accuracy: 0.4069\n",
      "Epoch 25/50\n",
      "4148/4148 [==============================] - 2s 375us/step - loss: 0.1117 - accuracy: 0.9622 - val_loss: 4.4422 - val_accuracy: 0.3934\n",
      "Epoch 26/50\n",
      "4148/4148 [==============================] - 2s 378us/step - loss: 0.0830 - accuracy: 0.9728 - val_loss: 4.4743 - val_accuracy: 0.4156\n",
      "Epoch 27/50\n",
      "4148/4148 [==============================] - 2s 376us/step - loss: 0.0564 - accuracy: 0.9807 - val_loss: 5.1842 - val_accuracy: 0.3905\n",
      "Epoch 28/50\n",
      "4148/4148 [==============================] - 2s 376us/step - loss: 0.0522 - accuracy: 0.9841 - val_loss: 5.0142 - val_accuracy: 0.3838\n",
      "Epoch 29/50\n",
      "4148/4148 [==============================] - 2s 377us/step - loss: 0.0253 - accuracy: 0.9920 - val_loss: 4.9964 - val_accuracy: 0.4060\n",
      "Epoch 30/50\n",
      "4148/4148 [==============================] - 2s 376us/step - loss: 0.0263 - accuracy: 0.9923 - val_loss: 5.3435 - val_accuracy: 0.4060\n",
      "Epoch 31/50\n",
      "4148/4148 [==============================] - 2s 374us/step - loss: 0.0324 - accuracy: 0.9896 - val_loss: 5.0223 - val_accuracy: 0.4118\n",
      "Epoch 32/50\n",
      "4148/4148 [==============================] - 2s 373us/step - loss: 0.0575 - accuracy: 0.9802 - val_loss: 5.4205 - val_accuracy: 0.3848\n",
      "Epoch 33/50\n",
      "4148/4148 [==============================] - 2s 374us/step - loss: 0.1625 - accuracy: 0.9479 - val_loss: 5.3553 - val_accuracy: 0.3742\n",
      "Epoch 34/50\n",
      "4148/4148 [==============================] - 2s 374us/step - loss: 0.1177 - accuracy: 0.9600 - val_loss: 5.2866 - val_accuracy: 0.4002\n",
      "Epoch 35/50\n",
      "4148/4148 [==============================] - 2s 379us/step - loss: 0.0834 - accuracy: 0.9713 - val_loss: 4.7730 - val_accuracy: 0.4069\n",
      "Epoch 36/50\n",
      "4148/4148 [==============================] - 2s 379us/step - loss: 0.0506 - accuracy: 0.9841 - val_loss: 5.0875 - val_accuracy: 0.3983\n",
      "Epoch 37/50\n",
      "4148/4148 [==============================] - 2s 379us/step - loss: 0.0227 - accuracy: 0.9952 - val_loss: 4.9640 - val_accuracy: 0.4118\n",
      "Epoch 38/50\n",
      "4148/4148 [==============================] - 2s 379us/step - loss: 0.0093 - accuracy: 0.9976 - val_loss: 5.3038 - val_accuracy: 0.4069\n",
      "Epoch 39/50\n",
      "4148/4148 [==============================] - 2s 379us/step - loss: 0.0223 - accuracy: 0.9940 - val_loss: 5.5417 - val_accuracy: 0.4041\n",
      "Epoch 40/50\n",
      "4148/4148 [==============================] - 2s 376us/step - loss: 0.0526 - accuracy: 0.9851 - val_loss: 6.0945 - val_accuracy: 0.3886\n",
      "Epoch 41/50\n",
      "4148/4148 [==============================] - 2s 387us/step - loss: 0.1596 - accuracy: 0.9513 - val_loss: 4.9877 - val_accuracy: 0.3819\n",
      "Epoch 42/50\n",
      "4148/4148 [==============================] - 2s 385us/step - loss: 0.1188 - accuracy: 0.9636 - val_loss: 5.1556 - val_accuracy: 0.3838\n",
      "Epoch 43/50\n",
      "4148/4148 [==============================] - 2s 372us/step - loss: 0.0396 - accuracy: 0.9875 - val_loss: 4.7886 - val_accuracy: 0.3915\n",
      "Epoch 44/50\n",
      "4148/4148 [==============================] - 2s 375us/step - loss: 0.0243 - accuracy: 0.9925 - val_loss: 5.2917 - val_accuracy: 0.4069\n",
      "Epoch 45/50\n",
      "4148/4148 [==============================] - 2s 376us/step - loss: 0.0392 - accuracy: 0.9892 - val_loss: 5.2367 - val_accuracy: 0.4195\n",
      "Epoch 46/50\n",
      "4148/4148 [==============================] - 2s 375us/step - loss: 0.0545 - accuracy: 0.9838 - val_loss: 5.1195 - val_accuracy: 0.4050\n",
      "Epoch 47/50\n",
      "4148/4148 [==============================] - 2s 374us/step - loss: 0.0433 - accuracy: 0.9870 - val_loss: 5.1127 - val_accuracy: 0.3925\n",
      "Epoch 48/50\n",
      "4148/4148 [==============================] - 2s 377us/step - loss: 0.0408 - accuracy: 0.9877 - val_loss: 5.7446 - val_accuracy: 0.3886\n",
      "Epoch 49/50\n",
      "4148/4148 [==============================] - 2s 375us/step - loss: 0.0731 - accuracy: 0.9749 - val_loss: 5.6406 - val_accuracy: 0.3732\n",
      "Epoch 50/50\n",
      "4148/4148 [==============================] - 2s 374us/step - loss: 0.1007 - accuracy: 0.9699 - val_loss: 5.1893 - val_accuracy: 0.3838\n",
      "1037/1037 [==============================] - 0s 201us/step\n",
      "1037/1037 [==============================] - 0s 119us/step\n",
      " \n",
      "Train on 4148 samples, validate on 1038 samples\n",
      "Epoch 1/50\n",
      "4148/4148 [==============================] - 3s 779us/step - loss: 1.8287 - accuracy: 0.2507 - val_loss: 1.7938 - val_accuracy: 0.1782\n",
      "Epoch 2/50\n",
      "4148/4148 [==============================] - 2s 430us/step - loss: 1.5828 - accuracy: 0.3595 - val_loss: 4.1023 - val_accuracy: 0.1676\n",
      "Epoch 3/50\n",
      "4148/4148 [==============================] - 2s 434us/step - loss: 1.3694 - accuracy: 0.4691 - val_loss: 2.8423 - val_accuracy: 0.3025\n",
      "Epoch 4/50\n",
      "4148/4148 [==============================] - 2s 430us/step - loss: 1.1897 - accuracy: 0.5388 - val_loss: 1.5687 - val_accuracy: 0.3911\n",
      "Epoch 5/50\n",
      "4148/4148 [==============================] - 2s 428us/step - loss: 0.9774 - accuracy: 0.6333 - val_loss: 1.7379 - val_accuracy: 0.4171\n",
      "Epoch 6/50\n",
      "4148/4148 [==============================] - 1s 359us/step - loss: 0.8116 - accuracy: 0.6962 - val_loss: 1.8877 - val_accuracy: 0.4114\n",
      "Epoch 7/50\n",
      "4148/4148 [==============================] - 1s 347us/step - loss: 0.6210 - accuracy: 0.7705 - val_loss: 2.1806 - val_accuracy: 0.3873\n",
      "Epoch 8/50\n",
      "4148/4148 [==============================] - 1s 356us/step - loss: 0.4627 - accuracy: 0.8402 - val_loss: 2.3851 - val_accuracy: 0.3834\n",
      "Epoch 9/50\n",
      "4148/4148 [==============================] - 1s 359us/step - loss: 0.3395 - accuracy: 0.8797 - val_loss: 2.8757 - val_accuracy: 0.3709\n",
      "Epoch 10/50\n",
      "4148/4148 [==============================] - 1s 354us/step - loss: 0.2756 - accuracy: 0.9062 - val_loss: 2.8000 - val_accuracy: 0.4171\n",
      "Epoch 11/50\n",
      "4148/4148 [==============================] - 1s 350us/step - loss: 0.2421 - accuracy: 0.9166 - val_loss: 2.9123 - val_accuracy: 0.3863\n",
      "Epoch 12/50\n",
      "4148/4148 [==============================] - 1s 352us/step - loss: 0.2052 - accuracy: 0.9282 - val_loss: 3.3069 - val_accuracy: 0.3960\n",
      "Epoch 13/50\n",
      "4148/4148 [==============================] - 1s 352us/step - loss: 0.1661 - accuracy: 0.9409 - val_loss: 3.0965 - val_accuracy: 0.3834\n",
      "Epoch 14/50\n",
      "4148/4148 [==============================] - 1s 348us/step - loss: 0.1046 - accuracy: 0.9631 - val_loss: 3.8357 - val_accuracy: 0.3632\n",
      "Epoch 15/50\n",
      "4148/4148 [==============================] - 1s 358us/step - loss: 0.1548 - accuracy: 0.9484 - val_loss: 3.6645 - val_accuracy: 0.3776\n",
      "Epoch 16/50\n",
      "4148/4148 [==============================] - 1s 350us/step - loss: 0.1983 - accuracy: 0.9286 - val_loss: 3.3743 - val_accuracy: 0.3825\n",
      "Epoch 17/50\n",
      "4148/4148 [==============================] - 1s 351us/step - loss: 0.1245 - accuracy: 0.9566 - val_loss: 3.4793 - val_accuracy: 0.3979\n",
      "Epoch 18/50\n",
      "4148/4148 [==============================] - 1s 357us/step - loss: 0.0740 - accuracy: 0.9757 - val_loss: 3.9625 - val_accuracy: 0.4123\n",
      "Epoch 19/50\n",
      "4148/4148 [==============================] - 2s 372us/step - loss: 0.0564 - accuracy: 0.9814 - val_loss: 3.7974 - val_accuracy: 0.3940\n",
      "Epoch 20/50\n",
      "4148/4148 [==============================] - 2s 378us/step - loss: 0.0435 - accuracy: 0.9877 - val_loss: 3.8293 - val_accuracy: 0.4114\n",
      "Epoch 21/50\n",
      "4148/4148 [==============================] - 2s 372us/step - loss: 0.1079 - accuracy: 0.9682 - val_loss: 3.9081 - val_accuracy: 0.4008\n",
      "Epoch 22/50\n",
      "4148/4148 [==============================] - 2s 375us/step - loss: 0.1598 - accuracy: 0.9482 - val_loss: 3.3788 - val_accuracy: 0.4114\n",
      "Epoch 23/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4148/4148 [==============================] - 2s 374us/step - loss: 0.0818 - accuracy: 0.9761 - val_loss: 3.8777 - val_accuracy: 0.3960\n",
      "Epoch 24/50\n",
      "4148/4148 [==============================] - 2s 368us/step - loss: 0.0710 - accuracy: 0.9769 - val_loss: 4.0837 - val_accuracy: 0.3911\n",
      "Epoch 25/50\n",
      "4148/4148 [==============================] - 2s 372us/step - loss: 0.0689 - accuracy: 0.9800 - val_loss: 3.9929 - val_accuracy: 0.3854\n",
      "Epoch 26/50\n",
      "4148/4148 [==============================] - 2s 375us/step - loss: 0.0762 - accuracy: 0.9752 - val_loss: 3.7283 - val_accuracy: 0.4017\n",
      "Epoch 27/50\n",
      "4148/4148 [==============================] - 2s 372us/step - loss: 0.1158 - accuracy: 0.9612 - val_loss: 3.5814 - val_accuracy: 0.3931\n",
      "Epoch 28/50\n",
      "4148/4148 [==============================] - 2s 365us/step - loss: 0.1073 - accuracy: 0.9653 - val_loss: 3.8950 - val_accuracy: 0.3748\n",
      "Epoch 29/50\n",
      "4148/4148 [==============================] - 2s 378us/step - loss: 0.0870 - accuracy: 0.9740 - val_loss: 4.0352 - val_accuracy: 0.3834\n",
      "Epoch 30/50\n",
      "4148/4148 [==============================] - 2s 371us/step - loss: 0.0617 - accuracy: 0.9785 - val_loss: 3.7792 - val_accuracy: 0.3950\n",
      "Epoch 31/50\n",
      "4148/4148 [==============================] - 2s 394us/step - loss: 0.0387 - accuracy: 0.9872 - val_loss: 4.0274 - val_accuracy: 0.4268\n",
      "Epoch 32/50\n",
      "4148/4148 [==============================] - 2s 436us/step - loss: 0.0316 - accuracy: 0.9908 - val_loss: 4.3863 - val_accuracy: 0.3940\n",
      "Epoch 33/50\n",
      "4148/4148 [==============================] - 2s 379us/step - loss: 0.0304 - accuracy: 0.9892 - val_loss: 4.5708 - val_accuracy: 0.3902\n",
      "Epoch 34/50\n",
      "4148/4148 [==============================] - 2s 374us/step - loss: 0.0500 - accuracy: 0.9848 - val_loss: 4.6881 - val_accuracy: 0.3892\n",
      "Epoch 35/50\n",
      "4148/4148 [==============================] - 2s 379us/step - loss: 0.0826 - accuracy: 0.9749 - val_loss: 4.4700 - val_accuracy: 0.3960\n",
      "Epoch 36/50\n",
      "4148/4148 [==============================] - 2s 402us/step - loss: 0.1328 - accuracy: 0.9597 - val_loss: 4.5318 - val_accuracy: 0.3642\n",
      "Epoch 37/50\n",
      "4148/4148 [==============================] - 2s 399us/step - loss: 0.1165 - accuracy: 0.9655 - val_loss: 3.9423 - val_accuracy: 0.3988\n",
      "Epoch 38/50\n",
      "4148/4148 [==============================] - 2s 397us/step - loss: 0.1244 - accuracy: 0.9622 - val_loss: 3.7149 - val_accuracy: 0.3844\n",
      "Epoch 39/50\n",
      "4148/4148 [==============================] - 2s 405us/step - loss: 0.0505 - accuracy: 0.9812 - val_loss: 3.5744 - val_accuracy: 0.4200\n",
      "Epoch 40/50\n",
      "4148/4148 [==============================] - 2s 400us/step - loss: 0.0198 - accuracy: 0.9937 - val_loss: 4.2008 - val_accuracy: 0.3940\n",
      "Epoch 41/50\n",
      "4148/4148 [==============================] - 2s 376us/step - loss: 0.0139 - accuracy: 0.9981 - val_loss: 4.5991 - val_accuracy: 0.4075\n",
      "Epoch 42/50\n",
      "4148/4148 [==============================] - 2s 377us/step - loss: 0.0075 - accuracy: 0.9983 - val_loss: 4.3563 - val_accuracy: 0.4085\n",
      "Epoch 43/50\n",
      "4148/4148 [==============================] - 2s 374us/step - loss: 0.0053 - accuracy: 0.9990 - val_loss: 4.3657 - val_accuracy: 0.4114\n",
      "Epoch 44/50\n",
      "4148/4148 [==============================] - 2s 375us/step - loss: 0.0039 - accuracy: 0.9995 - val_loss: 4.4442 - val_accuracy: 0.4249\n",
      "Epoch 45/50\n",
      "4148/4148 [==============================] - 2s 372us/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 4.5139 - val_accuracy: 0.4229\n",
      "Epoch 46/50\n",
      "4148/4148 [==============================] - 2s 371us/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 4.5047 - val_accuracy: 0.4210\n",
      "Epoch 47/50\n",
      "4148/4148 [==============================] - 2s 379us/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 4.5550 - val_accuracy: 0.4200\n",
      "Epoch 48/50\n",
      "4148/4148 [==============================] - 2s 389us/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 4.6505 - val_accuracy: 0.4191\n",
      "Epoch 49/50\n",
      "4148/4148 [==============================] - 2s 378us/step - loss: 0.0025 - accuracy: 0.9990 - val_loss: 4.6883 - val_accuracy: 0.4210\n",
      "Epoch 50/50\n",
      "4148/4148 [==============================] - 2s 420us/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 4.7153 - val_accuracy: 0.4258\n",
      "1038/1038 [==============================] - 0s 198us/step\n",
      "1038/1038 [==============================] - 0s 119us/step\n",
      " \n",
      "Train on 4150 samples, validate on 1038 samples\n",
      "Epoch 1/50\n",
      "4150/4150 [==============================] - 3s 697us/step - loss: 1.7965 - accuracy: 0.2528 - val_loss: 2.2599 - val_accuracy: 0.1667\n",
      "Epoch 2/50\n",
      "4150/4150 [==============================] - 2s 392us/step - loss: 1.5441 - accuracy: 0.3788 - val_loss: 3.2531 - val_accuracy: 0.1676\n",
      "Epoch 3/50\n",
      "4150/4150 [==============================] - 2s 393us/step - loss: 1.3741 - accuracy: 0.4533 - val_loss: 2.4800 - val_accuracy: 0.2360\n",
      "Epoch 4/50\n",
      "4150/4150 [==============================] - 2s 394us/step - loss: 1.1648 - accuracy: 0.5492 - val_loss: 1.6745 - val_accuracy: 0.3613\n",
      "Epoch 5/50\n",
      "4150/4150 [==============================] - 2s 393us/step - loss: 0.9893 - accuracy: 0.6205 - val_loss: 2.0320 - val_accuracy: 0.3613\n",
      "Epoch 6/50\n",
      "4150/4150 [==============================] - 2s 391us/step - loss: 0.7715 - accuracy: 0.7031 - val_loss: 2.0005 - val_accuracy: 0.3988\n",
      "Epoch 7/50\n",
      "4150/4150 [==============================] - 2s 390us/step - loss: 0.6205 - accuracy: 0.7672 - val_loss: 2.6450 - val_accuracy: 0.3728\n",
      "Epoch 8/50\n",
      "4150/4150 [==============================] - 2s 391us/step - loss: 0.5147 - accuracy: 0.8048 - val_loss: 2.5459 - val_accuracy: 0.3882\n",
      "Epoch 9/50\n",
      "4150/4150 [==============================] - 2s 392us/step - loss: 0.4301 - accuracy: 0.8400 - val_loss: 2.3785 - val_accuracy: 0.3988\n",
      "Epoch 10/50\n",
      "4150/4150 [==============================] - 2s 390us/step - loss: 0.3313 - accuracy: 0.8790 - val_loss: 2.7487 - val_accuracy: 0.4171\n",
      "Epoch 11/50\n",
      "4150/4150 [==============================] - 2s 392us/step - loss: 0.2284 - accuracy: 0.9195 - val_loss: 3.0681 - val_accuracy: 0.3805\n",
      "Epoch 12/50\n",
      "4150/4150 [==============================] - 2s 390us/step - loss: 0.2102 - accuracy: 0.9277 - val_loss: 3.6018 - val_accuracy: 0.4094\n",
      "Epoch 13/50\n",
      "4150/4150 [==============================] - 2s 394us/step - loss: 0.1890 - accuracy: 0.9337 - val_loss: 3.1874 - val_accuracy: 0.3960\n",
      "Epoch 14/50\n",
      "4150/4150 [==============================] - 2s 392us/step - loss: 0.1779 - accuracy: 0.9373 - val_loss: 3.6002 - val_accuracy: 0.3863\n",
      "Epoch 15/50\n",
      "4150/4150 [==============================] - 2s 393us/step - loss: 0.1673 - accuracy: 0.9443 - val_loss: 3.8474 - val_accuracy: 0.3998\n",
      "Epoch 16/50\n",
      "4150/4150 [==============================] - 2s 390us/step - loss: 0.1408 - accuracy: 0.9547 - val_loss: 4.0388 - val_accuracy: 0.3796\n",
      "Epoch 17/50\n",
      "4150/4150 [==============================] - 2s 391us/step - loss: 0.1272 - accuracy: 0.9586 - val_loss: 3.8483 - val_accuracy: 0.3873\n",
      "Epoch 18/50\n",
      "4150/4150 [==============================] - 2s 394us/step - loss: 0.1446 - accuracy: 0.9504 - val_loss: 3.4191 - val_accuracy: 0.3728\n",
      "Epoch 19/50\n",
      "4150/4150 [==============================] - 2s 376us/step - loss: 0.1166 - accuracy: 0.9605 - val_loss: 3.9732 - val_accuracy: 0.3767\n",
      "Epoch 20/50\n",
      "4150/4150 [==============================] - 1s 359us/step - loss: 0.0707 - accuracy: 0.9754 - val_loss: 4.5592 - val_accuracy: 0.3940\n",
      "Epoch 21/50\n",
      "4150/4150 [==============================] - 1s 361us/step - loss: 0.1079 - accuracy: 0.9646 - val_loss: 3.6684 - val_accuracy: 0.4162\n",
      "Epoch 22/50\n",
      "4150/4150 [==============================] - 1s 351us/step - loss: 0.0704 - accuracy: 0.9759 - val_loss: 3.8035 - val_accuracy: 0.3748\n",
      "Epoch 23/50\n",
      "4150/4150 [==============================] - 2s 382us/step - loss: 0.0744 - accuracy: 0.9745 - val_loss: 4.8119 - val_accuracy: 0.3950\n",
      "Epoch 24/50\n",
      "4150/4150 [==============================] - 2s 381us/step - loss: 0.1370 - accuracy: 0.9564 - val_loss: 4.0070 - val_accuracy: 0.3979\n",
      "Epoch 25/50\n",
      "4150/4150 [==============================] - 2s 379us/step - loss: 0.1081 - accuracy: 0.9646 - val_loss: 4.5344 - val_accuracy: 0.3960\n",
      "Epoch 26/50\n",
      "4150/4150 [==============================] - 2s 434us/step - loss: 0.0634 - accuracy: 0.9793 - val_loss: 4.3259 - val_accuracy: 0.3969\n",
      "Epoch 27/50\n",
      "4150/4150 [==============================] - 2s 394us/step - loss: 0.0483 - accuracy: 0.9824 - val_loss: 4.5735 - val_accuracy: 0.3882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50\n",
      "4150/4150 [==============================] - 2s 370us/step - loss: 0.0761 - accuracy: 0.9781 - val_loss: 4.3570 - val_accuracy: 0.3805\n",
      "Epoch 29/50\n",
      "4150/4150 [==============================] - 2s 378us/step - loss: 0.0505 - accuracy: 0.9834 - val_loss: 5.0494 - val_accuracy: 0.3979\n",
      "Epoch 30/50\n",
      "4150/4150 [==============================] - 2s 382us/step - loss: 0.0788 - accuracy: 0.9742 - val_loss: 4.3117 - val_accuracy: 0.3940\n",
      "Epoch 31/50\n",
      "4150/4150 [==============================] - 2s 384us/step - loss: 0.1421 - accuracy: 0.9583 - val_loss: 3.8715 - val_accuracy: 0.4008\n",
      "Epoch 32/50\n",
      "4150/4150 [==============================] - 2s 380us/step - loss: 0.1267 - accuracy: 0.9619 - val_loss: 4.2614 - val_accuracy: 0.4017\n",
      "Epoch 33/50\n",
      "4150/4150 [==============================] - 2s 382us/step - loss: 0.0666 - accuracy: 0.9776 - val_loss: 4.0094 - val_accuracy: 0.3950\n",
      "Epoch 34/50\n",
      "4150/4150 [==============================] - 2s 381us/step - loss: 0.0463 - accuracy: 0.9877 - val_loss: 4.2282 - val_accuracy: 0.4066\n",
      "Epoch 35/50\n",
      "4150/4150 [==============================] - 2s 379us/step - loss: 0.0154 - accuracy: 0.9947 - val_loss: 4.4046 - val_accuracy: 0.4085\n",
      "Epoch 36/50\n",
      "4150/4150 [==============================] - 2s 379us/step - loss: 0.0301 - accuracy: 0.9918 - val_loss: 4.6548 - val_accuracy: 0.4056\n",
      "Epoch 37/50\n",
      "4150/4150 [==============================] - 2s 380us/step - loss: 0.0542 - accuracy: 0.9839 - val_loss: 4.8921 - val_accuracy: 0.4066\n",
      "Epoch 38/50\n",
      "4150/4150 [==============================] - 2s 388us/step - loss: 0.0742 - accuracy: 0.9764 - val_loss: 4.2328 - val_accuracy: 0.4104\n",
      "Epoch 39/50\n",
      "4150/4150 [==============================] - 2s 374us/step - loss: 0.0767 - accuracy: 0.9747 - val_loss: 5.0651 - val_accuracy: 0.3911\n",
      "Epoch 40/50\n",
      "4150/4150 [==============================] - 2s 376us/step - loss: 0.0584 - accuracy: 0.9831 - val_loss: 4.5117 - val_accuracy: 0.4085\n",
      "Epoch 41/50\n",
      "4150/4150 [==============================] - 2s 370us/step - loss: 0.0552 - accuracy: 0.9819 - val_loss: 4.1080 - val_accuracy: 0.3979\n",
      "Epoch 42/50\n",
      "4150/4150 [==============================] - 2s 372us/step - loss: 0.0485 - accuracy: 0.9834 - val_loss: 5.1434 - val_accuracy: 0.3950\n",
      "Epoch 43/50\n",
      "4150/4150 [==============================] - 2s 369us/step - loss: 0.0481 - accuracy: 0.9848 - val_loss: 4.8349 - val_accuracy: 0.3796\n",
      "Epoch 44/50\n",
      "4150/4150 [==============================] - 2s 379us/step - loss: 0.0705 - accuracy: 0.9786 - val_loss: 4.1481 - val_accuracy: 0.3873\n",
      "Epoch 45/50\n",
      "4150/4150 [==============================] - 2s 411us/step - loss: 0.0536 - accuracy: 0.9843 - val_loss: 4.1864 - val_accuracy: 0.4046\n",
      "Epoch 46/50\n",
      "4150/4150 [==============================] - 2s 396us/step - loss: 0.0485 - accuracy: 0.9824 - val_loss: 4.7258 - val_accuracy: 0.4027\n",
      "Epoch 47/50\n",
      "4150/4150 [==============================] - 2s 382us/step - loss: 0.0849 - accuracy: 0.9730 - val_loss: 4.7626 - val_accuracy: 0.4056\n",
      "Epoch 48/50\n",
      "4150/4150 [==============================] - 2s 384us/step - loss: 0.0822 - accuracy: 0.9773 - val_loss: 4.5936 - val_accuracy: 0.4046\n",
      "Epoch 49/50\n",
      "4150/4150 [==============================] - 2s 390us/step - loss: 0.0615 - accuracy: 0.9814 - val_loss: 4.2000 - val_accuracy: 0.4046\n",
      "Epoch 50/50\n",
      "4150/4150 [==============================] - 2s 411us/step - loss: 0.0454 - accuracy: 0.9863 - val_loss: 4.1025 - val_accuracy: 0.4075\n",
      "1038/1038 [==============================] - 0s 205us/step\n",
      "1038/1038 [==============================] - 0s 122us/step\n",
      " \n",
      "Train on 4147 samples, validate on 1037 samples\n",
      "Epoch 1/50\n",
      "4147/4147 [==============================] - 3s 754us/step - loss: 1.8391 - accuracy: 0.1717 - val_loss: 1.8265 - val_accuracy: 0.1678\n",
      "Epoch 2/50\n",
      "4147/4147 [==============================] - 2s 413us/step - loss: 1.7973 - accuracy: 0.1582 - val_loss: 3.4437 - val_accuracy: 0.1649\n",
      "Epoch 3/50\n",
      "4147/4147 [==============================] - 2s 392us/step - loss: 1.7931 - accuracy: 0.1620 - val_loss: 1.8317 - val_accuracy: 0.1736\n",
      "Epoch 4/50\n",
      "4147/4147 [==============================] - 2s 389us/step - loss: 1.7958 - accuracy: 0.1531 - val_loss: 1.7896 - val_accuracy: 0.1668\n",
      "Epoch 5/50\n",
      "4147/4147 [==============================] - 2s 399us/step - loss: 1.7926 - accuracy: 0.1522 - val_loss: 1.7890 - val_accuracy: 0.1697\n",
      "Epoch 6/50\n",
      "4147/4147 [==============================] - 2s 398us/step - loss: 1.7925 - accuracy: 0.1565 - val_loss: 1.7898 - val_accuracy: 0.1697\n",
      "Epoch 7/50\n",
      "4147/4147 [==============================] - 2s 395us/step - loss: 1.7923 - accuracy: 0.1623 - val_loss: 1.7900 - val_accuracy: 0.1697\n",
      "Epoch 8/50\n",
      "4147/4147 [==============================] - 2s 390us/step - loss: 1.7923 - accuracy: 0.1608 - val_loss: 1.7899 - val_accuracy: 0.1668\n",
      "Epoch 9/50\n",
      "4147/4147 [==============================] - 2s 402us/step - loss: 1.7924 - accuracy: 0.1519 - val_loss: 1.7900 - val_accuracy: 0.1668\n",
      "Epoch 10/50\n",
      "4147/4147 [==============================] - 2s 389us/step - loss: 1.7925 - accuracy: 0.1633 - val_loss: 1.7900 - val_accuracy: 0.1668\n",
      "Epoch 11/50\n",
      "4147/4147 [==============================] - 2s 396us/step - loss: 1.7924 - accuracy: 0.1582 - val_loss: 1.7900 - val_accuracy: 0.1697\n",
      "Epoch 12/50\n",
      "4147/4147 [==============================] - 2s 395us/step - loss: 1.7924 - accuracy: 0.1657 - val_loss: 1.7896 - val_accuracy: 0.1649\n",
      "Epoch 13/50\n",
      "4147/4147 [==============================] - 2s 397us/step - loss: 1.7943 - accuracy: 0.1579 - val_loss: 1.7910 - val_accuracy: 0.1649\n",
      "Epoch 14/50\n",
      "4147/4147 [==============================] - 2s 402us/step - loss: 1.7951 - accuracy: 0.1589 - val_loss: 1.7904 - val_accuracy: 0.1697\n",
      "Epoch 15/50\n",
      "4147/4147 [==============================] - 2s 404us/step - loss: 1.7926 - accuracy: 0.1541 - val_loss: 1.7917 - val_accuracy: 0.1688\n",
      "Epoch 16/50\n",
      "4147/4147 [==============================] - 2s 410us/step - loss: 1.7923 - accuracy: 0.1572 - val_loss: 1.7915 - val_accuracy: 0.1649\n",
      "Epoch 17/50\n",
      "4147/4147 [==============================] - 2s 396us/step - loss: 1.7924 - accuracy: 0.1596 - val_loss: 1.7919 - val_accuracy: 0.1649\n",
      "Epoch 18/50\n",
      "4147/4147 [==============================] - 2s 422us/step - loss: 1.7923 - accuracy: 0.1616 - val_loss: 1.7919 - val_accuracy: 0.1649\n",
      "Epoch 19/50\n",
      "4147/4147 [==============================] - 2s 415us/step - loss: 1.7924 - accuracy: 0.1531 - val_loss: 1.7919 - val_accuracy: 0.1649\n",
      "Epoch 20/50\n",
      "4147/4147 [==============================] - 2s 401us/step - loss: 1.7924 - accuracy: 0.1543 - val_loss: 1.7918 - val_accuracy: 0.1688\n",
      "Epoch 21/50\n",
      "4147/4147 [==============================] - 2s 394us/step - loss: 1.7924 - accuracy: 0.1596 - val_loss: 1.7918 - val_accuracy: 0.1688\n",
      "Epoch 22/50\n",
      "4147/4147 [==============================] - 2s 403us/step - loss: 1.7924 - accuracy: 0.1587 - val_loss: 1.7918 - val_accuracy: 0.1688\n",
      "Epoch 23/50\n",
      "4147/4147 [==============================] - 2s 398us/step - loss: 1.7925 - accuracy: 0.1577 - val_loss: 1.7918 - val_accuracy: 0.1649\n",
      "Epoch 24/50\n",
      "4147/4147 [==============================] - 2s 396us/step - loss: 1.7924 - accuracy: 0.1514 - val_loss: 1.7919 - val_accuracy: 0.1649\n",
      "Epoch 25/50\n",
      "4147/4147 [==============================] - 2s 397us/step - loss: 1.7924 - accuracy: 0.1483 - val_loss: 1.7918 - val_accuracy: 0.1678\n",
      "Epoch 26/50\n",
      "4147/4147 [==============================] - 2s 396us/step - loss: 1.7924 - accuracy: 0.1579 - val_loss: 1.7918 - val_accuracy: 0.1649\n",
      "Epoch 27/50\n",
      "4147/4147 [==============================] - 2s 400us/step - loss: 1.7925 - accuracy: 0.1546 - val_loss: 1.7920 - val_accuracy: 0.1649\n",
      "Epoch 28/50\n",
      "4147/4147 [==============================] - 2s 397us/step - loss: 1.7923 - accuracy: 0.1572 - val_loss: 1.7920 - val_accuracy: 0.1649\n",
      "Epoch 29/50\n",
      "4147/4147 [==============================] - 2s 397us/step - loss: 1.7924 - accuracy: 0.1601 - val_loss: 1.7918 - val_accuracy: 0.1649\n",
      "Epoch 30/50\n",
      "4147/4147 [==============================] - 2s 393us/step - loss: 1.7924 - accuracy: 0.1548 - val_loss: 1.7918 - val_accuracy: 0.1678\n",
      "Epoch 31/50\n",
      "4147/4147 [==============================] - 2s 390us/step - loss: 1.7925 - accuracy: 0.1565 - val_loss: 1.7918 - val_accuracy: 0.1649\n",
      "Epoch 32/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4147/4147 [==============================] - 2s 380us/step - loss: 1.7923 - accuracy: 0.1594 - val_loss: 1.7918 - val_accuracy: 0.1649\n",
      "Epoch 33/50\n",
      "4147/4147 [==============================] - 2s 382us/step - loss: 1.7923 - accuracy: 0.1618 - val_loss: 1.7919 - val_accuracy: 0.1649\n",
      "Epoch 34/50\n",
      "4147/4147 [==============================] - 2s 385us/step - loss: 1.7925 - accuracy: 0.1606 - val_loss: 1.7918 - val_accuracy: 0.1688\n",
      "Epoch 35/50\n",
      "4147/4147 [==============================] - 2s 385us/step - loss: 1.7924 - accuracy: 0.1599 - val_loss: 1.7918 - val_accuracy: 0.1649\n",
      "Epoch 36/50\n",
      "4147/4147 [==============================] - 2s 385us/step - loss: 1.7922 - accuracy: 0.1599 - val_loss: 1.7918 - val_accuracy: 0.1649\n",
      "Epoch 37/50\n",
      "4147/4147 [==============================] - 2s 384us/step - loss: 1.7925 - accuracy: 0.1599 - val_loss: 1.7919 - val_accuracy: 0.1649\n",
      "Epoch 38/50\n",
      "4147/4147 [==============================] - 2s 381us/step - loss: 1.7923 - accuracy: 0.1582 - val_loss: 1.7918 - val_accuracy: 0.1688\n",
      "Epoch 39/50\n",
      "4147/4147 [==============================] - 2s 381us/step - loss: 1.7923 - accuracy: 0.1493 - val_loss: 1.7920 - val_accuracy: 0.1649\n",
      "Epoch 40/50\n",
      "4147/4147 [==============================] - 2s 379us/step - loss: 1.7924 - accuracy: 0.1567 - val_loss: 1.7919 - val_accuracy: 0.1649\n",
      "Epoch 41/50\n",
      "4147/4147 [==============================] - 2s 381us/step - loss: 1.7924 - accuracy: 0.1599 - val_loss: 1.7918 - val_accuracy: 0.1649\n",
      "Epoch 42/50\n",
      "4147/4147 [==============================] - 2s 383us/step - loss: 1.7924 - accuracy: 0.1623 - val_loss: 1.7917 - val_accuracy: 0.1688\n",
      "Epoch 43/50\n",
      "4147/4147 [==============================] - 2s 382us/step - loss: 1.7924 - accuracy: 0.1620 - val_loss: 1.7917 - val_accuracy: 0.1678\n",
      "Epoch 44/50\n",
      "4147/4147 [==============================] - 2s 382us/step - loss: 1.7925 - accuracy: 0.1524 - val_loss: 1.7918 - val_accuracy: 0.1649\n",
      "Epoch 45/50\n",
      "4147/4147 [==============================] - 2s 381us/step - loss: 1.7924 - accuracy: 0.1616 - val_loss: 1.7918 - val_accuracy: 0.1649\n",
      "Epoch 46/50\n",
      "4147/4147 [==============================] - 2s 388us/step - loss: 1.7925 - accuracy: 0.1543 - val_loss: 1.7918 - val_accuracy: 0.1649\n",
      "Epoch 47/50\n",
      "4147/4147 [==============================] - 2s 377us/step - loss: 1.7925 - accuracy: 0.1589 - val_loss: 1.7918 - val_accuracy: 0.1688\n",
      "Epoch 48/50\n",
      "4147/4147 [==============================] - 2s 375us/step - loss: 1.7923 - accuracy: 0.1604 - val_loss: 1.7920 - val_accuracy: 0.1649\n",
      "Epoch 49/50\n",
      "4147/4147 [==============================] - 2s 371us/step - loss: 1.7924 - accuracy: 0.1657 - val_loss: 1.7919 - val_accuracy: 0.1649\n",
      "Epoch 50/50\n",
      "4147/4147 [==============================] - 2s 369us/step - loss: 1.7923 - accuracy: 0.1628 - val_loss: 1.7918 - val_accuracy: 0.1649\n",
      "1037/1037 [==============================] - 0s 195us/step\n",
      "1037/1037 [==============================] - 0s 106us/step\n",
      " \n",
      "Train on 4148 samples, validate on 1037 samples\n",
      "Epoch 1/50\n",
      "4148/4148 [==============================] - 3s 732us/step - loss: 1.8079 - accuracy: 0.2457 - val_loss: 2.3062 - val_accuracy: 0.1688\n",
      "Epoch 2/50\n",
      "4148/4148 [==============================] - 2s 404us/step - loss: 1.6265 - accuracy: 0.3255 - val_loss: 3.9890 - val_accuracy: 0.1755\n",
      "Epoch 3/50\n",
      "4148/4148 [==============================] - 2s 404us/step - loss: 1.4883 - accuracy: 0.3872 - val_loss: 6.4656 - val_accuracy: 0.2150\n",
      "Epoch 4/50\n",
      "4148/4148 [==============================] - 2s 404us/step - loss: 1.3485 - accuracy: 0.4578 - val_loss: 2.5637 - val_accuracy: 0.3192\n",
      "Epoch 5/50\n",
      "4148/4148 [==============================] - 2s 382us/step - loss: 1.1976 - accuracy: 0.5188 - val_loss: 2.0689 - val_accuracy: 0.4079\n",
      "Epoch 6/50\n",
      "4148/4148 [==============================] - 2s 375us/step - loss: 1.0515 - accuracy: 0.5841 - val_loss: 2.3214 - val_accuracy: 0.3693\n",
      "Epoch 7/50\n",
      "4148/4148 [==============================] - 2s 401us/step - loss: 0.9069 - accuracy: 0.6478 - val_loss: 2.2790 - val_accuracy: 0.3848\n",
      "Epoch 8/50\n",
      "4148/4148 [==============================] - 2s 399us/step - loss: 0.7134 - accuracy: 0.7261 - val_loss: 3.4166 - val_accuracy: 0.4176\n",
      "Epoch 9/50\n",
      "4148/4148 [==============================] - 2s 406us/step - loss: 0.6244 - accuracy: 0.7664 - val_loss: 2.4200 - val_accuracy: 0.3761\n",
      "Epoch 10/50\n",
      "4148/4148 [==============================] - 2s 424us/step - loss: 0.5253 - accuracy: 0.8059 - val_loss: 3.0057 - val_accuracy: 0.3925\n",
      "Epoch 11/50\n",
      "4148/4148 [==============================] - ETA: 0s - loss: 0.4259 - accuracy: 0.84 - 2s 416us/step - loss: 0.4255 - accuracy: 0.8455 - val_loss: 3.5801 - val_accuracy: 0.3905\n",
      "Epoch 12/50\n",
      "4148/4148 [==============================] - 2s 431us/step - loss: 0.3575 - accuracy: 0.8681 - val_loss: 4.5298 - val_accuracy: 0.4233\n",
      "Epoch 13/50\n",
      "4148/4148 [==============================] - 2s 418us/step - loss: 0.2851 - accuracy: 0.8946 - val_loss: 5.4663 - val_accuracy: 0.3905\n",
      "Epoch 14/50\n",
      "4148/4148 [==============================] - 2s 388us/step - loss: 0.2819 - accuracy: 0.9033 - val_loss: 6.6433 - val_accuracy: 0.3655\n",
      "Epoch 15/50\n",
      "4148/4148 [==============================] - 2s 384us/step - loss: 0.3034 - accuracy: 0.8959 - val_loss: 5.2840 - val_accuracy: 0.3857\n",
      "Epoch 16/50\n",
      "4148/4148 [==============================] - 2s 392us/step - loss: 0.2499 - accuracy: 0.9144 - val_loss: 5.5006 - val_accuracy: 0.3886\n",
      "Epoch 17/50\n",
      "4148/4148 [==============================] - 2s 394us/step - loss: 0.1997 - accuracy: 0.9296 - val_loss: 5.9518 - val_accuracy: 0.3664\n",
      "Epoch 18/50\n",
      "4148/4148 [==============================] - 2s 393us/step - loss: 0.1742 - accuracy: 0.9361 - val_loss: 5.3136 - val_accuracy: 0.3780\n",
      "Epoch 19/50\n",
      "4148/4148 [==============================] - 2s 412us/step - loss: 0.2355 - accuracy: 0.9142 - val_loss: 6.4201 - val_accuracy: 0.3915\n",
      "Epoch 20/50\n",
      "4148/4148 [==============================] - 2s 434us/step - loss: 0.1670 - accuracy: 0.9388 - val_loss: 5.0675 - val_accuracy: 0.3819\n",
      "Epoch 21/50\n",
      "4148/4148 [==============================] - 2s 396us/step - loss: 0.1338 - accuracy: 0.9523 - val_loss: 7.4173 - val_accuracy: 0.3983\n",
      "Epoch 22/50\n",
      "4148/4148 [==============================] - 2s 385us/step - loss: 0.1201 - accuracy: 0.9607 - val_loss: 6.7409 - val_accuracy: 0.3954\n",
      "Epoch 23/50\n",
      "4148/4148 [==============================] - 2s 387us/step - loss: 0.1425 - accuracy: 0.9537 - val_loss: 6.8880 - val_accuracy: 0.3925\n",
      "Epoch 24/50\n",
      "4148/4148 [==============================] - 2s 385us/step - loss: 0.1373 - accuracy: 0.9568 - val_loss: 6.0320 - val_accuracy: 0.3944\n",
      "Epoch 25/50\n",
      "4148/4148 [==============================] - 2s 385us/step - loss: 0.1248 - accuracy: 0.9576 - val_loss: 5.6761 - val_accuracy: 0.3944\n",
      "Epoch 26/50\n",
      "4148/4148 [==============================] - 2s 390us/step - loss: 0.1435 - accuracy: 0.9518 - val_loss: 6.3834 - val_accuracy: 0.3780\n",
      "Epoch 27/50\n",
      "4148/4148 [==============================] - 2s 387us/step - loss: 0.0798 - accuracy: 0.9737 - val_loss: 6.1868 - val_accuracy: 0.4021\n",
      "Epoch 28/50\n",
      "4148/4148 [==============================] - 2s 392us/step - loss: 0.0932 - accuracy: 0.9711 - val_loss: 5.6163 - val_accuracy: 0.4176\n",
      "Epoch 29/50\n",
      "4148/4148 [==============================] - 2s 387us/step - loss: 0.0888 - accuracy: 0.9723 - val_loss: 5.6213 - val_accuracy: 0.4147\n",
      "Epoch 30/50\n",
      "4148/4148 [==============================] - 2s 384us/step - loss: 0.1138 - accuracy: 0.9653 - val_loss: 6.6010 - val_accuracy: 0.4050\n",
      "Epoch 31/50\n",
      "4148/4148 [==============================] - 2s 415us/step - loss: 0.0837 - accuracy: 0.9737 - val_loss: 6.4437 - val_accuracy: 0.3857\n",
      "Epoch 32/50\n",
      "4148/4148 [==============================] - 2s 392us/step - loss: 0.1003 - accuracy: 0.9684 - val_loss: 5.6682 - val_accuracy: 0.4185\n",
      "Epoch 33/50\n",
      "4148/4148 [==============================] - 2s 381us/step - loss: 0.1147 - accuracy: 0.9667 - val_loss: 5.9173 - val_accuracy: 0.3954\n",
      "Epoch 34/50\n",
      "4148/4148 [==============================] - 2s 387us/step - loss: 0.1153 - accuracy: 0.9653 - val_loss: 5.1888 - val_accuracy: 0.4012\n",
      "Epoch 35/50\n",
      "4148/4148 [==============================] - 2s 395us/step - loss: 0.0891 - accuracy: 0.9742 - val_loss: 5.6081 - val_accuracy: 0.4156\n",
      "Epoch 36/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4148/4148 [==============================] - 2s 385us/step - loss: 0.0436 - accuracy: 0.9877 - val_loss: 5.9349 - val_accuracy: 0.4224\n",
      "Epoch 37/50\n",
      "4148/4148 [==============================] - 2s 381us/step - loss: 0.0349 - accuracy: 0.9892 - val_loss: 6.7633 - val_accuracy: 0.4041\n",
      "Epoch 38/50\n",
      "4148/4148 [==============================] - 2s 385us/step - loss: 0.0238 - accuracy: 0.9925 - val_loss: 6.3796 - val_accuracy: 0.4069\n",
      "Epoch 39/50\n",
      "4148/4148 [==============================] - 2s 386us/step - loss: 0.0394 - accuracy: 0.9884 - val_loss: 7.9175 - val_accuracy: 0.4021\n",
      "Epoch 40/50\n",
      "4148/4148 [==============================] - 2s 392us/step - loss: 0.0886 - accuracy: 0.9703 - val_loss: 9.0120 - val_accuracy: 0.3886\n",
      "Epoch 41/50\n",
      "4148/4148 [==============================] - 2s 390us/step - loss: 0.1411 - accuracy: 0.9607 - val_loss: 5.2972 - val_accuracy: 0.3549\n",
      "Epoch 42/50\n",
      "4148/4148 [==============================] - 2s 386us/step - loss: 0.1236 - accuracy: 0.9612 - val_loss: 5.6586 - val_accuracy: 0.3992\n",
      "Epoch 43/50\n",
      "4148/4148 [==============================] - 2s 386us/step - loss: 0.0637 - accuracy: 0.9785 - val_loss: 5.5676 - val_accuracy: 0.4156\n",
      "Epoch 44/50\n",
      "4148/4148 [==============================] - 2s 388us/step - loss: 0.0528 - accuracy: 0.9863 - val_loss: 6.8320 - val_accuracy: 0.4214\n",
      "Epoch 45/50\n",
      "4148/4148 [==============================] - 2s 387us/step - loss: 0.0870 - accuracy: 0.9771 - val_loss: 6.5995 - val_accuracy: 0.3896\n",
      "Epoch 46/50\n",
      "4148/4148 [==============================] - 2s 391us/step - loss: 0.0746 - accuracy: 0.9797 - val_loss: 6.7963 - val_accuracy: 0.4060\n",
      "Epoch 47/50\n",
      "4148/4148 [==============================] - 2s 387us/step - loss: 0.0700 - accuracy: 0.9814 - val_loss: 6.1581 - val_accuracy: 0.4089\n",
      "Epoch 48/50\n",
      "4148/4148 [==============================] - 2s 386us/step - loss: 0.0656 - accuracy: 0.9814 - val_loss: 6.2105 - val_accuracy: 0.4311\n",
      "Epoch 49/50\n",
      "4148/4148 [==============================] - 2s 387us/step - loss: 0.0734 - accuracy: 0.9800 - val_loss: 5.7089 - val_accuracy: 0.3761\n",
      "Epoch 50/50\n",
      "4148/4148 [==============================] - 2s 385us/step - loss: 0.0497 - accuracy: 0.9838 - val_loss: 6.6415 - val_accuracy: 0.4291\n",
      "1037/1037 [==============================] - 0s 196us/step\n",
      "1037/1037 [==============================] - 0s 114us/step\n",
      " \n",
      "Train on 4147 samples, validate on 1037 samples\n",
      "Epoch 1/50\n",
      "4147/4147 [==============================] - 2s 541us/step - loss: 1.8466 - accuracy: 0.2173 - val_loss: 1.8124 - val_accuracy: 0.1707\n",
      "Epoch 2/50\n",
      "4147/4147 [==============================] - 1s 316us/step - loss: 1.6347 - accuracy: 0.3212 - val_loss: 2.2001 - val_accuracy: 0.2314\n",
      "Epoch 3/50\n",
      "4147/4147 [==============================] - 1s 310us/step - loss: 1.4193 - accuracy: 0.4321 - val_loss: 1.5981 - val_accuracy: 0.3414\n",
      "Epoch 4/50\n",
      "4147/4147 [==============================] - 1s 311us/step - loss: 1.2263 - accuracy: 0.5134 - val_loss: 1.5350 - val_accuracy: 0.3848\n",
      "Epoch 5/50\n",
      "4147/4147 [==============================] - 1s 314us/step - loss: 1.0400 - accuracy: 0.5874 - val_loss: 1.6216 - val_accuracy: 0.3790\n",
      "Epoch 6/50\n",
      "4147/4147 [==============================] - 1s 311us/step - loss: 0.8746 - accuracy: 0.6701 - val_loss: 1.9281 - val_accuracy: 0.3848\n",
      "Epoch 7/50\n",
      "4147/4147 [==============================] - 1s 329us/step - loss: 0.6390 - accuracy: 0.7552 - val_loss: 2.0643 - val_accuracy: 0.4041\n",
      "Epoch 8/50\n",
      "4147/4147 [==============================] - 1s 329us/step - loss: 0.5706 - accuracy: 0.7888 - val_loss: 2.3735 - val_accuracy: 0.3838\n",
      "Epoch 9/50\n",
      "4147/4147 [==============================] - 1s 320us/step - loss: 0.3974 - accuracy: 0.8512 - val_loss: 2.3850 - val_accuracy: 0.3828\n",
      "Epoch 10/50\n",
      "4147/4147 [==============================] - 1s 351us/step - loss: 0.3228 - accuracy: 0.8855 - val_loss: 2.4891 - val_accuracy: 0.4079\n",
      "Epoch 11/50\n",
      "4147/4147 [==============================] - 2s 379us/step - loss: 0.2510 - accuracy: 0.9105 - val_loss: 3.1593 - val_accuracy: 0.4224\n",
      "Epoch 12/50\n",
      "4147/4147 [==============================] - 2s 395us/step - loss: 0.2603 - accuracy: 0.9072 - val_loss: 3.0276 - val_accuracy: 0.4137\n",
      "Epoch 13/50\n",
      "4147/4147 [==============================] - 2s 391us/step - loss: 0.2005 - accuracy: 0.9293 - val_loss: 3.6887 - val_accuracy: 0.3934\n",
      "Epoch 14/50\n",
      "4147/4147 [==============================] - 2s 395us/step - loss: 0.1965 - accuracy: 0.9334 - val_loss: 3.3617 - val_accuracy: 0.3732\n",
      "Epoch 15/50\n",
      "4147/4147 [==============================] - 2s 387us/step - loss: 0.1764 - accuracy: 0.9409 - val_loss: 3.2753 - val_accuracy: 0.3944\n",
      "Epoch 16/50\n",
      "4147/4147 [==============================] - 2s 394us/step - loss: 0.1629 - accuracy: 0.9462 - val_loss: 3.7121 - val_accuracy: 0.3886\n",
      "Epoch 17/50\n",
      "4147/4147 [==============================] - 2s 394us/step - loss: 0.1237 - accuracy: 0.9588 - val_loss: 3.7951 - val_accuracy: 0.3954\n",
      "Epoch 18/50\n",
      "4147/4147 [==============================] - 2s 386us/step - loss: 0.1395 - accuracy: 0.9549 - val_loss: 3.9402 - val_accuracy: 0.4002\n",
      "Epoch 19/50\n",
      "4147/4147 [==============================] - 2s 385us/step - loss: 0.1086 - accuracy: 0.9653 - val_loss: 3.7937 - val_accuracy: 0.3828\n",
      "Epoch 20/50\n",
      "4147/4147 [==============================] - 2s 395us/step - loss: 0.0888 - accuracy: 0.9718 - val_loss: 3.8077 - val_accuracy: 0.3722\n",
      "Epoch 21/50\n",
      "4147/4147 [==============================] - 2s 388us/step - loss: 0.1147 - accuracy: 0.9619 - val_loss: 3.4073 - val_accuracy: 0.3790\n",
      "Epoch 22/50\n",
      "4147/4147 [==============================] - 2s 388us/step - loss: 0.1521 - accuracy: 0.9503 - val_loss: 4.1729 - val_accuracy: 0.3886\n",
      "Epoch 23/50\n",
      "4147/4147 [==============================] - 2s 410us/step - loss: 0.1192 - accuracy: 0.9653 - val_loss: 4.0895 - val_accuracy: 0.3664\n",
      "Epoch 24/50\n",
      "4147/4147 [==============================] - 2s 385us/step - loss: 0.0742 - accuracy: 0.9766 - val_loss: 3.9087 - val_accuracy: 0.3877\n",
      "Epoch 25/50\n",
      "4147/4147 [==============================] - 2s 381us/step - loss: 0.0610 - accuracy: 0.9778 - val_loss: 4.7508 - val_accuracy: 0.3751\n",
      "Epoch 26/50\n",
      "4147/4147 [==============================] - 2s 384us/step - loss: 0.0447 - accuracy: 0.9841 - val_loss: 4.4905 - val_accuracy: 0.3963\n",
      "Epoch 27/50\n",
      "4147/4147 [==============================] - 2s 385us/step - loss: 0.0524 - accuracy: 0.9838 - val_loss: 5.0334 - val_accuracy: 0.3742\n",
      "Epoch 28/50\n",
      "4147/4147 [==============================] - 2s 382us/step - loss: 0.1511 - accuracy: 0.9508 - val_loss: 3.7861 - val_accuracy: 0.3770\n",
      "Epoch 29/50\n",
      "4147/4147 [==============================] - 2s 383us/step - loss: 0.1667 - accuracy: 0.9445 - val_loss: 3.6792 - val_accuracy: 0.3886\n",
      "Epoch 30/50\n",
      "4147/4147 [==============================] - 2s 386us/step - loss: 0.0744 - accuracy: 0.9761 - val_loss: 4.9088 - val_accuracy: 0.3973\n",
      "Epoch 31/50\n",
      "4147/4147 [==============================] - 2s 382us/step - loss: 0.0411 - accuracy: 0.9875 - val_loss: 4.4019 - val_accuracy: 0.3857\n",
      "Epoch 32/50\n",
      "4147/4147 [==============================] - 2s 380us/step - loss: 0.0332 - accuracy: 0.9896 - val_loss: 4.6544 - val_accuracy: 0.3954\n",
      "Epoch 33/50\n",
      "4147/4147 [==============================] - 2s 385us/step - loss: 0.0413 - accuracy: 0.9860 - val_loss: 4.5455 - val_accuracy: 0.3732\n",
      "Epoch 34/50\n",
      "4147/4147 [==============================] - 2s 383us/step - loss: 0.0412 - accuracy: 0.9870 - val_loss: 5.0185 - val_accuracy: 0.3973\n",
      "Epoch 35/50\n",
      "4147/4147 [==============================] - 2s 383us/step - loss: 0.0820 - accuracy: 0.9742 - val_loss: 5.1176 - val_accuracy: 0.3684\n",
      "Epoch 36/50\n",
      "4147/4147 [==============================] - 2s 383us/step - loss: 0.1123 - accuracy: 0.9636 - val_loss: 4.9357 - val_accuracy: 0.4069\n",
      "Epoch 37/50\n",
      "4147/4147 [==============================] - 2s 394us/step - loss: 0.1035 - accuracy: 0.9682 - val_loss: 4.0350 - val_accuracy: 0.4002\n",
      "Epoch 38/50\n",
      "4147/4147 [==============================] - 2s 423us/step - loss: 0.0754 - accuracy: 0.9785 - val_loss: 4.6181 - val_accuracy: 0.4002\n",
      "Epoch 39/50\n",
      "4147/4147 [==============================] - 2s 396us/step - loss: 0.0499 - accuracy: 0.9838 - val_loss: 4.1703 - val_accuracy: 0.3983\n",
      "Epoch 40/50\n",
      "4147/4147 [==============================] - 2s 401us/step - loss: 0.0309 - accuracy: 0.9904 - val_loss: 4.8374 - val_accuracy: 0.4098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50\n",
      "4147/4147 [==============================] - 2s 383us/step - loss: 0.0198 - accuracy: 0.9940 - val_loss: 5.6456 - val_accuracy: 0.4224\n",
      "Epoch 42/50\n",
      "4147/4147 [==============================] - 2s 419us/step - loss: 0.0155 - accuracy: 0.9949 - val_loss: 5.1013 - val_accuracy: 0.4262\n",
      "Epoch 43/50\n",
      "4147/4147 [==============================] - 2s 388us/step - loss: 0.0210 - accuracy: 0.9937 - val_loss: 5.6156 - val_accuracy: 0.4147\n",
      "Epoch 44/50\n",
      "4147/4147 [==============================] - 2s 405us/step - loss: 0.0569 - accuracy: 0.9848 - val_loss: 5.1761 - val_accuracy: 0.4176\n",
      "Epoch 45/50\n",
      "4147/4147 [==============================] - 2s 382us/step - loss: 0.1468 - accuracy: 0.9602 - val_loss: 4.3434 - val_accuracy: 0.3848\n",
      "Epoch 46/50\n",
      "4147/4147 [==============================] - 2s 377us/step - loss: 0.1261 - accuracy: 0.9636 - val_loss: 4.1957 - val_accuracy: 0.3819\n",
      "Epoch 47/50\n",
      "4147/4147 [==============================] - 2s 387us/step - loss: 0.0823 - accuracy: 0.9761 - val_loss: 4.3669 - val_accuracy: 0.3925\n",
      "Epoch 48/50\n",
      "4147/4147 [==============================] - 2s 379us/step - loss: 0.0367 - accuracy: 0.9884 - val_loss: 4.6413 - val_accuracy: 0.4108\n",
      "Epoch 49/50\n",
      "4147/4147 [==============================] - 2s 375us/step - loss: 0.0273 - accuracy: 0.9920 - val_loss: 4.6252 - val_accuracy: 0.4012\n",
      "Epoch 50/50\n",
      "4147/4147 [==============================] - 2s 376us/step - loss: 0.0130 - accuracy: 0.9959 - val_loss: 5.2256 - val_accuracy: 0.3963\n",
      "1037/1037 [==============================] - 0s 204us/step\n",
      "1037/1037 [==============================] - 0s 122us/step\n",
      " \n",
      "Accuracy: 35.28\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 468x468 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "keep_accuracy = np.zeros((10))\n",
    "j = 0\n",
    "\n",
    "for participant in files:\n",
    "    mat = loadmat(participant)\n",
    "    X_2D = np.array(mat[\"X_2D\"])\n",
    "    categoryLabels = np.array(mat[\"categoryLabels\"])     # get labels\n",
    "\n",
    "    k = 180\n",
    "    X = X_2D.copy()\n",
    "    y = categoryLabels.ravel()\n",
    "    X -= np.mean(X, axis=0)\n",
    "\n",
    "    [u,s,v] = la.svd(X)                                   # pca with svd, using an optimum k\n",
    "    v = v.transpose() \n",
    "    v_new = v[:,:k]\n",
    "    X_pca = np.dot(X, v_new)\n",
    "\n",
    "    X_training = X[:int(0.8*len(X))]\n",
    "    X_validation = X[int(0.8*len(X)):]\n",
    "\n",
    "    y_training = y[:int(0.8*len(X))]\n",
    "    y_validation = y[int(0.8*len(X)):]\n",
    "\n",
    "    num_classes = 6\n",
    "    y_training1hot = keras.utils.to_categorical(y_training - 1, num_classes) # We subtract 1 to convert to 0-index\n",
    "    y_validation1hot = keras.utils.to_categorical(y_validation - 1, num_classes)\n",
    "\n",
    "    \n",
    "    X_training = np.reshape(X_training, (-1, electrodes, N, 1))\n",
    "    X_validation = np.reshape(X_validation, (-1, electrodes, N, 1))\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(8, kernel_size=3,input_shape=(124,32, 1), activation = 'relu'))\n",
    "    model.add(Conv2D(8, kernel_size=3, activation = 'relu'))\n",
    "    model.add(MaxPool2D(2,2))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(16, kernel_size=2,activation = 'relu'))\n",
    "    model.add(Conv2D(16, kernel_size=2,activation = 'relu'))\n",
    "    model.add(MaxPool2D(2,2))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "    model.add(Conv2D(64, kernel_size=3, activation = 'relu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(32, activation = \"relu\"))\n",
    "    model.add(Dense(16, activation = \"relu\"))\n",
    "    model.add(Dense(6, activation = \"softmax\"))\n",
    "\n",
    "\n",
    "    optimizer=Nadam(lr=0.004)\n",
    "    model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "    model.fit(X_training, y_training1hot,                               # train the model\n",
    "              epochs=50,\n",
    "              validation_data=(X_validation, y_validation1hot), \n",
    "              shuffle=True)\n",
    "\n",
    "    y_validation_predictions = model.predict(X_validation, verbose=1)   # make predictions\n",
    "\n",
    "    # create the confusion matrix\n",
    "    cnf_matrix3 = confusion_matrix(y_validation-1, np.argmax(y_validation_predictions, axis=1))\n",
    "    cm_cv3 += cnf_matrix3                                               # add together all the confusion matrices\n",
    "    \n",
    "    _, accuracy = model.evaluate(X_validation, y_validation1hot)        # find accuracy\n",
    "    keep_accuracy[j] = accuracy\n",
    "    j = j + 1\n",
    "    print(\" \")\n",
    "    \n",
    "print('Accuracy: %.2f' % (np.mean(keep_accuracy)*100))                  # print mean accuracy\n",
    "\n",
    "sum_by_row = np.sum(cm_cv3, 1)                                          # normalize the final confusion matrix\n",
    "for i in range(0,6):\n",
    "    cm_cv3[i,:] = cm_cv3[i,:] / sum_by_row[i]\n",
    "    \n",
    "plot_cm(np.round(cm_cv3, 4),6)                                          # plot the final confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.37103289, 0.10386613, 0.12867859, 0.13675707, 0.12463935,\n",
       "        0.13502597],\n",
       "       [0.19163763, 0.47619048, 0.07897793, 0.0981417 , 0.08188153,\n",
       "        0.07317073],\n",
       "       [0.20912767, 0.06065858, 0.34142114, 0.14038128, 0.12709417,\n",
       "        0.12131716],\n",
       "       [0.22748268, 0.10508083, 0.1460739 , 0.34815242, 0.09584296,\n",
       "        0.07736721],\n",
       "       [0.20496536, 0.05600462, 0.1443418 , 0.10450346, 0.2852194 ,\n",
       "        0.20496536],\n",
       "       [0.23594203, 0.0684058 , 0.13333333, 0.05971014, 0.20753623,\n",
       "        0.29507246]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_cv3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA with DFNN, 2 classes\n",
    "\n",
    "Αρχικά τρέχουμε PCA με svd πριν, χρησιμοποιώντας k=180. Στη συνέχεια, εφαρμόζουμε ένα μοντέλο DFNN στις δύο κλάσεις, human face και inanimate object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1382 samples, validate on 346 samples\n",
      "Epoch 1/50\n",
      "1382/1382 [==============================] - 1s 486us/step - loss: 1.5681 - accuracy: 0.6715 - val_loss: 1.3383 - val_accuracy: 0.7283\n",
      "Epoch 2/50\n",
      "1382/1382 [==============================] - 0s 185us/step - loss: 1.0166 - accuracy: 0.8350 - val_loss: 1.1381 - val_accuracy: 0.7283\n",
      "Epoch 3/50\n",
      "1382/1382 [==============================] - 0s 189us/step - loss: 0.6903 - accuracy: 0.9204 - val_loss: 1.0761 - val_accuracy: 0.7139\n",
      "Epoch 4/50\n",
      "1382/1382 [==============================] - 0s 193us/step - loss: 0.5348 - accuracy: 0.9508 - val_loss: 1.1414 - val_accuracy: 0.7399\n",
      "Epoch 5/50\n",
      "1382/1382 [==============================] - 0s 164us/step - loss: 0.4243 - accuracy: 0.9696 - val_loss: 1.7449 - val_accuracy: 0.6908\n",
      "Epoch 6/50\n",
      "1382/1382 [==============================] - 0s 173us/step - loss: 0.4038 - accuracy: 0.9674 - val_loss: 1.1839 - val_accuracy: 0.7601\n",
      "Epoch 7/50\n",
      "1382/1382 [==============================] - 0s 179us/step - loss: 0.3263 - accuracy: 0.9834 - val_loss: 1.4447 - val_accuracy: 0.6705\n",
      "Epoch 8/50\n",
      "1382/1382 [==============================] - 0s 164us/step - loss: 0.3118 - accuracy: 0.9797 - val_loss: 1.3019 - val_accuracy: 0.7139\n",
      "Epoch 9/50\n",
      "1382/1382 [==============================] - 0s 177us/step - loss: 0.2553 - accuracy: 0.9863 - val_loss: 1.2135 - val_accuracy: 0.7428\n",
      "Epoch 10/50\n",
      "1382/1382 [==============================] - 0s 167us/step - loss: 0.2283 - accuracy: 0.9913 - val_loss: 1.2027 - val_accuracy: 0.7428\n",
      "Epoch 11/50\n",
      "1382/1382 [==============================] - 0s 160us/step - loss: 0.1702 - accuracy: 0.9978 - val_loss: 1.4251 - val_accuracy: 0.7225\n",
      "Epoch 12/50\n",
      "1382/1382 [==============================] - 0s 164us/step - loss: 0.1437 - accuracy: 0.9978 - val_loss: 1.6322 - val_accuracy: 0.6936\n",
      "Epoch 13/50\n",
      "1382/1382 [==============================] - 0s 164us/step - loss: 0.1216 - accuracy: 0.9978 - val_loss: 1.7268 - val_accuracy: 0.7139\n",
      "Epoch 14/50\n",
      "1382/1382 [==============================] - 0s 179us/step - loss: 0.1024 - accuracy: 1.0000 - val_loss: 1.7392 - val_accuracy: 0.6908\n",
      "Epoch 15/50\n",
      "1382/1382 [==============================] - 0s 180us/step - loss: 0.2043 - accuracy: 0.9689 - val_loss: 1.1315 - val_accuracy: 0.7370\n",
      "Epoch 16/50\n",
      "1382/1382 [==============================] - 0s 173us/step - loss: 0.1696 - accuracy: 0.9805 - val_loss: 1.2272 - val_accuracy: 0.7486\n",
      "Epoch 17/50\n",
      "1382/1382 [==============================] - 0s 167us/step - loss: 0.1406 - accuracy: 0.9920 - val_loss: 1.3064 - val_accuracy: 0.6705\n",
      "Epoch 18/50\n",
      "1382/1382 [==============================] - 0s 191us/step - loss: 0.2084 - accuracy: 0.9783 - val_loss: 1.2030 - val_accuracy: 0.7283\n",
      "Epoch 19/50\n",
      "1382/1382 [==============================] - 0s 180us/step - loss: 0.1536 - accuracy: 0.9906 - val_loss: 1.3092 - val_accuracy: 0.7254\n",
      "Epoch 20/50\n",
      "1382/1382 [==============================] - 0s 164us/step - loss: 0.0997 - accuracy: 0.9986 - val_loss: 1.5303 - val_accuracy: 0.7312\n",
      "Epoch 21/50\n",
      "1382/1382 [==============================] - 0s 164us/step - loss: 0.0824 - accuracy: 0.9993 - val_loss: 1.5947 - val_accuracy: 0.7312\n",
      "Epoch 22/50\n",
      "1382/1382 [==============================] - 0s 168us/step - loss: 0.0705 - accuracy: 1.0000 - val_loss: 1.6425 - val_accuracy: 0.7341\n",
      "Epoch 23/50\n",
      "1382/1382 [==============================] - 0s 187us/step - loss: 0.0626 - accuracy: 1.0000 - val_loss: 1.6986 - val_accuracy: 0.7341\n",
      "Epoch 24/50\n",
      "1382/1382 [==============================] - 0s 189us/step - loss: 0.0559 - accuracy: 1.0000 - val_loss: 1.7497 - val_accuracy: 0.7370\n",
      "Epoch 25/50\n",
      "1382/1382 [==============================] - 0s 173us/step - loss: 0.0513 - accuracy: 1.0000 - val_loss: 1.8061 - val_accuracy: 0.7283\n",
      "Epoch 26/50\n",
      "1382/1382 [==============================] - 0s 187us/step - loss: 0.0466 - accuracy: 1.0000 - val_loss: 1.8484 - val_accuracy: 0.7254\n",
      "Epoch 27/50\n",
      "1382/1382 [==============================] - 0s 187us/step - loss: 0.0435 - accuracy: 1.0000 - val_loss: 1.8951 - val_accuracy: 0.7225\n",
      "Epoch 28/50\n",
      "1382/1382 [==============================] - 0s 175us/step - loss: 0.0957 - accuracy: 0.9935 - val_loss: 1.9433 - val_accuracy: 0.6994\n",
      "Epoch 29/50\n",
      "1382/1382 [==============================] - 0s 185us/step - loss: 0.1879 - accuracy: 0.9754 - val_loss: 1.4702 - val_accuracy: 0.6879\n",
      "Epoch 30/50\n",
      "1382/1382 [==============================] - 0s 183us/step - loss: 0.1570 - accuracy: 0.9805 - val_loss: 1.3249 - val_accuracy: 0.7283\n",
      "Epoch 31/50\n",
      "1382/1382 [==============================] - 0s 174us/step - loss: 0.0772 - accuracy: 1.0000 - val_loss: 1.5963 - val_accuracy: 0.7168\n",
      "Epoch 32/50\n",
      "1382/1382 [==============================] - 0s 166us/step - loss: 0.0596 - accuracy: 1.0000 - val_loss: 1.6918 - val_accuracy: 0.7168\n",
      "Epoch 33/50\n",
      "1382/1382 [==============================] - 0s 183us/step - loss: 0.0513 - accuracy: 1.0000 - val_loss: 1.7560 - val_accuracy: 0.7168\n",
      "Epoch 34/50\n",
      "1382/1382 [==============================] - 0s 175us/step - loss: 0.0463 - accuracy: 1.0000 - val_loss: 1.8145 - val_accuracy: 0.7168\n",
      "Epoch 35/50\n",
      "1382/1382 [==============================] - 0s 200us/step - loss: 0.0419 - accuracy: 1.0000 - val_loss: 1.8700 - val_accuracy: 0.7139\n",
      "Epoch 36/50\n",
      "1382/1382 [==============================] - 0s 190us/step - loss: 0.0372 - accuracy: 1.0000 - val_loss: 1.9205 - val_accuracy: 0.7110\n",
      "Epoch 37/50\n",
      "1382/1382 [==============================] - 0s 178us/step - loss: 0.0367 - accuracy: 1.0000 - val_loss: 1.9610 - val_accuracy: 0.7139\n",
      "Epoch 38/50\n",
      "1382/1382 [==============================] - 0s 198us/step - loss: 0.0348 - accuracy: 1.0000 - val_loss: 2.0037 - val_accuracy: 0.7081\n",
      "Epoch 39/50\n",
      "1382/1382 [==============================] - 0s 190us/step - loss: 0.0328 - accuracy: 1.0000 - val_loss: 2.0252 - val_accuracy: 0.7052\n",
      "Epoch 40/50\n",
      "1382/1382 [==============================] - 0s 161us/step - loss: 0.0313 - accuracy: 1.0000 - val_loss: 2.0783 - val_accuracy: 0.7052\n",
      "Epoch 41/50\n",
      "1382/1382 [==============================] - 0s 167us/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 2.1098 - val_accuracy: 0.7052\n",
      "Epoch 42/50\n",
      "1382/1382 [==============================] - 0s 159us/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 2.1583 - val_accuracy: 0.7081\n",
      "Epoch 43/50\n",
      "1382/1382 [==============================] - 0s 156us/step - loss: 0.0275 - accuracy: 1.0000 - val_loss: 2.1680 - val_accuracy: 0.7110\n",
      "Epoch 44/50\n",
      "1382/1382 [==============================] - 0s 166us/step - loss: 0.0270 - accuracy: 1.0000 - val_loss: 2.2090 - val_accuracy: 0.7052\n",
      "Epoch 45/50\n",
      "1382/1382 [==============================] - 0s 190us/step - loss: 0.0258 - accuracy: 1.0000 - val_loss: 2.2316 - val_accuracy: 0.7052\n",
      "Epoch 46/50\n",
      "1382/1382 [==============================] - 0s 183us/step - loss: 0.0248 - accuracy: 1.0000 - val_loss: 2.2564 - val_accuracy: 0.7081\n",
      "Epoch 47/50\n",
      "1382/1382 [==============================] - 0s 168us/step - loss: 0.0240 - accuracy: 1.0000 - val_loss: 2.2968 - val_accuracy: 0.7168\n",
      "Epoch 48/50\n",
      "1382/1382 [==============================] - 0s 159us/step - loss: 0.0231 - accuracy: 1.0000 - val_loss: 2.3397 - val_accuracy: 0.7139\n",
      "Epoch 49/50\n",
      "1382/1382 [==============================] - 0s 159us/step - loss: 0.0226 - accuracy: 1.0000 - val_loss: 2.3416 - val_accuracy: 0.7139\n",
      "Epoch 50/50\n",
      "1382/1382 [==============================] - 0s 163us/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 2.3607 - val_accuracy: 0.7139\n",
      "346/346 [==============================] - 0s 52us/step\n",
      "Accuracy: 71.39\n",
      "346/346 [==============================] - 0s 75us/step\n",
      "346/346 [==============================] - 0s 55us/step\n",
      " \n",
      "Train on 1382 samples, validate on 346 samples\n",
      "Epoch 1/50\n",
      "1382/1382 [==============================] - 1s 466us/step - loss: 1.2792 - accuracy: 0.6737 - val_loss: 1.0837 - val_accuracy: 0.7225\n",
      "Epoch 2/50\n",
      "1382/1382 [==============================] - 0s 179us/step - loss: 0.7907 - accuracy: 0.8611 - val_loss: 1.0759 - val_accuracy: 0.7052\n",
      "Epoch 3/50\n",
      "1382/1382 [==============================] - 0s 187us/step - loss: 0.5015 - accuracy: 0.9479 - val_loss: 1.6450 - val_accuracy: 0.6763\n",
      "Epoch 4/50\n",
      "1382/1382 [==============================] - 0s 180us/step - loss: 0.3882 - accuracy: 0.9703 - val_loss: 1.5171 - val_accuracy: 0.6763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50\n",
      "1382/1382 [==============================] - 0s 175us/step - loss: 0.3044 - accuracy: 0.9805 - val_loss: 1.1775 - val_accuracy: 0.7659\n",
      "Epoch 6/50\n",
      "1382/1382 [==============================] - 0s 175us/step - loss: 0.2663 - accuracy: 0.9826 - val_loss: 1.1312 - val_accuracy: 0.7746\n",
      "Epoch 7/50\n",
      "1382/1382 [==============================] - 0s 171us/step - loss: 0.2629 - accuracy: 0.9783 - val_loss: 1.0983 - val_accuracy: 0.7688\n",
      "Epoch 8/50\n",
      "1382/1382 [==============================] - 0s 169us/step - loss: 0.2034 - accuracy: 0.9884 - val_loss: 1.7702 - val_accuracy: 0.7197\n",
      "Epoch 9/50\n",
      "1382/1382 [==============================] - 0s 173us/step - loss: 0.2059 - accuracy: 0.9841 - val_loss: 1.1260 - val_accuracy: 0.7746\n",
      "Epoch 10/50\n",
      "1382/1382 [==============================] - 0s 172us/step - loss: 0.1426 - accuracy: 0.9964 - val_loss: 1.3949 - val_accuracy: 0.7341\n",
      "Epoch 11/50\n",
      "1382/1382 [==============================] - 0s 170us/step - loss: 0.1228 - accuracy: 0.9957 - val_loss: 1.5766 - val_accuracy: 0.7543\n",
      "Epoch 12/50\n",
      "1382/1382 [==============================] - 0s 169us/step - loss: 0.1246 - accuracy: 0.9942 - val_loss: 1.3920 - val_accuracy: 0.7543\n",
      "Epoch 13/50\n",
      "1382/1382 [==============================] - 0s 171us/step - loss: 0.1305 - accuracy: 0.9848 - val_loss: 1.6551 - val_accuracy: 0.7312\n",
      "Epoch 14/50\n",
      "1382/1382 [==============================] - 0s 175us/step - loss: 0.1490 - accuracy: 0.9805 - val_loss: 1.2626 - val_accuracy: 0.7486\n",
      "Epoch 15/50\n",
      "1382/1382 [==============================] - 0s 180us/step - loss: 0.1208 - accuracy: 0.9942 - val_loss: 1.3615 - val_accuracy: 0.7486\n",
      "Epoch 16/50\n",
      "1382/1382 [==============================] - 0s 169us/step - loss: 0.0910 - accuracy: 0.9986 - val_loss: 1.6115 - val_accuracy: 0.7168\n",
      "Epoch 17/50\n",
      "1382/1382 [==============================] - 0s 160us/step - loss: 0.0981 - accuracy: 0.9949 - val_loss: 1.3923 - val_accuracy: 0.7514\n",
      "Epoch 18/50\n",
      "1382/1382 [==============================] - 0s 165us/step - loss: 0.0705 - accuracy: 1.0000 - val_loss: 1.6489 - val_accuracy: 0.7254\n",
      "Epoch 19/50\n",
      "1382/1382 [==============================] - 0s 170us/step - loss: 0.0612 - accuracy: 1.0000 - val_loss: 1.7385 - val_accuracy: 0.7254\n",
      "Epoch 20/50\n",
      "1382/1382 [==============================] - 0s 169us/step - loss: 0.0542 - accuracy: 1.0000 - val_loss: 1.7756 - val_accuracy: 0.7225\n",
      "Epoch 21/50\n",
      "1382/1382 [==============================] - 0s 164us/step - loss: 0.0485 - accuracy: 1.0000 - val_loss: 1.8497 - val_accuracy: 0.7197\n",
      "Epoch 22/50\n",
      "1382/1382 [==============================] - 0s 169us/step - loss: 0.0439 - accuracy: 1.0000 - val_loss: 1.8966 - val_accuracy: 0.7225\n",
      "Epoch 23/50\n",
      "1382/1382 [==============================] - 0s 164us/step - loss: 0.0397 - accuracy: 1.0000 - val_loss: 1.9562 - val_accuracy: 0.7110\n",
      "Epoch 24/50\n",
      "1382/1382 [==============================] - 0s 168us/step - loss: 0.0363 - accuracy: 1.0000 - val_loss: 1.9998 - val_accuracy: 0.7139\n",
      "Epoch 25/50\n",
      "1382/1382 [==============================] - 0s 188us/step - loss: 0.0332 - accuracy: 1.0000 - val_loss: 2.0144 - val_accuracy: 0.7197\n",
      "Epoch 26/50\n",
      "1382/1382 [==============================] - 0s 169us/step - loss: 0.0305 - accuracy: 1.0000 - val_loss: 2.0665 - val_accuracy: 0.7139\n",
      "Epoch 27/50\n",
      "1382/1382 [==============================] - 0s 181us/step - loss: 0.0281 - accuracy: 1.0000 - val_loss: 2.1259 - val_accuracy: 0.7081\n",
      "Epoch 28/50\n",
      "1382/1382 [==============================] - 0s 180us/step - loss: 0.0261 - accuracy: 1.0000 - val_loss: 2.1349 - val_accuracy: 0.7110\n",
      "Epoch 29/50\n",
      "1382/1382 [==============================] - 0s 168us/step - loss: 0.0244 - accuracy: 1.0000 - val_loss: 2.1313 - val_accuracy: 0.7168\n",
      "Epoch 30/50\n",
      "1382/1382 [==============================] - 0s 163us/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 2.1615 - val_accuracy: 0.7081\n",
      "Epoch 31/50\n",
      "1382/1382 [==============================] - 0s 188us/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 2.1765 - val_accuracy: 0.7081\n",
      "Epoch 32/50\n",
      "1382/1382 [==============================] - 0s 163us/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 2.2083 - val_accuracy: 0.7052\n",
      "Epoch 33/50\n",
      "1382/1382 [==============================] - 0s 191us/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 2.2705 - val_accuracy: 0.6994\n",
      "Epoch 34/50\n",
      "1382/1382 [==============================] - 0s 173us/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 2.1566 - val_accuracy: 0.7254\n",
      "Epoch 35/50\n",
      "1382/1382 [==============================] - 0s 164us/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 2.2145 - val_accuracy: 0.7139\n",
      "Epoch 36/50\n",
      "1382/1382 [==============================] - 0s 170us/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 2.2877 - val_accuracy: 0.6994\n",
      "Epoch 37/50\n",
      "1382/1382 [==============================] - 0s 167us/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 2.3314 - val_accuracy: 0.6994\n",
      "Epoch 38/50\n",
      "1382/1382 [==============================] - 0s 164us/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 2.2402 - val_accuracy: 0.7110\n",
      "Epoch 39/50\n",
      "1382/1382 [==============================] - 0s 188us/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 2.2791 - val_accuracy: 0.7023\n",
      "Epoch 40/50\n",
      "1382/1382 [==============================] - 0s 180us/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 2.2311 - val_accuracy: 0.7081\n",
      "Epoch 41/50\n",
      "1382/1382 [==============================] - 0s 191us/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 2.2221 - val_accuracy: 0.7081\n",
      "Epoch 42/50\n",
      "1382/1382 [==============================] - 0s 175us/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 2.2153 - val_accuracy: 0.7052\n",
      "Epoch 43/50\n",
      "1382/1382 [==============================] - 0s 169us/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 2.2811 - val_accuracy: 0.7023\n",
      "Epoch 44/50\n",
      "1382/1382 [==============================] - 0s 166us/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 2.1700 - val_accuracy: 0.7254\n",
      "Epoch 45/50\n",
      "1382/1382 [==============================] - 0s 163us/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 2.1636 - val_accuracy: 0.7283\n",
      "Epoch 46/50\n",
      "1382/1382 [==============================] - 0s 187us/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 2.2488 - val_accuracy: 0.7081\n",
      "Epoch 47/50\n",
      "1382/1382 [==============================] - 0s 181us/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 2.2067 - val_accuracy: 0.7168\n",
      "Epoch 48/50\n",
      "1382/1382 [==============================] - 0s 170us/step - loss: 0.9797 - accuracy: 0.8965 - val_loss: 0.9921 - val_accuracy: 0.7890\n",
      "Epoch 49/50\n",
      "1382/1382 [==============================] - 0s 161us/step - loss: 0.2553 - accuracy: 0.9667 - val_loss: 1.0388 - val_accuracy: 0.7861\n",
      "Epoch 50/50\n",
      "1382/1382 [==============================] - 0s 164us/step - loss: 0.1503 - accuracy: 0.9841 - val_loss: 0.9224 - val_accuracy: 0.8006\n",
      "346/346 [==============================] - 0s 55us/step\n",
      "Accuracy: 80.06\n",
      "346/346 [==============================] - 0s 75us/step\n",
      "346/346 [==============================] - 0s 55us/step\n",
      " \n",
      "Train on 1383 samples, validate on 346 samples\n",
      "Epoch 1/50\n",
      "1383/1383 [==============================] - 1s 512us/step - loss: 1.5700 - accuracy: 0.7361 - val_loss: 1.4169 - val_accuracy: 0.7803\n",
      "Epoch 2/50\n",
      "1383/1383 [==============================] - 0s 178us/step - loss: 1.0132 - accuracy: 0.8792 - val_loss: 1.3494 - val_accuracy: 0.7514\n",
      "Epoch 3/50\n",
      "1383/1383 [==============================] - 0s 180us/step - loss: 0.7211 - accuracy: 0.9349 - val_loss: 1.2449 - val_accuracy: 0.7832\n",
      "Epoch 4/50\n",
      "1383/1383 [==============================] - 0s 182us/step - loss: 0.5735 - accuracy: 0.9552 - val_loss: 1.2589 - val_accuracy: 0.7803\n",
      "Epoch 5/50\n",
      "1383/1383 [==============================] - 0s 178us/step - loss: 0.4631 - accuracy: 0.9754 - val_loss: 1.4457 - val_accuracy: 0.7543\n",
      "Epoch 6/50\n",
      "1383/1383 [==============================] - 0s 177us/step - loss: 0.4168 - accuracy: 0.9725 - val_loss: 1.4188 - val_accuracy: 0.7457\n",
      "Epoch 7/50\n",
      "1383/1383 [==============================] - 0s 180us/step - loss: 0.3469 - accuracy: 0.9870 - val_loss: 1.3144 - val_accuracy: 0.7630\n",
      "Epoch 8/50\n",
      "1383/1383 [==============================] - 0s 181us/step - loss: 0.2948 - accuracy: 0.9913 - val_loss: 1.4743 - val_accuracy: 0.7688\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1383/1383 [==============================] - 0s 181us/step - loss: 0.2483 - accuracy: 0.9957 - val_loss: 1.6993 - val_accuracy: 0.7601\n",
      "Epoch 10/50\n",
      "1383/1383 [==============================] - 0s 177us/step - loss: 0.3008 - accuracy: 0.9740 - val_loss: 1.2637 - val_accuracy: 0.7399\n",
      "Epoch 11/50\n",
      "1383/1383 [==============================] - 0s 175us/step - loss: 0.2589 - accuracy: 0.9863 - val_loss: 1.4544 - val_accuracy: 0.7630\n",
      "Epoch 12/50\n",
      "1383/1383 [==============================] - 0s 178us/step - loss: 0.2503 - accuracy: 0.9826 - val_loss: 1.1829 - val_accuracy: 0.7919\n",
      "Epoch 13/50\n",
      "1383/1383 [==============================] - 0s 180us/step - loss: 0.2119 - accuracy: 0.9920 - val_loss: 1.5076 - val_accuracy: 0.7717\n",
      "Epoch 14/50\n",
      "1383/1383 [==============================] - 0s 177us/step - loss: 0.2062 - accuracy: 0.9906 - val_loss: 1.2235 - val_accuracy: 0.7861\n",
      "Epoch 15/50\n",
      "1383/1383 [==============================] - 0s 174us/step - loss: 0.1526 - accuracy: 0.9978 - val_loss: 1.4760 - val_accuracy: 0.7803\n",
      "Epoch 16/50\n",
      "1383/1383 [==============================] - 0s 175us/step - loss: 0.1219 - accuracy: 0.9986 - val_loss: 1.6091 - val_accuracy: 0.7803\n",
      "Epoch 17/50\n",
      "1383/1383 [==============================] - 0s 177us/step - loss: 0.1186 - accuracy: 0.9993 - val_loss: 1.6138 - val_accuracy: 0.7775\n",
      "Epoch 18/50\n",
      "1383/1383 [==============================] - 0s 177us/step - loss: 0.0956 - accuracy: 0.9993 - val_loss: 1.6547 - val_accuracy: 0.7688\n",
      "Epoch 19/50\n",
      "1383/1383 [==============================] - 0s 174us/step - loss: 0.0845 - accuracy: 0.9993 - val_loss: 1.7693 - val_accuracy: 0.7717\n",
      "Epoch 20/50\n",
      "1383/1383 [==============================] - 0s 180us/step - loss: 0.0762 - accuracy: 1.0000 - val_loss: 1.7776 - val_accuracy: 0.7630\n",
      "Epoch 21/50\n",
      "1383/1383 [==============================] - 0s 175us/step - loss: 0.1541 - accuracy: 0.9848 - val_loss: 1.1881 - val_accuracy: 0.7601\n",
      "Epoch 22/50\n",
      "1383/1383 [==============================] - 0s 175us/step - loss: 0.2050 - accuracy: 0.9754 - val_loss: 1.0720 - val_accuracy: 0.7717\n",
      "Epoch 23/50\n",
      "1383/1383 [==============================] - 0s 176us/step - loss: 0.1243 - accuracy: 0.9949 - val_loss: 1.3632 - val_accuracy: 0.7601\n",
      "Epoch 24/50\n",
      "1383/1383 [==============================] - 0s 180us/step - loss: 0.0972 - accuracy: 0.9971 - val_loss: 1.3857 - val_accuracy: 0.7399\n",
      "Epoch 25/50\n",
      "1383/1383 [==============================] - 0s 174us/step - loss: 0.1482 - accuracy: 0.9892 - val_loss: 1.5407 - val_accuracy: 0.7341\n",
      "Epoch 26/50\n",
      "1383/1383 [==============================] - 0s 172us/step - loss: 0.1560 - accuracy: 0.9826 - val_loss: 1.0662 - val_accuracy: 0.7630\n",
      "Epoch 27/50\n",
      "1383/1383 [==============================] - 0s 178us/step - loss: 0.1845 - accuracy: 0.9877 - val_loss: 1.2418 - val_accuracy: 0.7919\n",
      "Epoch 28/50\n",
      "1383/1383 [==============================] - 0s 174us/step - loss: 0.1132 - accuracy: 0.9964 - val_loss: 1.5115 - val_accuracy: 0.7775\n",
      "Epoch 29/50\n",
      "1383/1383 [==============================] - 0s 177us/step - loss: 0.0893 - accuracy: 1.0000 - val_loss: 1.6567 - val_accuracy: 0.7832\n",
      "Epoch 30/50\n",
      "1383/1383 [==============================] - 0s 176us/step - loss: 0.0789 - accuracy: 1.0000 - val_loss: 1.7419 - val_accuracy: 0.7717\n",
      "Epoch 31/50\n",
      "1383/1383 [==============================] - 0s 180us/step - loss: 0.0706 - accuracy: 1.0000 - val_loss: 1.8283 - val_accuracy: 0.7717\n",
      "Epoch 32/50\n",
      "1383/1383 [==============================] - 0s 179us/step - loss: 0.0661 - accuracy: 1.0000 - val_loss: 1.8931 - val_accuracy: 0.7688\n",
      "Epoch 33/50\n",
      "1383/1383 [==============================] - 0s 179us/step - loss: 0.0612 - accuracy: 1.0000 - val_loss: 1.9825 - val_accuracy: 0.7688\n",
      "Epoch 34/50\n",
      "1383/1383 [==============================] - 0s 176us/step - loss: 0.0596 - accuracy: 1.0000 - val_loss: 2.0243 - val_accuracy: 0.7688\n",
      "Epoch 35/50\n",
      "1383/1383 [==============================] - 0s 182us/step - loss: 0.0541 - accuracy: 1.0000 - val_loss: 2.2618 - val_accuracy: 0.7630\n",
      "Epoch 36/50\n",
      "1383/1383 [==============================] - 0s 181us/step - loss: 0.1991 - accuracy: 0.9834 - val_loss: 1.2929 - val_accuracy: 0.7832\n",
      "Epoch 37/50\n",
      "1383/1383 [==============================] - 0s 180us/step - loss: 0.1624 - accuracy: 0.9877 - val_loss: 1.2554 - val_accuracy: 0.7861\n",
      "Epoch 38/50\n",
      "1383/1383 [==============================] - 0s 176us/step - loss: 0.1654 - accuracy: 0.9841 - val_loss: 1.1796 - val_accuracy: 0.7746\n",
      "Epoch 39/50\n",
      "1383/1383 [==============================] - 0s 177us/step - loss: 0.1140 - accuracy: 0.9957 - val_loss: 1.5793 - val_accuracy: 0.7775\n",
      "Epoch 40/50\n",
      "1383/1383 [==============================] - 0s 178us/step - loss: 0.0979 - accuracy: 0.9942 - val_loss: 1.5672 - val_accuracy: 0.7630\n",
      "Epoch 41/50\n",
      "1383/1383 [==============================] - 0s 175us/step - loss: 0.1476 - accuracy: 0.9964 - val_loss: 1.8152 - val_accuracy: 0.7601\n",
      "Epoch 42/50\n",
      "1383/1383 [==============================] - 0s 178us/step - loss: 0.1069 - accuracy: 0.9986 - val_loss: 1.8221 - val_accuracy: 0.7746\n",
      "Epoch 43/50\n",
      "1383/1383 [==============================] - 0s 177us/step - loss: 0.0834 - accuracy: 1.0000 - val_loss: 1.8722 - val_accuracy: 0.7601\n",
      "Epoch 44/50\n",
      "1383/1383 [==============================] - 0s 177us/step - loss: 0.0709 - accuracy: 1.0000 - val_loss: 1.9684 - val_accuracy: 0.7572\n",
      "Epoch 45/50\n",
      "1383/1383 [==============================] - 0s 180us/step - loss: 0.0620 - accuracy: 1.0000 - val_loss: 2.0271 - val_accuracy: 0.7601\n",
      "Epoch 46/50\n",
      "1383/1383 [==============================] - 0s 177us/step - loss: 0.0587 - accuracy: 1.0000 - val_loss: 2.0822 - val_accuracy: 0.7601\n",
      "Epoch 47/50\n",
      "1383/1383 [==============================] - 0s 179us/step - loss: 0.0530 - accuracy: 1.0000 - val_loss: 2.1540 - val_accuracy: 0.7514\n",
      "Epoch 48/50\n",
      "1383/1383 [==============================] - 0s 177us/step - loss: 0.0524 - accuracy: 1.0000 - val_loss: 2.1945 - val_accuracy: 0.7572\n",
      "Epoch 49/50\n",
      "1383/1383 [==============================] - 0s 180us/step - loss: 0.0489 - accuracy: 1.0000 - val_loss: 2.2493 - val_accuracy: 0.7399\n",
      "Epoch 50/50\n",
      "1383/1383 [==============================] - 0s 190us/step - loss: 0.0472 - accuracy: 1.0000 - val_loss: 2.3007 - val_accuracy: 0.7543\n",
      "346/346 [==============================] - 0s 64us/step\n",
      "Accuracy: 75.43\n",
      "346/346 [==============================] - 0s 87us/step\n",
      "346/346 [==============================] - 0s 64us/step\n",
      " \n",
      "Train on 1382 samples, validate on 346 samples\n",
      "Epoch 1/50\n",
      "1382/1382 [==============================] - 1s 461us/step - loss: 1.4027 - accuracy: 0.7106 - val_loss: 1.1205 - val_accuracy: 0.7832\n",
      "Epoch 2/50\n",
      "1382/1382 [==============================] - 0s 180us/step - loss: 0.9278 - accuracy: 0.8575 - val_loss: 0.9520 - val_accuracy: 0.8035\n",
      "Epoch 3/50\n",
      "1382/1382 [==============================] - 0s 183us/step - loss: 0.6689 - accuracy: 0.9190 - val_loss: 0.9947 - val_accuracy: 0.7399\n",
      "Epoch 4/50\n",
      "1382/1382 [==============================] - 0s 178us/step - loss: 0.5469 - accuracy: 0.9436 - val_loss: 1.3172 - val_accuracy: 0.7110\n",
      "Epoch 5/50\n",
      "1382/1382 [==============================] - 0s 174us/step - loss: 0.5044 - accuracy: 0.9522 - val_loss: 1.1543 - val_accuracy: 0.7601\n",
      "Epoch 6/50\n",
      "1382/1382 [==============================] - 0s 178us/step - loss: 0.3966 - accuracy: 0.9754 - val_loss: 1.0723 - val_accuracy: 0.7717\n",
      "Epoch 7/50\n",
      "1382/1382 [==============================] - 0s 180us/step - loss: 0.3679 - accuracy: 0.9718 - val_loss: 1.0373 - val_accuracy: 0.7919\n",
      "Epoch 8/50\n",
      "1382/1382 [==============================] - 0s 178us/step - loss: 0.2942 - accuracy: 0.9899 - val_loss: 1.1101 - val_accuracy: 0.7832\n",
      "Epoch 9/50\n",
      "1382/1382 [==============================] - 0s 180us/step - loss: 0.2714 - accuracy: 0.9899 - val_loss: 0.9930 - val_accuracy: 0.7948\n",
      "Epoch 10/50\n",
      "1382/1382 [==============================] - 0s 179us/step - loss: 0.2293 - accuracy: 0.9949 - val_loss: 1.1253 - val_accuracy: 0.7977\n",
      "Epoch 11/50\n",
      "1382/1382 [==============================] - 0s 179us/step - loss: 0.1918 - accuracy: 0.9964 - val_loss: 1.2555 - val_accuracy: 0.7803\n",
      "Epoch 12/50\n",
      "1382/1382 [==============================] - 0s 180us/step - loss: 0.2512 - accuracy: 0.9740 - val_loss: 1.1161 - val_accuracy: 0.7832\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1382/1382 [==============================] - 0s 179us/step - loss: 0.2638 - accuracy: 0.9812 - val_loss: 0.9540 - val_accuracy: 0.7717\n",
      "Epoch 14/50\n",
      "1382/1382 [==============================] - 0s 179us/step - loss: 0.2000 - accuracy: 0.9935 - val_loss: 1.0753 - val_accuracy: 0.7659\n",
      "Epoch 15/50\n",
      "1382/1382 [==============================] - 0s 179us/step - loss: 0.1809 - accuracy: 0.9949 - val_loss: 1.1358 - val_accuracy: 0.7746\n",
      "Epoch 16/50\n",
      "1382/1382 [==============================] - 0s 176us/step - loss: 0.1648 - accuracy: 0.9935 - val_loss: 1.1720 - val_accuracy: 0.7803\n",
      "Epoch 17/50\n",
      "1382/1382 [==============================] - 0s 180us/step - loss: 0.1616 - accuracy: 0.9906 - val_loss: 1.0513 - val_accuracy: 0.8064\n",
      "Epoch 18/50\n",
      "1382/1382 [==============================] - 0s 179us/step - loss: 0.1299 - accuracy: 0.9964 - val_loss: 1.1227 - val_accuracy: 0.7890\n",
      "Epoch 19/50\n",
      "1382/1382 [==============================] - 0s 177us/step - loss: 0.1072 - accuracy: 0.9993 - val_loss: 1.2585 - val_accuracy: 0.7717\n",
      "Epoch 20/50\n",
      "1382/1382 [==============================] - 0s 179us/step - loss: 0.2146 - accuracy: 0.9740 - val_loss: 1.1332 - val_accuracy: 0.7370\n",
      "Epoch 21/50\n",
      "1382/1382 [==============================] - ETA: 0s - loss: 0.1741 - accuracy: 0.98 - 0s 177us/step - loss: 0.1724 - accuracy: 0.9834 - val_loss: 1.0045 - val_accuracy: 0.8006\n",
      "Epoch 22/50\n",
      "1382/1382 [==============================] - 0s 179us/step - loss: 0.1577 - accuracy: 0.9920 - val_loss: 1.1094 - val_accuracy: 0.8035\n",
      "Epoch 23/50\n",
      "1382/1382 [==============================] - 0s 183us/step - loss: 0.1410 - accuracy: 0.9899 - val_loss: 1.1618 - val_accuracy: 0.7746\n",
      "Epoch 24/50\n",
      "1382/1382 [==============================] - 0s 178us/step - loss: 0.1193 - accuracy: 0.9949 - val_loss: 1.3078 - val_accuracy: 0.7861\n",
      "Epoch 25/50\n",
      "1382/1382 [==============================] - 0s 178us/step - loss: 0.1232 - accuracy: 0.9913 - val_loss: 1.1356 - val_accuracy: 0.7948\n",
      "Epoch 26/50\n",
      "1382/1382 [==============================] - 0s 177us/step - loss: 0.1264 - accuracy: 0.9913 - val_loss: 1.4229 - val_accuracy: 0.7688\n",
      "Epoch 27/50\n",
      "1382/1382 [==============================] - 0s 177us/step - loss: 0.1057 - accuracy: 0.9964 - val_loss: 1.4740 - val_accuracy: 0.7659\n",
      "Epoch 28/50\n",
      "1382/1382 [==============================] - 0s 179us/step - loss: 0.0942 - accuracy: 0.9971 - val_loss: 1.4554 - val_accuracy: 0.7630\n",
      "Epoch 29/50\n",
      "1382/1382 [==============================] - 0s 178us/step - loss: 0.0818 - accuracy: 0.9993 - val_loss: 1.5570 - val_accuracy: 0.7543\n",
      "Epoch 30/50\n",
      "1382/1382 [==============================] - 0s 180us/step - loss: 0.0751 - accuracy: 1.0000 - val_loss: 1.5867 - val_accuracy: 0.7514\n",
      "Epoch 31/50\n",
      "1382/1382 [==============================] - 0s 207us/step - loss: 0.0690 - accuracy: 1.0000 - val_loss: 1.6048 - val_accuracy: 0.7543\n",
      "Epoch 32/50\n",
      "1382/1382 [==============================] - 0s 231us/step - loss: 0.0649 - accuracy: 1.0000 - val_loss: 1.6226 - val_accuracy: 0.7486\n",
      "Epoch 33/50\n",
      "1382/1382 [==============================] - 0s 196us/step - loss: 0.0607 - accuracy: 1.0000 - val_loss: 1.6831 - val_accuracy: 0.7457\n",
      "Epoch 34/50\n",
      "1382/1382 [==============================] - 0s 184us/step - loss: 0.0589 - accuracy: 1.0000 - val_loss: 1.6886 - val_accuracy: 0.7486\n",
      "Epoch 35/50\n",
      "1382/1382 [==============================] - 0s 175us/step - loss: 0.0534 - accuracy: 1.0000 - val_loss: 1.7377 - val_accuracy: 0.7457\n",
      "Epoch 36/50\n",
      "1382/1382 [==============================] - 0s 180us/step - loss: 0.0528 - accuracy: 1.0000 - val_loss: 1.7353 - val_accuracy: 0.7486\n",
      "Epoch 37/50\n",
      "1382/1382 [==============================] - 0s 175us/step - loss: 0.0509 - accuracy: 1.0000 - val_loss: 1.7484 - val_accuracy: 0.7486\n",
      "Epoch 38/50\n",
      "1382/1382 [==============================] - 0s 167us/step - loss: 0.0480 - accuracy: 1.0000 - val_loss: 1.7901 - val_accuracy: 0.7457\n",
      "Epoch 39/50\n",
      "1382/1382 [==============================] - 0s 168us/step - loss: 0.0453 - accuracy: 1.0000 - val_loss: 1.7973 - val_accuracy: 0.7457\n",
      "Epoch 40/50\n",
      "1382/1382 [==============================] - 0s 162us/step - loss: 0.0426 - accuracy: 1.0000 - val_loss: 1.8261 - val_accuracy: 0.7457\n",
      "Epoch 41/50\n",
      "1382/1382 [==============================] - 0s 163us/step - loss: 0.0430 - accuracy: 1.0000 - val_loss: 1.8419 - val_accuracy: 0.7428\n",
      "Epoch 42/50\n",
      "1382/1382 [==============================] - 0s 164us/step - loss: 0.0400 - accuracy: 1.0000 - val_loss: 1.8551 - val_accuracy: 0.7428\n",
      "Epoch 43/50\n",
      "1382/1382 [==============================] - 0s 160us/step - loss: 0.0388 - accuracy: 1.0000 - val_loss: 1.8677 - val_accuracy: 0.7370\n",
      "Epoch 44/50\n",
      "1382/1382 [==============================] - 0s 158us/step - loss: 0.0370 - accuracy: 1.0000 - val_loss: 1.9062 - val_accuracy: 0.7457\n",
      "Epoch 45/50\n",
      "1382/1382 [==============================] - 0s 160us/step - loss: 0.0353 - accuracy: 1.0000 - val_loss: 1.9244 - val_accuracy: 0.7399\n",
      "Epoch 46/50\n",
      "1382/1382 [==============================] - 0s 161us/step - loss: 0.0341 - accuracy: 1.0000 - val_loss: 1.9226 - val_accuracy: 0.7399\n",
      "Epoch 47/50\n",
      "1382/1382 [==============================] - 0s 164us/step - loss: 0.0330 - accuracy: 1.0000 - val_loss: 1.9795 - val_accuracy: 0.7399\n",
      "Epoch 48/50\n",
      "1382/1382 [==============================] - 0s 162us/step - loss: 0.4284 - accuracy: 0.9255 - val_loss: 0.8081 - val_accuracy: 0.7746\n",
      "Epoch 49/50\n",
      "1382/1382 [==============================] - 0s 162us/step - loss: 0.2861 - accuracy: 0.9537 - val_loss: 0.9461 - val_accuracy: 0.8035\n",
      "Epoch 50/50\n",
      "1382/1382 [==============================] - 0s 159us/step - loss: 0.1558 - accuracy: 0.9906 - val_loss: 1.1786 - val_accuracy: 0.7861\n",
      "346/346 [==============================] - 0s 49us/step\n",
      "Accuracy: 78.61\n",
      "346/346 [==============================] - 0s 75us/step\n",
      "346/346 [==============================] - 0s 58us/step\n",
      " \n",
      "Train on 1382 samples, validate on 346 samples\n",
      "Epoch 1/50\n",
      "1382/1382 [==============================] - 1s 506us/step - loss: 1.3431 - accuracy: 0.7467 - val_loss: 1.2288 - val_accuracy: 0.7630\n",
      "Epoch 2/50\n",
      "1382/1382 [==============================] - 0s 188us/step - loss: 0.8174 - accuracy: 0.8973 - val_loss: 1.1395 - val_accuracy: 0.7832\n",
      "Epoch 3/50\n",
      "1382/1382 [==============================] - 0s 167us/step - loss: 0.5619 - accuracy: 0.9530 - val_loss: 1.2081 - val_accuracy: 0.7601\n",
      "Epoch 4/50\n",
      "1382/1382 [==============================] - 0s 169us/step - loss: 0.4074 - accuracy: 0.9819 - val_loss: 1.3846 - val_accuracy: 0.7688\n",
      "Epoch 5/50\n",
      "1382/1382 [==============================] - 0s 165us/step - loss: 0.3743 - accuracy: 0.9754 - val_loss: 1.4328 - val_accuracy: 0.7399\n",
      "Epoch 6/50\n",
      "1382/1382 [==============================] - 0s 168us/step - loss: 0.3035 - accuracy: 0.9877 - val_loss: 1.2381 - val_accuracy: 0.8035\n",
      "Epoch 7/50\n",
      "1382/1382 [==============================] - 0s 164us/step - loss: 0.2401 - accuracy: 0.9928 - val_loss: 1.3130 - val_accuracy: 0.7919\n",
      "Epoch 8/50\n",
      "1382/1382 [==============================] - 0s 168us/step - loss: 0.1939 - accuracy: 0.9928 - val_loss: 1.9157 - val_accuracy: 0.7283\n",
      "Epoch 9/50\n",
      "1382/1382 [==============================] - 0s 169us/step - loss: 0.2012 - accuracy: 0.9841 - val_loss: 1.5829 - val_accuracy: 0.7572\n",
      "Epoch 10/50\n",
      "1382/1382 [==============================] - 0s 168us/step - loss: 0.1850 - accuracy: 0.9906 - val_loss: 1.5228 - val_accuracy: 0.7457\n",
      "Epoch 11/50\n",
      "1382/1382 [==============================] - 0s 166us/step - loss: 0.1920 - accuracy: 0.9841 - val_loss: 1.3164 - val_accuracy: 0.7717\n",
      "Epoch 12/50\n",
      "1382/1382 [==============================] - 0s 169us/step - loss: 0.1799 - accuracy: 0.9848 - val_loss: 1.3222 - val_accuracy: 0.7572\n",
      "Epoch 13/50\n",
      "1382/1382 [==============================] - 0s 166us/step - loss: 0.1263 - accuracy: 0.9964 - val_loss: 1.5808 - val_accuracy: 0.7514\n",
      "Epoch 14/50\n",
      "1382/1382 [==============================] - 0s 168us/step - loss: 0.1011 - accuracy: 1.0000 - val_loss: 1.6914 - val_accuracy: 0.7486\n",
      "Epoch 15/50\n",
      "1382/1382 [==============================] - 0s 167us/step - loss: 0.0849 - accuracy: 1.0000 - val_loss: 1.7608 - val_accuracy: 0.7428\n",
      "Epoch 16/50\n",
      "1382/1382 [==============================] - 0s 164us/step - loss: 0.0731 - accuracy: 1.0000 - val_loss: 1.8173 - val_accuracy: 0.7428\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1382/1382 [==============================] - 0s 168us/step - loss: 0.0638 - accuracy: 1.0000 - val_loss: 1.8844 - val_accuracy: 0.7428\n",
      "Epoch 18/50\n",
      "1382/1382 [==============================] - 0s 163us/step - loss: 0.0563 - accuracy: 1.0000 - val_loss: 1.9460 - val_accuracy: 0.7341\n",
      "Epoch 19/50\n",
      "1382/1382 [==============================] - 0s 166us/step - loss: 0.0506 - accuracy: 1.0000 - val_loss: 1.9986 - val_accuracy: 0.7399\n",
      "Epoch 20/50\n",
      "1382/1382 [==============================] - 0s 166us/step - loss: 0.0453 - accuracy: 1.0000 - val_loss: 2.0472 - val_accuracy: 0.7457\n",
      "Epoch 21/50\n",
      "1382/1382 [==============================] - 0s 164us/step - loss: 0.0412 - accuracy: 1.0000 - val_loss: 2.1295 - val_accuracy: 0.7543\n",
      "Epoch 22/50\n",
      "1382/1382 [==============================] - 0s 162us/step - loss: 0.0379 - accuracy: 1.0000 - val_loss: 2.1739 - val_accuracy: 0.7514\n",
      "Epoch 23/50\n",
      "1382/1382 [==============================] - 0s 164us/step - loss: 0.0346 - accuracy: 1.0000 - val_loss: 2.2293 - val_accuracy: 0.7514\n",
      "Epoch 24/50\n",
      "1382/1382 [==============================] - 0s 166us/step - loss: 0.0323 - accuracy: 1.0000 - val_loss: 2.2655 - val_accuracy: 0.7543\n",
      "Epoch 25/50\n",
      "1382/1382 [==============================] - 0s 166us/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 2.3218 - val_accuracy: 0.7630\n",
      "Epoch 26/50\n",
      "1382/1382 [==============================] - 0s 165us/step - loss: 0.0279 - accuracy: 1.0000 - val_loss: 2.3793 - val_accuracy: 0.7659\n",
      "Epoch 27/50\n",
      "1382/1382 [==============================] - 0s 167us/step - loss: 0.0256 - accuracy: 1.0000 - val_loss: 2.4378 - val_accuracy: 0.7688\n",
      "Epoch 28/50\n",
      "1382/1382 [==============================] - 0s 164us/step - loss: 0.0248 - accuracy: 1.0000 - val_loss: 2.4972 - val_accuracy: 0.7659\n",
      "Epoch 29/50\n",
      "1382/1382 [==============================] - 0s 169us/step - loss: 0.0228 - accuracy: 1.0000 - val_loss: 2.5532 - val_accuracy: 0.7601\n",
      "Epoch 30/50\n",
      "1382/1382 [==============================] - 0s 168us/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 2.6037 - val_accuracy: 0.7572\n",
      "Epoch 31/50\n",
      "1382/1382 [==============================] - 0s 168us/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 2.6796 - val_accuracy: 0.7486\n",
      "Epoch 32/50\n",
      "1382/1382 [==============================] - 0s 168us/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 2.8327 - val_accuracy: 0.7514\n",
      "Epoch 33/50\n",
      "1382/1382 [==============================] - 0s 170us/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 2.8114 - val_accuracy: 0.7601\n",
      "Epoch 34/50\n",
      "1382/1382 [==============================] - 0s 172us/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 2.8701 - val_accuracy: 0.7514\n",
      "Epoch 35/50\n",
      "1382/1382 [==============================] - 0s 172us/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 2.8784 - val_accuracy: 0.7514\n",
      "Epoch 36/50\n",
      "1382/1382 [==============================] - 0s 170us/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 2.9379 - val_accuracy: 0.7543\n",
      "Epoch 37/50\n",
      "1382/1382 [==============================] - 0s 169us/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 2.9939 - val_accuracy: 0.7428\n",
      "Epoch 38/50\n",
      "1382/1382 [==============================] - 0s 171us/step - loss: 0.5309 - accuracy: 0.9653 - val_loss: 1.3125 - val_accuracy: 0.7312\n",
      "Epoch 39/50\n",
      "1382/1382 [==============================] - 0s 169us/step - loss: 0.3473 - accuracy: 0.9342 - val_loss: 1.0604 - val_accuracy: 0.7601\n",
      "Epoch 40/50\n",
      "1382/1382 [==============================] - 0s 168us/step - loss: 0.1736 - accuracy: 0.9797 - val_loss: 1.4106 - val_accuracy: 0.7514\n",
      "Epoch 41/50\n",
      "1382/1382 [==============================] - 0s 169us/step - loss: 0.1149 - accuracy: 0.9935 - val_loss: 1.1451 - val_accuracy: 0.7803\n",
      "Epoch 42/50\n",
      "1382/1382 [==============================] - 0s 172us/step - loss: 0.0816 - accuracy: 0.9957 - val_loss: 1.2816 - val_accuracy: 0.7717\n",
      "Epoch 43/50\n",
      "1382/1382 [==============================] - 0s 169us/step - loss: 0.0573 - accuracy: 1.0000 - val_loss: 1.4381 - val_accuracy: 0.7746\n",
      "Epoch 44/50\n",
      "1382/1382 [==============================] - 0s 168us/step - loss: 0.0452 - accuracy: 1.0000 - val_loss: 1.4692 - val_accuracy: 0.7630\n",
      "Epoch 45/50\n",
      "1382/1382 [==============================] - 0s 173us/step - loss: 0.0393 - accuracy: 1.0000 - val_loss: 1.5072 - val_accuracy: 0.7630\n",
      "Epoch 46/50\n",
      "1382/1382 [==============================] - 0s 169us/step - loss: 0.0348 - accuracy: 1.0000 - val_loss: 1.5401 - val_accuracy: 0.7572\n",
      "Epoch 47/50\n",
      "1382/1382 [==============================] - 0s 172us/step - loss: 0.0319 - accuracy: 1.0000 - val_loss: 1.5732 - val_accuracy: 0.7572\n",
      "Epoch 48/50\n",
      "1382/1382 [==============================] - 0s 169us/step - loss: 0.0288 - accuracy: 1.0000 - val_loss: 1.6172 - val_accuracy: 0.7572\n",
      "Epoch 49/50\n",
      "1382/1382 [==============================] - 0s 169us/step - loss: 0.0270 - accuracy: 1.0000 - val_loss: 1.6499 - val_accuracy: 0.7572\n",
      "Epoch 50/50\n",
      "1382/1382 [==============================] - 0s 171us/step - loss: 0.0251 - accuracy: 1.0000 - val_loss: 1.6870 - val_accuracy: 0.7543\n",
      "346/346 [==============================] - 0s 58us/step\n",
      "Accuracy: 75.43\n",
      "346/346 [==============================] - 0s 84us/step\n",
      "346/346 [==============================] - 0s 58us/step\n",
      " \n",
      "Train on 1382 samples, validate on 346 samples\n",
      "Epoch 1/50\n",
      "1382/1382 [==============================] - 1s 469us/step - loss: 1.2219 - accuracy: 0.7207 - val_loss: 1.2694 - val_accuracy: 0.7341\n",
      "Epoch 2/50\n",
      "1382/1382 [==============================] - 0s 182us/step - loss: 0.7508 - accuracy: 0.8813 - val_loss: 1.3373 - val_accuracy: 0.6792\n",
      "Epoch 3/50\n",
      "1382/1382 [==============================] - 0s 181us/step - loss: 0.4856 - accuracy: 0.9551 - val_loss: 1.3378 - val_accuracy: 0.7514\n",
      "Epoch 4/50\n",
      "1382/1382 [==============================] - 0s 184us/step - loss: 0.3759 - accuracy: 0.9703 - val_loss: 1.3064 - val_accuracy: 0.7370\n",
      "Epoch 5/50\n",
      "1382/1382 [==============================] - 0s 181us/step - loss: 0.2876 - accuracy: 0.9855 - val_loss: 1.4936 - val_accuracy: 0.7370\n",
      "Epoch 6/50\n",
      "1382/1382 [==============================] - 0s 183us/step - loss: 0.2355 - accuracy: 0.9877 - val_loss: 1.7263 - val_accuracy: 0.7168\n",
      "Epoch 7/50\n",
      "1382/1382 [==============================] - 0s 213us/step - loss: 0.2047 - accuracy: 0.9891 - val_loss: 1.9145 - val_accuracy: 0.7283\n",
      "Epoch 8/50\n",
      "1382/1382 [==============================] - 0s 169us/step - loss: 0.1900 - accuracy: 0.9877 - val_loss: 1.6839 - val_accuracy: 0.7486\n",
      "Epoch 9/50\n",
      "1382/1382 [==============================] - 0s 167us/step - loss: 0.1991 - accuracy: 0.9834 - val_loss: 1.3487 - val_accuracy: 0.7630\n",
      "Epoch 10/50\n",
      "1382/1382 [==============================] - 0s 169us/step - loss: 0.2089 - accuracy: 0.9754 - val_loss: 1.3045 - val_accuracy: 0.7283\n",
      "Epoch 11/50\n",
      "1382/1382 [==============================] - 0s 183us/step - loss: 0.1387 - accuracy: 0.9957 - val_loss: 1.7574 - val_accuracy: 0.7370\n",
      "Epoch 12/50\n",
      "1382/1382 [==============================] - 0s 170us/step - loss: 0.1114 - accuracy: 0.9978 - val_loss: 1.6702 - val_accuracy: 0.7341\n",
      "Epoch 13/50\n",
      "1382/1382 [==============================] - 0s 170us/step - loss: 0.0885 - accuracy: 1.0000 - val_loss: 1.8043 - val_accuracy: 0.7283\n",
      "Epoch 14/50\n",
      "1382/1382 [==============================] - 0s 169us/step - loss: 0.0743 - accuracy: 1.0000 - val_loss: 1.8721 - val_accuracy: 0.7110\n",
      "Epoch 15/50\n",
      "1382/1382 [==============================] - 0s 182us/step - loss: 0.0642 - accuracy: 1.0000 - val_loss: 1.9519 - val_accuracy: 0.7110\n",
      "Epoch 16/50\n",
      "1382/1382 [==============================] - 0s 167us/step - loss: 0.0564 - accuracy: 1.0000 - val_loss: 2.0505 - val_accuracy: 0.7052\n",
      "Epoch 17/50\n",
      "1382/1382 [==============================] - 0s 169us/step - loss: 0.0500 - accuracy: 1.0000 - val_loss: 2.1310 - val_accuracy: 0.7023\n",
      "Epoch 18/50\n",
      "1382/1382 [==============================] - 0s 165us/step - loss: 0.0454 - accuracy: 1.0000 - val_loss: 2.2136 - val_accuracy: 0.7023\n",
      "Epoch 19/50\n",
      "1382/1382 [==============================] - 0s 170us/step - loss: 0.0410 - accuracy: 1.0000 - val_loss: 2.3145 - val_accuracy: 0.6994\n",
      "Epoch 20/50\n",
      "1382/1382 [==============================] - 0s 165us/step - loss: 0.0373 - accuracy: 1.0000 - val_loss: 2.3710 - val_accuracy: 0.6994\n",
      "Epoch 21/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1382/1382 [==============================] - 0s 172us/step - loss: 0.0346 - accuracy: 1.0000 - val_loss: 2.4492 - val_accuracy: 0.6994\n",
      "Epoch 22/50\n",
      "1382/1382 [==============================] - 0s 164us/step - loss: 0.0313 - accuracy: 1.0000 - val_loss: 2.5148 - val_accuracy: 0.7052\n",
      "Epoch 23/50\n",
      "1382/1382 [==============================] - 0s 163us/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 2.5670 - val_accuracy: 0.7110\n",
      "Epoch 24/50\n",
      "1382/1382 [==============================] - 0s 168us/step - loss: 0.0270 - accuracy: 1.0000 - val_loss: 2.5975 - val_accuracy: 0.7023\n",
      "Epoch 25/50\n",
      "1382/1382 [==============================] - 0s 166us/step - loss: 0.0258 - accuracy: 1.0000 - val_loss: 2.6570 - val_accuracy: 0.7081\n",
      "Epoch 26/50\n",
      "1382/1382 [==============================] - 0s 162us/step - loss: 0.0238 - accuracy: 1.0000 - val_loss: 2.6437 - val_accuracy: 0.7081\n",
      "Epoch 27/50\n",
      "1382/1382 [==============================] - 0s 162us/step - loss: 0.0231 - accuracy: 1.0000 - val_loss: 2.7471 - val_accuracy: 0.7139\n",
      "Epoch 28/50\n",
      "1382/1382 [==============================] - 0s 165us/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 2.7705 - val_accuracy: 0.7110\n",
      "Epoch 29/50\n",
      "1382/1382 [==============================] - 0s 160us/step - loss: 0.3287 - accuracy: 0.9573 - val_loss: 1.2517 - val_accuracy: 0.7168\n",
      "Epoch 30/50\n",
      "1382/1382 [==============================] - 0s 162us/step - loss: 0.3063 - accuracy: 0.9465 - val_loss: 1.0589 - val_accuracy: 0.7601\n",
      "Epoch 31/50\n",
      "1382/1382 [==============================] - 0s 161us/step - loss: 0.1382 - accuracy: 0.9891 - val_loss: 1.5606 - val_accuracy: 0.7486\n",
      "Epoch 32/50\n",
      "1382/1382 [==============================] - 0s 164us/step - loss: 0.1124 - accuracy: 0.9935 - val_loss: 1.6205 - val_accuracy: 0.7486\n",
      "Epoch 33/50\n",
      "1382/1382 [==============================] - 0s 162us/step - loss: 0.0668 - accuracy: 1.0000 - val_loss: 1.8372 - val_accuracy: 0.7457\n",
      "Epoch 34/50\n",
      "1382/1382 [==============================] - 0s 162us/step - loss: 0.0540 - accuracy: 1.0000 - val_loss: 1.9425 - val_accuracy: 0.7399\n",
      "Epoch 35/50\n",
      "1382/1382 [==============================] - 0s 162us/step - loss: 0.0465 - accuracy: 1.0000 - val_loss: 2.0451 - val_accuracy: 0.7370\n",
      "Epoch 36/50\n",
      "1382/1382 [==============================] - 0s 165us/step - loss: 0.0412 - accuracy: 1.0000 - val_loss: 2.1342 - val_accuracy: 0.7283\n",
      "Epoch 37/50\n",
      "1382/1382 [==============================] - 0s 162us/step - loss: 0.0382 - accuracy: 1.0000 - val_loss: 2.2181 - val_accuracy: 0.7197\n",
      "Epoch 38/50\n",
      "1382/1382 [==============================] - 0s 161us/step - loss: 0.0353 - accuracy: 1.0000 - val_loss: 2.2855 - val_accuracy: 0.7168\n",
      "Epoch 39/50\n",
      "1382/1382 [==============================] - 0s 161us/step - loss: 0.0323 - accuracy: 1.0000 - val_loss: 2.3588 - val_accuracy: 0.7197\n",
      "Epoch 40/50\n",
      "1382/1382 [==============================] - 0s 162us/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 2.4280 - val_accuracy: 0.7168\n",
      "Epoch 41/50\n",
      "1382/1382 [==============================] - 0s 159us/step - loss: 0.0284 - accuracy: 1.0000 - val_loss: 2.4925 - val_accuracy: 0.7197\n",
      "Epoch 42/50\n",
      "1382/1382 [==============================] - 0s 160us/step - loss: 0.0268 - accuracy: 1.0000 - val_loss: 2.5518 - val_accuracy: 0.7139\n",
      "Epoch 43/50\n",
      "1382/1382 [==============================] - 0s 162us/step - loss: 0.0259 - accuracy: 1.0000 - val_loss: 2.6057 - val_accuracy: 0.7081\n",
      "Epoch 44/50\n",
      "1382/1382 [==============================] - 0s 163us/step - loss: 0.0240 - accuracy: 1.0000 - val_loss: 2.6710 - val_accuracy: 0.7081\n",
      "Epoch 45/50\n",
      "1382/1382 [==============================] - 0s 163us/step - loss: 0.0228 - accuracy: 1.0000 - val_loss: 2.7238 - val_accuracy: 0.7081\n",
      "Epoch 46/50\n",
      "1382/1382 [==============================] - 0s 162us/step - loss: 0.0218 - accuracy: 1.0000 - val_loss: 2.7885 - val_accuracy: 0.7110\n",
      "Epoch 47/50\n",
      "1382/1382 [==============================] - 0s 164us/step - loss: 0.0212 - accuracy: 1.0000 - val_loss: 2.8414 - val_accuracy: 0.7052\n",
      "Epoch 48/50\n",
      "1382/1382 [==============================] - 0s 160us/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 2.8957 - val_accuracy: 0.7052\n",
      "Epoch 49/50\n",
      "1382/1382 [==============================] - 0s 159us/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 2.9489 - val_accuracy: 0.7081\n",
      "Epoch 50/50\n",
      "1382/1382 [==============================] - 0s 162us/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 3.0165 - val_accuracy: 0.7052\n",
      "346/346 [==============================] - 0s 58us/step\n",
      "Accuracy: 70.52\n",
      "346/346 [==============================] - 0s 84us/step\n",
      "346/346 [==============================] - 0s 52us/step\n",
      " \n",
      "Train on 1382 samples, validate on 346 samples\n",
      "Epoch 1/50\n",
      "1382/1382 [==============================] - 1s 459us/step - loss: 1.3553 - accuracy: 0.7410 - val_loss: 1.2736 - val_accuracy: 0.7630\n",
      "Epoch 2/50\n",
      "1382/1382 [==============================] - 0s 176us/step - loss: 0.8214 - accuracy: 0.8965 - val_loss: 0.9266 - val_accuracy: 0.8266\n",
      "Epoch 3/50\n",
      "1382/1382 [==============================] - 0s 177us/step - loss: 0.5354 - accuracy: 0.9559 - val_loss: 0.9370 - val_accuracy: 0.8353\n",
      "Epoch 4/50\n",
      "1382/1382 [==============================] - 0s 179us/step - loss: 0.3836 - accuracy: 0.9776 - val_loss: 1.0834 - val_accuracy: 0.8092\n",
      "Epoch 5/50\n",
      "1382/1382 [==============================] - 0s 177us/step - loss: 0.3646 - accuracy: 0.9682 - val_loss: 0.8462 - val_accuracy: 0.8266\n",
      "Epoch 6/50\n",
      "1382/1382 [==============================] - 0s 175us/step - loss: 0.2606 - accuracy: 0.9891 - val_loss: 0.8817 - val_accuracy: 0.8468\n",
      "Epoch 7/50\n",
      "1382/1382 [==============================] - 0s 178us/step - loss: 0.1981 - accuracy: 0.9964 - val_loss: 0.9391 - val_accuracy: 0.8439\n",
      "Epoch 8/50\n",
      "1382/1382 [==============================] - 0s 172us/step - loss: 0.1517 - accuracy: 0.9993 - val_loss: 1.0566 - val_accuracy: 0.8179\n",
      "Epoch 9/50\n",
      "1382/1382 [==============================] - 0s 175us/step - loss: 0.1647 - accuracy: 0.9884 - val_loss: 1.0698 - val_accuracy: 0.8324\n",
      "Epoch 10/50\n",
      "1382/1382 [==============================] - 0s 175us/step - loss: 0.1933 - accuracy: 0.9725 - val_loss: 0.8541 - val_accuracy: 0.8324\n",
      "Epoch 11/50\n",
      "1382/1382 [==============================] - 0s 172us/step - loss: 0.1568 - accuracy: 0.9863 - val_loss: 0.7696 - val_accuracy: 0.8613\n",
      "Epoch 12/50\n",
      "1382/1382 [==============================] - 0s 172us/step - loss: 0.1225 - accuracy: 0.9957 - val_loss: 0.8052 - val_accuracy: 0.8497\n",
      "Epoch 13/50\n",
      "1382/1382 [==============================] - 0s 175us/step - loss: 0.1006 - accuracy: 0.9971 - val_loss: 0.8341 - val_accuracy: 0.8526\n",
      "Epoch 14/50\n",
      "1382/1382 [==============================] - 0s 169us/step - loss: 0.0808 - accuracy: 0.9993 - val_loss: 0.8348 - val_accuracy: 0.8439\n",
      "Epoch 15/50\n",
      "1382/1382 [==============================] - 0s 174us/step - loss: 0.0681 - accuracy: 1.0000 - val_loss: 0.8343 - val_accuracy: 0.8497\n",
      "Epoch 16/50\n",
      "1382/1382 [==============================] - 0s 176us/step - loss: 0.0580 - accuracy: 1.0000 - val_loss: 0.8440 - val_accuracy: 0.8497\n",
      "Epoch 17/50\n",
      "1382/1382 [==============================] - 0s 176us/step - loss: 0.0504 - accuracy: 1.0000 - val_loss: 0.8547 - val_accuracy: 0.8526\n",
      "Epoch 18/50\n",
      "1382/1382 [==============================] - 0s 175us/step - loss: 0.0445 - accuracy: 1.0000 - val_loss: 0.8664 - val_accuracy: 0.8468\n",
      "Epoch 19/50\n",
      "1382/1382 [==============================] - 0s 187us/step - loss: 0.0397 - accuracy: 1.0000 - val_loss: 0.8792 - val_accuracy: 0.8468\n",
      "Epoch 20/50\n",
      "1382/1382 [==============================] - 0s 167us/step - loss: 0.0356 - accuracy: 1.0000 - val_loss: 0.8980 - val_accuracy: 0.8497\n",
      "Epoch 21/50\n",
      "1382/1382 [==============================] - 0s 162us/step - loss: 0.0326 - accuracy: 1.0000 - val_loss: 0.9070 - val_accuracy: 0.8439\n",
      "Epoch 22/50\n",
      "1382/1382 [==============================] - 0s 163us/step - loss: 0.0295 - accuracy: 1.0000 - val_loss: 0.9260 - val_accuracy: 0.8382\n",
      "Epoch 23/50\n",
      "1382/1382 [==============================] - 0s 164us/step - loss: 0.0276 - accuracy: 1.0000 - val_loss: 0.9420 - val_accuracy: 0.8382\n",
      "Epoch 24/50\n",
      "1382/1382 [==============================] - 0s 170us/step - loss: 0.0252 - accuracy: 1.0000 - val_loss: 0.9561 - val_accuracy: 0.8410\n",
      "Epoch 25/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1382/1382 [==============================] - 0s 165us/step - loss: 0.0236 - accuracy: 1.0000 - val_loss: 0.9701 - val_accuracy: 0.8382\n",
      "Epoch 26/50\n",
      "1382/1382 [==============================] - 0s 161us/step - loss: 0.0223 - accuracy: 1.0000 - val_loss: 0.9852 - val_accuracy: 0.8439\n",
      "Epoch 27/50\n",
      "1382/1382 [==============================] - 0s 159us/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 1.0008 - val_accuracy: 0.8410\n",
      "Epoch 28/50\n",
      "1382/1382 [==============================] - 0s 164us/step - loss: 0.5746 - accuracy: 0.9399 - val_loss: 1.0110 - val_accuracy: 0.8266\n",
      "Epoch 29/50\n",
      "1382/1382 [==============================] - 0s 170us/step - loss: 0.2291 - accuracy: 0.9703 - val_loss: 0.7551 - val_accuracy: 0.8410\n",
      "Epoch 30/50\n",
      "1382/1382 [==============================] - 0s 176us/step - loss: 0.1264 - accuracy: 0.9942 - val_loss: 0.8687 - val_accuracy: 0.8121\n",
      "Epoch 31/50\n",
      "1382/1382 [==============================] - 0s 177us/step - loss: 0.1043 - accuracy: 0.9935 - val_loss: 0.9595 - val_accuracy: 0.8266\n",
      "Epoch 32/50\n",
      "1382/1382 [==============================] - 0s 173us/step - loss: 0.0988 - accuracy: 0.9935 - val_loss: 0.9710 - val_accuracy: 0.8208\n",
      "Epoch 33/50\n",
      "1382/1382 [==============================] - 0s 170us/step - loss: 0.0837 - accuracy: 0.9957 - val_loss: 0.9812 - val_accuracy: 0.8150\n",
      "Epoch 34/50\n",
      "1382/1382 [==============================] - 0s 162us/step - loss: 0.0734 - accuracy: 0.9978 - val_loss: 1.0781 - val_accuracy: 0.8150\n",
      "Epoch 35/50\n",
      "1382/1382 [==============================] - 0s 158us/step - loss: 0.1105 - accuracy: 0.9899 - val_loss: 0.9741 - val_accuracy: 0.8208\n",
      "Epoch 36/50\n",
      "1382/1382 [==============================] - 0s 162us/step - loss: 0.0710 - accuracy: 0.9993 - val_loss: 1.1463 - val_accuracy: 0.8237\n",
      "Epoch 37/50\n",
      "1382/1382 [==============================] - 0s 159us/step - loss: 0.0571 - accuracy: 1.0000 - val_loss: 1.1635 - val_accuracy: 0.8237\n",
      "Epoch 38/50\n",
      "1382/1382 [==============================] - 0s 165us/step - loss: 0.0513 - accuracy: 1.0000 - val_loss: 1.1810 - val_accuracy: 0.8208\n",
      "Epoch 39/50\n",
      "1382/1382 [==============================] - 0s 163us/step - loss: 0.0450 - accuracy: 1.0000 - val_loss: 1.1900 - val_accuracy: 0.8208\n",
      "Epoch 40/50\n",
      "1382/1382 [==============================] - 0s 159us/step - loss: 0.0416 - accuracy: 1.0000 - val_loss: 1.1936 - val_accuracy: 0.8208\n",
      "Epoch 41/50\n",
      "1382/1382 [==============================] - 0s 160us/step - loss: 0.0383 - accuracy: 1.0000 - val_loss: 1.2053 - val_accuracy: 0.8179\n",
      "Epoch 42/50\n",
      "1382/1382 [==============================] - 0s 161us/step - loss: 0.0358 - accuracy: 1.0000 - val_loss: 1.2172 - val_accuracy: 0.8179\n",
      "Epoch 43/50\n",
      "1382/1382 [==============================] - 0s 160us/step - loss: 0.0333 - accuracy: 1.0000 - val_loss: 1.2238 - val_accuracy: 0.8150\n",
      "Epoch 44/50\n",
      "1382/1382 [==============================] - 0s 162us/step - loss: 0.0315 - accuracy: 1.0000 - val_loss: 1.2303 - val_accuracy: 0.8150\n",
      "Epoch 45/50\n",
      "1382/1382 [==============================] - 0s 159us/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 1.2439 - val_accuracy: 0.8150\n",
      "Epoch 46/50\n",
      "1382/1382 [==============================] - 0s 161us/step - loss: 0.0279 - accuracy: 1.0000 - val_loss: 1.2551 - val_accuracy: 0.8092\n",
      "Epoch 47/50\n",
      "1382/1382 [==============================] - 0s 165us/step - loss: 0.0268 - accuracy: 1.0000 - val_loss: 1.2633 - val_accuracy: 0.8006\n",
      "Epoch 48/50\n",
      "1382/1382 [==============================] - 0s 162us/step - loss: 0.0246 - accuracy: 1.0000 - val_loss: 1.2782 - val_accuracy: 0.8006\n",
      "Epoch 49/50\n",
      "1382/1382 [==============================] - 0s 161us/step - loss: 0.0244 - accuracy: 1.0000 - val_loss: 1.2876 - val_accuracy: 0.8035\n",
      "Epoch 50/50\n",
      "1382/1382 [==============================] - 0s 164us/step - loss: 0.0230 - accuracy: 1.0000 - val_loss: 1.2974 - val_accuracy: 0.7977\n",
      "346/346 [==============================] - 0s 55us/step\n",
      "Accuracy: 79.77\n",
      "346/346 [==============================] - 0s 84us/step\n",
      "346/346 [==============================] - 0s 58us/step\n",
      " \n",
      "Train on 1382 samples, validate on 346 samples\n",
      "Epoch 1/50\n",
      "1382/1382 [==============================] - 1s 464us/step - loss: 1.1305 - accuracy: 0.6469 - val_loss: 1.0668 - val_accuracy: 0.6936\n",
      "Epoch 2/50\n",
      "1382/1382 [==============================] - 0s 176us/step - loss: 0.7801 - accuracy: 0.7988 - val_loss: 1.0820 - val_accuracy: 0.6474\n",
      "Epoch 3/50\n",
      "1382/1382 [==============================] - 0s 178us/step - loss: 0.5330 - accuracy: 0.8987 - val_loss: 1.2185 - val_accuracy: 0.7023\n",
      "Epoch 4/50\n",
      "1382/1382 [==============================] - 0s 172us/step - loss: 0.3725 - accuracy: 0.9566 - val_loss: 1.3277 - val_accuracy: 0.7139\n",
      "Epoch 5/50\n",
      "1382/1382 [==============================] - 0s 175us/step - loss: 0.2802 - accuracy: 0.9768 - val_loss: 1.6859 - val_accuracy: 0.6908\n",
      "Epoch 6/50\n",
      "1382/1382 [==============================] - 0s 183us/step - loss: 0.2591 - accuracy: 0.9754 - val_loss: 1.6803 - val_accuracy: 0.6908\n",
      "Epoch 7/50\n",
      "1382/1382 [==============================] - 0s 176us/step - loss: 0.2646 - accuracy: 0.9732 - val_loss: 1.7139 - val_accuracy: 0.6705\n",
      "Epoch 8/50\n",
      "1382/1382 [==============================] - 0s 176us/step - loss: 0.1873 - accuracy: 0.9913 - val_loss: 1.8744 - val_accuracy: 0.6879\n",
      "Epoch 9/50\n",
      "1382/1382 [==============================] - 0s 176us/step - loss: 0.1797 - accuracy: 0.9884 - val_loss: 1.9433 - val_accuracy: 0.6705\n",
      "Epoch 10/50\n",
      "1382/1382 [==============================] - 0s 175us/step - loss: 0.1774 - accuracy: 0.9841 - val_loss: 2.0018 - val_accuracy: 0.6532\n",
      "Epoch 11/50\n",
      "1382/1382 [==============================] - 0s 177us/step - loss: 0.1813 - accuracy: 0.9834 - val_loss: 2.0253 - val_accuracy: 0.6561\n",
      "Epoch 12/50\n",
      "1382/1382 [==============================] - 0s 178us/step - loss: 0.1287 - accuracy: 0.9964 - val_loss: 2.1243 - val_accuracy: 0.6618\n",
      "Epoch 13/50\n",
      "1382/1382 [==============================] - 0s 176us/step - loss: 0.1394 - accuracy: 0.9891 - val_loss: 1.9726 - val_accuracy: 0.6821\n",
      "Epoch 14/50\n",
      "1382/1382 [==============================] - 0s 177us/step - loss: 0.1666 - accuracy: 0.9783 - val_loss: 1.8914 - val_accuracy: 0.6734\n",
      "Epoch 15/50\n",
      "1382/1382 [==============================] - 0s 175us/step - loss: 0.1516 - accuracy: 0.9841 - val_loss: 1.8222 - val_accuracy: 0.6792\n",
      "Epoch 16/50\n",
      "1382/1382 [==============================] - 0s 174us/step - loss: 0.1239 - accuracy: 0.9928 - val_loss: 2.2300 - val_accuracy: 0.6647\n",
      "Epoch 17/50\n",
      "1382/1382 [==============================] - 0s 174us/step - loss: 0.1004 - accuracy: 0.9978 - val_loss: 2.2673 - val_accuracy: 0.6908\n",
      "Epoch 18/50\n",
      "1382/1382 [==============================] - 0s 181us/step - loss: 0.0946 - accuracy: 0.9971 - val_loss: 2.2674 - val_accuracy: 0.6734\n",
      "Epoch 19/50\n",
      "1382/1382 [==============================] - 0s 173us/step - loss: 0.1377 - accuracy: 0.9841 - val_loss: 1.5681 - val_accuracy: 0.6965\n",
      "Epoch 20/50\n",
      "1382/1382 [==============================] - 0s 177us/step - loss: 0.1147 - accuracy: 0.9928 - val_loss: 1.9108 - val_accuracy: 0.6705\n",
      "Epoch 21/50\n",
      "1382/1382 [==============================] - 0s 179us/step - loss: 0.0786 - accuracy: 0.9993 - val_loss: 2.1816 - val_accuracy: 0.6879\n",
      "Epoch 22/50\n",
      "1382/1382 [==============================] - 0s 175us/step - loss: 0.0698 - accuracy: 1.0000 - val_loss: 2.3153 - val_accuracy: 0.6763\n",
      "Epoch 23/50\n",
      "1382/1382 [==============================] - 0s 175us/step - loss: 0.0622 - accuracy: 1.0000 - val_loss: 2.4048 - val_accuracy: 0.6734\n",
      "Epoch 24/50\n",
      "1382/1382 [==============================] - 0s 181us/step - loss: 0.0569 - accuracy: 1.0000 - val_loss: 2.4886 - val_accuracy: 0.6763\n",
      "Epoch 25/50\n",
      "1382/1382 [==============================] - 0s 176us/step - loss: 0.0535 - accuracy: 1.0000 - val_loss: 2.5714 - val_accuracy: 0.6763\n",
      "Epoch 26/50\n",
      "1382/1382 [==============================] - 0s 182us/step - loss: 0.0490 - accuracy: 1.0000 - val_loss: 2.6415 - val_accuracy: 0.6763\n",
      "Epoch 27/50\n",
      "1382/1382 [==============================] - 0s 177us/step - loss: 0.0457 - accuracy: 1.0000 - val_loss: 2.7182 - val_accuracy: 0.6763\n",
      "Epoch 28/50\n",
      "1382/1382 [==============================] - 0s 175us/step - loss: 0.0437 - accuracy: 1.0000 - val_loss: 2.7663 - val_accuracy: 0.6734\n",
      "Epoch 29/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1382/1382 [==============================] - 0s 180us/step - loss: 0.0400 - accuracy: 1.0000 - val_loss: 2.8449 - val_accuracy: 0.6705\n",
      "Epoch 30/50\n",
      "1382/1382 [==============================] - 0s 170us/step - loss: 0.0387 - accuracy: 1.0000 - val_loss: 2.8719 - val_accuracy: 0.6647\n",
      "Epoch 31/50\n",
      "1382/1382 [==============================] - 0s 173us/step - loss: 0.0350 - accuracy: 1.0000 - val_loss: 2.9309 - val_accuracy: 0.6647\n",
      "Epoch 32/50\n",
      "1382/1382 [==============================] - 0s 173us/step - loss: 0.0340 - accuracy: 1.0000 - val_loss: 2.9569 - val_accuracy: 0.6647\n",
      "Epoch 33/50\n",
      "1382/1382 [==============================] - 0s 177us/step - loss: 0.0328 - accuracy: 1.0000 - val_loss: 3.0050 - val_accuracy: 0.6618\n",
      "Epoch 34/50\n",
      "1382/1382 [==============================] - 0s 176us/step - loss: 0.0304 - accuracy: 1.0000 - val_loss: 3.0194 - val_accuracy: 0.6618\n",
      "Epoch 35/50\n",
      "1382/1382 [==============================] - 0s 175us/step - loss: 0.0291 - accuracy: 1.0000 - val_loss: 3.0656 - val_accuracy: 0.6618\n",
      "Epoch 36/50\n",
      "1382/1382 [==============================] - 0s 175us/step - loss: 0.0279 - accuracy: 1.0000 - val_loss: 3.0860 - val_accuracy: 0.6705\n",
      "Epoch 37/50\n",
      "1382/1382 [==============================] - 0s 175us/step - loss: 0.0263 - accuracy: 1.0000 - val_loss: 3.1329 - val_accuracy: 0.6561\n",
      "Epoch 38/50\n",
      "1382/1382 [==============================] - 0s 175us/step - loss: 0.0251 - accuracy: 1.0000 - val_loss: 3.1682 - val_accuracy: 0.6590\n",
      "Epoch 39/50\n",
      "1382/1382 [==============================] - 0s 176us/step - loss: 0.0241 - accuracy: 1.0000 - val_loss: 3.1826 - val_accuracy: 0.6618\n",
      "Epoch 40/50\n",
      "1382/1382 [==============================] - 0s 175us/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 3.2213 - val_accuracy: 0.6647\n",
      "Epoch 41/50\n",
      "1382/1382 [==============================] - 0s 175us/step - loss: 0.0236 - accuracy: 1.0000 - val_loss: 3.2113 - val_accuracy: 0.6647\n",
      "Epoch 42/50\n",
      "1382/1382 [==============================] - 0s 177us/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 3.2863 - val_accuracy: 0.6647\n",
      "Epoch 43/50\n",
      "1382/1382 [==============================] - 0s 176us/step - loss: 0.0209 - accuracy: 1.0000 - val_loss: 3.2631 - val_accuracy: 0.6705\n",
      "Epoch 44/50\n",
      "1382/1382 [==============================] - 0s 173us/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 3.3103 - val_accuracy: 0.6705\n",
      "Epoch 45/50\n",
      "1382/1382 [==============================] - 0s 175us/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 3.2897 - val_accuracy: 0.6705\n",
      "Epoch 46/50\n",
      "1382/1382 [==============================] - 0s 175us/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 3.3712 - val_accuracy: 0.6676\n",
      "Epoch 47/50\n",
      "1382/1382 [==============================] - 0s 177us/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 3.3397 - val_accuracy: 0.6763\n",
      "Epoch 48/50\n",
      "1382/1382 [==============================] - 0s 175us/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 3.3834 - val_accuracy: 0.6734\n",
      "Epoch 49/50\n",
      "1382/1382 [==============================] - 0s 172us/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 3.3897 - val_accuracy: 0.6763\n",
      "Epoch 50/50\n",
      "1382/1382 [==============================] - 0s 173us/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 3.3605 - val_accuracy: 0.6850\n",
      "346/346 [==============================] - 0s 69us/step\n",
      "Accuracy: 68.50\n",
      "346/346 [==============================] - 0s 90us/step\n",
      "346/346 [==============================] - 0s 64us/step\n",
      " \n",
      "Train on 1382 samples, validate on 346 samples\n",
      "Epoch 1/50\n",
      "1382/1382 [==============================] - 1s 456us/step - loss: 1.1843 - accuracy: 0.7055 - val_loss: 0.8936 - val_accuracy: 0.8179\n",
      "Epoch 2/50\n",
      "1382/1382 [==============================] - 0s 172us/step - loss: 0.8122 - accuracy: 0.8300 - val_loss: 0.7960 - val_accuracy: 0.7977\n",
      "Epoch 3/50\n",
      "1382/1382 [==============================] - 0s 177us/step - loss: 0.5867 - accuracy: 0.8987 - val_loss: 0.8796 - val_accuracy: 0.7861\n",
      "Epoch 4/50\n",
      "1382/1382 [==============================] - 0s 174us/step - loss: 0.4279 - accuracy: 0.9501 - val_loss: 1.1462 - val_accuracy: 0.7081\n",
      "Epoch 5/50\n",
      "1382/1382 [==============================] - 0s 177us/step - loss: 0.3518 - accuracy: 0.9674 - val_loss: 0.8553 - val_accuracy: 0.8237\n",
      "Epoch 6/50\n",
      "1382/1382 [==============================] - 0s 170us/step - loss: 0.2651 - accuracy: 0.9877 - val_loss: 0.9860 - val_accuracy: 0.7948\n",
      "Epoch 7/50\n",
      "1382/1382 [==============================] - 0s 174us/step - loss: 0.2124 - accuracy: 0.9920 - val_loss: 1.5968 - val_accuracy: 0.5376\n",
      "Epoch 8/50\n",
      "1382/1382 [==============================] - 0s 175us/step - loss: 0.3268 - accuracy: 0.9450 - val_loss: 2.1830 - val_accuracy: 0.6590\n",
      "Epoch 9/50\n",
      "1382/1382 [==============================] - 0s 175us/step - loss: 0.3294 - accuracy: 0.9609 - val_loss: 0.9161 - val_accuracy: 0.7803\n",
      "Epoch 10/50\n",
      "1382/1382 [==============================] - 0s 169us/step - loss: 0.2332 - accuracy: 0.9855 - val_loss: 0.9338 - val_accuracy: 0.7977\n",
      "Epoch 11/50\n",
      "1382/1382 [==============================] - 0s 178us/step - loss: 0.1808 - accuracy: 0.9949 - val_loss: 0.8989 - val_accuracy: 0.7890\n",
      "Epoch 12/50\n",
      "1382/1382 [==============================] - 0s 175us/step - loss: 0.1611 - accuracy: 0.9920 - val_loss: 0.9539 - val_accuracy: 0.7775\n",
      "Epoch 13/50\n",
      "1382/1382 [==============================] - 0s 177us/step - loss: 0.1394 - accuracy: 0.9957 - val_loss: 1.1137 - val_accuracy: 0.7746\n",
      "Epoch 14/50\n",
      "1382/1382 [==============================] - 0s 175us/step - loss: 0.1224 - accuracy: 0.9964 - val_loss: 1.2679 - val_accuracy: 0.7775\n",
      "Epoch 15/50\n",
      "1382/1382 [==============================] - 0s 177us/step - loss: 0.1615 - accuracy: 0.9877 - val_loss: 1.0675 - val_accuracy: 0.7514\n",
      "Epoch 16/50\n",
      "1382/1382 [==============================] - 0s 180us/step - loss: 0.1315 - accuracy: 0.9884 - val_loss: 1.0563 - val_accuracy: 0.7601\n",
      "Epoch 17/50\n",
      "1382/1382 [==============================] - 0s 178us/step - loss: 0.1424 - accuracy: 0.9877 - val_loss: 1.6698 - val_accuracy: 0.7081\n",
      "Epoch 18/50\n",
      "1382/1382 [==============================] - 0s 172us/step - loss: 0.1916 - accuracy: 0.9747 - val_loss: 0.8610 - val_accuracy: 0.7948\n",
      "Epoch 19/50\n",
      "1382/1382 [==============================] - 0s 177us/step - loss: 0.1240 - accuracy: 0.9920 - val_loss: 0.9852 - val_accuracy: 0.7832\n",
      "Epoch 20/50\n",
      "1382/1382 [==============================] - 0s 177us/step - loss: 0.0956 - accuracy: 0.9986 - val_loss: 1.0087 - val_accuracy: 0.7746\n",
      "Epoch 21/50\n",
      "1382/1382 [==============================] - 0s 172us/step - loss: 0.0791 - accuracy: 1.0000 - val_loss: 1.0783 - val_accuracy: 0.7861\n",
      "Epoch 22/50\n",
      "1382/1382 [==============================] - 0s 175us/step - loss: 0.0694 - accuracy: 1.0000 - val_loss: 1.1089 - val_accuracy: 0.7775\n",
      "Epoch 23/50\n",
      "1382/1382 [==============================] - 0s 176us/step - loss: 0.0621 - accuracy: 1.0000 - val_loss: 1.1406 - val_accuracy: 0.7717\n",
      "Epoch 24/50\n",
      "1382/1382 [==============================] - 0s 175us/step - loss: 0.0562 - accuracy: 1.0000 - val_loss: 1.1540 - val_accuracy: 0.7659\n",
      "Epoch 25/50\n",
      "1382/1382 [==============================] - 0s 175us/step - loss: 0.0513 - accuracy: 1.0000 - val_loss: 1.1836 - val_accuracy: 0.7630\n",
      "Epoch 26/50\n",
      "1382/1382 [==============================] - 0s 179us/step - loss: 0.0471 - accuracy: 1.0000 - val_loss: 1.2020 - val_accuracy: 0.7601\n",
      "Epoch 27/50\n",
      "1382/1382 [==============================] - 0s 176us/step - loss: 0.0439 - accuracy: 1.0000 - val_loss: 1.2278 - val_accuracy: 0.7514\n",
      "Epoch 28/50\n",
      "1382/1382 [==============================] - 0s 175us/step - loss: 0.0406 - accuracy: 1.0000 - val_loss: 1.2343 - val_accuracy: 0.7601\n",
      "Epoch 29/50\n",
      "1382/1382 [==============================] - 0s 176us/step - loss: 0.0379 - accuracy: 1.0000 - val_loss: 1.2380 - val_accuracy: 0.7659\n",
      "Epoch 30/50\n",
      "1382/1382 [==============================] - 0s 177us/step - loss: 0.0355 - accuracy: 1.0000 - val_loss: 1.2777 - val_accuracy: 0.7630\n",
      "Epoch 31/50\n",
      "1382/1382 [==============================] - 0s 176us/step - loss: 0.0329 - accuracy: 1.0000 - val_loss: 1.2769 - val_accuracy: 0.7572\n",
      "Epoch 32/50\n",
      "1382/1382 [==============================] - 0s 175us/step - loss: 0.0315 - accuracy: 1.0000 - val_loss: 1.2855 - val_accuracy: 0.7601\n",
      "Epoch 33/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1382/1382 [==============================] - 0s 176us/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 1.2891 - val_accuracy: 0.7630\n",
      "Epoch 34/50\n",
      "1382/1382 [==============================] - 0s 175us/step - loss: 0.0282 - accuracy: 1.0000 - val_loss: 1.2995 - val_accuracy: 0.7630\n",
      "Epoch 35/50\n",
      "1382/1382 [==============================] - 0s 173us/step - loss: 0.0266 - accuracy: 1.0000 - val_loss: 1.3156 - val_accuracy: 0.7630\n",
      "Epoch 36/50\n",
      "1382/1382 [==============================] - 0s 176us/step - loss: 0.0253 - accuracy: 1.0000 - val_loss: 1.3361 - val_accuracy: 0.7601\n",
      "Epoch 37/50\n",
      "1382/1382 [==============================] - 0s 175us/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 1.3461 - val_accuracy: 0.7630\n",
      "Epoch 38/50\n",
      "1382/1382 [==============================] - 0s 175us/step - loss: 0.0231 - accuracy: 1.0000 - val_loss: 1.3408 - val_accuracy: 0.7717\n",
      "Epoch 39/50\n",
      "1382/1382 [==============================] - 0s 176us/step - loss: 0.0222 - accuracy: 1.0000 - val_loss: 1.3506 - val_accuracy: 0.7688\n",
      "Epoch 40/50\n",
      "1382/1382 [==============================] - 0s 176us/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 1.3919 - val_accuracy: 0.7601\n",
      "Epoch 41/50\n",
      "1382/1382 [==============================] - 0s 172us/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 1.3753 - val_accuracy: 0.7659\n",
      "Epoch 42/50\n",
      "1382/1382 [==============================] - 0s 172us/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 1.4143 - val_accuracy: 0.7514\n",
      "Epoch 43/50\n",
      "1382/1382 [==============================] - 0s 172us/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 1.4296 - val_accuracy: 0.7543\n",
      "Epoch 44/50\n",
      "1382/1382 [==============================] - 0s 177us/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 1.4348 - val_accuracy: 0.7543\n",
      "Epoch 45/50\n",
      "1382/1382 [==============================] - 0s 173us/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 1.4606 - val_accuracy: 0.7514\n",
      "Epoch 46/50\n",
      "1382/1382 [==============================] - 0s 179us/step - loss: 0.3800 - accuracy: 0.9262 - val_loss: 0.7950 - val_accuracy: 0.7659\n",
      "Epoch 47/50\n",
      "1382/1382 [==============================] - 0s 173us/step - loss: 0.2354 - accuracy: 0.9573 - val_loss: 0.6553 - val_accuracy: 0.8121\n",
      "Epoch 48/50\n",
      "1382/1382 [==============================] - 0s 175us/step - loss: 0.1674 - accuracy: 0.9776 - val_loss: 0.6927 - val_accuracy: 0.7861\n",
      "Epoch 49/50\n",
      "1382/1382 [==============================] - 0s 178us/step - loss: 0.1080 - accuracy: 0.9899 - val_loss: 0.9461 - val_accuracy: 0.7775\n",
      "Epoch 50/50\n",
      "1382/1382 [==============================] - 0s 178us/step - loss: 0.0840 - accuracy: 0.9935 - val_loss: 0.9188 - val_accuracy: 0.8150\n",
      "346/346 [==============================] - 0s 55us/step\n",
      "Accuracy: 81.50\n",
      "346/346 [==============================] - 0s 84us/step\n",
      "346/346 [==============================] - 0s 55us/step\n",
      " \n",
      "Train on 1382 samples, validate on 346 samples\n",
      "Epoch 1/50\n",
      "1382/1382 [==============================] - 1s 403us/step - loss: 1.4997 - accuracy: 0.7019 - val_loss: 1.4284 - val_accuracy: 0.6850\n",
      "Epoch 2/50\n",
      "1382/1382 [==============================] - 0s 153us/step - loss: 0.9214 - accuracy: 0.8835 - val_loss: 1.1531 - val_accuracy: 0.7370\n",
      "Epoch 3/50\n",
      "1382/1382 [==============================] - 0s 152us/step - loss: 0.6443 - accuracy: 0.9356 - val_loss: 1.1318 - val_accuracy: 0.7399\n",
      "Epoch 4/50\n",
      "1382/1382 [==============================] - 0s 151us/step - loss: 0.4577 - accuracy: 0.9754 - val_loss: 1.3327 - val_accuracy: 0.7225\n",
      "Epoch 5/50\n",
      "1382/1382 [==============================] - 0s 154us/step - loss: 0.3809 - accuracy: 0.9761 - val_loss: 1.2805 - val_accuracy: 0.7370\n",
      "Epoch 6/50\n",
      "1382/1382 [==============================] - 0s 152us/step - loss: 0.3259 - accuracy: 0.9797 - val_loss: 1.3607 - val_accuracy: 0.7486\n",
      "Epoch 7/50\n",
      "1382/1382 [==============================] - 0s 151us/step - loss: 0.2506 - accuracy: 0.9891 - val_loss: 1.6161 - val_accuracy: 0.7225\n",
      "Epoch 8/50\n",
      "1382/1382 [==============================] - 0s 151us/step - loss: 0.2045 - accuracy: 0.9920 - val_loss: 1.6620 - val_accuracy: 0.7225\n",
      "Epoch 9/50\n",
      "1382/1382 [==============================] - 0s 151us/step - loss: 0.2231 - accuracy: 0.9812 - val_loss: 1.3506 - val_accuracy: 0.7283\n",
      "Epoch 10/50\n",
      "1382/1382 [==============================] - 0s 151us/step - loss: 0.1875 - accuracy: 0.9899 - val_loss: 1.2714 - val_accuracy: 0.7630\n",
      "Epoch 11/50\n",
      "1382/1382 [==============================] - 0s 152us/step - loss: 0.1756 - accuracy: 0.9877 - val_loss: 1.3492 - val_accuracy: 0.7601\n",
      "Epoch 12/50\n",
      "1382/1382 [==============================] - 0s 153us/step - loss: 0.1292 - accuracy: 0.9971 - val_loss: 1.5364 - val_accuracy: 0.7601\n",
      "Epoch 13/50\n",
      "1382/1382 [==============================] - 0s 151us/step - loss: 0.1367 - accuracy: 0.9913 - val_loss: 1.4895 - val_accuracy: 0.7341\n",
      "Epoch 14/50\n",
      "1382/1382 [==============================] - 0s 152us/step - loss: 0.1520 - accuracy: 0.9848 - val_loss: 1.3894 - val_accuracy: 0.7630\n",
      "Epoch 15/50\n",
      "1382/1382 [==============================] - 0s 154us/step - loss: 0.0997 - accuracy: 0.9964 - val_loss: 1.5960 - val_accuracy: 0.7457\n",
      "Epoch 16/50\n",
      "1382/1382 [==============================] - 0s 150us/step - loss: 0.0922 - accuracy: 0.9978 - val_loss: 1.6713 - val_accuracy: 0.7572\n",
      "Epoch 17/50\n",
      "1382/1382 [==============================] - 0s 150us/step - loss: 0.0743 - accuracy: 1.0000 - val_loss: 1.7304 - val_accuracy: 0.7572\n",
      "Epoch 18/50\n",
      "1382/1382 [==============================] - 0s 151us/step - loss: 0.0648 - accuracy: 1.0000 - val_loss: 1.7491 - val_accuracy: 0.7572\n",
      "Epoch 19/50\n",
      "1382/1382 [==============================] - 0s 153us/step - loss: 0.0575 - accuracy: 1.0000 - val_loss: 1.7832 - val_accuracy: 0.7514\n",
      "Epoch 20/50\n",
      "1382/1382 [==============================] - 0s 151us/step - loss: 0.0528 - accuracy: 1.0000 - val_loss: 1.8132 - val_accuracy: 0.7572\n",
      "Epoch 21/50\n",
      "1382/1382 [==============================] - 0s 164us/step - loss: 0.0478 - accuracy: 1.0000 - val_loss: 1.8545 - val_accuracy: 0.7543\n",
      "Epoch 22/50\n",
      "1382/1382 [==============================] - 0s 175us/step - loss: 0.0436 - accuracy: 1.0000 - val_loss: 1.8911 - val_accuracy: 0.7514\n",
      "Epoch 23/50\n",
      "1382/1382 [==============================] - 0s 177us/step - loss: 0.0404 - accuracy: 1.0000 - val_loss: 1.9276 - val_accuracy: 0.7514\n",
      "Epoch 24/50\n",
      "1382/1382 [==============================] - 0s 175us/step - loss: 0.0371 - accuracy: 1.0000 - val_loss: 1.9795 - val_accuracy: 0.7514\n",
      "Epoch 25/50\n",
      "1382/1382 [==============================] - 0s 175us/step - loss: 0.0357 - accuracy: 1.0000 - val_loss: 2.0119 - val_accuracy: 0.7514\n",
      "Epoch 26/50\n",
      "1382/1382 [==============================] - 0s 176us/step - loss: 0.0329 - accuracy: 1.0000 - val_loss: 2.0507 - val_accuracy: 0.7457\n",
      "Epoch 27/50\n",
      "1382/1382 [==============================] - 0s 177us/step - loss: 0.0308 - accuracy: 1.0000 - val_loss: 2.0874 - val_accuracy: 0.7457\n",
      "Epoch 28/50\n",
      "1382/1382 [==============================] - 0s 180us/step - loss: 0.0292 - accuracy: 1.0000 - val_loss: 2.1233 - val_accuracy: 0.7428\n",
      "Epoch 29/50\n",
      "1382/1382 [==============================] - 0s 180us/step - loss: 0.0277 - accuracy: 1.0000 - val_loss: 2.1724 - val_accuracy: 0.7428\n",
      "Epoch 30/50\n",
      "1382/1382 [==============================] - 0s 161us/step - loss: 0.0259 - accuracy: 1.0000 - val_loss: 2.2056 - val_accuracy: 0.7341\n",
      "Epoch 31/50\n",
      "1382/1382 [==============================] - 0s 151us/step - loss: 0.0246 - accuracy: 1.0000 - val_loss: 2.2544 - val_accuracy: 0.7341\n",
      "Epoch 32/50\n",
      "1382/1382 [==============================] - 0s 152us/step - loss: 0.0240 - accuracy: 1.0000 - val_loss: 2.2901 - val_accuracy: 0.7312\n",
      "Epoch 33/50\n",
      "1382/1382 [==============================] - 0s 152us/step - loss: 0.0223 - accuracy: 1.0000 - val_loss: 2.3191 - val_accuracy: 0.7312\n",
      "Epoch 34/50\n",
      "1382/1382 [==============================] - 0s 153us/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 2.3771 - val_accuracy: 0.7370\n",
      "Epoch 35/50\n",
      "1382/1382 [==============================] - 0s 152us/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 2.3966 - val_accuracy: 0.7341\n",
      "Epoch 36/50\n",
      "1382/1382 [==============================] - 0s 151us/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 2.4268 - val_accuracy: 0.7341\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1382/1382 [==============================] - 0s 155us/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 2.4641 - val_accuracy: 0.7370\n",
      "Epoch 38/50\n",
      "1382/1382 [==============================] - 0s 156us/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 2.5013 - val_accuracy: 0.7370\n",
      "Epoch 39/50\n",
      "1382/1382 [==============================] - 0s 151us/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 2.5405 - val_accuracy: 0.7370\n",
      "Epoch 40/50\n",
      "1382/1382 [==============================] - 0s 148us/step - loss: 0.6305 - accuracy: 0.9255 - val_loss: 0.9480 - val_accuracy: 0.7457\n",
      "Epoch 41/50\n",
      "1382/1382 [==============================] - 0s 151us/step - loss: 0.2684 - accuracy: 0.9682 - val_loss: 1.2826 - val_accuracy: 0.7139\n",
      "Epoch 42/50\n",
      "1382/1382 [==============================] - 0s 153us/step - loss: 0.1747 - accuracy: 0.9848 - val_loss: 1.4160 - val_accuracy: 0.7225\n",
      "Epoch 43/50\n",
      "1382/1382 [==============================] - 0s 153us/step - loss: 0.1139 - accuracy: 0.9971 - val_loss: 1.5839 - val_accuracy: 0.7139\n",
      "Epoch 44/50\n",
      "1382/1382 [==============================] - 0s 153us/step - loss: 0.1108 - accuracy: 0.9906 - val_loss: 1.5252 - val_accuracy: 0.7312\n",
      "Epoch 45/50\n",
      "1382/1382 [==============================] - 0s 152us/step - loss: 0.0821 - accuracy: 0.9978 - val_loss: 1.6732 - val_accuracy: 0.7370\n",
      "Epoch 46/50\n",
      "1382/1382 [==============================] - 0s 154us/step - loss: 0.0678 - accuracy: 0.9971 - val_loss: 1.8930 - val_accuracy: 0.7399\n",
      "Epoch 47/50\n",
      "1382/1382 [==============================] - 0s 154us/step - loss: 0.0548 - accuracy: 0.9993 - val_loss: 2.1156 - val_accuracy: 0.7139\n",
      "Epoch 48/50\n",
      "1382/1382 [==============================] - 0s 151us/step - loss: 0.0506 - accuracy: 1.0000 - val_loss: 2.1122 - val_accuracy: 0.7197\n",
      "Epoch 49/50\n",
      "1382/1382 [==============================] - 0s 151us/step - loss: 0.0456 - accuracy: 1.0000 - val_loss: 2.1209 - val_accuracy: 0.7168\n",
      "Epoch 50/50\n",
      "1382/1382 [==============================] - 0s 154us/step - loss: 0.0412 - accuracy: 1.0000 - val_loss: 2.1391 - val_accuracy: 0.7225\n",
      "346/346 [==============================] - 0s 52us/step\n",
      "Accuracy: 72.25\n",
      "346/346 [==============================] - 0s 72us/step\n",
      "346/346 [==============================] - 0s 49us/step\n",
      " \n",
      "Accuracy: 75.35\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 468x468 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "keep_accuracy = np.zeros((10))\n",
    "j = 0\n",
    "\n",
    "for participant in files:\n",
    "    mat = loadmat(participant)\n",
    "    X = np.array(mat[\"X_2D\"])\n",
    "    y = np.array(mat[\"exemplarLabels\"]).ravel()    # get labels\n",
    "\n",
    "    y_bin =[]\n",
    "    X_bin = []\n",
    "    \n",
    "    for i in range(0,len(X)):                   # keep only the hf and the io category\n",
    "        if (12 < y[i] < 25):\n",
    "            y_bin.append(0)                     # set class hf as 0\n",
    "            X_bin.append(X[i])\n",
    "        elif (60 < y[i]):                       # set class io as 1\n",
    "            y_bin.append(1)\n",
    "            X_bin.append(X[i])\n",
    "\n",
    "    X_bin = np.array(X_bin)\n",
    "    y_bin = np.array(y_bin).ravel()\n",
    "\n",
    "    [u,s,v] = la.svd(X_bin)                      # pca with svd using an optimum k\n",
    "    v = v.transpose() \n",
    "    v_new = v[:,:180]\n",
    "    X_bin = np.dot(X_bin, v_new)\n",
    "\n",
    "    X_training = X_bin[:int(0.8*len(X_bin))]     # create train and test sets\n",
    "    X_validation = X_bin[int(0.8*len(X_bin)):]\n",
    "\n",
    "    y_training = y_bin[:int(0.8*len(X_bin))]\n",
    "    y_validation =y_bin[int(0.8*len(X_bin)):]\n",
    "\n",
    "    num_classes = 2                              # we have only 2 classes, hf and io\n",
    "\n",
    "    # dfnn model\n",
    "    model = Sequential()                       \n",
    "    model.add(Dense(160, input_dim=180, activation='relu'))\n",
    "    model.add(Dense(140, activation='tanh',activity_regularizer=regularizers.l1(1e-3))) \n",
    "    model.add(Dense(120, activation='tanh',kernel_regularizer=regularizers.l2(1e-5)))\n",
    "    model.add(Dense(64, input_dim=8, activation='tanh'))\n",
    "    model.add(Dense(32, activation='relu',activity_regularizer=regularizers.l2(1e-7)))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='nadam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_training, y_training,                                 # train the model\n",
    "              epochs=50, \n",
    "              validation_data=(X_validation, y_validation), \n",
    "              shuffle=True)\n",
    "\n",
    "    _, accuracy = model.evaluate(X_validation, y_validation)\n",
    "    print('Accuracy: %.2f' % (accuracy*100))\n",
    "\n",
    "    y_validation_predictions = np.round(model.predict(X_validation, verbose=1))  # make predictions\n",
    "\n",
    "    # create the confusion matrix\n",
    "    cnf_matrix4 = confusion_matrix(y_validation, y_validation_predictions)\n",
    "    cm_cv4 += cnf_matrix4                                           # add together all the confusion matrices\n",
    "    \n",
    "    _, accuracy = model.evaluate(X_validation, y_validation)        # find accuracy\n",
    "    keep_accuracy[j] = accuracy\n",
    "    j = j + 1\n",
    "    print(\" \")\n",
    "    \n",
    "print('Accuracy: %.2f' % (np.mean(keep_accuracy)*100))              # print mean accuracy\n",
    "\n",
    "sum_by_row = np.sum(cm_cv4, 1)                                      # normalize the final confusion matrix\n",
    "for i in range(0,2):\n",
    "    cm_cv4[i,:] = cm_cv4[i,:] / sum_by_row[i]\n",
    "    \n",
    "plot_cm(np.round(cm_cv4, 4),2)                                      # plot the final confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.74971031, 0.25028969],\n",
       "       [0.24279123, 0.75720877]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_cv4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple CNN, 2 classes\n",
    "\n",
    "Εφαρμόζουμε το απλό cnn στις δύο κλάσεις, human face και inanimate object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1382 samples, validate on 346 samples\n",
      "Epoch 1/50\n",
      "1382/1382 [==============================] - 1s 1ms/step - loss: 1.3689 - accuracy: 0.5145 - val_loss: 0.9608 - val_accuracy: 0.5087\n",
      "Epoch 2/50\n",
      "1382/1382 [==============================] - 1s 558us/step - loss: 1.0004 - accuracy: 0.5043 - val_loss: 0.9497 - val_accuracy: 0.5087\n",
      "Epoch 3/50\n",
      "1382/1382 [==============================] - 1s 563us/step - loss: 0.9451 - accuracy: 0.5065 - val_loss: 0.8667 - val_accuracy: 0.5087\n",
      "Epoch 4/50\n",
      "1382/1382 [==============================] - 1s 560us/step - loss: 0.8503 - accuracy: 0.5586 - val_loss: 0.8814 - val_accuracy: 0.4913\n",
      "Epoch 5/50\n",
      "1382/1382 [==============================] - 1s 561us/step - loss: 0.8129 - accuracy: 0.6816 - val_loss: 0.8161 - val_accuracy: 0.5578\n",
      "Epoch 6/50\n",
      "1382/1382 [==============================] - 1s 563us/step - loss: 0.7619 - accuracy: 0.7359 - val_loss: 0.7662 - val_accuracy: 0.6965\n",
      "Epoch 7/50\n",
      "1382/1382 [==============================] - 1s 566us/step - loss: 0.7435 - accuracy: 0.7554 - val_loss: 0.7480 - val_accuracy: 0.7746\n",
      "Epoch 8/50\n",
      "1382/1382 [==============================] - 1s 562us/step - loss: 0.6996 - accuracy: 0.8061 - val_loss: 0.7038 - val_accuracy: 0.8006\n",
      "Epoch 9/50\n",
      "1382/1382 [==============================] - 1s 563us/step - loss: 0.6890 - accuracy: 0.8090 - val_loss: 0.7689 - val_accuracy: 0.6561\n",
      "Epoch 10/50\n",
      "1382/1382 [==============================] - 1s 563us/step - loss: 0.6664 - accuracy: 0.8437 - val_loss: 0.7843 - val_accuracy: 0.6965\n",
      "Epoch 11/50\n",
      "1382/1382 [==============================] - 1s 562us/step - loss: 0.6528 - accuracy: 0.8560 - val_loss: 0.8264 - val_accuracy: 0.7081\n",
      "Epoch 12/50\n",
      "1382/1382 [==============================] - 1s 563us/step - loss: 0.6220 - accuracy: 0.8531 - val_loss: 0.8738 - val_accuracy: 0.7081\n",
      "Epoch 13/50\n",
      "1382/1382 [==============================] - 1s 561us/step - loss: 0.6091 - accuracy: 0.8683 - val_loss: 0.8274 - val_accuracy: 0.7803\n",
      "Epoch 14/50\n",
      "1382/1382 [==============================] - 1s 559us/step - loss: 0.6031 - accuracy: 0.8886 - val_loss: 0.7334 - val_accuracy: 0.7775\n",
      "Epoch 15/50\n",
      "1382/1382 [==============================] - 1s 561us/step - loss: 0.5579 - accuracy: 0.8871 - val_loss: 1.3680 - val_accuracy: 0.5694\n",
      "Epoch 16/50\n",
      "1382/1382 [==============================] - 1s 561us/step - loss: 0.5359 - accuracy: 0.8849 - val_loss: 0.7533 - val_accuracy: 0.7948\n",
      "Epoch 17/50\n",
      "1382/1382 [==============================] - 1s 560us/step - loss: 0.4846 - accuracy: 0.9081 - val_loss: 0.8599 - val_accuracy: 0.6821\n",
      "Epoch 18/50\n",
      "1382/1382 [==============================] - 1s 561us/step - loss: 0.4870 - accuracy: 0.9081 - val_loss: 0.6959 - val_accuracy: 0.7717\n",
      "Epoch 19/50\n",
      "1382/1382 [==============================] - 1s 559us/step - loss: 0.4668 - accuracy: 0.9052 - val_loss: 0.7323 - val_accuracy: 0.7832\n",
      "Epoch 20/50\n",
      "1382/1382 [==============================] - 1s 562us/step - loss: 0.4761 - accuracy: 0.9059 - val_loss: 0.6862 - val_accuracy: 0.7659\n",
      "Epoch 21/50\n",
      "1382/1382 [==============================] - 1s 560us/step - loss: 0.4692 - accuracy: 0.8987 - val_loss: 0.7244 - val_accuracy: 0.7746\n",
      "Epoch 22/50\n",
      "1382/1382 [==============================] - 1s 558us/step - loss: 0.4406 - accuracy: 0.9081 - val_loss: 0.7723 - val_accuracy: 0.7659\n",
      "Epoch 23/50\n",
      "1382/1382 [==============================] - 1s 558us/step - loss: 0.4240 - accuracy: 0.9110 - val_loss: 0.6308 - val_accuracy: 0.8006\n",
      "Epoch 24/50\n",
      "1382/1382 [==============================] - 1s 560us/step - loss: 0.3969 - accuracy: 0.9117 - val_loss: 0.6916 - val_accuracy: 0.7861\n",
      "Epoch 25/50\n",
      "1382/1382 [==============================] - 1s 558us/step - loss: 0.4082 - accuracy: 0.9081 - val_loss: 0.7804 - val_accuracy: 0.7283\n",
      "Epoch 26/50\n",
      "1382/1382 [==============================] - 1s 563us/step - loss: 0.4332 - accuracy: 0.8973 - val_loss: 0.6587 - val_accuracy: 0.7977\n",
      "Epoch 27/50\n",
      "1382/1382 [==============================] - 1s 561us/step - loss: 0.3939 - accuracy: 0.9088 - val_loss: 0.6559 - val_accuracy: 0.8064\n",
      "Epoch 28/50\n",
      "1382/1382 [==============================] - 1s 559us/step - loss: 0.4046 - accuracy: 0.8951 - val_loss: 0.6156 - val_accuracy: 0.7977\n",
      "Epoch 29/50\n",
      "1382/1382 [==============================] - 1s 562us/step - loss: 0.3759 - accuracy: 0.9161 - val_loss: 0.7209 - val_accuracy: 0.7688\n",
      "Epoch 30/50\n",
      "1382/1382 [==============================] - 1s 565us/step - loss: 0.3918 - accuracy: 0.9124 - val_loss: 0.6581 - val_accuracy: 0.8092\n",
      "Epoch 31/50\n",
      "1382/1382 [==============================] - 1s 563us/step - loss: 0.3900 - accuracy: 0.9110 - val_loss: 0.7207 - val_accuracy: 0.7717\n",
      "Epoch 32/50\n",
      "1382/1382 [==============================] - 1s 562us/step - loss: 0.3701 - accuracy: 0.9059 - val_loss: 0.6472 - val_accuracy: 0.8092\n",
      "Epoch 33/50\n",
      "1382/1382 [==============================] - 1s 581us/step - loss: 0.3310 - accuracy: 0.9146 - val_loss: 0.6204 - val_accuracy: 0.7919\n",
      "Epoch 34/50\n",
      "1382/1382 [==============================] - 1s 555us/step - loss: 0.3380 - accuracy: 0.9146 - val_loss: 0.7196 - val_accuracy: 0.7630\n",
      "Epoch 35/50\n",
      "1382/1382 [==============================] - 1s 547us/step - loss: 0.3425 - accuracy: 0.9088 - val_loss: 0.6489 - val_accuracy: 0.8064\n",
      "Epoch 36/50\n",
      "1382/1382 [==============================] - 1s 566us/step - loss: 0.3608 - accuracy: 0.9132 - val_loss: 0.6938 - val_accuracy: 0.8006\n",
      "Epoch 37/50\n",
      "1382/1382 [==============================] - 1s 548us/step - loss: 0.3512 - accuracy: 0.9197 - val_loss: 0.6481 - val_accuracy: 0.8150\n",
      "Epoch 38/50\n",
      "1382/1382 [==============================] - 1s 548us/step - loss: 0.3514 - accuracy: 0.9240 - val_loss: 0.6553 - val_accuracy: 0.7919\n",
      "Epoch 39/50\n",
      "1382/1382 [==============================] - 1s 548us/step - loss: 0.3590 - accuracy: 0.9117 - val_loss: 0.6289 - val_accuracy: 0.8092\n",
      "Epoch 40/50\n",
      "1382/1382 [==============================] - 1s 546us/step - loss: 0.3147 - accuracy: 0.9139 - val_loss: 0.6426 - val_accuracy: 0.7890\n",
      "Epoch 41/50\n",
      "1382/1382 [==============================] - 1s 545us/step - loss: 0.3400 - accuracy: 0.9038 - val_loss: 0.6346 - val_accuracy: 0.8208\n",
      "Epoch 42/50\n",
      "1382/1382 [==============================] - 1s 546us/step - loss: 0.3421 - accuracy: 0.9175 - val_loss: 0.6959 - val_accuracy: 0.7717\n",
      "Epoch 43/50\n",
      "1382/1382 [==============================] - 1s 560us/step - loss: 0.3404 - accuracy: 0.9110 - val_loss: 0.7424 - val_accuracy: 0.8035\n",
      "Epoch 44/50\n",
      "1382/1382 [==============================] - 1s 558us/step - loss: 0.3730 - accuracy: 0.9124 - val_loss: 0.6461 - val_accuracy: 0.8064\n",
      "Epoch 45/50\n",
      "1382/1382 [==============================] - 1s 562us/step - loss: 0.3367 - accuracy: 0.9219 - val_loss: 0.6377 - val_accuracy: 0.8006\n",
      "Epoch 46/50\n",
      "1382/1382 [==============================] - 1s 563us/step - loss: 0.3307 - accuracy: 0.9146 - val_loss: 0.7814 - val_accuracy: 0.7341\n",
      "Epoch 47/50\n",
      "1382/1382 [==============================] - 1s 565us/step - loss: 0.3115 - accuracy: 0.9168 - val_loss: 0.6374 - val_accuracy: 0.7890\n",
      "Epoch 48/50\n",
      "1382/1382 [==============================] - 1s 563us/step - loss: 0.3237 - accuracy: 0.9132 - val_loss: 0.6125 - val_accuracy: 0.8150\n",
      "Epoch 49/50\n",
      "1382/1382 [==============================] - 1s 560us/step - loss: 0.3067 - accuracy: 0.9103 - val_loss: 0.6657 - val_accuracy: 0.7948\n",
      "Epoch 50/50\n",
      "1382/1382 [==============================] - 1s 563us/step - loss: 0.3027 - accuracy: 0.9161 - val_loss: 0.6008 - val_accuracy: 0.7977\n",
      "346/346 [==============================] - 0s 156us/step\n",
      "346/346 [==============================] - 0s 127us/step\n",
      " \n",
      "Train on 1382 samples, validate on 346 samples\n",
      "Epoch 1/50\n",
      "1382/1382 [==============================] - 1s 1ms/step - loss: 1.2946 - accuracy: 0.4841 - val_loss: 0.9202 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "1382/1382 [==============================] - 1s 569us/step - loss: 0.9205 - accuracy: 0.4913 - val_loss: 0.9517 - val_accuracy: 0.5000\n",
      "Epoch 3/50\n",
      "1382/1382 [==============================] - 1s 569us/step - loss: 0.8412 - accuracy: 0.4906 - val_loss: 0.7882 - val_accuracy: 0.5000\n",
      "Epoch 4/50\n",
      "1382/1382 [==============================] - 1s 566us/step - loss: 0.7713 - accuracy: 0.5007 - val_loss: 0.7670 - val_accuracy: 0.5000\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1382/1382 [==============================] - 1s 561us/step - loss: 0.7523 - accuracy: 0.5022 - val_loss: 1.0490 - val_accuracy: 0.5000\n",
      "Epoch 6/50\n",
      "1382/1382 [==============================] - 1s 558us/step - loss: 0.7744 - accuracy: 0.5702 - val_loss: 0.7612 - val_accuracy: 0.6301\n",
      "Epoch 7/50\n",
      "1382/1382 [==============================] - 1s 561us/step - loss: 0.7562 - accuracy: 0.6961 - val_loss: 0.7486 - val_accuracy: 0.7254\n",
      "Epoch 8/50\n",
      "1382/1382 [==============================] - 1s 563us/step - loss: 0.7142 - accuracy: 0.7851 - val_loss: 0.8480 - val_accuracy: 0.5607\n",
      "Epoch 9/50\n",
      "1382/1382 [==============================] - 1s 561us/step - loss: 0.7026 - accuracy: 0.8119 - val_loss: 0.7708 - val_accuracy: 0.7370\n",
      "Epoch 10/50\n",
      "1382/1382 [==============================] - 1s 559us/step - loss: 0.6519 - accuracy: 0.8596 - val_loss: 0.7367 - val_accuracy: 0.7919\n",
      "Epoch 11/50\n",
      "1382/1382 [==============================] - 1s 555us/step - loss: 0.6036 - accuracy: 0.8958 - val_loss: 0.7749 - val_accuracy: 0.7428\n",
      "Epoch 12/50\n",
      "1382/1382 [==============================] - 1s 558us/step - loss: 0.5539 - accuracy: 0.9233 - val_loss: 0.8552 - val_accuracy: 0.6618\n",
      "Epoch 13/50\n",
      "1382/1382 [==============================] - 1s 558us/step - loss: 0.5313 - accuracy: 0.9349 - val_loss: 0.6760 - val_accuracy: 0.8006\n",
      "Epoch 14/50\n",
      "1382/1382 [==============================] - 1s 559us/step - loss: 0.5070 - accuracy: 0.9276 - val_loss: 0.6584 - val_accuracy: 0.8035\n",
      "Epoch 15/50\n",
      "1382/1382 [==============================] - 1s 559us/step - loss: 0.4547 - accuracy: 0.9588 - val_loss: 0.6464 - val_accuracy: 0.8179\n",
      "Epoch 16/50\n",
      "1382/1382 [==============================] - 1s 558us/step - loss: 0.4222 - accuracy: 0.9725 - val_loss: 0.6753 - val_accuracy: 0.7948\n",
      "Epoch 17/50\n",
      "1382/1382 [==============================] - 1s 558us/step - loss: 0.4001 - accuracy: 0.9725 - val_loss: 0.6632 - val_accuracy: 0.8092\n",
      "Epoch 18/50\n",
      "1382/1382 [==============================] - 1s 554us/step - loss: 0.4275 - accuracy: 0.9609 - val_loss: 0.6102 - val_accuracy: 0.8353\n",
      "Epoch 19/50\n",
      "1382/1382 [==============================] - 1s 557us/step - loss: 0.3812 - accuracy: 0.9732 - val_loss: 0.6083 - val_accuracy: 0.8064\n",
      "Epoch 20/50\n",
      "1382/1382 [==============================] - 1s 557us/step - loss: 0.4017 - accuracy: 0.9725 - val_loss: 0.6489 - val_accuracy: 0.8064\n",
      "Epoch 21/50\n",
      "1382/1382 [==============================] - 1s 557us/step - loss: 0.3635 - accuracy: 0.9783 - val_loss: 0.6671 - val_accuracy: 0.8035\n",
      "Epoch 22/50\n",
      "1382/1382 [==============================] - 1s 557us/step - loss: 0.4072 - accuracy: 0.9486 - val_loss: 0.6700 - val_accuracy: 0.7919\n",
      "Epoch 23/50\n",
      "1382/1382 [==============================] - 1s 555us/step - loss: 0.3608 - accuracy: 0.9732 - val_loss: 0.6098 - val_accuracy: 0.8324\n",
      "Epoch 24/50\n",
      "1382/1382 [==============================] - 1s 557us/step - loss: 0.3493 - accuracy: 0.9747 - val_loss: 0.5952 - val_accuracy: 0.8266\n",
      "Epoch 25/50\n",
      "1382/1382 [==============================] - 1s 555us/step - loss: 0.3080 - accuracy: 0.9812 - val_loss: 0.5636 - val_accuracy: 0.8092\n",
      "Epoch 26/50\n",
      "1382/1382 [==============================] - 1s 557us/step - loss: 0.3010 - accuracy: 0.9877 - val_loss: 0.6115 - val_accuracy: 0.8410\n",
      "Epoch 27/50\n",
      "1382/1382 [==============================] - 1s 555us/step - loss: 0.2985 - accuracy: 0.9819 - val_loss: 0.6021 - val_accuracy: 0.8092\n",
      "Epoch 28/50\n",
      "1382/1382 [==============================] - 1s 559us/step - loss: 0.3161 - accuracy: 0.9711 - val_loss: 0.5985 - val_accuracy: 0.8150\n",
      "Epoch 29/50\n",
      "1382/1382 [==============================] - 1s 560us/step - loss: 0.3416 - accuracy: 0.9674 - val_loss: 0.6116 - val_accuracy: 0.8179\n",
      "Epoch 30/50\n",
      "1382/1382 [==============================] - 1s 558us/step - loss: 0.2999 - accuracy: 0.9805 - val_loss: 0.6102 - val_accuracy: 0.8237\n",
      "Epoch 31/50\n",
      "1382/1382 [==============================] - 1s 556us/step - loss: 0.2680 - accuracy: 0.9848 - val_loss: 0.5634 - val_accuracy: 0.8295\n",
      "Epoch 32/50\n",
      "1382/1382 [==============================] - 1s 561us/step - loss: 0.2669 - accuracy: 0.9834 - val_loss: 0.5804 - val_accuracy: 0.8179\n",
      "Epoch 33/50\n",
      "1382/1382 [==============================] - 1s 562us/step - loss: 0.2637 - accuracy: 0.9826 - val_loss: 0.8164 - val_accuracy: 0.7312\n",
      "Epoch 34/50\n",
      "1382/1382 [==============================] - 1s 563us/step - loss: 0.2671 - accuracy: 0.9812 - val_loss: 0.6528 - val_accuracy: 0.8006\n",
      "Epoch 35/50\n",
      "1382/1382 [==============================] - 1s 563us/step - loss: 0.2626 - accuracy: 0.9848 - val_loss: 0.6558 - val_accuracy: 0.7803\n",
      "Epoch 36/50\n",
      "1382/1382 [==============================] - 1s 562us/step - loss: 0.2548 - accuracy: 0.9848 - val_loss: 0.5617 - val_accuracy: 0.8179\n",
      "Epoch 37/50\n",
      "1382/1382 [==============================] - 1s 559us/step - loss: 0.2621 - accuracy: 0.9747 - val_loss: 0.5849 - val_accuracy: 0.7890\n",
      "Epoch 38/50\n",
      "1382/1382 [==============================] - 1s 563us/step - loss: 0.2748 - accuracy: 0.9768 - val_loss: 0.8154 - val_accuracy: 0.7572\n",
      "Epoch 39/50\n",
      "1382/1382 [==============================] - 1s 561us/step - loss: 0.2598 - accuracy: 0.9870 - val_loss: 0.5438 - val_accuracy: 0.8295\n",
      "Epoch 40/50\n",
      "1382/1382 [==============================] - 1s 560us/step - loss: 0.2267 - accuracy: 0.9884 - val_loss: 0.6159 - val_accuracy: 0.7688\n",
      "Epoch 41/50\n",
      "1382/1382 [==============================] - 1s 558us/step - loss: 0.2341 - accuracy: 0.9819 - val_loss: 0.5232 - val_accuracy: 0.8324\n",
      "Epoch 42/50\n",
      "1382/1382 [==============================] - 1s 574us/step - loss: 0.2321 - accuracy: 0.9805 - val_loss: 0.7745 - val_accuracy: 0.7370\n",
      "Epoch 43/50\n",
      "1382/1382 [==============================] - 1s 574us/step - loss: 0.2634 - accuracy: 0.9732 - val_loss: 0.7692 - val_accuracy: 0.7399\n",
      "Epoch 44/50\n",
      "1382/1382 [==============================] - 1s 553us/step - loss: 0.2509 - accuracy: 0.9790 - val_loss: 0.6088 - val_accuracy: 0.8150\n",
      "Epoch 45/50\n",
      "1382/1382 [==============================] - 1s 561us/step - loss: 0.2185 - accuracy: 0.9877 - val_loss: 0.5418 - val_accuracy: 0.8353\n",
      "Epoch 46/50\n",
      "1382/1382 [==============================] - 1s 555us/step - loss: 0.2187 - accuracy: 0.9899 - val_loss: 0.6091 - val_accuracy: 0.8150\n",
      "Epoch 47/50\n",
      "1382/1382 [==============================] - 1s 559us/step - loss: 0.2186 - accuracy: 0.9870 - val_loss: 0.5695 - val_accuracy: 0.8150\n",
      "Epoch 48/50\n",
      "1382/1382 [==============================] - 1s 563us/step - loss: 0.2154 - accuracy: 0.9841 - val_loss: 0.5155 - val_accuracy: 0.8208\n",
      "Epoch 49/50\n",
      "1382/1382 [==============================] - 1s 558us/step - loss: 0.2115 - accuracy: 0.9877 - val_loss: 0.5367 - val_accuracy: 0.8353\n",
      "Epoch 50/50\n",
      "1382/1382 [==============================] - 1s 556us/step - loss: 0.2061 - accuracy: 0.9848 - val_loss: 0.5449 - val_accuracy: 0.8121\n",
      "346/346 [==============================] - 0s 153us/step\n",
      "346/346 [==============================] - 0s 130us/step\n",
      " \n",
      "Train on 1383 samples, validate on 346 samples\n",
      "Epoch 1/50\n",
      "1383/1383 [==============================] - 1s 1ms/step - loss: 1.1665 - accuracy: 0.5763 - val_loss: 1.0234 - val_accuracy: 0.5145\n",
      "Epoch 2/50\n",
      "1383/1383 [==============================] - 1s 557us/step - loss: 0.9541 - accuracy: 0.5228 - val_loss: 0.8655 - val_accuracy: 0.4971\n",
      "Epoch 3/50\n",
      "1383/1383 [==============================] - 1s 559us/step - loss: 0.8487 - accuracy: 0.5944 - val_loss: 0.8103 - val_accuracy: 0.7630\n",
      "Epoch 4/50\n",
      "1383/1383 [==============================] - 1s 560us/step - loss: 0.7940 - accuracy: 0.7469 - val_loss: 0.8876 - val_accuracy: 0.5549\n",
      "Epoch 5/50\n",
      "1383/1383 [==============================] - 1s 557us/step - loss: 0.7602 - accuracy: 0.7657 - val_loss: 0.7521 - val_accuracy: 0.7630\n",
      "Epoch 6/50\n",
      "1383/1383 [==============================] - 1s 557us/step - loss: 0.7175 - accuracy: 0.8185 - val_loss: 0.7913 - val_accuracy: 0.7081\n",
      "Epoch 7/50\n",
      "1383/1383 [==============================] - 1s 557us/step - loss: 0.6944 - accuracy: 0.8467 - val_loss: 0.7859 - val_accuracy: 0.7081\n",
      "Epoch 8/50\n",
      "1383/1383 [==============================] - 1s 555us/step - loss: 0.7277 - accuracy: 0.8294 - val_loss: 0.7869 - val_accuracy: 0.7370\n",
      "Epoch 9/50\n",
      "1383/1383 [==============================] - 1s 557us/step - loss: 0.6634 - accuracy: 0.8633 - val_loss: 0.7065 - val_accuracy: 0.8179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50\n",
      "1383/1383 [==============================] - 1s 557us/step - loss: 0.6506 - accuracy: 0.8915 - val_loss: 0.8397 - val_accuracy: 0.7254\n",
      "Epoch 11/50\n",
      "1383/1383 [==============================] - 1s 561us/step - loss: 0.6357 - accuracy: 0.8937 - val_loss: 0.8225 - val_accuracy: 0.7919\n",
      "Epoch 12/50\n",
      "1383/1383 [==============================] - 1s 561us/step - loss: 0.6831 - accuracy: 0.8952 - val_loss: 0.8731 - val_accuracy: 0.7341\n",
      "Epoch 13/50\n",
      "1383/1383 [==============================] - 1s 561us/step - loss: 0.6387 - accuracy: 0.8792 - val_loss: 0.9634 - val_accuracy: 0.6792\n",
      "Epoch 14/50\n",
      "1383/1383 [==============================] - 1s 560us/step - loss: 0.5786 - accuracy: 0.8901 - val_loss: 0.7081 - val_accuracy: 0.7688\n",
      "Epoch 15/50\n",
      "1383/1383 [==============================] - 1s 558us/step - loss: 0.5570 - accuracy: 0.9060 - val_loss: 0.6649 - val_accuracy: 0.8121\n",
      "Epoch 16/50\n",
      "1383/1383 [==============================] - 1s 559us/step - loss: 0.5495 - accuracy: 0.9096 - val_loss: 0.6497 - val_accuracy: 0.8324\n",
      "Epoch 17/50\n",
      "1383/1383 [==============================] - 1s 559us/step - loss: 0.5884 - accuracy: 0.9060 - val_loss: 0.8366 - val_accuracy: 0.7110\n",
      "Epoch 18/50\n",
      "1383/1383 [==============================] - 1s 562us/step - loss: 0.5589 - accuracy: 0.9089 - val_loss: 0.9823 - val_accuracy: 0.6936\n",
      "Epoch 19/50\n",
      "1383/1383 [==============================] - 1s 558us/step - loss: 0.5539 - accuracy: 0.8923 - val_loss: 0.6449 - val_accuracy: 0.8006\n",
      "Epoch 20/50\n",
      "1383/1383 [==============================] - 1s 559us/step - loss: 0.5862 - accuracy: 0.8988 - val_loss: 1.0288 - val_accuracy: 0.6503\n",
      "Epoch 21/50\n",
      "1383/1383 [==============================] - 1s 560us/step - loss: 0.5315 - accuracy: 0.8988 - val_loss: 0.6632 - val_accuracy: 0.8208\n",
      "Epoch 22/50\n",
      "1383/1383 [==============================] - 1s 553us/step - loss: 0.4995 - accuracy: 0.9234 - val_loss: 0.6840 - val_accuracy: 0.7861\n",
      "Epoch 23/50\n",
      "1383/1383 [==============================] - 1s 553us/step - loss: 0.4890 - accuracy: 0.9089 - val_loss: 0.6381 - val_accuracy: 0.8439\n",
      "Epoch 24/50\n",
      "1383/1383 [==============================] - 1s 597us/step - loss: 0.4961 - accuracy: 0.9176 - val_loss: 0.8532 - val_accuracy: 0.7543\n",
      "Epoch 25/50\n",
      "1383/1383 [==============================] - 1s 558us/step - loss: 0.4856 - accuracy: 0.9103 - val_loss: 0.6376 - val_accuracy: 0.8035\n",
      "Epoch 26/50\n",
      "1383/1383 [==============================] - 1s 553us/step - loss: 0.4859 - accuracy: 0.9089 - val_loss: 0.6513 - val_accuracy: 0.8006\n",
      "Epoch 27/50\n",
      "1383/1383 [==============================] - 1s 551us/step - loss: 0.4956 - accuracy: 0.9190 - val_loss: 0.8020 - val_accuracy: 0.8295\n",
      "Epoch 28/50\n",
      "1383/1383 [==============================] - 1s 554us/step - loss: 0.4705 - accuracy: 0.9197 - val_loss: 0.8757 - val_accuracy: 0.7254\n",
      "Epoch 29/50\n",
      "1383/1383 [==============================] - 1s 561us/step - loss: 0.4756 - accuracy: 0.9111 - val_loss: 0.6774 - val_accuracy: 0.8006\n",
      "Epoch 30/50\n",
      "1383/1383 [==============================] - 1s 591us/step - loss: 0.5298 - accuracy: 0.8980 - val_loss: 0.7425 - val_accuracy: 0.7775\n",
      "Epoch 31/50\n",
      "1383/1383 [==============================] - 1s 573us/step - loss: 0.4814 - accuracy: 0.9197 - val_loss: 0.9333 - val_accuracy: 0.7746\n",
      "Epoch 32/50\n",
      "1383/1383 [==============================] - 1s 565us/step - loss: 0.4907 - accuracy: 0.9132 - val_loss: 0.6114 - val_accuracy: 0.8208\n",
      "Epoch 33/50\n",
      "1383/1383 [==============================] - 1s 565us/step - loss: 0.4939 - accuracy: 0.9118 - val_loss: 0.7070 - val_accuracy: 0.8006\n",
      "Epoch 34/50\n",
      "1383/1383 [==============================] - 1s 583us/step - loss: 0.5441 - accuracy: 0.9096 - val_loss: 0.7226 - val_accuracy: 0.8237\n",
      "Epoch 35/50\n",
      "1383/1383 [==============================] - 1s 558us/step - loss: 0.4858 - accuracy: 0.9277 - val_loss: 0.6867 - val_accuracy: 0.8006\n",
      "Epoch 36/50\n",
      "1383/1383 [==============================] - 1s 550us/step - loss: 0.4700 - accuracy: 0.9147 - val_loss: 0.6188 - val_accuracy: 0.7948\n",
      "Epoch 37/50\n",
      "1383/1383 [==============================] - 1s 561us/step - loss: 0.4559 - accuracy: 0.9103 - val_loss: 0.6392 - val_accuracy: 0.8237\n",
      "Epoch 38/50\n",
      "1383/1383 [==============================] - 1s 558us/step - loss: 0.4443 - accuracy: 0.9255 - val_loss: 0.6042 - val_accuracy: 0.8266\n",
      "Epoch 39/50\n",
      "1383/1383 [==============================] - 1s 562us/step - loss: 0.4993 - accuracy: 0.9067 - val_loss: 0.7441 - val_accuracy: 0.7659\n",
      "Epoch 40/50\n",
      "1383/1383 [==============================] - 1s 557us/step - loss: 0.9836 - accuracy: 0.6782 - val_loss: 0.7345 - val_accuracy: 0.8237\n",
      "Epoch 41/50\n",
      "1383/1383 [==============================] - 1s 560us/step - loss: 0.5376 - accuracy: 0.9060 - val_loss: 0.7539 - val_accuracy: 0.7803\n",
      "Epoch 42/50\n",
      "1383/1383 [==============================] - 1s 559us/step - loss: 0.4884 - accuracy: 0.9132 - val_loss: 0.6730 - val_accuracy: 0.8092\n",
      "Epoch 43/50\n",
      "1383/1383 [==============================] - 1s 561us/step - loss: 0.4739 - accuracy: 0.9190 - val_loss: 0.6355 - val_accuracy: 0.8150\n",
      "Epoch 44/50\n",
      "1383/1383 [==============================] - 1s 557us/step - loss: 0.4653 - accuracy: 0.9212 - val_loss: 0.7956 - val_accuracy: 0.7601\n",
      "Epoch 45/50\n",
      "1383/1383 [==============================] - 1s 558us/step - loss: 0.4405 - accuracy: 0.9212 - val_loss: 0.6416 - val_accuracy: 0.8266\n",
      "Epoch 46/50\n",
      "1383/1383 [==============================] - 1s 560us/step - loss: 0.4103 - accuracy: 0.9277 - val_loss: 0.6143 - val_accuracy: 0.8208\n",
      "Epoch 47/50\n",
      "1383/1383 [==============================] - 1s 556us/step - loss: 0.4088 - accuracy: 0.9306 - val_loss: 0.6170 - val_accuracy: 0.8179\n",
      "Epoch 48/50\n",
      "1383/1383 [==============================] - 1s 558us/step - loss: 0.4238 - accuracy: 0.9226 - val_loss: 0.7085 - val_accuracy: 0.7948\n",
      "Epoch 49/50\n",
      "1383/1383 [==============================] - 1s 556us/step - loss: 0.3913 - accuracy: 0.9328 - val_loss: 0.6081 - val_accuracy: 0.8092\n",
      "Epoch 50/50\n",
      "1383/1383 [==============================] - 1s 557us/step - loss: 0.3672 - accuracy: 0.9508 - val_loss: 0.6739 - val_accuracy: 0.8266\n",
      "346/346 [==============================] - 0s 156us/step\n",
      "346/346 [==============================] - 0s 127us/step\n",
      " \n",
      "Train on 1382 samples, validate on 346 samples\n",
      "Epoch 1/50\n",
      "1382/1382 [==============================] - 1s 995us/step - loss: 1.2569 - accuracy: 0.5145 - val_loss: 1.0887 - val_accuracy: 0.5058\n",
      "Epoch 2/50\n",
      "1382/1382 [==============================] - 1s 561us/step - loss: 0.9404 - accuracy: 0.5420 - val_loss: 0.8893 - val_accuracy: 0.5723\n",
      "Epoch 3/50\n",
      "1382/1382 [==============================] - 1s 563us/step - loss: 0.8633 - accuracy: 0.5159 - val_loss: 0.7990 - val_accuracy: 0.4971\n",
      "Epoch 4/50\n",
      "1382/1382 [==============================] - 1s 561us/step - loss: 0.8415 - accuracy: 0.5507 - val_loss: 0.8425 - val_accuracy: 0.5145\n",
      "Epoch 5/50\n",
      "1382/1382 [==============================] - 1s 576us/step - loss: 0.8956 - accuracy: 0.6302 - val_loss: 0.8392 - val_accuracy: 0.5549\n",
      "Epoch 6/50\n",
      "1382/1382 [==============================] - 1s 558us/step - loss: 0.8118 - accuracy: 0.7373 - val_loss: 0.7974 - val_accuracy: 0.7630\n",
      "Epoch 7/50\n",
      "1382/1382 [==============================] - 1s 555us/step - loss: 0.7101 - accuracy: 0.8025 - val_loss: 0.7347 - val_accuracy: 0.7659\n",
      "Epoch 8/50\n",
      "1382/1382 [==============================] - 1s 558us/step - loss: 0.6465 - accuracy: 0.8459 - val_loss: 0.7391 - val_accuracy: 0.7601\n",
      "Epoch 9/50\n",
      "1382/1382 [==============================] - 1s 558us/step - loss: 0.6161 - accuracy: 0.8734 - val_loss: 0.7038 - val_accuracy: 0.7803\n",
      "Epoch 10/50\n",
      "1382/1382 [==============================] - 1s 561us/step - loss: 0.5608 - accuracy: 0.8922 - val_loss: 0.7114 - val_accuracy: 0.7977\n",
      "Epoch 11/50\n",
      "1382/1382 [==============================] - 1s 557us/step - loss: 0.5471 - accuracy: 0.9132 - val_loss: 0.7662 - val_accuracy: 0.7948\n",
      "Epoch 12/50\n",
      "1382/1382 [==============================] - 1s 559us/step - loss: 0.5082 - accuracy: 0.9240 - val_loss: 0.8510 - val_accuracy: 0.7919\n",
      "Epoch 13/50\n",
      "1382/1382 [==============================] - 1s 557us/step - loss: 0.4802 - accuracy: 0.9465 - val_loss: 0.6860 - val_accuracy: 0.8121\n",
      "Epoch 14/50\n",
      "1382/1382 [==============================] - 1s 559us/step - loss: 0.4411 - accuracy: 0.9522 - val_loss: 0.7144 - val_accuracy: 0.7948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50\n",
      "1382/1382 [==============================] - 1s 548us/step - loss: 0.4507 - accuracy: 0.9551 - val_loss: 0.7359 - val_accuracy: 0.7775\n",
      "Epoch 16/50\n",
      "1382/1382 [==============================] - 1s 554us/step - loss: 0.4702 - accuracy: 0.9486 - val_loss: 0.8309 - val_accuracy: 0.7486\n",
      "Epoch 17/50\n",
      "1382/1382 [==============================] - 1s 560us/step - loss: 0.4339 - accuracy: 0.9508 - val_loss: 0.6959 - val_accuracy: 0.7832\n",
      "Epoch 18/50\n",
      "1382/1382 [==============================] - 1s 569us/step - loss: 0.3868 - accuracy: 0.9689 - val_loss: 0.6317 - val_accuracy: 0.7919\n",
      "Epoch 19/50\n",
      "1382/1382 [==============================] - 1s 563us/step - loss: 0.3877 - accuracy: 0.9631 - val_loss: 0.6774 - val_accuracy: 0.8092\n",
      "Epoch 20/50\n",
      "1382/1382 [==============================] - 1s 559us/step - loss: 0.3841 - accuracy: 0.9573 - val_loss: 0.6881 - val_accuracy: 0.8035\n",
      "Epoch 21/50\n",
      "1382/1382 [==============================] - 1s 567us/step - loss: 0.4473 - accuracy: 0.9638 - val_loss: 0.7910 - val_accuracy: 0.8006\n",
      "Epoch 22/50\n",
      "1382/1382 [==============================] - 1s 566us/step - loss: 0.5778 - accuracy: 0.9269 - val_loss: 0.8241 - val_accuracy: 0.7775\n",
      "Epoch 23/50\n",
      "1382/1382 [==============================] - 1s 561us/step - loss: 0.4652 - accuracy: 0.9472 - val_loss: 0.8564 - val_accuracy: 0.8006\n",
      "Epoch 24/50\n",
      "1382/1382 [==============================] - 1s 562us/step - loss: 0.4401 - accuracy: 0.9703 - val_loss: 1.1010 - val_accuracy: 0.8208\n",
      "Epoch 25/50\n",
      "1382/1382 [==============================] - 1s 560us/step - loss: 0.6312 - accuracy: 0.9689 - val_loss: 0.7695 - val_accuracy: 0.8179\n",
      "Epoch 26/50\n",
      "1382/1382 [==============================] - 1s 560us/step - loss: 0.4323 - accuracy: 0.9609 - val_loss: 0.7457 - val_accuracy: 0.8121\n",
      "Epoch 27/50\n",
      "1382/1382 [==============================] - 1s 559us/step - loss: 0.5979 - accuracy: 0.9689 - val_loss: 1.0036 - val_accuracy: 0.7861\n",
      "Epoch 28/50\n",
      "1382/1382 [==============================] - 1s 558us/step - loss: 0.4211 - accuracy: 0.9689 - val_loss: 0.7321 - val_accuracy: 0.8092\n",
      "Epoch 29/50\n",
      "1382/1382 [==============================] - 1s 557us/step - loss: 0.3866 - accuracy: 0.9754 - val_loss: 0.6706 - val_accuracy: 0.8092\n",
      "Epoch 30/50\n",
      "1382/1382 [==============================] - 1s 559us/step - loss: 0.3545 - accuracy: 0.9761 - val_loss: 0.7269 - val_accuracy: 0.7919\n",
      "Epoch 31/50\n",
      "1382/1382 [==============================] - 1s 558us/step - loss: 0.3473 - accuracy: 0.9776 - val_loss: 0.8203 - val_accuracy: 0.7861\n",
      "Epoch 32/50\n",
      "1382/1382 [==============================] - 1s 563us/step - loss: 0.3113 - accuracy: 0.9776 - val_loss: 0.6489 - val_accuracy: 0.8064\n",
      "Epoch 33/50\n",
      "1382/1382 [==============================] - 1s 558us/step - loss: 0.3117 - accuracy: 0.9754 - val_loss: 0.8842 - val_accuracy: 0.7457\n",
      "Epoch 34/50\n",
      "1382/1382 [==============================] - 1s 561us/step - loss: 0.2911 - accuracy: 0.9776 - val_loss: 0.7071 - val_accuracy: 0.7832\n",
      "Epoch 35/50\n",
      "1382/1382 [==============================] - 1s 559us/step - loss: 0.2732 - accuracy: 0.9732 - val_loss: 0.6809 - val_accuracy: 0.7746\n",
      "Epoch 36/50\n",
      "1382/1382 [==============================] - 1s 558us/step - loss: 0.2640 - accuracy: 0.9805 - val_loss: 0.6405 - val_accuracy: 0.8035\n",
      "Epoch 37/50\n",
      "1382/1382 [==============================] - 1s 558us/step - loss: 0.2965 - accuracy: 0.9790 - val_loss: 0.7326 - val_accuracy: 0.7977\n",
      "Epoch 38/50\n",
      "1382/1382 [==============================] - 1s 559us/step - loss: 0.2664 - accuracy: 0.9797 - val_loss: 0.7210 - val_accuracy: 0.8092\n",
      "Epoch 39/50\n",
      "1382/1382 [==============================] - 1s 561us/step - loss: 0.2511 - accuracy: 0.9768 - val_loss: 0.6349 - val_accuracy: 0.8179\n",
      "Epoch 40/50\n",
      "1382/1382 [==============================] - 1s 560us/step - loss: 0.2467 - accuracy: 0.9819 - val_loss: 0.6387 - val_accuracy: 0.8121\n",
      "Epoch 41/50\n",
      "1382/1382 [==============================] - 1s 561us/step - loss: 0.2891 - accuracy: 0.9653 - val_loss: 0.7254 - val_accuracy: 0.7948\n",
      "Epoch 42/50\n",
      "1382/1382 [==============================] - 1s 558us/step - loss: 0.3115 - accuracy: 0.9522 - val_loss: 0.6854 - val_accuracy: 0.8121\n",
      "Epoch 43/50\n",
      "1382/1382 [==============================] - 1s 560us/step - loss: 0.2856 - accuracy: 0.9696 - val_loss: 0.7409 - val_accuracy: 0.8035\n",
      "Epoch 44/50\n",
      "1382/1382 [==============================] - 1s 559us/step - loss: 0.2659 - accuracy: 0.9645 - val_loss: 0.7400 - val_accuracy: 0.8064\n",
      "Epoch 45/50\n",
      "1382/1382 [==============================] - 1s 559us/step - loss: 0.2621 - accuracy: 0.9667 - val_loss: 0.7062 - val_accuracy: 0.7948\n",
      "Epoch 46/50\n",
      "1382/1382 [==============================] - 1s 560us/step - loss: 0.2686 - accuracy: 0.9580 - val_loss: 0.6659 - val_accuracy: 0.8179\n",
      "Epoch 47/50\n",
      "1382/1382 [==============================] - 1s 558us/step - loss: 0.2556 - accuracy: 0.9631 - val_loss: 0.7972 - val_accuracy: 0.7630\n",
      "Epoch 48/50\n",
      "1382/1382 [==============================] - 1s 560us/step - loss: 0.2334 - accuracy: 0.9725 - val_loss: 0.6711 - val_accuracy: 0.8121\n",
      "Epoch 49/50\n",
      "1382/1382 [==============================] - 1s 557us/step - loss: 0.2425 - accuracy: 0.9689 - val_loss: 0.6682 - val_accuracy: 0.8035\n",
      "Epoch 50/50\n",
      "1382/1382 [==============================] - 1s 560us/step - loss: 0.2330 - accuracy: 0.9740 - val_loss: 0.7794 - val_accuracy: 0.7948\n",
      "346/346 [==============================] - 0s 156us/step\n",
      "346/346 [==============================] - 0s 121us/step\n",
      " \n",
      "Train on 1382 samples, validate on 346 samples\n",
      "Epoch 1/50\n",
      "1382/1382 [==============================] - 1s 994us/step - loss: 1.0561 - accuracy: 0.5080 - val_loss: 0.8441 - val_accuracy: 0.4971\n",
      "Epoch 2/50\n",
      "1382/1382 [==============================] - 1s 557us/step - loss: 0.8285 - accuracy: 0.5210 - val_loss: 0.8022 - val_accuracy: 0.4971\n",
      "Epoch 3/50\n",
      "1382/1382 [==============================] - 1s 558us/step - loss: 0.7920 - accuracy: 0.5253 - val_loss: 0.7828 - val_accuracy: 0.5029\n",
      "Epoch 4/50\n",
      "1382/1382 [==============================] - 1s 553us/step - loss: 0.7741 - accuracy: 0.5854 - val_loss: 0.7636 - val_accuracy: 0.8353\n",
      "Epoch 5/50\n",
      "1382/1382 [==============================] - 1s 556us/step - loss: 0.7420 - accuracy: 0.8097 - val_loss: 0.7888 - val_accuracy: 0.7890\n",
      "Epoch 6/50\n",
      "1382/1382 [==============================] - 1s 558us/step - loss: 0.6315 - accuracy: 0.9030 - val_loss: 0.8101 - val_accuracy: 0.8295\n",
      "Epoch 7/50\n",
      "1382/1382 [==============================] - 1s 558us/step - loss: 0.5483 - accuracy: 0.9342 - val_loss: 0.7229 - val_accuracy: 0.8324\n",
      "Epoch 8/50\n",
      "1382/1382 [==============================] - 1s 557us/step - loss: 0.4901 - accuracy: 0.9573 - val_loss: 0.6133 - val_accuracy: 0.8757\n",
      "Epoch 9/50\n",
      "1382/1382 [==============================] - 1s 553us/step - loss: 0.4596 - accuracy: 0.9551 - val_loss: 0.6560 - val_accuracy: 0.8410\n",
      "Epoch 10/50\n",
      "1382/1382 [==============================] - 1s 555us/step - loss: 0.4152 - accuracy: 0.9725 - val_loss: 0.7724 - val_accuracy: 0.8150\n",
      "Epoch 11/50\n",
      "1382/1382 [==============================] - 1s 555us/step - loss: 0.3766 - accuracy: 0.9797 - val_loss: 0.7673 - val_accuracy: 0.8208\n",
      "Epoch 12/50\n",
      "1382/1382 [==============================] - 1s 554us/step - loss: 0.3533 - accuracy: 0.9783 - val_loss: 0.6063 - val_accuracy: 0.8295\n",
      "Epoch 13/50\n",
      "1382/1382 [==============================] - 1s 553us/step - loss: 0.3480 - accuracy: 0.9797 - val_loss: 0.6069 - val_accuracy: 0.8584\n",
      "Epoch 14/50\n",
      "1382/1382 [==============================] - 1s 557us/step - loss: 0.3309 - accuracy: 0.9848 - val_loss: 0.6522 - val_accuracy: 0.8353\n",
      "Epoch 15/50\n",
      "1382/1382 [==============================] - 1s 558us/step - loss: 0.3344 - accuracy: 0.9768 - val_loss: 0.5627 - val_accuracy: 0.8497\n",
      "Epoch 16/50\n",
      "1382/1382 [==============================] - 1s 556us/step - loss: 0.3153 - accuracy: 0.9768 - val_loss: 0.5826 - val_accuracy: 0.8526\n",
      "Epoch 17/50\n",
      "1382/1382 [==============================] - 1s 558us/step - loss: 0.2969 - accuracy: 0.9790 - val_loss: 0.5356 - val_accuracy: 0.8671\n",
      "Epoch 18/50\n",
      "1382/1382 [==============================] - 1s 553us/step - loss: 0.2995 - accuracy: 0.9805 - val_loss: 0.5565 - val_accuracy: 0.8671\n",
      "Epoch 19/50\n",
      "1382/1382 [==============================] - 1s 558us/step - loss: 0.3030 - accuracy: 0.9855 - val_loss: 0.5614 - val_accuracy: 0.8150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50\n",
      "1382/1382 [==============================] - 1s 555us/step - loss: 0.2714 - accuracy: 0.9805 - val_loss: 0.5659 - val_accuracy: 0.7977\n",
      "Epoch 21/50\n",
      "1382/1382 [==============================] - 1s 560us/step - loss: 0.2570 - accuracy: 0.9870 - val_loss: 0.5010 - val_accuracy: 0.8642\n",
      "Epoch 22/50\n",
      "1382/1382 [==============================] - 1s 557us/step - loss: 0.2649 - accuracy: 0.9790 - val_loss: 0.5397 - val_accuracy: 0.8555\n",
      "Epoch 23/50\n",
      "1382/1382 [==============================] - 1s 555us/step - loss: 0.2746 - accuracy: 0.9768 - val_loss: 0.5200 - val_accuracy: 0.8757\n",
      "Epoch 24/50\n",
      "1382/1382 [==============================] - 1s 554us/step - loss: 0.2640 - accuracy: 0.9826 - val_loss: 0.8901 - val_accuracy: 0.8555\n",
      "Epoch 25/50\n",
      "1382/1382 [==============================] - 1s 557us/step - loss: 0.3384 - accuracy: 0.9805 - val_loss: 0.6004 - val_accuracy: 0.8035\n",
      "Epoch 26/50\n",
      "1382/1382 [==============================] - 1s 559us/step - loss: 0.2894 - accuracy: 0.9797 - val_loss: 0.4991 - val_accuracy: 0.8699\n",
      "Epoch 27/50\n",
      "1382/1382 [==============================] - 1s 555us/step - loss: 0.2903 - accuracy: 0.9674 - val_loss: 0.5852 - val_accuracy: 0.8266\n",
      "Epoch 28/50\n",
      "1382/1382 [==============================] - 1s 561us/step - loss: 0.2596 - accuracy: 0.9826 - val_loss: 0.5193 - val_accuracy: 0.8815\n",
      "Epoch 29/50\n",
      "1382/1382 [==============================] - 1s 557us/step - loss: 0.2360 - accuracy: 0.9891 - val_loss: 0.5161 - val_accuracy: 0.8699\n",
      "Epoch 30/50\n",
      "1382/1382 [==============================] - 1s 559us/step - loss: 0.2417 - accuracy: 0.9819 - val_loss: 0.5261 - val_accuracy: 0.8439\n",
      "Epoch 31/50\n",
      "1382/1382 [==============================] - 1s 557us/step - loss: 0.2344 - accuracy: 0.9812 - val_loss: 0.5585 - val_accuracy: 0.8410\n",
      "Epoch 32/50\n",
      "1382/1382 [==============================] - 1s 555us/step - loss: 0.2508 - accuracy: 0.9891 - val_loss: 0.5603 - val_accuracy: 0.8728\n",
      "Epoch 33/50\n",
      "1382/1382 [==============================] - 1s 557us/step - loss: 0.2326 - accuracy: 0.9848 - val_loss: 0.5732 - val_accuracy: 0.8324\n",
      "Epoch 34/50\n",
      "1382/1382 [==============================] - 1s 559us/step - loss: 0.2331 - accuracy: 0.9797 - val_loss: 0.5210 - val_accuracy: 0.8324\n",
      "Epoch 35/50\n",
      "1382/1382 [==============================] - 1s 558us/step - loss: 0.2130 - accuracy: 0.9884 - val_loss: 0.5045 - val_accuracy: 0.8613\n",
      "Epoch 36/50\n",
      "1382/1382 [==============================] - 1s 558us/step - loss: 0.2078 - accuracy: 0.9906 - val_loss: 0.5226 - val_accuracy: 0.8439\n",
      "Epoch 37/50\n",
      "1382/1382 [==============================] - 1s 552us/step - loss: 0.2159 - accuracy: 0.9884 - val_loss: 0.5188 - val_accuracy: 0.8410\n",
      "Epoch 38/50\n",
      "1382/1382 [==============================] - 1s 555us/step - loss: 0.2082 - accuracy: 0.9855 - val_loss: 0.4859 - val_accuracy: 0.8757\n",
      "Epoch 39/50\n",
      "1382/1382 [==============================] - 1s 554us/step - loss: 0.1991 - accuracy: 0.9877 - val_loss: 0.4987 - val_accuracy: 0.8873\n",
      "Epoch 40/50\n",
      "1382/1382 [==============================] - 1s 553us/step - loss: 0.2061 - accuracy: 0.9870 - val_loss: 0.4993 - val_accuracy: 0.8526\n",
      "Epoch 41/50\n",
      "1382/1382 [==============================] - 1s 555us/step - loss: 0.2058 - accuracy: 0.9877 - val_loss: 0.5040 - val_accuracy: 0.8699\n",
      "Epoch 42/50\n",
      "1382/1382 [==============================] - 1s 553us/step - loss: 0.1997 - accuracy: 0.9877 - val_loss: 0.5646 - val_accuracy: 0.8468\n",
      "Epoch 43/50\n",
      "1382/1382 [==============================] - 1s 556us/step - loss: 0.2397 - accuracy: 0.9725 - val_loss: 0.5697 - val_accuracy: 0.8439\n",
      "Epoch 44/50\n",
      "1382/1382 [==============================] - 1s 553us/step - loss: 0.2971 - accuracy: 0.9834 - val_loss: 0.7195 - val_accuracy: 0.7977\n",
      "Epoch 45/50\n",
      "1382/1382 [==============================] - 1s 556us/step - loss: 0.2677 - accuracy: 0.9797 - val_loss: 0.5216 - val_accuracy: 0.8728\n",
      "Epoch 46/50\n",
      "1382/1382 [==============================] - 1s 555us/step - loss: 0.2462 - accuracy: 0.9913 - val_loss: 0.5659 - val_accuracy: 0.8382\n",
      "Epoch 47/50\n",
      "1382/1382 [==============================] - 1s 558us/step - loss: 0.2102 - accuracy: 0.9870 - val_loss: 0.5155 - val_accuracy: 0.8642\n",
      "Epoch 48/50\n",
      "1382/1382 [==============================] - 1s 555us/step - loss: 0.1926 - accuracy: 0.9906 - val_loss: 0.4832 - val_accuracy: 0.8671\n",
      "Epoch 49/50\n",
      "1382/1382 [==============================] - 1s 555us/step - loss: 0.1924 - accuracy: 0.9884 - val_loss: 0.5041 - val_accuracy: 0.8642\n",
      "Epoch 50/50\n",
      "1382/1382 [==============================] - 1s 556us/step - loss: 0.1940 - accuracy: 0.9891 - val_loss: 0.5227 - val_accuracy: 0.8613\n",
      "346/346 [==============================] - 0s 153us/step\n",
      "346/346 [==============================] - 0s 127us/step\n",
      " \n",
      "Train on 1382 samples, validate on 346 samples\n",
      "Epoch 1/50\n",
      "1382/1382 [==============================] - 1s 989us/step - loss: 1.0758 - accuracy: 0.6447 - val_loss: 0.8515 - val_accuracy: 0.5751\n",
      "Epoch 2/50\n",
      "1382/1382 [==============================] - 1s 556us/step - loss: 0.8187 - accuracy: 0.7294 - val_loss: 0.7991 - val_accuracy: 0.7659\n",
      "Epoch 3/50\n",
      "1382/1382 [==============================] - 1s 558us/step - loss: 0.7478 - accuracy: 0.8025 - val_loss: 0.7557 - val_accuracy: 0.6879\n",
      "Epoch 4/50\n",
      "1382/1382 [==============================] - 1s 561us/step - loss: 0.7056 - accuracy: 0.8263 - val_loss: 0.7366 - val_accuracy: 0.7688\n",
      "Epoch 5/50\n",
      "1382/1382 [==============================] - 1s 558us/step - loss: 0.6816 - accuracy: 0.8647 - val_loss: 0.7331 - val_accuracy: 0.8121\n",
      "Epoch 6/50\n",
      "1382/1382 [==============================] - 1s 557us/step - loss: 0.6917 - accuracy: 0.8741 - val_loss: 0.7410 - val_accuracy: 0.7919\n",
      "Epoch 7/50\n",
      "1382/1382 [==============================] - 1s 557us/step - loss: 0.6434 - accuracy: 0.8980 - val_loss: 0.7908 - val_accuracy: 0.5751\n",
      "Epoch 8/50\n",
      "1382/1382 [==============================] - 1s 557us/step - loss: 0.5998 - accuracy: 0.9059 - val_loss: 0.8727 - val_accuracy: 0.6965\n",
      "Epoch 9/50\n",
      "1382/1382 [==============================] - 1s 560us/step - loss: 0.5714 - accuracy: 0.9298 - val_loss: 0.7479 - val_accuracy: 0.7803\n",
      "Epoch 10/50\n",
      "1382/1382 [==============================] - 1s 563us/step - loss: 0.5149 - accuracy: 0.9450 - val_loss: 2.5912 - val_accuracy: 0.5058\n",
      "Epoch 11/50\n",
      "1382/1382 [==============================] - 1s 562us/step - loss: 0.5697 - accuracy: 0.9255 - val_loss: 0.7351 - val_accuracy: 0.7630\n",
      "Epoch 12/50\n",
      "1382/1382 [==============================] - 1s 559us/step - loss: 0.4882 - accuracy: 0.9660 - val_loss: 1.1661 - val_accuracy: 0.6734\n",
      "Epoch 13/50\n",
      "1382/1382 [==============================] - 1s 561us/step - loss: 0.4459 - accuracy: 0.9638 - val_loss: 0.9348 - val_accuracy: 0.6358\n",
      "Epoch 14/50\n",
      "1382/1382 [==============================] - 1s 555us/step - loss: 0.4391 - accuracy: 0.9638 - val_loss: 0.7981 - val_accuracy: 0.7630\n",
      "Epoch 15/50\n",
      "1382/1382 [==============================] - 1s 557us/step - loss: 0.4133 - accuracy: 0.9689 - val_loss: 0.9745 - val_accuracy: 0.7486\n",
      "Epoch 16/50\n",
      "1382/1382 [==============================] - 1s 555us/step - loss: 0.5012 - accuracy: 0.9559 - val_loss: 0.8071 - val_accuracy: 0.7514\n",
      "Epoch 17/50\n",
      "1382/1382 [==============================] - 1s 559us/step - loss: 0.4219 - accuracy: 0.9718 - val_loss: 0.9032 - val_accuracy: 0.7139\n",
      "Epoch 18/50\n",
      "1382/1382 [==============================] - 1s 559us/step - loss: 0.3986 - accuracy: 0.9740 - val_loss: 0.7360 - val_accuracy: 0.7803\n",
      "Epoch 19/50\n",
      "1382/1382 [==============================] - 1s 555us/step - loss: 0.3899 - accuracy: 0.9718 - val_loss: 0.8125 - val_accuracy: 0.7197\n",
      "Epoch 20/50\n",
      "1382/1382 [==============================] - 1s 555us/step - loss: 0.3856 - accuracy: 0.9689 - val_loss: 0.7827 - val_accuracy: 0.7514\n",
      "Epoch 21/50\n",
      "1382/1382 [==============================] - 1s 556us/step - loss: 0.3553 - accuracy: 0.9790 - val_loss: 0.7186 - val_accuracy: 0.7746\n",
      "Epoch 22/50\n",
      "1382/1382 [==============================] - 1s 554us/step - loss: 0.3689 - accuracy: 0.9747 - val_loss: 0.9615 - val_accuracy: 0.6936\n",
      "Epoch 23/50\n",
      "1382/1382 [==============================] - 1s 558us/step - loss: 0.3891 - accuracy: 0.9761 - val_loss: 0.7637 - val_accuracy: 0.7630\n",
      "Epoch 24/50\n",
      "1382/1382 [==============================] - 1s 561us/step - loss: 0.3717 - accuracy: 0.9826 - val_loss: 0.7164 - val_accuracy: 0.7659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50\n",
      "1382/1382 [==============================] - 1s 559us/step - loss: 0.3464 - accuracy: 0.9732 - val_loss: 0.7999 - val_accuracy: 0.7514\n",
      "Epoch 26/50\n",
      "1382/1382 [==============================] - 1s 559us/step - loss: 0.3185 - accuracy: 0.9776 - val_loss: 0.7280 - val_accuracy: 0.7717\n",
      "Epoch 27/50\n",
      "1382/1382 [==============================] - 1s 560us/step - loss: 0.3361 - accuracy: 0.9682 - val_loss: 0.7734 - val_accuracy: 0.7341\n",
      "Epoch 28/50\n",
      "1382/1382 [==============================] - 1s 562us/step - loss: 0.3246 - accuracy: 0.9754 - val_loss: 0.7519 - val_accuracy: 0.7572\n",
      "Epoch 29/50\n",
      "1382/1382 [==============================] - 1s 559us/step - loss: 0.3201 - accuracy: 0.9819 - val_loss: 0.8492 - val_accuracy: 0.7486\n",
      "Epoch 30/50\n",
      "1382/1382 [==============================] - 1s 558us/step - loss: 0.3255 - accuracy: 0.9718 - val_loss: 0.8217 - val_accuracy: 0.7630\n",
      "Epoch 31/50\n",
      "1382/1382 [==============================] - 1s 557us/step - loss: 0.3269 - accuracy: 0.9703 - val_loss: 0.6373 - val_accuracy: 0.7659\n",
      "Epoch 32/50\n",
      "1382/1382 [==============================] - 1s 556us/step - loss: 0.3295 - accuracy: 0.9797 - val_loss: 0.7963 - val_accuracy: 0.7659\n",
      "Epoch 33/50\n",
      "1382/1382 [==============================] - 1s 555us/step - loss: 0.3076 - accuracy: 0.9805 - val_loss: 0.7156 - val_accuracy: 0.7717\n",
      "Epoch 34/50\n",
      "1382/1382 [==============================] - 1s 559us/step - loss: 0.3263 - accuracy: 0.9863 - val_loss: 0.8347 - val_accuracy: 0.7168\n",
      "Epoch 35/50\n",
      "1382/1382 [==============================] - 1s 558us/step - loss: 0.3272 - accuracy: 0.9826 - val_loss: 0.8891 - val_accuracy: 0.7428\n",
      "Epoch 36/50\n",
      "1382/1382 [==============================] - 1s 558us/step - loss: 0.2949 - accuracy: 0.9805 - val_loss: 0.8005 - val_accuracy: 0.7717\n",
      "Epoch 37/50\n",
      "1382/1382 [==============================] - 1s 553us/step - loss: 0.2885 - accuracy: 0.9819 - val_loss: 0.8463 - val_accuracy: 0.7370\n",
      "Epoch 38/50\n",
      "1382/1382 [==============================] - 1s 553us/step - loss: 0.2772 - accuracy: 0.9790 - val_loss: 0.8211 - val_accuracy: 0.7486\n",
      "Epoch 39/50\n",
      "1382/1382 [==============================] - 1s 553us/step - loss: 0.2809 - accuracy: 0.9819 - val_loss: 0.7882 - val_accuracy: 0.7514\n",
      "Epoch 40/50\n",
      "1382/1382 [==============================] - 1s 558us/step - loss: 0.3106 - accuracy: 0.9711 - val_loss: 0.7894 - val_accuracy: 0.7601\n",
      "Epoch 41/50\n",
      "1382/1382 [==============================] - 1s 555us/step - loss: 0.3143 - accuracy: 0.9783 - val_loss: 0.7301 - val_accuracy: 0.7717\n",
      "Epoch 42/50\n",
      "1382/1382 [==============================] - 1s 555us/step - loss: 0.2851 - accuracy: 0.9797 - val_loss: 0.6870 - val_accuracy: 0.7659\n",
      "Epoch 43/50\n",
      "1382/1382 [==============================] - 1s 555us/step - loss: 0.2760 - accuracy: 0.9805 - val_loss: 0.7020 - val_accuracy: 0.7746\n",
      "Epoch 44/50\n",
      "1382/1382 [==============================] - 1s 555us/step - loss: 0.2666 - accuracy: 0.9834 - val_loss: 0.6899 - val_accuracy: 0.7775\n",
      "Epoch 45/50\n",
      "1382/1382 [==============================] - 1s 555us/step - loss: 0.2881 - accuracy: 0.9855 - val_loss: 0.7788 - val_accuracy: 0.7717\n",
      "Epoch 46/50\n",
      "1382/1382 [==============================] - 1s 558us/step - loss: 0.3110 - accuracy: 0.9732 - val_loss: 0.8067 - val_accuracy: 0.7572\n",
      "Epoch 47/50\n",
      "1382/1382 [==============================] - 1s 561us/step - loss: 0.2921 - accuracy: 0.9841 - val_loss: 0.7249 - val_accuracy: 0.7919\n",
      "Epoch 48/50\n",
      "1382/1382 [==============================] - 1s 556us/step - loss: 0.2915 - accuracy: 0.9776 - val_loss: 0.7208 - val_accuracy: 0.7890\n",
      "Epoch 49/50\n",
      "1382/1382 [==============================] - 1s 559us/step - loss: 0.2731 - accuracy: 0.9841 - val_loss: 0.8214 - val_accuracy: 0.7543\n",
      "Epoch 50/50\n",
      "1382/1382 [==============================] - 1s 561us/step - loss: 0.2825 - accuracy: 0.9841 - val_loss: 0.7312 - val_accuracy: 0.7861\n",
      "346/346 [==============================] - 0s 156us/step\n",
      "346/346 [==============================] - 0s 124us/step\n",
      " \n",
      "Train on 1382 samples, validate on 346 samples\n",
      "Epoch 1/50\n",
      "1382/1382 [==============================] - 1s 979us/step - loss: 1.2955 - accuracy: 0.6454 - val_loss: 0.9098 - val_accuracy: 0.7283\n",
      "Epoch 2/50\n",
      "1382/1382 [==============================] - 1s 546us/step - loss: 0.8553 - accuracy: 0.7467 - val_loss: 0.8073 - val_accuracy: 0.7717\n",
      "Epoch 3/50\n",
      "1382/1382 [==============================] - 1s 550us/step - loss: 0.7949 - accuracy: 0.7713 - val_loss: 0.7724 - val_accuracy: 0.7283\n",
      "Epoch 4/50\n",
      "1382/1382 [==============================] - 1s 562us/step - loss: 0.7177 - accuracy: 0.8046 - val_loss: 0.6988 - val_accuracy: 0.7977\n",
      "Epoch 5/50\n",
      "1382/1382 [==============================] - 1s 547us/step - loss: 0.6814 - accuracy: 0.8350 - val_loss: 0.7210 - val_accuracy: 0.7601\n",
      "Epoch 6/50\n",
      "1382/1382 [==============================] - 1s 546us/step - loss: 0.6750 - accuracy: 0.8386 - val_loss: 0.6899 - val_accuracy: 0.8208\n",
      "Epoch 7/50\n",
      "1382/1382 [==============================] - 1s 558us/step - loss: 0.6556 - accuracy: 0.8502 - val_loss: 0.6604 - val_accuracy: 0.7803\n",
      "Epoch 8/50\n",
      "1382/1382 [==============================] - 1s 544us/step - loss: 0.6218 - accuracy: 0.8698 - val_loss: 0.6464 - val_accuracy: 0.8208\n",
      "Epoch 9/50\n",
      "1382/1382 [==============================] - 1s 540us/step - loss: 0.5871 - accuracy: 0.8857 - val_loss: 0.6801 - val_accuracy: 0.7399\n",
      "Epoch 10/50\n",
      "1382/1382 [==============================] - 1s 539us/step - loss: 0.5830 - accuracy: 0.8763 - val_loss: 0.6068 - val_accuracy: 0.8584\n",
      "Epoch 11/50\n",
      "1382/1382 [==============================] - 1s 541us/step - loss: 0.5877 - accuracy: 0.8907 - val_loss: 0.6611 - val_accuracy: 0.7832\n",
      "Epoch 12/50\n",
      "1382/1382 [==============================] - 1s 539us/step - loss: 0.5773 - accuracy: 0.9067 - val_loss: 0.6212 - val_accuracy: 0.8555\n",
      "Epoch 13/50\n",
      "1382/1382 [==============================] - 1s 537us/step - loss: 0.5476 - accuracy: 0.8987 - val_loss: 0.5723 - val_accuracy: 0.8757\n",
      "Epoch 14/50\n",
      "1382/1382 [==============================] - 1s 540us/step - loss: 0.5183 - accuracy: 0.9117 - val_loss: 0.6771 - val_accuracy: 0.7659\n",
      "Epoch 15/50\n",
      "1382/1382 [==============================] - 1s 542us/step - loss: 0.5384 - accuracy: 0.8958 - val_loss: 0.5721 - val_accuracy: 0.8728\n",
      "Epoch 16/50\n",
      "1382/1382 [==============================] - 1s 542us/step - loss: 0.5096 - accuracy: 0.9175 - val_loss: 0.6998 - val_accuracy: 0.7977\n",
      "Epoch 17/50\n",
      "1382/1382 [==============================] - 1s 540us/step - loss: 0.5166 - accuracy: 0.9168 - val_loss: 0.5705 - val_accuracy: 0.8439\n",
      "Epoch 18/50\n",
      "1382/1382 [==============================] - 1s 544us/step - loss: 0.4849 - accuracy: 0.9247 - val_loss: 0.6454 - val_accuracy: 0.7312\n",
      "Epoch 19/50\n",
      "1382/1382 [==============================] - 1s 553us/step - loss: 0.4750 - accuracy: 0.9153 - val_loss: 0.7466 - val_accuracy: 0.8613\n",
      "Epoch 20/50\n",
      "1382/1382 [==============================] - 1s 548us/step - loss: 0.4703 - accuracy: 0.9349 - val_loss: 0.5738 - val_accuracy: 0.8410\n",
      "Epoch 21/50\n",
      "1382/1382 [==============================] - 1s 546us/step - loss: 0.4670 - accuracy: 0.9233 - val_loss: 0.5483 - val_accuracy: 0.8468\n",
      "Epoch 22/50\n",
      "1382/1382 [==============================] - 1s 552us/step - loss: 0.4704 - accuracy: 0.9204 - val_loss: 0.5849 - val_accuracy: 0.8642\n",
      "Epoch 23/50\n",
      "1382/1382 [==============================] - 1s 548us/step - loss: 0.4814 - accuracy: 0.9255 - val_loss: 0.5110 - val_accuracy: 0.8786\n",
      "Epoch 24/50\n",
      "1382/1382 [==============================] - 1s 550us/step - loss: 0.4518 - accuracy: 0.9146 - val_loss: 0.5169 - val_accuracy: 0.8671\n",
      "Epoch 25/50\n",
      "1382/1382 [==============================] - 1s 550us/step - loss: 0.4270 - accuracy: 0.9262 - val_loss: 0.5044 - val_accuracy: 0.8728\n",
      "Epoch 26/50\n",
      "1382/1382 [==============================] - 1s 550us/step - loss: 0.4301 - accuracy: 0.9291 - val_loss: 0.4941 - val_accuracy: 0.8815\n",
      "Epoch 27/50\n",
      "1382/1382 [==============================] - 1s 546us/step - loss: 0.4187 - accuracy: 0.9284 - val_loss: 0.5201 - val_accuracy: 0.8439\n",
      "Epoch 28/50\n",
      "1382/1382 [==============================] - 1s 544us/step - loss: 0.4533 - accuracy: 0.9211 - val_loss: 0.5188 - val_accuracy: 0.8642\n",
      "Epoch 29/50\n",
      "1382/1382 [==============================] - 1s 551us/step - loss: 0.4499 - accuracy: 0.9117 - val_loss: 0.5152 - val_accuracy: 0.8757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50\n",
      "1382/1382 [==============================] - 1s 550us/step - loss: 0.4342 - accuracy: 0.9197 - val_loss: 0.5339 - val_accuracy: 0.8584\n",
      "Epoch 31/50\n",
      "1382/1382 [==============================] - 1s 548us/step - loss: 0.4417 - accuracy: 0.9175 - val_loss: 0.5026 - val_accuracy: 0.8555\n",
      "Epoch 32/50\n",
      "1382/1382 [==============================] - 1s 553us/step - loss: 0.4144 - accuracy: 0.9211 - val_loss: 0.4804 - val_accuracy: 0.8555\n",
      "Epoch 33/50\n",
      "1382/1382 [==============================] - 1s 548us/step - loss: 0.4148 - accuracy: 0.9226 - val_loss: 0.5006 - val_accuracy: 0.8613\n",
      "Epoch 34/50\n",
      "1382/1382 [==============================] - 1s 549us/step - loss: 0.3998 - accuracy: 0.9276 - val_loss: 0.4905 - val_accuracy: 0.8642\n",
      "Epoch 35/50\n",
      "1382/1382 [==============================] - 1s 550us/step - loss: 0.3939 - accuracy: 0.9284 - val_loss: 0.4766 - val_accuracy: 0.8960\n",
      "Epoch 36/50\n",
      "1382/1382 [==============================] - 1s 570us/step - loss: 0.4081 - accuracy: 0.9226 - val_loss: 0.5117 - val_accuracy: 0.8410\n",
      "Epoch 37/50\n",
      "1382/1382 [==============================] - 1s 563us/step - loss: 0.4162 - accuracy: 0.9139 - val_loss: 0.5071 - val_accuracy: 0.8497\n",
      "Epoch 38/50\n",
      "1382/1382 [==============================] - 1s 563us/step - loss: 0.3987 - accuracy: 0.9255 - val_loss: 0.4758 - val_accuracy: 0.8815\n",
      "Epoch 39/50\n",
      "1382/1382 [==============================] - 1s 563us/step - loss: 0.4369 - accuracy: 0.9124 - val_loss: 0.4889 - val_accuracy: 0.8699\n",
      "Epoch 40/50\n",
      "1382/1382 [==============================] - 1s 563us/step - loss: 0.3957 - accuracy: 0.9305 - val_loss: 0.4803 - val_accuracy: 0.8671\n",
      "Epoch 41/50\n",
      "1382/1382 [==============================] - 1s 567us/step - loss: 0.4341 - accuracy: 0.9168 - val_loss: 0.5017 - val_accuracy: 0.8671\n",
      "Epoch 42/50\n",
      "1382/1382 [==============================] - 1s 563us/step - loss: 0.4227 - accuracy: 0.9096 - val_loss: 0.5084 - val_accuracy: 0.8439\n",
      "Epoch 43/50\n",
      "1382/1382 [==============================] - 1s 562us/step - loss: 0.4083 - accuracy: 0.9262 - val_loss: 0.5436 - val_accuracy: 0.8728\n",
      "Epoch 44/50\n",
      "1382/1382 [==============================] - 1s 550us/step - loss: 0.4015 - accuracy: 0.9298 - val_loss: 0.5791 - val_accuracy: 0.8728\n",
      "Epoch 45/50\n",
      "1382/1382 [==============================] - 1s 540us/step - loss: 0.3939 - accuracy: 0.9247 - val_loss: 0.4609 - val_accuracy: 0.8757\n",
      "Epoch 46/50\n",
      "1382/1382 [==============================] - 1s 535us/step - loss: 0.3734 - accuracy: 0.9240 - val_loss: 0.4580 - val_accuracy: 0.8757\n",
      "Epoch 47/50\n",
      "1382/1382 [==============================] - 1s 538us/step - loss: 0.4097 - accuracy: 0.9124 - val_loss: 0.4871 - val_accuracy: 0.8613\n",
      "Epoch 48/50\n",
      "1382/1382 [==============================] - 1s 539us/step - loss: 0.3918 - accuracy: 0.9240 - val_loss: 0.4680 - val_accuracy: 0.8699\n",
      "Epoch 49/50\n",
      "1382/1382 [==============================] - 1s 540us/step - loss: 0.3843 - accuracy: 0.9226 - val_loss: 0.4753 - val_accuracy: 0.8584\n",
      "Epoch 50/50\n",
      "1382/1382 [==============================] - 1s 540us/step - loss: 0.3860 - accuracy: 0.9219 - val_loss: 0.4490 - val_accuracy: 0.8757\n",
      "346/346 [==============================] - 0s 153us/step\n",
      "346/346 [==============================] - 0s 124us/step\n",
      " \n",
      "Train on 1382 samples, validate on 346 samples\n",
      "Epoch 1/50\n",
      "1382/1382 [==============================] - 1s 1ms/step - loss: 0.9491 - accuracy: 0.5912 - val_loss: 0.8560 - val_accuracy: 0.5694\n",
      "Epoch 2/50\n",
      "1382/1382 [==============================] - 1s 555us/step - loss: 0.7767 - accuracy: 0.6787 - val_loss: 0.8268 - val_accuracy: 0.6532\n",
      "Epoch 3/50\n",
      "1382/1382 [==============================] - 1s 555us/step - loss: 0.7672 - accuracy: 0.7185 - val_loss: 0.8247 - val_accuracy: 0.6243\n",
      "Epoch 4/50\n",
      "1382/1382 [==============================] - 1s 553us/step - loss: 0.7611 - accuracy: 0.7634 - val_loss: 0.8218 - val_accuracy: 0.7283\n",
      "Epoch 5/50\n",
      "1382/1382 [==============================] - 1s 553us/step - loss: 0.7260 - accuracy: 0.8090 - val_loss: 0.7877 - val_accuracy: 0.7168\n",
      "Epoch 6/50\n",
      "1382/1382 [==============================] - 1s 551us/step - loss: 0.6777 - accuracy: 0.8300 - val_loss: 0.8571 - val_accuracy: 0.7110\n",
      "Epoch 7/50\n",
      "1382/1382 [==============================] - 1s 553us/step - loss: 0.6385 - accuracy: 0.8611 - val_loss: 0.8597 - val_accuracy: 0.6532\n",
      "Epoch 8/50\n",
      "1382/1382 [==============================] - 1s 555us/step - loss: 0.6163 - accuracy: 0.8886 - val_loss: 0.7910 - val_accuracy: 0.7225\n",
      "Epoch 9/50\n",
      "1382/1382 [==============================] - 1s 553us/step - loss: 0.5646 - accuracy: 0.9009 - val_loss: 0.7807 - val_accuracy: 0.7572\n",
      "Epoch 10/50\n",
      "1382/1382 [==============================] - 1s 553us/step - loss: 0.6074 - accuracy: 0.9030 - val_loss: 0.9129 - val_accuracy: 0.6734\n",
      "Epoch 11/50\n",
      "1382/1382 [==============================] - 1s 553us/step - loss: 0.5424 - accuracy: 0.9255 - val_loss: 0.8607 - val_accuracy: 0.7225\n",
      "Epoch 12/50\n",
      "1382/1382 [==============================] - 1s 556us/step - loss: 0.5072 - accuracy: 0.9327 - val_loss: 0.8995 - val_accuracy: 0.7399\n",
      "Epoch 13/50\n",
      "1382/1382 [==============================] - 1s 556us/step - loss: 0.5151 - accuracy: 0.9349 - val_loss: 0.8916 - val_accuracy: 0.7370\n",
      "Epoch 14/50\n",
      "1382/1382 [==============================] - 1s 557us/step - loss: 0.5102 - accuracy: 0.9443 - val_loss: 0.8648 - val_accuracy: 0.7254\n",
      "Epoch 15/50\n",
      "1382/1382 [==============================] - 1s 555us/step - loss: 0.5422 - accuracy: 0.9465 - val_loss: 0.8860 - val_accuracy: 0.7168\n",
      "Epoch 16/50\n",
      "1382/1382 [==============================] - 1s 554us/step - loss: 0.5167 - accuracy: 0.9436 - val_loss: 0.8448 - val_accuracy: 0.7341\n",
      "Epoch 17/50\n",
      "1382/1382 [==============================] - 1s 557us/step - loss: 0.4670 - accuracy: 0.9537 - val_loss: 0.7568 - val_accuracy: 0.7428\n",
      "Epoch 18/50\n",
      "1382/1382 [==============================] - 1s 558us/step - loss: 0.4308 - accuracy: 0.9588 - val_loss: 0.8407 - val_accuracy: 0.7110\n",
      "Epoch 19/50\n",
      "1382/1382 [==============================] - 1s 555us/step - loss: 0.4273 - accuracy: 0.9588 - val_loss: 1.0903 - val_accuracy: 0.6214\n",
      "Epoch 20/50\n",
      "1382/1382 [==============================] - 1s 555us/step - loss: 0.4322 - accuracy: 0.9515 - val_loss: 0.8018 - val_accuracy: 0.7457\n",
      "Epoch 21/50\n",
      "1382/1382 [==============================] - 1s 555us/step - loss: 0.3789 - accuracy: 0.9725 - val_loss: 0.8620 - val_accuracy: 0.7572\n",
      "Epoch 22/50\n",
      "1382/1382 [==============================] - 1s 555us/step - loss: 0.3833 - accuracy: 0.9747 - val_loss: 1.0066 - val_accuracy: 0.7168\n",
      "Epoch 23/50\n",
      "1382/1382 [==============================] - 1s 552us/step - loss: 0.3937 - accuracy: 0.9768 - val_loss: 0.8538 - val_accuracy: 0.7428\n",
      "Epoch 24/50\n",
      "1382/1382 [==============================] - 1s 551us/step - loss: 0.4007 - accuracy: 0.9667 - val_loss: 1.2949 - val_accuracy: 0.6647\n",
      "Epoch 25/50\n",
      "1382/1382 [==============================] - 1s 551us/step - loss: 0.3905 - accuracy: 0.9696 - val_loss: 0.9721 - val_accuracy: 0.7110\n",
      "Epoch 26/50\n",
      "1382/1382 [==============================] - 1s 550us/step - loss: 0.3814 - accuracy: 0.9725 - val_loss: 0.9225 - val_accuracy: 0.7312\n",
      "Epoch 27/50\n",
      "1382/1382 [==============================] - 1s 547us/step - loss: 0.4017 - accuracy: 0.9631 - val_loss: 0.9132 - val_accuracy: 0.7283\n",
      "Epoch 28/50\n",
      "1382/1382 [==============================] - 1s 555us/step - loss: 0.4259 - accuracy: 0.9768 - val_loss: 0.9475 - val_accuracy: 0.7428\n",
      "Epoch 29/50\n",
      "1382/1382 [==============================] - 1s 550us/step - loss: 0.3748 - accuracy: 0.9711 - val_loss: 0.8453 - val_accuracy: 0.7514\n",
      "Epoch 30/50\n",
      "1382/1382 [==============================] - 1s 550us/step - loss: 0.3482 - accuracy: 0.9797 - val_loss: 0.9037 - val_accuracy: 0.7197\n",
      "Epoch 31/50\n",
      "1382/1382 [==============================] - 1s 552us/step - loss: 0.3498 - accuracy: 0.9740 - val_loss: 1.0458 - val_accuracy: 0.6994\n",
      "Epoch 32/50\n",
      "1382/1382 [==============================] - 1s 551us/step - loss: 0.3441 - accuracy: 0.9754 - val_loss: 1.0211 - val_accuracy: 0.7168\n",
      "Epoch 33/50\n",
      "1382/1382 [==============================] - 1s 552us/step - loss: 0.4128 - accuracy: 0.9740 - val_loss: 1.0343 - val_accuracy: 0.7110\n",
      "Epoch 34/50\n",
      "1382/1382 [==============================] - 1s 553us/step - loss: 0.3782 - accuracy: 0.9718 - val_loss: 1.1052 - val_accuracy: 0.6532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50\n",
      "1382/1382 [==============================] - 1s 553us/step - loss: 0.4027 - accuracy: 0.9588 - val_loss: 0.8312 - val_accuracy: 0.7399\n",
      "Epoch 36/50\n",
      "1382/1382 [==============================] - 1s 553us/step - loss: 0.4013 - accuracy: 0.9674 - val_loss: 0.9021 - val_accuracy: 0.7312\n",
      "Epoch 37/50\n",
      "1382/1382 [==============================] - 1s 554us/step - loss: 0.3950 - accuracy: 0.9740 - val_loss: 0.9911 - val_accuracy: 0.7139\n",
      "Epoch 38/50\n",
      "1382/1382 [==============================] - 1s 553us/step - loss: 0.3485 - accuracy: 0.9812 - val_loss: 0.8111 - val_accuracy: 0.7746\n",
      "Epoch 39/50\n",
      "1382/1382 [==============================] - 1s 557us/step - loss: 0.3144 - accuracy: 0.9826 - val_loss: 0.8658 - val_accuracy: 0.7399\n",
      "Epoch 40/50\n",
      "1382/1382 [==============================] - 1s 555us/step - loss: 0.3161 - accuracy: 0.9834 - val_loss: 1.3001 - val_accuracy: 0.6821\n",
      "Epoch 41/50\n",
      "1382/1382 [==============================] - 1s 558us/step - loss: 0.3025 - accuracy: 0.9855 - val_loss: 0.8168 - val_accuracy: 0.7630\n",
      "Epoch 42/50\n",
      "1382/1382 [==============================] - 1s 555us/step - loss: 0.3008 - accuracy: 0.9718 - val_loss: 0.8342 - val_accuracy: 0.7168\n",
      "Epoch 43/50\n",
      "1382/1382 [==============================] - 1s 554us/step - loss: 0.2949 - accuracy: 0.9754 - val_loss: 0.9357 - val_accuracy: 0.7168\n",
      "Epoch 44/50\n",
      "1382/1382 [==============================] - 1s 557us/step - loss: 0.2881 - accuracy: 0.9790 - val_loss: 0.8606 - val_accuracy: 0.7254\n",
      "Epoch 45/50\n",
      "1382/1382 [==============================] - 1s 554us/step - loss: 0.2838 - accuracy: 0.9848 - val_loss: 0.8686 - val_accuracy: 0.7341\n",
      "Epoch 46/50\n",
      "1382/1382 [==============================] - 1s 555us/step - loss: 0.2986 - accuracy: 0.9790 - val_loss: 1.0003 - val_accuracy: 0.7225\n",
      "Epoch 47/50\n",
      "1382/1382 [==============================] - 1s 557us/step - loss: 0.2758 - accuracy: 0.9834 - val_loss: 0.8261 - val_accuracy: 0.7312\n",
      "Epoch 48/50\n",
      "1382/1382 [==============================] - 1s 555us/step - loss: 0.2642 - accuracy: 0.9790 - val_loss: 1.2405 - val_accuracy: 0.7023\n",
      "Epoch 49/50\n",
      "1382/1382 [==============================] - 1s 552us/step - loss: 0.2911 - accuracy: 0.9768 - val_loss: 0.9141 - val_accuracy: 0.7225\n",
      "Epoch 50/50\n",
      "1382/1382 [==============================] - 1s 552us/step - loss: 0.2690 - accuracy: 0.9812 - val_loss: 0.8729 - val_accuracy: 0.7370\n",
      "346/346 [==============================] - 0s 156us/step\n",
      "346/346 [==============================] - 0s 124us/step\n",
      " \n",
      "Train on 1382 samples, validate on 346 samples\n",
      "Epoch 1/50\n",
      "1382/1382 [==============================] - 1s 987us/step - loss: 1.0441 - accuracy: 0.6397 - val_loss: 0.9305 - val_accuracy: 0.5029\n",
      "Epoch 2/50\n",
      "1382/1382 [==============================] - 1s 556us/step - loss: 0.7616 - accuracy: 0.7207 - val_loss: 0.8565 - val_accuracy: 0.7688\n",
      "Epoch 3/50\n",
      "1382/1382 [==============================] - 1s 556us/step - loss: 0.7241 - accuracy: 0.8097 - val_loss: 0.8604 - val_accuracy: 0.8121\n",
      "Epoch 4/50\n",
      "1382/1382 [==============================] - 1s 553us/step - loss: 0.6902 - accuracy: 0.8444 - val_loss: 0.8351 - val_accuracy: 0.8699\n",
      "Epoch 5/50\n",
      "1382/1382 [==============================] - 1s 559us/step - loss: 0.6318 - accuracy: 0.8864 - val_loss: 0.7415 - val_accuracy: 0.8410\n",
      "Epoch 6/50\n",
      "1382/1382 [==============================] - 1s 555us/step - loss: 0.5849 - accuracy: 0.9074 - val_loss: 0.7527 - val_accuracy: 0.8728\n",
      "Epoch 7/50\n",
      "1382/1382 [==============================] - 1s 550us/step - loss: 0.5682 - accuracy: 0.9103 - val_loss: 0.7932 - val_accuracy: 0.8613\n",
      "Epoch 8/50\n",
      "1382/1382 [==============================] - 1s 552us/step - loss: 0.5291 - accuracy: 0.9378 - val_loss: 0.9311 - val_accuracy: 0.8931\n",
      "Epoch 9/50\n",
      "1382/1382 [==============================] - 1s 550us/step - loss: 0.4849 - accuracy: 0.9530 - val_loss: 0.8615 - val_accuracy: 0.8815\n",
      "Epoch 10/50\n",
      "1382/1382 [==============================] - 1s 551us/step - loss: 0.4947 - accuracy: 0.9486 - val_loss: 0.8111 - val_accuracy: 0.8410\n",
      "Epoch 11/50\n",
      "1382/1382 [==============================] - 1s 553us/step - loss: 0.4409 - accuracy: 0.9609 - val_loss: 0.9943 - val_accuracy: 0.8728\n",
      "Epoch 12/50\n",
      "1382/1382 [==============================] - 1s 550us/step - loss: 0.4068 - accuracy: 0.9740 - val_loss: 1.1666 - val_accuracy: 0.8844\n",
      "Epoch 13/50\n",
      "1382/1382 [==============================] - 1s 553us/step - loss: 0.4008 - accuracy: 0.9696 - val_loss: 2.1828 - val_accuracy: 0.7370\n",
      "Epoch 14/50\n",
      "1382/1382 [==============================] - 1s 551us/step - loss: 0.4036 - accuracy: 0.9682 - val_loss: 1.3166 - val_accuracy: 0.8902\n",
      "Epoch 15/50\n",
      "1382/1382 [==============================] - 1s 553us/step - loss: 0.3849 - accuracy: 0.9747 - val_loss: 1.3794 - val_accuracy: 0.8728\n",
      "Epoch 16/50\n",
      "1382/1382 [==============================] - 1s 553us/step - loss: 0.3740 - accuracy: 0.9805 - val_loss: 1.4366 - val_accuracy: 0.8786\n",
      "Epoch 17/50\n",
      "1382/1382 [==============================] - 1s 553us/step - loss: 0.3386 - accuracy: 0.9819 - val_loss: 1.4103 - val_accuracy: 0.8757\n",
      "Epoch 18/50\n",
      "1382/1382 [==============================] - 1s 556us/step - loss: 0.3595 - accuracy: 0.9826 - val_loss: 1.0225 - val_accuracy: 0.8555\n",
      "Epoch 19/50\n",
      "1382/1382 [==============================] - 1s 555us/step - loss: 0.3774 - accuracy: 0.9624 - val_loss: 1.7027 - val_accuracy: 0.8324\n",
      "Epoch 20/50\n",
      "1382/1382 [==============================] - 1s 551us/step - loss: 0.3552 - accuracy: 0.9776 - val_loss: 1.0900 - val_accuracy: 0.8902\n",
      "Epoch 21/50\n",
      "1382/1382 [==============================] - 1s 554us/step - loss: 0.3130 - accuracy: 0.9848 - val_loss: 1.3218 - val_accuracy: 0.8786\n",
      "Epoch 22/50\n",
      "1382/1382 [==============================] - 1s 554us/step - loss: 0.2982 - accuracy: 0.9863 - val_loss: 1.4980 - val_accuracy: 0.8353\n",
      "Epoch 23/50\n",
      "1382/1382 [==============================] - 1s 553us/step - loss: 0.2839 - accuracy: 0.9848 - val_loss: 1.2390 - val_accuracy: 0.8642\n",
      "Epoch 24/50\n",
      "1382/1382 [==============================] - 1s 557us/step - loss: 0.2871 - accuracy: 0.9819 - val_loss: 2.0681 - val_accuracy: 0.8237\n",
      "Epoch 25/50\n",
      "1382/1382 [==============================] - 1s 555us/step - loss: 0.2838 - accuracy: 0.9848 - val_loss: 1.3504 - val_accuracy: 0.8555\n",
      "Epoch 26/50\n",
      "1382/1382 [==============================] - 1s 556us/step - loss: 0.2858 - accuracy: 0.9819 - val_loss: 1.5133 - val_accuracy: 0.7370\n",
      "Epoch 27/50\n",
      "1382/1382 [==============================] - 1s 555us/step - loss: 0.3439 - accuracy: 0.9754 - val_loss: 1.8361 - val_accuracy: 0.8121\n",
      "Epoch 28/50\n",
      "1382/1382 [==============================] - 1s 549us/step - loss: 0.2859 - accuracy: 0.9906 - val_loss: 1.4441 - val_accuracy: 0.8815\n",
      "Epoch 29/50\n",
      "1382/1382 [==============================] - 1s 552us/step - loss: 0.2600 - accuracy: 0.9906 - val_loss: 1.7331 - val_accuracy: 0.8526\n",
      "Epoch 30/50\n",
      "1382/1382 [==============================] - 1s 553us/step - loss: 0.2598 - accuracy: 0.9906 - val_loss: 1.3989 - val_accuracy: 0.8757\n",
      "Epoch 31/50\n",
      "1382/1382 [==============================] - 1s 553us/step - loss: 0.2445 - accuracy: 0.9913 - val_loss: 1.5448 - val_accuracy: 0.8902\n",
      "Epoch 32/50\n",
      "1382/1382 [==============================] - 1s 552us/step - loss: 0.2458 - accuracy: 0.9899 - val_loss: 1.7644 - val_accuracy: 0.7861\n",
      "Epoch 33/50\n",
      "1382/1382 [==============================] - 1s 551us/step - loss: 0.2307 - accuracy: 0.9920 - val_loss: 1.3860 - val_accuracy: 0.8873\n",
      "Epoch 34/50\n",
      "1382/1382 [==============================] - 1s 553us/step - loss: 0.2310 - accuracy: 0.9906 - val_loss: 1.1895 - val_accuracy: 0.8902\n",
      "Epoch 35/50\n",
      "1382/1382 [==============================] - 1s 550us/step - loss: 0.2436 - accuracy: 0.9884 - val_loss: 1.2791 - val_accuracy: 0.8844\n",
      "Epoch 36/50\n",
      "1382/1382 [==============================] - 1s 552us/step - loss: 0.2557 - accuracy: 0.9884 - val_loss: 0.9841 - val_accuracy: 0.8757\n",
      "Epoch 37/50\n",
      "1382/1382 [==============================] - 1s 555us/step - loss: 0.2436 - accuracy: 0.9870 - val_loss: 0.9692 - val_accuracy: 0.8728\n",
      "Epoch 38/50\n",
      "1382/1382 [==============================] - 1s 553us/step - loss: 0.2937 - accuracy: 0.9797 - val_loss: 1.3020 - val_accuracy: 0.8671\n",
      "Epoch 39/50\n",
      "1382/1382 [==============================] - 1s 558us/step - loss: 0.2837 - accuracy: 0.9848 - val_loss: 0.8101 - val_accuracy: 0.8757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50\n",
      "1382/1382 [==============================] - 1s 556us/step - loss: 0.2384 - accuracy: 0.9920 - val_loss: 0.8094 - val_accuracy: 0.8728\n",
      "Epoch 41/50\n",
      "1382/1382 [==============================] - 1s 555us/step - loss: 0.2207 - accuracy: 0.9935 - val_loss: 0.7609 - val_accuracy: 0.8728\n",
      "Epoch 42/50\n",
      "1382/1382 [==============================] - 1s 556us/step - loss: 0.2066 - accuracy: 0.9913 - val_loss: 0.9650 - val_accuracy: 0.8613\n",
      "Epoch 43/50\n",
      "1382/1382 [==============================] - 1s 558us/step - loss: 0.2315 - accuracy: 0.9942 - val_loss: 0.7128 - val_accuracy: 0.8786\n",
      "Epoch 44/50\n",
      "1382/1382 [==============================] - 1s 555us/step - loss: 0.2131 - accuracy: 0.9942 - val_loss: 0.8995 - val_accuracy: 0.8844\n",
      "Epoch 45/50\n",
      "1382/1382 [==============================] - 1s 558us/step - loss: 0.2161 - accuracy: 0.9906 - val_loss: 1.3349 - val_accuracy: 0.7775\n",
      "Epoch 46/50\n",
      "1382/1382 [==============================] - 1s 556us/step - loss: 0.2318 - accuracy: 0.9863 - val_loss: 0.9056 - val_accuracy: 0.8728\n",
      "Epoch 47/50\n",
      "1382/1382 [==============================] - 1s 555us/step - loss: 0.2241 - accuracy: 0.9884 - val_loss: 0.9675 - val_accuracy: 0.8786\n",
      "Epoch 48/50\n",
      "1382/1382 [==============================] - 1s 576us/step - loss: 0.2116 - accuracy: 0.9928 - val_loss: 1.1832 - val_accuracy: 0.8382\n",
      "Epoch 49/50\n",
      "1382/1382 [==============================] - 1s 547us/step - loss: 0.2015 - accuracy: 0.9935 - val_loss: 0.9993 - val_accuracy: 0.8526\n",
      "Epoch 50/50\n",
      "1382/1382 [==============================] - 1s 558us/step - loss: 0.2076 - accuracy: 0.9913 - val_loss: 0.8464 - val_accuracy: 0.8699\n",
      "346/346 [==============================] - 0s 162us/step\n",
      "346/346 [==============================] - 0s 127us/step\n",
      " \n",
      "Train on 1382 samples, validate on 346 samples\n",
      "Epoch 1/50\n",
      "1382/1382 [==============================] - 1s 986us/step - loss: 1.2761 - accuracy: 0.5767 - val_loss: 0.9364 - val_accuracy: 0.7023\n",
      "Epoch 2/50\n",
      "1382/1382 [==============================] - 1s 554us/step - loss: 0.8957 - accuracy: 0.6816 - val_loss: 0.8567 - val_accuracy: 0.7746\n",
      "Epoch 3/50\n",
      "1382/1382 [==============================] - 1s 552us/step - loss: 0.8296 - accuracy: 0.7460 - val_loss: 0.8272 - val_accuracy: 0.5809\n",
      "Epoch 4/50\n",
      "1382/1382 [==============================] - 1s 553us/step - loss: 0.7346 - accuracy: 0.7757 - val_loss: 0.8381 - val_accuracy: 0.5723\n",
      "Epoch 5/50\n",
      "1382/1382 [==============================] - 1s 553us/step - loss: 0.6962 - accuracy: 0.8126 - val_loss: 1.1204 - val_accuracy: 0.5231\n",
      "Epoch 6/50\n",
      "1382/1382 [==============================] - 1s 556us/step - loss: 0.7089 - accuracy: 0.8423 - val_loss: 0.8290 - val_accuracy: 0.6069\n",
      "Epoch 7/50\n",
      "1382/1382 [==============================] - 1s 553us/step - loss: 0.6590 - accuracy: 0.8480 - val_loss: 0.6837 - val_accuracy: 0.7803\n",
      "Epoch 8/50\n",
      "1382/1382 [==============================] - 1s 553us/step - loss: 0.6281 - accuracy: 0.8828 - val_loss: 0.7250 - val_accuracy: 0.7803\n",
      "Epoch 9/50\n",
      "1382/1382 [==============================] - 1s 552us/step - loss: 0.6095 - accuracy: 0.8878 - val_loss: 0.8910 - val_accuracy: 0.6127\n",
      "Epoch 10/50\n",
      "1382/1382 [==============================] - 1s 548us/step - loss: 0.5811 - accuracy: 0.9081 - val_loss: 0.6594 - val_accuracy: 0.8006\n",
      "Epoch 11/50\n",
      "1382/1382 [==============================] - 1s 550us/step - loss: 0.5767 - accuracy: 0.9030 - val_loss: 0.7995 - val_accuracy: 0.6965\n",
      "Epoch 12/50\n",
      "1382/1382 [==============================] - 1s 550us/step - loss: 0.5692 - accuracy: 0.9059 - val_loss: 0.6650 - val_accuracy: 0.8150\n",
      "Epoch 13/50\n",
      "1382/1382 [==============================] - 1s 552us/step - loss: 0.5391 - accuracy: 0.9153 - val_loss: 0.6810 - val_accuracy: 0.7861\n",
      "Epoch 14/50\n",
      "1382/1382 [==============================] - 1s 550us/step - loss: 0.5927 - accuracy: 0.9096 - val_loss: 0.7094 - val_accuracy: 0.7399\n",
      "Epoch 15/50\n",
      "1382/1382 [==============================] - 1s 546us/step - loss: 0.5138 - accuracy: 0.9219 - val_loss: 0.7068 - val_accuracy: 0.7312\n",
      "Epoch 16/50\n",
      "1382/1382 [==============================] - 1s 549us/step - loss: 0.4958 - accuracy: 0.9313 - val_loss: 0.5949 - val_accuracy: 0.8150\n",
      "Epoch 17/50\n",
      "1382/1382 [==============================] - 1s 550us/step - loss: 0.5105 - accuracy: 0.9023 - val_loss: 0.6302 - val_accuracy: 0.8237\n",
      "Epoch 18/50\n",
      "1382/1382 [==============================] - 1s 550us/step - loss: 0.5145 - accuracy: 0.9088 - val_loss: 0.7182 - val_accuracy: 0.6936\n",
      "Epoch 19/50\n",
      "1382/1382 [==============================] - 1s 548us/step - loss: 0.4887 - accuracy: 0.9153 - val_loss: 0.7726 - val_accuracy: 0.6908\n",
      "Epoch 20/50\n",
      "1382/1382 [==============================] - 1s 548us/step - loss: 0.4725 - accuracy: 0.9219 - val_loss: 0.6376 - val_accuracy: 0.8035\n",
      "Epoch 21/50\n",
      "1382/1382 [==============================] - 1s 552us/step - loss: 0.4888 - accuracy: 0.9175 - val_loss: 0.7493 - val_accuracy: 0.7023\n",
      "Epoch 22/50\n",
      "1382/1382 [==============================] - 1s 550us/step - loss: 0.4724 - accuracy: 0.9088 - val_loss: 0.6298 - val_accuracy: 0.7890\n",
      "Epoch 23/50\n",
      "1382/1382 [==============================] - 1s 551us/step - loss: 0.4582 - accuracy: 0.9139 - val_loss: 0.6526 - val_accuracy: 0.7457\n",
      "Epoch 24/50\n",
      "1382/1382 [==============================] - 1s 550us/step - loss: 0.4457 - accuracy: 0.9226 - val_loss: 0.5918 - val_accuracy: 0.8035\n",
      "Epoch 25/50\n",
      "1382/1382 [==============================] - 1s 550us/step - loss: 0.4360 - accuracy: 0.9255 - val_loss: 0.6443 - val_accuracy: 0.8035\n",
      "Epoch 26/50\n",
      "1382/1382 [==============================] - 1s 550us/step - loss: 0.4186 - accuracy: 0.9334 - val_loss: 0.6389 - val_accuracy: 0.7919\n",
      "Epoch 27/50\n",
      "1382/1382 [==============================] - 1s 555us/step - loss: 0.4489 - accuracy: 0.9190 - val_loss: 0.5620 - val_accuracy: 0.8237\n",
      "Epoch 28/50\n",
      "1382/1382 [==============================] - 1s 550us/step - loss: 0.4798 - accuracy: 0.8857 - val_loss: 0.6066 - val_accuracy: 0.7948\n",
      "Epoch 29/50\n",
      "1382/1382 [==============================] - 1s 551us/step - loss: 0.4476 - accuracy: 0.9146 - val_loss: 0.5614 - val_accuracy: 0.8237\n",
      "Epoch 30/50\n",
      "1382/1382 [==============================] - 1s 550us/step - loss: 0.4473 - accuracy: 0.9182 - val_loss: 0.6592 - val_accuracy: 0.7803\n",
      "Epoch 31/50\n",
      "1382/1382 [==============================] - 1s 551us/step - loss: 0.4069 - accuracy: 0.9269 - val_loss: 0.6659 - val_accuracy: 0.7572\n",
      "Epoch 32/50\n",
      "1382/1382 [==============================] - 1s 549us/step - loss: 0.4264 - accuracy: 0.9291 - val_loss: 0.6035 - val_accuracy: 0.8150\n",
      "Epoch 33/50\n",
      "1382/1382 [==============================] - 1s 552us/step - loss: 0.4956 - accuracy: 0.9038 - val_loss: 0.6151 - val_accuracy: 0.7948\n",
      "Epoch 34/50\n",
      "1382/1382 [==============================] - 1s 550us/step - loss: 0.4389 - accuracy: 0.9175 - val_loss: 0.5799 - val_accuracy: 0.8121\n",
      "Epoch 35/50\n",
      "1382/1382 [==============================] - 1s 550us/step - loss: 0.4350 - accuracy: 0.9146 - val_loss: 0.5954 - val_accuracy: 0.8035\n",
      "Epoch 36/50\n",
      "1382/1382 [==============================] - 1s 551us/step - loss: 0.4174 - accuracy: 0.9204 - val_loss: 0.5856 - val_accuracy: 0.8064\n",
      "Epoch 37/50\n",
      "1382/1382 [==============================] - 1s 551us/step - loss: 0.4036 - accuracy: 0.9204 - val_loss: 0.7505 - val_accuracy: 0.8035\n",
      "Epoch 38/50\n",
      "1382/1382 [==============================] - 1s 550us/step - loss: 0.4165 - accuracy: 0.9211 - val_loss: 0.5875 - val_accuracy: 0.8150\n",
      "Epoch 39/50\n",
      "1382/1382 [==============================] - 1s 548us/step - loss: 0.4693 - accuracy: 0.9074 - val_loss: 0.6301 - val_accuracy: 0.7572\n",
      "Epoch 40/50\n",
      "1382/1382 [==============================] - 1s 552us/step - loss: 0.4338 - accuracy: 0.9088 - val_loss: 0.5914 - val_accuracy: 0.7977\n",
      "Epoch 41/50\n",
      "1382/1382 [==============================] - 1s 553us/step - loss: 0.3897 - accuracy: 0.9291 - val_loss: 0.5846 - val_accuracy: 0.8266\n",
      "Epoch 42/50\n",
      "1382/1382 [==============================] - 1s 550us/step - loss: 0.4028 - accuracy: 0.9197 - val_loss: 0.5521 - val_accuracy: 0.8295\n",
      "Epoch 43/50\n",
      "1382/1382 [==============================] - 1s 551us/step - loss: 0.3881 - accuracy: 0.9226 - val_loss: 0.5626 - val_accuracy: 0.8064\n",
      "Epoch 44/50\n",
      "1382/1382 [==============================] - 1s 553us/step - loss: 0.4037 - accuracy: 0.9182 - val_loss: 0.5787 - val_accuracy: 0.8121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50\n",
      "1382/1382 [==============================] - 1s 553us/step - loss: 0.3843 - accuracy: 0.9240 - val_loss: 0.5904 - val_accuracy: 0.7919\n",
      "Epoch 46/50\n",
      "1382/1382 [==============================] - 1s 553us/step - loss: 0.3762 - accuracy: 0.9262 - val_loss: 0.6512 - val_accuracy: 0.7543\n",
      "Epoch 47/50\n",
      "1382/1382 [==============================] - 1s 550us/step - loss: 0.9833 - accuracy: 0.5224 - val_loss: 0.9763 - val_accuracy: 0.4971\n",
      "Epoch 48/50\n",
      "1382/1382 [==============================] - 1s 553us/step - loss: 0.9109 - accuracy: 0.5304 - val_loss: 0.8338 - val_accuracy: 0.6994\n",
      "Epoch 49/50\n",
      "1382/1382 [==============================] - 1s 553us/step - loss: 0.7545 - accuracy: 0.7576 - val_loss: 1.7143 - val_accuracy: 0.5376\n",
      "Epoch 50/50\n",
      "1382/1382 [==============================] - 1s 550us/step - loss: 0.6498 - accuracy: 0.8618 - val_loss: 0.7045 - val_accuracy: 0.7832\n",
      "346/346 [==============================] - 0s 159us/step\n",
      "346/346 [==============================] - 0s 127us/step\n",
      " \n",
      "Accuracy: 81.45\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAFvCAYAAAC2K5dYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deXwV1f3/8dcnCUFWRdkkQQQB2VSEsIgbalGoKGoVcas7osVf69JKrV+/1n7b4vJ1x1Jx/bohroAi2GpdQFEWAQUBkaUEENlcQCkmfH5/3AEvISQTksxkwvvJYx6POzPnnjlDbvK5n3Nmzpi7IyIiEkZG3A0QEZHkUNAQEZHQFDRERCQ0BQ0REQlNQUNERELLirsBIiJ7msz6LdwLfihXHf7Dmknu3reCmhSagoaISMS84AdqHjywXHVsnjWiYQU1p0wUNEREImdgyRwdSGarRUQkFso0RESiZoBZ3K3YLQoaIiJxSGj3lIKGiEgcEpppJDPUiYhILJRpiIhELrlXTyloiIjEQd1TIiJS3SnTEBGJmqHuKRERCcsS2z2loCEiEoeEZhrJbLWIiMRCmYaISBzUPSUiIuEk9z6NZLZaqgUzq2Vm483sGzN7vhz1nGdmb1Rk2+JiZkeb2YK42yGyKwoaUiozO9fMppvZRjNbZWavm9lRFVD1mUATYD93P2t3K3H3p939xApoT6UyMzez1iWVcff33P3gqNokMdk2y215ljCHMetrZgvMbJGZDStm/97BF7fZZjbXzC4urU4FDSmRmV0L3AP8hdQf+AOAB4EBFVB9C2ChuxdUQF2JZ2bqLt6TWEb5ltKqN8sERgD9gA7AOWbWoUixXwHz3P0woDfwv2aWXVK9ChqyS2a2N3Ar8Ct3f8ndN7n7j+4+3t1/G5SpaWb3mNnKYLnHzGoG+3qbWb6ZXWdmXwVZysXBvj8CNwNnBxnMpWZ2i5k9lXb8A4Nv51nB+kVmttjMvjOzJWZ2Xtr2yWnv62Vm04Jur2lm1itt39tm9iczmxLU84aZFfvYzLT2/y6t/aeZ2c/NbKGZrTezG9PKdzezD8zs66DsA9t+Ac3s3aDY7OB8z06r/wYz+xJ4bNu24D0HBcfoEqw3M7O1Zta7XD9YqQKs0oMG0B1Y5O6L3X0LMJqdv+w5UM/MDKgLrAdK/BKnoCElOQLYC3i5hDJ/AHoCnYHDSH1Qb0rb3xTYG8gBLgVGmFkDd/9vUtnLc+5e190fKakhZlYHuA/o5+71gF7ArGLK7Qu8FpTdD7gLeM3M9ksrdi5wMdAYyAauL+HQTUn9H+SQCnKjgPOBrsDRwM1m1iooWwhcAzQk9X93AnAVgLsfE5Q5LDjf59Lq35dU1jU4/cDu/gVwA/C0mdUGHgMed/e3S2iv7DkaBt3G25bBRfbnAMvT1vODbekeANoDK4FPgF+7+9aSDqqgISXZD1hbSvfRecCt7v6Vu68B/ghckLb/x2D/j+4+AdgI7G6f/Vagk5nVcvdV7j63mDInA5+7+5PuXuDuzwLzgVPSyjzm7gvd/QdgDKmAtys/An929x9JfVNrCNzr7t8Fx58LHArg7jPcfWpw3KXA34FjQ5zTf7v7f4L27MDdRwGfAx8C+5MK0lIdZFj5ltTvZl7a8lCRIxQ38OFF1k8i9eWrGanfgwfMrH6Jzd7N05U9wzpS32ZK6mtvBixLW18WbNteR5Gg8z2pNLhM3H0TcDYwBFhlZq+ZWbsQ7dnWpvRvWF+WoT3r3L0weL3tj/rqtP0/bHu/mbU1s1fN7Esz+5ZUJlVs11eaNe6+uZQyo4BOwP3u/p9SykoSbJt7qnK7p/KB5mnruaQyinQXAy95yiJgCVDc79V2ChpSkg+AzcBpJZRZSaprZZsD2PmDGdYmoHbaetP0ne4+yd37kPrGPZ/UH9PS2rOtTSt2s01l8TdS7Wrj7vWBGyn+2166ot/8dmBmdUldiPAIcEvQ/SbVQeVfPTUNaGNmLYOxtUHAuCJl/k2qGxUza0KqF2BxSZUqaMguufs3pPrxRwQDwLXNrIaZ9TOz24NizwI3mVmjYED5ZuCpXdVZilnAMWZ2QDAI//ttO8ysiZmdGoxt/IdUN1dhMXVMANpa6jLhLDM7m9SVI6/uZpvKoh7wLbAxyIKuLLJ/NdBqp3eV7F5ghrtfRmqsZmS5Wyl7hCDDHwpMAj4Dxrj7XDMbYmZDgmJ/AnqZ2SfAm8AN7r62pHp1iZ+UyN3vMrPVpAa3nwa+A2YAfw6K/A9QH5gTrD8fbNudY/3DzJ4L6loL3AacGuzOAK4DniT17XwWwSBzkTrWmVl/Un9s/wYsAvqX9otQQa4HHgJ+B3wMPAccn7b/FuAJM6tFatD7q5IqM7MBQF/gkGDTtcAsMzvP3Z+u2KZLtKK5IzwYR5xQZNvItNcrgTLd42TuJWbHIiJSwTLq53rNHleXq47N/xw2w93zKqhJoal7SkREQlP3lIhIHBI6YaGChohI1Mowf1RVo6AhIhIHZRqVx7LruO3VIO5mSIIdclCTuJsg1cCcWTPXunujuNsRp2QEjb0aULN7+a40kD3bGy9dG3cTpBpound20dkGdp+6p0REJJzkPrlPQUNEJA4JzTSSGepERCQWyjRERKK2bZbbBFLQEBGJXHLHNJLZahERiYUyDRGROCR0IFxBQ0QkDgntnlLQEBGJQ0IzjWSGOhERiYUyDRGRqFlyr55S0BARiYO6p0REpLpTpiEiEgNLaKahoCEiEjFDQUNERMKyYEkgjWmIiEhoyjRERCJn6p4SEZHwFDRERCS0pAYNjWmIiEhoyjRERGKQ1ExDQUNEJGq65FZERPYEyjRERCJmuuRWRETKQkFDRERCS2rQ0JiGiIiEpkxDRCQGSc00FDRERKKW4EtuFTRERGKQ1ExDYxoiIhKaMg0RkYjpPg0RESmTpAYNdU+JiEhoyjREROKQzERDmYaISOQs1T1VniXUYcz6mtkCM1tkZsOK2f9bM5sVLJ+aWaGZ7VtSnQoaIiIxqOygYWaZwAigH9ABOMfMOqSXcfc73L2zu3cGfg+84+7rS6pXQUNEpHrqDixy98XuvgUYDQwoofw5wLOlVaqgISISgwrINBqa2fS0ZXCRQ+QAy9PW84NtxbWlNtAXeLG0dmsgXEQkYhV0n8Zad88r8TA7812UPQWYUlrXFChoiIjEo/KvnsoHmqet5wIrd1F2ECG6pkDdUyIi1dU0oI2ZtTSzbFKBYVzRQma2N3AsMDZMpco0RESiZpV/R7i7F5jZUGASkAk86u5zzWxIsH9kUPR04A133xSmXgUNEZEYRDGNiLtPACYU2TayyPrjwONh61T3lIiIhKZMQ0QkBkmdsFBBQ0QkDsmMGQoaIiJxSGqmoTENEREJTZmGiEjEyjJTbVWjoCEiEoOkBg11T4mISGjKNEREYpDUTENBQ0QkDsmMGQoaIiJxSGqmoTENEREJTZmGiEjUIpjltrIoaIiIRMyAhMYMBQ0Rkegl9+Y+jWmIiEhoyjRERGKQ0ERDQUNEJA7qnpJy6dOtJbMfu4xPnxjM9YN67LT/moHdmTryIqaOvIjpoy5h46Tf0qDeXgBc/Ys8Zjx8KdNHXcITN55CzRqZABzSqhFv33c+00Zdwgt/+gX1amcDsG/9vZh45yDWjL+Gu4f+LLqTlEr11j8ncWTXjvTs3J7777p9p/0vjnmG43p14bheXejf5xjmfjJ7+77f/OpyOh6Uw7E9O+/wng3r1zNwQD+OOLwDAwf04+sNGwDYsmULv77qMnofcTjHH9mVKe+9U7knJ1WGgkYVkJFh3HN1Hwbc+DyHX/owZx3XgXYH7LdDmbvHfETPIY/Tc8jj3PzIO7w3ZzkbvttMs/3qctVpXTnyqifIu/xRMjMzOOu49gD87bp+3PTwO3S7/FHGTVnINQNTwWjzlkJuffw9fv/3f0V+rlI5CgsL+f11v+aZF8bz7kezefnF51gwf94OZQ5o0ZKXX3uTf70/k2t+dyPX//qq7fvOPveXPPviqzvVe//dt3P0scfxwcfzOPrY47j/7lQweuqJRwB4+4OPee6V1/njH37H1q1bK/EMqxlLdU+VZ4mLgkYV0O3g/fli5dcsXfUNPxZs5fm3P6P/kW12WX7g8R0Y86/Ptq9nZWZQq2YWmRlGrZpZrFq3EYA2ufsyec5yAN6asZTTjm4LwPebf+T9T1eweUtBJZ6VROnjGdNo2eogWrRsRXZ2NqedMZBJr43foUy3HkewT4MGAHTN68GqlSu27zviyKO370s3acJ4Bp57AQADz72Aia+NA2Dh/M84+tjjAGjUqDH1996HWR/PqJRzq46M1JfF8ixxUdCoApo1rEf+V99uX1+x5jty9qtbbNlaNbPok9eSV95bAMDKdRu55/mPWPjMlSwZM5RvN/2HN2csBWDe0rX079UagDOOaUduo3qVeyISm1UrV9AsJ3f7+v45OaxatXKX5Z958jGO/9lJpda7Zs1XNGm6PwBNmu7P2jVrAOjY6VAmvjaegoICli1dwpzZM1mZv7ycZ7FnUaZRhJltLLJ+kZk9ELy+xcxWmNmsYBleWe1IguI+AL6Lsicf0ZoP5q5gw3ebAdinbk3692pD+/NH0ursEdTZqwaDTugAwBV3TuCKU7sw5cELqVs7my0F6j6ortx3/sTsaqB18rtv8+yTj3HTrX/Z7eOdc8FFNMvJ5aTePbn599eR1/0IsrJ0Xc2eIM6f8t3ufmeMx68yVqz5jtzG9bev5zSqx8p1G4ste1bv9jz/r5/6qo/vciBLv/yGtd/8AMArkxfSs2MOo9+cx8Ll6zll2BgAWuc0oF+PVpV4FhKnZjm5rFyRv3191YoVNA0yhHTzPp3DdVcP4ZkXx7HvvvvttL+oRo0as/rLVTRpuj+rv1xFw0aNAMjKyuLWv/7069u/zzG0PKh1BZzJnkNXT8lum75gFa1zGtCi6d7UyMrgrN7tee39RTuVq18nm6MObc74tH3Lv/qW7u2bUatmKv4fd3gLFvx7HQCN9qkNpDKZYef3YtSrsyI4G4lD5y55LP5iEcuWLmHLli288tIYTvx5/x3K5C//N5ecfzYPPPQYB7VuG6reE/udwphnngRgzDNPctLPTwHg+++/Z9OmTQC889Y/ycrK4uB2HSrwjKq5BA+EV2amUcvM0v9K7QuMS1u/xszOD17f4O6TKrEtVVrhVuea+//B+OEDycwwnpj4CZ8tW8tl/VOXPz4c/LE/9ci2vDljKd9v/nH7e6fNX8XL7y7gg79dREHhVmYvWs0jr6UupRx4XHuuGNAFgLGTF/J/Ez/Z/r75Tw2hXu1ssmtkcsqRbel/w3PMD4KNJE9WVhZ/ufMezjnjZAoLt3LO+RfSrn1HnnjkIQAuvHQwd932ZzasX8ew664GIDMzizfemQrAkEvO5/3J77J+3VoOb9+S3/7+Zs795cVcfe1vGXzhuTzz5OPk5DZn1BPPArB2zVecc8bJZGRk0HT/HO7/+2PxnHhCpeaeSmamYcX1hVZIxWYb3b1u2vpFQJ67DzWzW4CNJXVPmdlgYDAAe+3Tda8jh1VKO2XPsPSla+NuglQDTffOnuHueeWtp3aztt76sgfLVccnf+pTIW0pqyo7cuXuDwEPAWTUz62cyCYiEovkTlhYZYOGiEh1ltCYoYFwEREJr9IyjfTxjGD9ceDx4PUtlXVcEZEkUPeUiIiEE/Nls+WhoCEiErEkX3KrMQ0REQlNmYaISAwSmmgoaIiIxEHdUyIiUu0p0xARiUFCEw0FDRGRyFlyu6cUNEREIpa65DbuVuwejWmIiEhoyjRERCKnWW5FRKQMEhoz1D0lIhIHMyvXEvIYfc1sgZktMrNin2RnZr3NbJaZzTWzd0qrU5mGiEg1ZGaZwAigD5APTDOzce4+L63MPsCDQF93/7eZNS6tXmUaIiJRC2a5Lc8SQndgkbsvdvctwGhgQJEy5wIvufu/Adz9q9IqVdAQEYnYtlluy9k91dDMpqctg4scJgdYnraeH2xL1xZoYGZvm9kMM/tlaW1X95SISDKtdfe8EvYXl494kfUsoCtwAlAL+MDMprr7wl1VqqAhIhKDCC65zQeap63nAiuLKbPW3TcBm8zsXeAwYJdBQ91TIiIxiGBMYxrQxsxamlk2MAgYV6TMWOBoM8sys9pAD+CzkipVpiEiEoPKzjTcvcDMhgKTgEzgUXefa2ZDgv0j3f0zM5sIzAG2Ag+7+6cl1augISJSTbn7BGBCkW0ji6zfAdwRtk4FDRGRqIXvYqpyFDRERCJmmntKRETKIqExQ1dPiYhIeMo0RERikJHQVENBQ0QkBgmNGeqeEhGR8JRpiIhELHVXdzJTDQUNEZEYZCQzZihoiIjEIamZhsY0REQkNGUaIiIxSGiioaAhIhI1IzWVSBKpe0pEREJTpiEiEgNdPSUiIuGYZrkVEZEySGjM0JiGiIiEp0xDRCRihma5FRGRMkhozFDQEBGJQ1IHwjWmISIioSnTEBGJWGpq9LhbsXsUNEREYpDUgXB1T4mISGjKNEREYpDMPENBQ0QkFkm9ekpBQ0QkYqmb++Juxe7RmIaIiISmTENEJGqa5VZERMoioTFDQUNEJA5JzTQ0piEiIqEp0xARiViSr55S0BARiYG6p0REpNoLnWmYWU13/09lNkZEZE+RzDwjRKZhZt3N7BPg82D9MDO7v9JbJiJSTZmlZrktzxKXMN1T9wH9gXUA7j4bOK4yGyUiUt1te6bG7i5xCRM0Mtx9WZFthZXRGBERqdrCjGksN7PugJtZJnA1sLBymyUiUr0l9eqpMEHjSlJdVAcAq4F/BttERGQ3JTRmlB403P0rYFAEbRER2SMY8Q5ml0epQcPMRgFedLu7D66UFomISIUws77AvUAm8LC7Dy+yvzcwFlgSbHrJ3W8tqc4w3VP/THu9F3A6sDxkm0VEpKgIroAKxqBHAH2AfGCamY1z93lFir7n7v3D1hume+q5Ig15EvhH2ANUhMPbNGXKxBuiPKRUMw26DY27CSI7iGAgvDuwyN0XB8cbDQwAigaNMtmdaURaAi3Kc1ARESm3hmY2PW0pOmSQw469QvnBtqKOMLPZZva6mXUs7aBhxjQ28NOYRgawHhhW2vtERGTXKmDiv7XunlfC/uJSmaLj0zOBFu6+0cx+DrwCtCnpoCUGDUvlT4cBK4JNW919p0FxEREJz4ikeyofaJ62ngusTC/g7t+mvZ5gZg+aWUN3X7urSksMdkGAeNndC4NFAUNEpAJkWPmWEKYBbcyspZllk7p1Ylx6ATNrGiQHBDdxZxBMGbUrYa6e+sjMurj7zFDNFBGR2Ll7gZkNBSaRuuT2UXefa2ZDgv0jgTOBK82sAPgBGFRacrDLoGFmWe5eABwFXG5mXwCbSGVW7u5dKuLERET2RFE8uc/dJwATimwbmfb6AeCBstRZUqbxEdAFOK0sFYqISMlSM9VWvzvCDcDdv4ioLSIiUsWVFDQamdm1u9rp7ndVQntERPYIUXRPVYaSgkYmUJfkPpVQRKTKSmjvVIlBY1VpE1eJiEjZGSR2ltuS7tNI5hmJiEilKSnTOCGyVoiI7GEqYBqRWOwyaLj7+igbIiKyJ0lo71SoO8JFRKQCmSX3yX1JzZBERCQGyjRERGKQ0ERDQUNEJA5JvblP3VMiIhKaMg0RkYgl+eY+BQ0RkRgkNGYoaIiIRC780/eqHI1piIhIaMo0RERiYAmd3k9BQ0QkYqmB8LhbsXsUNEREYpDUoKExDRERCU2ZhohIDCyh19wqaIiIRCzJYxrqnhIRkdCUaYiIRM10R7iIiJSB5p4SEZFQNKYhIiJ7BGUaIiIxSGjvlIKGiEj0jIyEzj2l7ikREQlNmYaISMQMdU+JiEhYCX4Ik4KGiEgMknqfhsY0REQkNGUaIiIR05iGiIiUSVK7pxQ0RERikNCYoTENEREJT5mGiEjEjOR+Y1fQEBGJmiX3ca9JDXYiIhIDZRoiIjFIZp6hTENEJHKphzBZuZZQxzHra2YLzGyRmQ0roVw3Mys0szNLq1NBQ0QkBlbOpdT6zTKBEUA/oANwjpl12EW524BJYdqtoCEiUj11Bxa5+2J33wKMBgYUU+5q4EXgqzCVKmiIiMTArHwL0NDMpqctg4scIgdYnraeH2xLa4PlAKcDI8O2WwPhIiKRs4q45Hatu+eVeJCdeZH1e4Ab3L0wbHsUNEREIhbRzX35QPO09VxgZZEyecDoIGA0BH5uZgXu/squKlXQEBGpnqYBbcysJbACGAScm17A3Vtue21mjwOvlhQwQEFDRCQWlX1HuLsXmNlQUldFZQKPuvtcMxsS7A89jpFOQUNEJAZR3Nzn7hOACUW2FRss3P2iMHXq6ikREQlNmYaISNQSPGGhgoaISMQ0NbqIiJRJUjONpAY7ERGJgTINEZEYJDPPUNAQEYlFQnun1D1VVbwxaSKHdjyYju1ac8ftw3fav2D+fI496gj2rlOTu++6c4d9X3/9NeecfSaHdWpH50PaM/WDDwBYv349J/ftQ6f2bTi5bx82bNgAwLSPPqJH18706NqZ7l0OY+wrL1f+CUql69OrPbNf/i8+HfvfXH9xn53216+7Fy/ccwUfPjeMGS/8gQtO7QlAzews3nvy+u3bbxry8+3vOaRtDm8/cR3TxtzIC/dcQb06ewEwqF8eU0cP275smnEfh7bN2emYUrzUQLiVa4mLgkYVUFhYyG/+368YO/51Pp4zj+dHP8tn8+btUKbBvvvyv3ffx2+uvX6n919/za858cS+zP50Ph/NmE279u0BuPP24fQ+/gQ+/exzeh9/AncGwahjp05M+XA6H86YxdjXJnL1VVdQUFBQ+ScqlSYjw7hn2EAGDH2Qw3/xP5zVtyvtWjXdocwVA49h/uIv6XH2cE66/F6GX3s6NbIy+c+WAvoOvo8eZw+nx6C/cmKvDnQ/5EAA/nbzudx031i6DfwL4/41m2suPAGA0a9Pp+eg4fQcNJxLb/o/lq1cz5yFK6I+bYmBgkYVMO2jjzjooNa0bNWK7Oxszjp7EK+OH7tDmcaNG5PXrRs1atTYYfu3337L5MnvctEllwKQnZ3NPvvsA8Cr48dy/gUXAnD+BRcyflxqSpnatWuTlZXqmfzP5s2JvYpDftKt04F8sXwtS1es48eCQp6fNJP+vQ/doYwDdevUBKBOrZps+OZ7Cgq3ArDphy0A1MjKJCsrE/fUZKhtWjRm8oxFALw1dT6nndB5p2MP7NuVMRNnVNapVVsVMDV6LBQ0qoCVK1eQm/vTZJQ5ObmsWBHuW9uSxYtp2LARgy+9mJ55h3Pl4MvYtGkTAF+tXs3+++8PwP7778+ar356xspHH35Il8M6knf4Idw3YuT2ICLJ1Kzx3uSv3rB9fcXqDeQ02nuHMiNHv0O7lk1Z/Mafmf78jVx/xwvbg0NGhjF19DD+/eZw3po6n2mfLgNg3her6N/7EADO6NOF3CYNdjr2mSd2YczE6ZV1atWUlftfXCIJGma2Me11RzN7y8wWmtnnZvZftod/1d32i5su7H9JQUEBsz6eyeVXXMnU6R9Tu06d7d1QJeneowczZ89l8gfTuOO2v7J58+Yyt1uqjuL+iBT9VPXp1Z45C/JpdeIf6DHor9w97KztYxRbtzo9Bw2n9Uk3kdepBR0OSn3ZuOKWp7li4DFMefp31K1dky0/Fu5QZ7dOLfh+84/M+2JVpZyXVD2RZhpmVgsYBwx397bAYUAv4Koo21HV5OTkkp//0wO2VqzIp1mzZuHem5tLTm4u3Xv0AOD0X5zJrI9nAtC4SRNWrUr9Mq9atYpGjRvv9P527dtTp04d5n76aXlPQ2K04quvd8gCcpo0YOWab3Yoc8GpPRn71mwAFgddWQcf2GSHMt9s/IF3p3/Oib1Sj5JeuHQ1p1w1giPPu50xE2ewJH/NDuXPOqmrsozdpO6pcM4Fprj7GwDu/j0wFBgWcTuqlLxu3Vi06HOWLlnCli1beP650Zzc/9RQ723atCm5uc1ZuGABAG+/9Sbt2qd+4U/ufypPPfkEAE89+QT9T0k9HnjpkiXbB76XLVvGwoULaHHggRV8VhKl6XOX0fqARrRoth81sjI566QuvPb2nB3KLP9yA727HwxA433r0fbAJixZsZaGDeqyd91aAOxVswbH9ziYBUtXA9CoQV0glfkOu/wkRr0weXt9ZsYZfQ7n+UkazyirJF89FXVHdkdgh0+Yu39hZnXNrL67fxtxe6qErKws7r73AU45+SQKCwu58KJL6NCxI6P+nprB+PIrhvDll19yZM88vvv2WzIyMnjgvnv4eM486tevz1333M/FvzyPLVu2cGCrVjz08GMAXP+7YZx/zkCeeOwRmjc/gKdHPw/A+1Mmc+cdw6mRVYOMjAzuvf9BGjZsGNv5S/kVFm7lmtvGMP7BX5GZYTwxdiqfLf6Sy848CoCHX5jM8FETeeiP5zNtzI2YwR/uHcu6rzfRqU0zRt16AZkZGWRkGC/+Yyavv5fKPAf2zeOKs48BYOxbs/i/sVO3H/OoLq1Zsfprlq5YF/0JJ13M2UJ5WHH96RV+ELON7l7XzO4Glrj7fUX2bwAOcPfv0rYNBgYDND/ggK4Lv1hW6e2U6qtBt6FxN0Gqgc2zRswo5bncobTt1NnvH/OPctXRt2PjCmlLWUXdPTWX1DNptzOzVsDG9IAB4O4PuXueu+c1atgoyjaKiFQ6jWmE8zRwlJn9DLYPjN8H3B5xO0REYqVLbkNw9x+AAcBNZrYA+ITUw88fiLIdIiKyeyIZCHf3ummvPwF6R3FcEZGqyICMhA6E6zZgEZEYxNnFVB4KGiIiMUjqJbeae0pEREJTpiEiEgN1T4mISCgaCBcRkTKI916L8tCYhoiIhKZMQ0QkagmesFBBQ0QkBgmNGeqeEhGR8JRpiIhELHX1VDJzDQUNEZEYJDNkKGiIiMQjoVFDYxoiIhKaMg0RkRgk9eY+BQ0RkRgkdBxcQUNEJA4JjRka0xARkfCUaYiIxCGhqYaChohIxIzkDoSre0pEREJTpiEiEjXNcisiImWR0Jih7ikRkVhYOZcwh09+nTUAAAdmSURBVDDra2YLzGyRmQ0rZv8AM5tjZrPMbLqZHVVanco0RESqITPLBEYAfYB8YJqZjXP3eWnF3gTGubub2aHAGKBdSfUq0xARiZyV+18I3YFF7r7Y3bcAo4EB6QXcfaO7e7BaB3BKoUxDRCQGFTAQ3tDMpqetP+TuD6Wt5wDL09bzgR47t8NOB/4KNAZOLu2gChoiIsm01t3zSthfXFjaKZNw95eBl83sGOBPwM9KOqi6p0REIlbeMfCQSUo+0DxtPRdYuavC7v4ucJCZNSypUgUNEZE4VH7UmAa0MbOWZpYNDALG7dAEs9ZmqY4yM+sCZAPrSqpU3VMiIjGo7GlE3L3AzIYCk4BM4FF3n2tmQ4L9I4FfAL80sx+BH4Cz0wbGi6WgISJSTbn7BGBCkW0j017fBtxWljoVNEREYqBpREREJLSExgwFDRGRyJXhEqiqRldPiYhIaMo0RERikNSHMCloiIhEzEjuQLi6p0REJDRlGiIiMUhooqGgISISi4RGDQUNEZEYJHUgXGMaIiISmjINEZEYJPXqKQUNEZEYJDRmKGiIiMQioVFDYxoiIhKaMg0RkYil5itMZqqhoCEiEjVL7kC4uqdERCQ0ZRoiIjFIaKKhoCEiEouERg0FDRGRyFliB8I1piEiIqEp0xARiUFSr55S0BARiZiR2CENdU+JiEh4yjREROKQ0FRDQUNEJAZJvXpKQUNEJAZJHQjXmIaIiISmTENEJAYJTTQUNEREIpfgWW4VNEREYpHMqKExDRERCU2ZhohIxAx1T4mISBkkNGYkI2jMnDljba0atizudlRxDYG1cTdCEk2fodK1iLsBcUtE0HD3RnG3oaozs+nunhd3OyS59BmKlrqnREQkNE0jIiIi4SUzZuiS22rkobgbIImnz5CUSplGNeHu+oWXctFnKFoJTTQUNEREomaaRkRERMoiqQPhGtNIGDPbWGT9IjN7IHh9i5mtMLNZwTI8nlZKEqR/lsyso5m9ZWYLzexzM/svs6R+F5ZtzKyvmS0ws0VmNqyY/eeZ2Zxged/MDiutTmUa1c/d7n5n3I2Q5DCzWsA44Ep3f8PMagMvAlcBI2JtXHVWySHZzDJJ/fz6APnANDMb5+7z0ootAY519w1m1o/UxRA9SqpXmYaInAtMcfc3ANz9e2AosNM3U6k4Vs4lhO7AIndf7O5bgNHAgPQC7v6+u28IVqcCuaVVqqCRPLXSup9mAbcW2X9N2v6T4migJE5HYEb6Bnf/AqhrZvXjaZKE0NDMpqctg4vszwGWp63nB9t25VLg9dIOqu6p5PnB3TtvWzGzi4D0qR/UPSVlZYDvYt+utks5VcCI0dpSpn0p7gjF/jzN7DhSQeOo0g6qoCEic4Fj0jeYWStgo7t/F0+TqjuL4uqpfKB52nousHKnlpgdCjwM9HP3daVVqu4pEXkaOMrMfgbbB8bvA26PtVXV2LbnaZRnCWEa0MbMWppZNjCI1AUPP7XD7ADgJeACd18YplJlGiJ7OHf/wcwGAPeb2QggE3gSeCDelkl5uHuBmQ0FJpH6mT7q7nPNbEiwfyRwM7Af8GBwhXVBaTMdm7u6LEVEonR4lzx/a/KH5apj3zpZM+KYyl6ZhohIDJJ666SChohIDDSNiIiIVHvKNEREoqZZbkVEJKwyTAVS5ah7SqoUMysMpkD51MyeDybP2926epvZq8HrU4ub5TOt7D5mdtVuHOMWM7t+d9sokjQKGlLV/ODund29E7AFGJK+01LK/Ll193HuXtJU8fuQmtVVJBoRzFhYGRQ0pCp7D2htZgea2Wdm9iAwE2huZiea2QdmNjPISOrC9ucHzDezycAZ2yoq8tyRJmb2spnNDpZewHDgoCDLuSMo91szmxY8a+CPaXX9IXhGwT+BgyP735Bqxcr5Ly4a05AqycyygH7AxGDTwcDF7n6VmTUEbgJ+5u6bzOwG4Fozux0YBRwPLAKe20X19wHvuPvpwTMH6pKaBrzTtskgzexEoA2p6aUNGGdmxwCbSE3HcDip35+ZFJkhViQMDYSLVIxawZTvkMo0HgGaAcvcfWqwvSfQAZgSTH2QDXwAtAOWuPvnAGb2FFB0umhIBZVfArh7IfCNmTUoUubEYPk4WK9LKojUA14OnjmBmY1DZA+ioCFVzQ5TvwMEgWFT+ibgH+5+TpFynam4qbwN+Ku7/73IMX5TgceQPVhCEw2NaUgiTQWONLPWAGZW28zaAvOBlmZ2UFDunF28/03gyuC9mcGDhr4jlUVsMwm4JG2sJMfMGgPvAqebWS0zqwecUsHnJnsKDYSLRMPd1wAXAc+a2RxSQaSdu28m1R31WjAQvmwXVfwaOM7MPiE1HtExeI7AlOBS3zuCR58+A3wQlHsBqOfuM0mNlcwi9Rzt9yrtREWqIM1yKyISsS5d83zK1OnlqqN2tmmWWxGRPcG2hzAlkTINEZGImdlEoGE5q1nr7n0roj1loaAhIiKhaSBcRERCU9AQEZHQFDRERCQ0BQ0REQlNQUNEREL7/2aEL4u0MiWJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 468x468 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "keep_accuracy = np.zeros((10))\n",
    "j = 0\n",
    "\n",
    "for participant in files:\n",
    "    mat = loadmat(participant)\n",
    "    X = np.array(mat[\"X_2D\"])\n",
    "    y = np.array(mat[\"exemplarLabels\"]).ravel()    # get labels\n",
    "\n",
    "    y_bin =[]\n",
    "    X_bin = []\n",
    "    \n",
    "    for i in range(0,len(X)):                      # keep only the hf and the io category\n",
    "        if (12 < y[i] < 25):\n",
    "            y_bin.append(0)                        # set class hf as 0\n",
    "            X_bin.append(X[i])\n",
    "        elif (60 < y[i]):                          # set class io as 0\n",
    "            y_bin.append(1)\n",
    "            X_bin.append(X[i])\n",
    "\n",
    "    X_bin = np.array(X_bin)\n",
    "    y_bin = np.array(y_bin).ravel()\n",
    "\n",
    "    X_training = X_bin[:int(0.8*len(X_bin))]       # create train and test sets\n",
    "    X_validation = X_bin[int(0.8*len(X_bin)):]\n",
    "    \n",
    "    y_training = y_bin[:int(0.8*len(X_bin))]\n",
    "    y_validation =y_bin[int(0.8*len(X_bin)):]\n",
    "\n",
    "    # reshape to treat the data like images (124x32)\n",
    "    X_training = np.reshape(X_training, (-1, 124, 32, 1))\n",
    "    X_validation = np.reshape(X_validation, (-1, 124, 32, 1))\n",
    "\n",
    "    num_classes = 2                                # we have only 2 classes, hf and io\n",
    "\n",
    "    # cnn model\n",
    "    model = Sequential()                           \n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=X_training.shape[1:],  activation = \"relu\"))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=128,kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "                    bias_regularizer=regularizers.l2(1e-3),\n",
    "                    activity_regularizer=regularizers.l2(1e-3),\n",
    "                    activation = \"relu\"))\n",
    "    model.add(Dropout(0.15))\n",
    "    model.add(Dense(units=num_classes-1,activity_regularizer=regularizers.l2(1e-5), activation = \"sigmoid\"))\n",
    "\n",
    "    model.compile(loss=keras.losses.BinaryCrossentropy(),\n",
    "                  optimizer='nadam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_training, y_training,                                              # train the model\n",
    "              epochs=50,\n",
    "              validation_data=(X_validation, y_validation), \n",
    "              shuffle=True)\n",
    "\n",
    "    y_validation_predictions = np.round(model.predict(X_validation, verbose=1))    # make predictions\n",
    "\n",
    "    # create the confusion matrix\n",
    "    cnf_matrix5 = confusion_matrix(y_validation, y_validation_predictions)\n",
    "    cm_cv5 += cnf_matrix5                                                          # add together all the confusion matrices\n",
    "    \n",
    "    _, accuracy = model.evaluate(X_validation, y_validation)                       # find accuracy\n",
    "    keep_accuracy[j] = accuracy\n",
    "    j = j + 1\n",
    "    print(\" \")\n",
    "    \n",
    "print('Accuracy: %.2f' % (np.mean(keep_accuracy)*100))                             # print mean accuracy\n",
    "\n",
    "sum_by_row = np.sum(cm_cv5, 1)                                                     # normalize the final confusion matrix\n",
    "for i in range(0,2):\n",
    "    cm_cv5[i,:] = cm_cv5[i,:] / sum_by_row[i]\n",
    "    \n",
    "plot_cm(np.round(cm_cv5, 4),2)                                                     # plot the final confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.78910776, 0.21089224],\n",
       "       [0.16032295, 0.83967705]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_cv5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple CNN, hf class, exemplar\n",
    "\n",
    "Εφαρμόζουμε το απλό cnn για τις 12 κατηγορίες της κλάσης human face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 691 samples, validate on 173 samples\n",
      "Epoch 1/50\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 4.0592 - accuracy: 0.0753 - val_loss: 2.9377 - val_accuracy: 0.0809\n",
      "Epoch 2/50\n",
      "691/691 [==============================] - 0s 662us/step - loss: 2.9086 - accuracy: 0.0810 - val_loss: 2.9606 - val_accuracy: 0.0867\n",
      "Epoch 3/50\n",
      "691/691 [==============================] - 0s 571us/step - loss: 2.7898 - accuracy: 0.0637 - val_loss: 2.7192 - val_accuracy: 0.0809\n",
      "Epoch 4/50\n",
      "691/691 [==============================] - 0s 645us/step - loss: 2.7957 - accuracy: 0.0854 - val_loss: 2.7006 - val_accuracy: 0.0809\n",
      "Epoch 5/50\n",
      "691/691 [==============================] - 0s 636us/step - loss: 2.6859 - accuracy: 0.0854 - val_loss: 2.6563 - val_accuracy: 0.0636\n",
      "Epoch 6/50\n",
      "691/691 [==============================] - 0s 684us/step - loss: 2.7222 - accuracy: 0.0709 - val_loss: 2.9393 - val_accuracy: 0.0809\n",
      "Epoch 7/50\n",
      "691/691 [==============================] - 0s 672us/step - loss: 2.8473 - accuracy: 0.0796 - val_loss: 2.7472 - val_accuracy: 0.0809\n",
      "Epoch 8/50\n",
      "691/691 [==============================] - 0s 603us/step - loss: 2.7294 - accuracy: 0.0622 - val_loss: 2.6832 - val_accuracy: 0.0809\n",
      "Epoch 9/50\n",
      "691/691 [==============================] - 0s 563us/step - loss: 2.7784 - accuracy: 0.0825 - val_loss: 2.6959 - val_accuracy: 0.0809\n",
      "Epoch 10/50\n",
      "691/691 [==============================] - 0s 608us/step - loss: 2.6866 - accuracy: 0.0695 - val_loss: 2.6528 - val_accuracy: 0.0809\n",
      "Epoch 11/50\n",
      "691/691 [==============================] - 0s 614us/step - loss: 2.6640 - accuracy: 0.0767 - val_loss: 2.6204 - val_accuracy: 0.0809\n",
      "Epoch 12/50\n",
      "691/691 [==============================] - 0s 556us/step - loss: 2.6279 - accuracy: 0.0767 - val_loss: 2.6178 - val_accuracy: 0.0809\n",
      "Epoch 13/50\n",
      "691/691 [==============================] - 0s 611us/step - loss: 2.6359 - accuracy: 0.0651 - val_loss: 2.6105 - val_accuracy: 0.0809\n",
      "Epoch 14/50\n",
      "691/691 [==============================] - 0s 629us/step - loss: 2.6024 - accuracy: 0.0767 - val_loss: 2.5839 - val_accuracy: 0.0867\n",
      "Epoch 15/50\n",
      "691/691 [==============================] - 0s 634us/step - loss: 2.6267 - accuracy: 0.0753 - val_loss: 2.6052 - val_accuracy: 0.0809\n",
      "Epoch 16/50\n",
      "691/691 [==============================] - 0s 647us/step - loss: 2.6169 - accuracy: 0.0926 - val_loss: 2.5986 - val_accuracy: 0.0983\n",
      "Epoch 17/50\n",
      "691/691 [==============================] - 0s 572us/step - loss: 2.5732 - accuracy: 0.1071 - val_loss: 2.5816 - val_accuracy: 0.1156\n",
      "Epoch 18/50\n",
      "691/691 [==============================] - 0s 581us/step - loss: 2.5575 - accuracy: 0.1114 - val_loss: 2.5805 - val_accuracy: 0.1040\n",
      "Epoch 19/50\n",
      "691/691 [==============================] - 0s 550us/step - loss: 2.5281 - accuracy: 0.1201 - val_loss: 2.5906 - val_accuracy: 0.0925\n",
      "Epoch 20/50\n",
      "691/691 [==============================] - 0s 550us/step - loss: 2.5398 - accuracy: 0.1172 - val_loss: 2.6322 - val_accuracy: 0.1098\n",
      "Epoch 21/50\n",
      "691/691 [==============================] - 0s 655us/step - loss: 2.5632 - accuracy: 0.1317 - val_loss: 2.5909 - val_accuracy: 0.1156\n",
      "Epoch 22/50\n",
      "691/691 [==============================] - 0s 627us/step - loss: 2.4908 - accuracy: 0.1592 - val_loss: 2.6552 - val_accuracy: 0.0809\n",
      "Epoch 23/50\n",
      "691/691 [==============================] - 0s 633us/step - loss: 2.5368 - accuracy: 0.1534 - val_loss: 2.6175 - val_accuracy: 0.1329\n",
      "Epoch 24/50\n",
      "691/691 [==============================] - 0s 645us/step - loss: 2.4828 - accuracy: 0.1737 - val_loss: 2.6089 - val_accuracy: 0.1503\n",
      "Epoch 25/50\n",
      "691/691 [==============================] - 0s 600us/step - loss: 2.4433 - accuracy: 0.2127 - val_loss: 2.6144 - val_accuracy: 0.1503\n",
      "Epoch 26/50\n",
      "691/691 [==============================] - 0s 585us/step - loss: 2.4030 - accuracy: 0.2287 - val_loss: 2.6042 - val_accuracy: 0.1561\n",
      "Epoch 27/50\n",
      "691/691 [==============================] - 0s 649us/step - loss: 2.3239 - accuracy: 0.2648 - val_loss: 2.6549 - val_accuracy: 0.1214\n",
      "Epoch 28/50\n",
      "691/691 [==============================] - 0s 642us/step - loss: 2.2634 - accuracy: 0.2967 - val_loss: 2.7171 - val_accuracy: 0.1272\n",
      "Epoch 29/50\n",
      "691/691 [==============================] - 0s 659us/step - loss: 2.2144 - accuracy: 0.3184 - val_loss: 2.7028 - val_accuracy: 0.1272\n",
      "Epoch 30/50\n",
      "691/691 [==============================] - 0s 563us/step - loss: 2.1580 - accuracy: 0.3878 - val_loss: 2.6861 - val_accuracy: 0.1156\n",
      "Epoch 31/50\n",
      "691/691 [==============================] - 0s 548us/step - loss: 2.1112 - accuracy: 0.3922 - val_loss: 2.7099 - val_accuracy: 0.1445\n",
      "Epoch 32/50\n",
      "691/691 [==============================] - 0s 556us/step - loss: 2.0624 - accuracy: 0.4096 - val_loss: 2.6936 - val_accuracy: 0.1503\n",
      "Epoch 33/50\n",
      "691/691 [==============================] - 0s 571us/step - loss: 1.9805 - accuracy: 0.4544 - val_loss: 2.9038 - val_accuracy: 0.1156\n",
      "Epoch 34/50\n",
      "691/691 [==============================] - 0s 559us/step - loss: 1.9970 - accuracy: 0.4616 - val_loss: 2.8019 - val_accuracy: 0.1908\n",
      "Epoch 35/50\n",
      "691/691 [==============================] - 0s 556us/step - loss: 1.9292 - accuracy: 0.4993 - val_loss: 2.8382 - val_accuracy: 0.1156\n",
      "Epoch 36/50\n",
      "691/691 [==============================] - 0s 639us/step - loss: 1.8617 - accuracy: 0.5007 - val_loss: 2.7767 - val_accuracy: 0.1676\n",
      "Epoch 37/50\n",
      "691/691 [==============================] - 0s 582us/step - loss: 1.8606 - accuracy: 0.5051 - val_loss: 2.8055 - val_accuracy: 0.1618\n",
      "Epoch 38/50\n",
      "691/691 [==============================] - 0s 653us/step - loss: 1.7809 - accuracy: 0.5340 - val_loss: 2.8781 - val_accuracy: 0.1965\n",
      "Epoch 39/50\n",
      "691/691 [==============================] - 0s 633us/step - loss: 1.7554 - accuracy: 0.5456 - val_loss: 2.8731 - val_accuracy: 0.1676\n",
      "Epoch 40/50\n",
      "691/691 [==============================] - 0s 650us/step - loss: 1.6915 - accuracy: 0.5919 - val_loss: 2.8121 - val_accuracy: 0.1503\n",
      "Epoch 41/50\n",
      "691/691 [==============================] - 0s 579us/step - loss: 1.7531 - accuracy: 0.5687 - val_loss: 3.0332 - val_accuracy: 0.1561\n",
      "Epoch 42/50\n",
      "691/691 [==============================] - 0s 581us/step - loss: 1.6711 - accuracy: 0.5977 - val_loss: 2.8773 - val_accuracy: 0.1561\n",
      "Epoch 43/50\n",
      "691/691 [==============================] - 0s 555us/step - loss: 1.6554 - accuracy: 0.6107 - val_loss: 2.9299 - val_accuracy: 0.1387\n",
      "Epoch 44/50\n",
      "691/691 [==============================] - 0s 552us/step - loss: 1.6483 - accuracy: 0.6266 - val_loss: 2.9132 - val_accuracy: 0.1618\n",
      "Epoch 45/50\n",
      "691/691 [==============================] - 0s 576us/step - loss: 1.5793 - accuracy: 0.6483 - val_loss: 2.9075 - val_accuracy: 0.1850\n",
      "Epoch 46/50\n",
      "691/691 [==============================] - 0s 552us/step - loss: 1.5741 - accuracy: 0.6411 - val_loss: 2.9303 - val_accuracy: 0.1561\n",
      "Epoch 47/50\n",
      "691/691 [==============================] - 0s 550us/step - loss: 1.4984 - accuracy: 0.6990 - val_loss: 3.1437 - val_accuracy: 0.1618\n",
      "Epoch 48/50\n",
      "691/691 [==============================] - 0s 555us/step - loss: 1.4747 - accuracy: 0.7048 - val_loss: 3.0698 - val_accuracy: 0.1503\n",
      "Epoch 49/50\n",
      "691/691 [==============================] - 0s 552us/step - loss: 1.4465 - accuracy: 0.7091 - val_loss: 2.9797 - val_accuracy: 0.1618\n",
      "Epoch 50/50\n",
      "691/691 [==============================] - 0s 552us/step - loss: 1.3927 - accuracy: 0.7192 - val_loss: 2.9797 - val_accuracy: 0.1156\n",
      "173/173 [==============================] - 0s 255us/step\n",
      "173/173 [==============================] - 0s 150us/step\n",
      " \n",
      "Train on 691 samples, validate on 173 samples\n",
      "Epoch 1/50\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 3.1149 - accuracy: 0.0767 - val_loss: 2.7702 - val_accuracy: 0.0867\n",
      "Epoch 2/50\n",
      "691/691 [==============================] - 0s 595us/step - loss: 2.7676 - accuracy: 0.0854 - val_loss: 2.7613 - val_accuracy: 0.0809\n",
      "Epoch 3/50\n",
      "691/691 [==============================] - 0s 585us/step - loss: 2.6796 - accuracy: 0.1114 - val_loss: 2.6521 - val_accuracy: 0.1040\n",
      "Epoch 4/50\n",
      "691/691 [==============================] - 0s 577us/step - loss: 2.6251 - accuracy: 0.1346 - val_loss: 2.6386 - val_accuracy: 0.1156\n",
      "Epoch 5/50\n",
      "691/691 [==============================] - 0s 568us/step - loss: 2.6230 - accuracy: 0.1896 - val_loss: 2.6289 - val_accuracy: 0.1272\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "691/691 [==============================] - 0s 555us/step - loss: 2.5102 - accuracy: 0.2489 - val_loss: 2.6871 - val_accuracy: 0.1214\n",
      "Epoch 7/50\n",
      "691/691 [==============================] - 0s 549us/step - loss: 2.4616 - accuracy: 0.2880 - val_loss: 2.7218 - val_accuracy: 0.1156\n",
      "Epoch 8/50\n",
      "691/691 [==============================] - 0s 552us/step - loss: 2.4055 - accuracy: 0.3777 - val_loss: 2.7508 - val_accuracy: 0.1387\n",
      "Epoch 9/50\n",
      "691/691 [==============================] - 0s 549us/step - loss: 2.2773 - accuracy: 0.4544 - val_loss: 2.7995 - val_accuracy: 0.1156\n",
      "Epoch 10/50\n",
      "691/691 [==============================] - 0s 556us/step - loss: 2.1893 - accuracy: 0.5239 - val_loss: 3.0141 - val_accuracy: 0.1445\n",
      "Epoch 11/50\n",
      "691/691 [==============================] - 0s 552us/step - loss: 2.1664 - accuracy: 0.5876 - val_loss: 3.2046 - val_accuracy: 0.1329\n",
      "Epoch 12/50\n",
      "691/691 [==============================] - 0s 561us/step - loss: 2.1479 - accuracy: 0.6483 - val_loss: 3.0542 - val_accuracy: 0.1272\n",
      "Epoch 13/50\n",
      "691/691 [==============================] - 0s 575us/step - loss: 1.8492 - accuracy: 0.7294 - val_loss: 3.1739 - val_accuracy: 0.1272\n",
      "Epoch 14/50\n",
      "691/691 [==============================] - 0s 555us/step - loss: 1.7668 - accuracy: 0.7467 - val_loss: 3.2099 - val_accuracy: 0.1272\n",
      "Epoch 15/50\n",
      "691/691 [==============================] - 0s 561us/step - loss: 1.6682 - accuracy: 0.7656 - val_loss: 3.0205 - val_accuracy: 0.1329\n",
      "Epoch 16/50\n",
      "691/691 [==============================] - 0s 562us/step - loss: 1.5977 - accuracy: 0.7800 - val_loss: 3.1142 - val_accuracy: 0.1156\n",
      "Epoch 17/50\n",
      "691/691 [==============================] - 0s 559us/step - loss: 1.4827 - accuracy: 0.8061 - val_loss: 3.1486 - val_accuracy: 0.1098\n",
      "Epoch 18/50\n",
      "691/691 [==============================] - 0s 565us/step - loss: 1.4694 - accuracy: 0.8017 - val_loss: 3.2317 - val_accuracy: 0.1445\n",
      "Epoch 19/50\n",
      "691/691 [==============================] - 0s 561us/step - loss: 1.4449 - accuracy: 0.7902 - val_loss: 3.0052 - val_accuracy: 0.1040\n",
      "Epoch 20/50\n",
      "691/691 [==============================] - 0s 568us/step - loss: 1.3550 - accuracy: 0.8336 - val_loss: 3.1380 - val_accuracy: 0.0925\n",
      "Epoch 21/50\n",
      "691/691 [==============================] - 0s 562us/step - loss: 1.3107 - accuracy: 0.8220 - val_loss: 3.1450 - val_accuracy: 0.1098\n",
      "Epoch 22/50\n",
      "691/691 [==============================] - 0s 559us/step - loss: 1.3724 - accuracy: 0.8032 - val_loss: 3.0515 - val_accuracy: 0.1214\n",
      "Epoch 23/50\n",
      "691/691 [==============================] - 0s 561us/step - loss: 1.2503 - accuracy: 0.8394 - val_loss: 3.1360 - val_accuracy: 0.1445\n",
      "Epoch 24/50\n",
      "691/691 [==============================] - 0s 565us/step - loss: 1.3139 - accuracy: 0.8321 - val_loss: 3.0786 - val_accuracy: 0.1156\n",
      "Epoch 25/50\n",
      "691/691 [==============================] - 0s 566us/step - loss: 1.2216 - accuracy: 0.8249 - val_loss: 3.0676 - val_accuracy: 0.0983\n",
      "Epoch 26/50\n",
      "691/691 [==============================] - 0s 558us/step - loss: 1.1663 - accuracy: 0.8640 - val_loss: 3.0738 - val_accuracy: 0.1272\n",
      "Epoch 27/50\n",
      "691/691 [==============================] - 0s 556us/step - loss: 1.1060 - accuracy: 0.8567 - val_loss: 3.0959 - val_accuracy: 0.1387\n",
      "Epoch 28/50\n",
      "691/691 [==============================] - 0s 590us/step - loss: 1.1098 - accuracy: 0.8423 - val_loss: 3.0479 - val_accuracy: 0.1214\n",
      "Epoch 29/50\n",
      "691/691 [==============================] - 0s 678us/step - loss: 1.1269 - accuracy: 0.8683 - val_loss: 3.0621 - val_accuracy: 0.1214\n",
      "Epoch 30/50\n",
      "691/691 [==============================] - 0s 561us/step - loss: 1.0830 - accuracy: 0.8596 - val_loss: 3.1397 - val_accuracy: 0.1214\n",
      "Epoch 31/50\n",
      "691/691 [==============================] - 0s 658us/step - loss: 1.0340 - accuracy: 0.8741 - val_loss: 3.0611 - val_accuracy: 0.1098\n",
      "Epoch 32/50\n",
      "691/691 [==============================] - 0s 597us/step - loss: 1.0357 - accuracy: 0.8770 - val_loss: 3.1158 - val_accuracy: 0.1098\n",
      "Epoch 33/50\n",
      "691/691 [==============================] - 0s 647us/step - loss: 0.9768 - accuracy: 0.8784 - val_loss: 3.0930 - val_accuracy: 0.1040\n",
      "Epoch 34/50\n",
      "691/691 [==============================] - 0s 581us/step - loss: 0.9776 - accuracy: 0.8784 - val_loss: 3.1358 - val_accuracy: 0.0925\n",
      "Epoch 35/50\n",
      "691/691 [==============================] - 0s 563us/step - loss: 1.0448 - accuracy: 0.8857 - val_loss: 3.2616 - val_accuracy: 0.1098\n",
      "Epoch 36/50\n",
      "691/691 [==============================] - 0s 568us/step - loss: 0.9559 - accuracy: 0.8886 - val_loss: 3.0174 - val_accuracy: 0.1156\n",
      "Epoch 37/50\n",
      "691/691 [==============================] - 0s 584us/step - loss: 1.0275 - accuracy: 0.8538 - val_loss: 3.1963 - val_accuracy: 0.0983\n",
      "Epoch 38/50\n",
      "691/691 [==============================] - 0s 568us/step - loss: 0.9369 - accuracy: 0.8900 - val_loss: 3.2669 - val_accuracy: 0.1040\n",
      "Epoch 39/50\n",
      "691/691 [==============================] - 0s 566us/step - loss: 1.0211 - accuracy: 0.8698 - val_loss: 3.1433 - val_accuracy: 0.1329\n",
      "Epoch 40/50\n",
      "691/691 [==============================] - 0s 565us/step - loss: 0.8794 - accuracy: 0.9132 - val_loss: 3.1853 - val_accuracy: 0.1214\n",
      "Epoch 41/50\n",
      "691/691 [==============================] - 0s 572us/step - loss: 0.8766 - accuracy: 0.9030 - val_loss: 3.0470 - val_accuracy: 0.1387\n",
      "Epoch 42/50\n",
      "691/691 [==============================] - 0s 587us/step - loss: 0.9031 - accuracy: 0.8755 - val_loss: 3.3608 - val_accuracy: 0.1503\n",
      "Epoch 43/50\n",
      "691/691 [==============================] - 0s 688us/step - loss: 0.8830 - accuracy: 0.8871 - val_loss: 3.2052 - val_accuracy: 0.1098\n",
      "Epoch 44/50\n",
      "691/691 [==============================] - 0s 595us/step - loss: 0.9323 - accuracy: 0.8828 - val_loss: 3.3532 - val_accuracy: 0.1329\n",
      "Epoch 45/50\n",
      "691/691 [==============================] - 0s 574us/step - loss: 0.8865 - accuracy: 0.8842 - val_loss: 3.1973 - val_accuracy: 0.1445\n",
      "Epoch 46/50\n",
      "691/691 [==============================] - 0s 574us/step - loss: 0.8452 - accuracy: 0.9117 - val_loss: 3.1728 - val_accuracy: 0.1503\n",
      "Epoch 47/50\n",
      "691/691 [==============================] - 0s 582us/step - loss: 0.7949 - accuracy: 0.9132 - val_loss: 3.1544 - val_accuracy: 0.1214\n",
      "Epoch 48/50\n",
      "691/691 [==============================] - 0s 676us/step - loss: 0.7913 - accuracy: 0.9103 - val_loss: 3.1024 - val_accuracy: 0.1272\n",
      "Epoch 49/50\n",
      "691/691 [==============================] - 0s 611us/step - loss: 0.7674 - accuracy: 0.9161 - val_loss: 3.1526 - val_accuracy: 0.1214\n",
      "Epoch 50/50\n",
      "691/691 [==============================] - 0s 574us/step - loss: 0.7542 - accuracy: 0.9103 - val_loss: 3.5349 - val_accuracy: 0.1214\n",
      "173/173 [==============================] - 0s 237us/step\n",
      "173/173 [==============================] - 0s 156us/step\n",
      " \n",
      "Train on 692 samples, validate on 173 samples\n",
      "Epoch 1/50\n",
      "692/692 [==============================] - 1s 1ms/step - loss: 3.6495 - accuracy: 0.0824 - val_loss: 2.9978 - val_accuracy: 0.0636\n",
      "Epoch 2/50\n",
      "692/692 [==============================] - 0s 576us/step - loss: 2.9577 - accuracy: 0.0939 - val_loss: 2.8490 - val_accuracy: 0.0809\n",
      "Epoch 3/50\n",
      "692/692 [==============================] - 0s 577us/step - loss: 2.8064 - accuracy: 0.0665 - val_loss: 2.7547 - val_accuracy: 0.0751\n",
      "Epoch 4/50\n",
      "692/692 [==============================] - 0s 581us/step - loss: 2.7068 - accuracy: 0.0766 - val_loss: 2.6623 - val_accuracy: 0.0867\n",
      "Epoch 5/50\n",
      "692/692 [==============================] - 0s 579us/step - loss: 2.6986 - accuracy: 0.0694 - val_loss: 2.6739 - val_accuracy: 0.0751\n",
      "Epoch 6/50\n",
      "692/692 [==============================] - 0s 576us/step - loss: 2.6924 - accuracy: 0.0925 - val_loss: 2.6700 - val_accuracy: 0.0694\n",
      "Epoch 7/50\n",
      "692/692 [==============================] - 0s 576us/step - loss: 2.6528 - accuracy: 0.0853 - val_loss: 2.6643 - val_accuracy: 0.0809\n",
      "Epoch 8/50\n",
      "692/692 [==============================] - 0s 579us/step - loss: 2.6491 - accuracy: 0.1156 - val_loss: 2.7419 - val_accuracy: 0.0925\n",
      "Epoch 9/50\n",
      "692/692 [==============================] - 0s 576us/step - loss: 2.6262 - accuracy: 0.1329 - val_loss: 2.6514 - val_accuracy: 0.0809\n",
      "Epoch 10/50\n",
      "692/692 [==============================] - 0s 576us/step - loss: 2.6048 - accuracy: 0.1460 - val_loss: 2.7914 - val_accuracy: 0.0636\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "692/692 [==============================] - 0s 560us/step - loss: 2.5981 - accuracy: 0.1647 - val_loss: 2.6520 - val_accuracy: 0.0751\n",
      "Epoch 12/50\n",
      "692/692 [==============================] - 0s 554us/step - loss: 2.5340 - accuracy: 0.1618 - val_loss: 2.6685 - val_accuracy: 0.0867\n",
      "Epoch 13/50\n",
      "692/692 [==============================] - 0s 554us/step - loss: 2.4828 - accuracy: 0.1850 - val_loss: 2.6900 - val_accuracy: 0.0867\n",
      "Epoch 14/50\n",
      "692/692 [==============================] - 0s 555us/step - loss: 2.4119 - accuracy: 0.1965 - val_loss: 2.8202 - val_accuracy: 0.1156\n",
      "Epoch 15/50\n",
      "692/692 [==============================] - 0s 553us/step - loss: 2.3970 - accuracy: 0.1994 - val_loss: 2.7042 - val_accuracy: 0.0694\n",
      "Epoch 16/50\n",
      "692/692 [==============================] - 0s 553us/step - loss: 2.3838 - accuracy: 0.2153 - val_loss: 2.7514 - val_accuracy: 0.1040\n",
      "Epoch 17/50\n",
      "692/692 [==============================] - 0s 551us/step - loss: 2.3056 - accuracy: 0.2370 - val_loss: 3.3576 - val_accuracy: 0.0867\n",
      "Epoch 18/50\n",
      "692/692 [==============================] - 0s 551us/step - loss: 2.2970 - accuracy: 0.2370 - val_loss: 2.8728 - val_accuracy: 0.0809\n",
      "Epoch 19/50\n",
      "692/692 [==============================] - 0s 553us/step - loss: 2.2822 - accuracy: 0.2442 - val_loss: 2.8299 - val_accuracy: 0.0983\n",
      "Epoch 20/50\n",
      "692/692 [==============================] - 0s 553us/step - loss: 2.2404 - accuracy: 0.2760 - val_loss: 2.7801 - val_accuracy: 0.0925\n",
      "Epoch 21/50\n",
      "692/692 [==============================] - 0s 554us/step - loss: 2.1972 - accuracy: 0.2702 - val_loss: 2.7351 - val_accuracy: 0.1214\n",
      "Epoch 22/50\n",
      "692/692 [==============================] - 0s 550us/step - loss: 2.2113 - accuracy: 0.2803 - val_loss: 2.8669 - val_accuracy: 0.0983\n",
      "Epoch 23/50\n",
      "692/692 [==============================] - 0s 555us/step - loss: 2.1680 - accuracy: 0.3237 - val_loss: 2.7500 - val_accuracy: 0.1156\n",
      "Epoch 24/50\n",
      "692/692 [==============================] - 0s 557us/step - loss: 2.1431 - accuracy: 0.3772 - val_loss: 2.7736 - val_accuracy: 0.1272\n",
      "Epoch 25/50\n",
      "692/692 [==============================] - 0s 553us/step - loss: 2.1411 - accuracy: 0.3772 - val_loss: 2.7726 - val_accuracy: 0.1040\n",
      "Epoch 26/50\n",
      "692/692 [==============================] - 0s 551us/step - loss: 2.1338 - accuracy: 0.4017 - val_loss: 2.9267 - val_accuracy: 0.1387\n",
      "Epoch 27/50\n",
      "692/692 [==============================] - 0s 554us/step - loss: 2.1387 - accuracy: 0.4075 - val_loss: 2.8355 - val_accuracy: 0.1214\n",
      "Epoch 28/50\n",
      "692/692 [==============================] - 0s 554us/step - loss: 2.1488 - accuracy: 0.4191 - val_loss: 2.9639 - val_accuracy: 0.1098\n",
      "Epoch 29/50\n",
      "692/692 [==============================] - 0s 557us/step - loss: 2.0573 - accuracy: 0.4335 - val_loss: 2.8663 - val_accuracy: 0.1329\n",
      "Epoch 30/50\n",
      "692/692 [==============================] - 0s 553us/step - loss: 2.0427 - accuracy: 0.4393 - val_loss: 2.9878 - val_accuracy: 0.0983\n",
      "Epoch 31/50\n",
      "692/692 [==============================] - 0s 553us/step - loss: 1.9550 - accuracy: 0.4523 - val_loss: 2.9066 - val_accuracy: 0.0867\n",
      "Epoch 32/50\n",
      "692/692 [==============================] - 0s 554us/step - loss: 1.9152 - accuracy: 0.4595 - val_loss: 2.8122 - val_accuracy: 0.0925\n",
      "Epoch 33/50\n",
      "692/692 [==============================] - 0s 554us/step - loss: 1.8871 - accuracy: 0.4595 - val_loss: 2.8273 - val_accuracy: 0.1272\n",
      "Epoch 34/50\n",
      "692/692 [==============================] - 0s 555us/step - loss: 1.8798 - accuracy: 0.4552 - val_loss: 2.7736 - val_accuracy: 0.1214\n",
      "Epoch 35/50\n",
      "692/692 [==============================] - 0s 554us/step - loss: 1.8391 - accuracy: 0.4509 - val_loss: 2.8937 - val_accuracy: 0.1329\n",
      "Epoch 36/50\n",
      "692/692 [==============================] - 0s 557us/step - loss: 1.8923 - accuracy: 0.4162 - val_loss: 2.8584 - val_accuracy: 0.1214\n",
      "Epoch 37/50\n",
      "692/692 [==============================] - 0s 555us/step - loss: 1.8170 - accuracy: 0.4754 - val_loss: 2.8366 - val_accuracy: 0.1561\n",
      "Epoch 38/50\n",
      "692/692 [==============================] - 0s 560us/step - loss: 1.7876 - accuracy: 0.4725 - val_loss: 2.9117 - val_accuracy: 0.1329\n",
      "Epoch 39/50\n",
      "692/692 [==============================] - 0s 558us/step - loss: 1.7828 - accuracy: 0.4841 - val_loss: 2.9111 - val_accuracy: 0.1272\n",
      "Epoch 40/50\n",
      "692/692 [==============================] - 0s 553us/step - loss: 1.7846 - accuracy: 0.4827 - val_loss: 3.0248 - val_accuracy: 0.1156\n",
      "Epoch 41/50\n",
      "692/692 [==============================] - 0s 555us/step - loss: 1.7919 - accuracy: 0.4769 - val_loss: 2.9527 - val_accuracy: 0.1156\n",
      "Epoch 42/50\n",
      "692/692 [==============================] - 0s 555us/step - loss: 1.7401 - accuracy: 0.4971 - val_loss: 2.9290 - val_accuracy: 0.1272\n",
      "Epoch 43/50\n",
      "692/692 [==============================] - 0s 555us/step - loss: 1.7348 - accuracy: 0.5318 - val_loss: 2.9777 - val_accuracy: 0.1503\n",
      "Epoch 44/50\n",
      "692/692 [==============================] - 0s 554us/step - loss: 1.7238 - accuracy: 0.5231 - val_loss: 2.9761 - val_accuracy: 0.1445\n",
      "Epoch 45/50\n",
      "692/692 [==============================] - 0s 557us/step - loss: 1.6744 - accuracy: 0.5289 - val_loss: 2.9674 - val_accuracy: 0.1503\n",
      "Epoch 46/50\n",
      "692/692 [==============================] - 0s 554us/step - loss: 1.6287 - accuracy: 0.5520 - val_loss: 2.8803 - val_accuracy: 0.1387\n",
      "Epoch 47/50\n",
      "692/692 [==============================] - 0s 557us/step - loss: 1.6000 - accuracy: 0.5477 - val_loss: 3.0123 - val_accuracy: 0.1272\n",
      "Epoch 48/50\n",
      "692/692 [==============================] - 0s 558us/step - loss: 1.5946 - accuracy: 0.5491 - val_loss: 2.9964 - val_accuracy: 0.1098\n",
      "Epoch 49/50\n",
      "692/692 [==============================] - 0s 555us/step - loss: 1.5482 - accuracy: 0.5694 - val_loss: 2.9418 - val_accuracy: 0.1272\n",
      "Epoch 50/50\n",
      "692/692 [==============================] - 0s 554us/step - loss: 1.5402 - accuracy: 0.5737 - val_loss: 3.1363 - val_accuracy: 0.1272\n",
      "173/173 [==============================] - 0s 260us/step\n",
      "173/173 [==============================] - 0s 150us/step\n",
      " \n",
      "Train on 691 samples, validate on 173 samples\n",
      "Epoch 1/50\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 3.0877 - accuracy: 0.0767 - val_loss: 2.7784 - val_accuracy: 0.0809\n",
      "Epoch 2/50\n",
      "691/691 [==============================] - 0s 565us/step - loss: 2.8219 - accuracy: 0.0868 - val_loss: 2.7247 - val_accuracy: 0.0694\n",
      "Epoch 3/50\n",
      "691/691 [==============================] - 0s 565us/step - loss: 2.6997 - accuracy: 0.1143 - val_loss: 2.6697 - val_accuracy: 0.0636\n",
      "Epoch 4/50\n",
      "691/691 [==============================] - 0s 562us/step - loss: 2.6704 - accuracy: 0.1129 - val_loss: 2.7251 - val_accuracy: 0.0867\n",
      "Epoch 5/50\n",
      "691/691 [==============================] - 0s 561us/step - loss: 2.7227 - accuracy: 0.1302 - val_loss: 2.7126 - val_accuracy: 0.0751\n",
      "Epoch 6/50\n",
      "691/691 [==============================] - 0s 559us/step - loss: 2.6722 - accuracy: 0.1766 - val_loss: 2.7501 - val_accuracy: 0.0983\n",
      "Epoch 7/50\n",
      "691/691 [==============================] - 0s 566us/step - loss: 2.6559 - accuracy: 0.2185 - val_loss: 2.7967 - val_accuracy: 0.1503\n",
      "Epoch 8/50\n",
      "691/691 [==============================] - 0s 563us/step - loss: 2.6807 - accuracy: 0.2865 - val_loss: 2.8276 - val_accuracy: 0.1214\n",
      "Epoch 9/50\n",
      "691/691 [==============================] - 0s 563us/step - loss: 2.6801 - accuracy: 0.3415 - val_loss: 2.9647 - val_accuracy: 0.1503\n",
      "Epoch 10/50\n",
      "691/691 [==============================] - 0s 561us/step - loss: 2.4858 - accuracy: 0.4182 - val_loss: 2.8995 - val_accuracy: 0.1214\n",
      "Epoch 11/50\n",
      "691/691 [==============================] - 0s 561us/step - loss: 2.3354 - accuracy: 0.5195 - val_loss: 3.0076 - val_accuracy: 0.1561\n",
      "Epoch 12/50\n",
      "691/691 [==============================] - 0s 561us/step - loss: 2.3197 - accuracy: 0.6136 - val_loss: 3.1855 - val_accuracy: 0.0983\n",
      "Epoch 13/50\n",
      "691/691 [==============================] - 0s 566us/step - loss: 2.0847 - accuracy: 0.6715 - val_loss: 3.3826 - val_accuracy: 0.1329\n",
      "Epoch 14/50\n",
      "691/691 [==============================] - 0s 559us/step - loss: 1.9579 - accuracy: 0.7728 - val_loss: 3.3086 - val_accuracy: 0.1329\n",
      "Epoch 15/50\n",
      "691/691 [==============================] - 0s 562us/step - loss: 1.8532 - accuracy: 0.8177 - val_loss: 3.3062 - val_accuracy: 0.2081\n",
      "Epoch 16/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "691/691 [==============================] - 0s 568us/step - loss: 1.6655 - accuracy: 0.8379 - val_loss: 3.3737 - val_accuracy: 0.1734\n",
      "Epoch 17/50\n",
      "691/691 [==============================] - 0s 563us/step - loss: 1.6729 - accuracy: 0.8712 - val_loss: 3.4719 - val_accuracy: 0.1329\n",
      "Epoch 18/50\n",
      "691/691 [==============================] - 0s 558us/step - loss: 1.6001 - accuracy: 0.8915 - val_loss: 3.4361 - val_accuracy: 0.1676\n",
      "Epoch 19/50\n",
      "691/691 [==============================] - 0s 559us/step - loss: 1.3969 - accuracy: 0.9247 - val_loss: 3.5675 - val_accuracy: 0.1445\n",
      "Epoch 20/50\n",
      "691/691 [==============================] - 0s 558us/step - loss: 1.3204 - accuracy: 0.9233 - val_loss: 3.7434 - val_accuracy: 0.1618\n",
      "Epoch 21/50\n",
      "691/691 [==============================] - 0s 561us/step - loss: 1.2899 - accuracy: 0.9421 - val_loss: 3.4500 - val_accuracy: 0.1850\n",
      "Epoch 22/50\n",
      "691/691 [==============================] - 0s 559us/step - loss: 1.2704 - accuracy: 0.9436 - val_loss: 3.3870 - val_accuracy: 0.1329\n",
      "Epoch 23/50\n",
      "691/691 [==============================] - 0s 561us/step - loss: 1.1646 - accuracy: 0.9407 - val_loss: 3.3776 - val_accuracy: 0.1676\n",
      "Epoch 24/50\n",
      "691/691 [==============================] - 0s 561us/step - loss: 1.2167 - accuracy: 0.9465 - val_loss: 3.6329 - val_accuracy: 0.1329\n",
      "Epoch 25/50\n",
      "691/691 [==============================] - 0s 558us/step - loss: 1.0972 - accuracy: 0.9392 - val_loss: 3.3572 - val_accuracy: 0.1734\n",
      "Epoch 26/50\n",
      "691/691 [==============================] - 0s 562us/step - loss: 1.0282 - accuracy: 0.9566 - val_loss: 3.4442 - val_accuracy: 0.1734\n",
      "Epoch 27/50\n",
      "691/691 [==============================] - 0s 563us/step - loss: 0.9707 - accuracy: 0.9638 - val_loss: 3.2750 - val_accuracy: 0.1445\n",
      "Epoch 28/50\n",
      "691/691 [==============================] - 0s 563us/step - loss: 0.9252 - accuracy: 0.9667 - val_loss: 3.6671 - val_accuracy: 0.1792\n",
      "Epoch 29/50\n",
      "691/691 [==============================] - 0s 565us/step - loss: 0.9578 - accuracy: 0.9522 - val_loss: 3.2617 - val_accuracy: 0.1503\n",
      "Epoch 30/50\n",
      "691/691 [==============================] - 0s 563us/step - loss: 1.1659 - accuracy: 0.9682 - val_loss: 3.4372 - val_accuracy: 0.1676\n",
      "Epoch 31/50\n",
      "691/691 [==============================] - 0s 561us/step - loss: 1.1938 - accuracy: 0.9320 - val_loss: 3.5134 - val_accuracy: 0.1503\n",
      "Epoch 32/50\n",
      "691/691 [==============================] - 0s 562us/step - loss: 1.1181 - accuracy: 0.9334 - val_loss: 3.5158 - val_accuracy: 0.1503\n",
      "Epoch 33/50\n",
      "691/691 [==============================] - 0s 559us/step - loss: 1.0154 - accuracy: 0.9493 - val_loss: 3.4605 - val_accuracy: 0.1445\n",
      "Epoch 34/50\n",
      "691/691 [==============================] - 0s 561us/step - loss: 1.0006 - accuracy: 0.9407 - val_loss: 3.5335 - val_accuracy: 0.1850\n",
      "Epoch 35/50\n",
      "691/691 [==============================] - 0s 559us/step - loss: 0.9255 - accuracy: 0.9551 - val_loss: 3.3361 - val_accuracy: 0.1734\n",
      "Epoch 36/50\n",
      "691/691 [==============================] - 0s 558us/step - loss: 0.9862 - accuracy: 0.9522 - val_loss: 3.2934 - val_accuracy: 0.1618\n",
      "Epoch 37/50\n",
      "691/691 [==============================] - 0s 561us/step - loss: 1.0116 - accuracy: 0.9624 - val_loss: 3.5923 - val_accuracy: 0.1387\n",
      "Epoch 38/50\n",
      "691/691 [==============================] - 0s 559us/step - loss: 0.9813 - accuracy: 0.9595 - val_loss: 3.3628 - val_accuracy: 0.1850\n",
      "Epoch 39/50\n",
      "691/691 [==============================] - 0s 563us/step - loss: 0.9349 - accuracy: 0.9551 - val_loss: 3.3843 - val_accuracy: 0.1850\n",
      "Epoch 40/50\n",
      "691/691 [==============================] - 0s 562us/step - loss: 0.8159 - accuracy: 0.9826 - val_loss: 3.3748 - val_accuracy: 0.1734\n",
      "Epoch 41/50\n",
      "691/691 [==============================] - 0s 561us/step - loss: 0.7495 - accuracy: 0.9740 - val_loss: 3.3053 - val_accuracy: 0.1792\n",
      "Epoch 42/50\n",
      "691/691 [==============================] - 0s 561us/step - loss: 0.8564 - accuracy: 0.9653 - val_loss: 3.4369 - val_accuracy: 0.1445\n",
      "Epoch 43/50\n",
      "691/691 [==============================] - 0s 562us/step - loss: 0.8663 - accuracy: 0.9566 - val_loss: 3.2805 - val_accuracy: 0.1618\n",
      "Epoch 44/50\n",
      "691/691 [==============================] - 0s 562us/step - loss: 1.1401 - accuracy: 0.9682 - val_loss: 3.7229 - val_accuracy: 0.1445\n",
      "Epoch 45/50\n",
      "691/691 [==============================] - 0s 559us/step - loss: 1.1067 - accuracy: 0.9392 - val_loss: 3.9266 - val_accuracy: 0.1850\n",
      "Epoch 46/50\n",
      "691/691 [==============================] - 0s 558us/step - loss: 1.0999 - accuracy: 0.9363 - val_loss: 3.6675 - val_accuracy: 0.1734\n",
      "Epoch 47/50\n",
      "691/691 [==============================] - 0s 561us/step - loss: 1.3868 - accuracy: 0.9624 - val_loss: 3.5041 - val_accuracy: 0.1792\n",
      "Epoch 48/50\n",
      "691/691 [==============================] - 0s 561us/step - loss: 0.8818 - accuracy: 0.9580 - val_loss: 3.4035 - val_accuracy: 0.1908\n",
      "Epoch 49/50\n",
      "691/691 [==============================] - 0s 561us/step - loss: 1.0539 - accuracy: 0.9580 - val_loss: 3.4709 - val_accuracy: 0.1850\n",
      "Epoch 50/50\n",
      "691/691 [==============================] - 0s 563us/step - loss: 0.8100 - accuracy: 0.9595 - val_loss: 3.4429 - val_accuracy: 0.1792\n",
      "173/173 [==============================] - 0s 249us/step\n",
      "173/173 [==============================] - 0s 156us/step\n",
      " \n",
      "Train on 691 samples, validate on 173 samples\n",
      "Epoch 1/50\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 3.4679 - accuracy: 0.0941 - val_loss: 2.8752 - val_accuracy: 0.0867\n",
      "Epoch 2/50\n",
      "691/691 [==============================] - 0s 568us/step - loss: 2.8941 - accuracy: 0.0984 - val_loss: 2.8242 - val_accuracy: 0.1272\n",
      "Epoch 3/50\n",
      "691/691 [==============================] - 0s 559us/step - loss: 2.7775 - accuracy: 0.0839 - val_loss: 2.7157 - val_accuracy: 0.1040\n",
      "Epoch 4/50\n",
      "691/691 [==============================] - 0s 556us/step - loss: 2.6639 - accuracy: 0.0941 - val_loss: 2.6413 - val_accuracy: 0.0925\n",
      "Epoch 5/50\n",
      "691/691 [==============================] - 0s 559us/step - loss: 2.6838 - accuracy: 0.1129 - val_loss: 2.6555 - val_accuracy: 0.1040\n",
      "Epoch 6/50\n",
      "691/691 [==============================] - 0s 559us/step - loss: 2.6220 - accuracy: 0.1129 - val_loss: 2.7097 - val_accuracy: 0.0925\n",
      "Epoch 7/50\n",
      "691/691 [==============================] - 0s 558us/step - loss: 2.5908 - accuracy: 0.1245 - val_loss: 2.6114 - val_accuracy: 0.0925\n",
      "Epoch 8/50\n",
      "691/691 [==============================] - 0s 561us/step - loss: 2.5550 - accuracy: 0.1274 - val_loss: 2.6061 - val_accuracy: 0.0983\n",
      "Epoch 9/50\n",
      "691/691 [==============================] - 0s 563us/step - loss: 2.5284 - accuracy: 0.1418 - val_loss: 2.7057 - val_accuracy: 0.0925\n",
      "Epoch 10/50\n",
      "691/691 [==============================] - 0s 556us/step - loss: 2.5530 - accuracy: 0.1447 - val_loss: 2.6992 - val_accuracy: 0.0867\n",
      "Epoch 11/50\n",
      "691/691 [==============================] - 0s 563us/step - loss: 2.5432 - accuracy: 0.1389 - val_loss: 2.6827 - val_accuracy: 0.0809\n",
      "Epoch 12/50\n",
      "691/691 [==============================] - 0s 561us/step - loss: 2.5513 - accuracy: 0.1404 - val_loss: 2.6318 - val_accuracy: 0.1214\n",
      "Epoch 13/50\n",
      "691/691 [==============================] - 0s 561us/step - loss: 2.5171 - accuracy: 0.1520 - val_loss: 2.6632 - val_accuracy: 0.0983\n",
      "Epoch 14/50\n",
      "691/691 [==============================] - 0s 559us/step - loss: 2.5472 - accuracy: 0.1505 - val_loss: 2.6798 - val_accuracy: 0.1040\n",
      "Epoch 15/50\n",
      "691/691 [==============================] - 0s 566us/step - loss: 2.4866 - accuracy: 0.1520 - val_loss: 2.7304 - val_accuracy: 0.0694\n",
      "Epoch 16/50\n",
      "691/691 [==============================] - 0s 562us/step - loss: 2.4387 - accuracy: 0.1491 - val_loss: 2.6154 - val_accuracy: 0.0867\n",
      "Epoch 17/50\n",
      "691/691 [==============================] - 0s 561us/step - loss: 2.4400 - accuracy: 0.1476 - val_loss: 2.6430 - val_accuracy: 0.0983\n",
      "Epoch 18/50\n",
      "691/691 [==============================] - 0s 562us/step - loss: 2.4297 - accuracy: 0.1563 - val_loss: 2.6619 - val_accuracy: 0.0983\n",
      "Epoch 19/50\n",
      "691/691 [==============================] - 0s 559us/step - loss: 2.4762 - accuracy: 0.1621 - val_loss: 2.7833 - val_accuracy: 0.0867\n",
      "Epoch 20/50\n",
      "691/691 [==============================] - 0s 561us/step - loss: 2.4622 - accuracy: 0.1563 - val_loss: 2.6819 - val_accuracy: 0.0751\n",
      "Epoch 21/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "691/691 [==============================] - 0s 565us/step - loss: 2.3956 - accuracy: 0.1534 - val_loss: 2.7104 - val_accuracy: 0.0925\n",
      "Epoch 22/50\n",
      "691/691 [==============================] - 0s 558us/step - loss: 2.3650 - accuracy: 0.1621 - val_loss: 2.7291 - val_accuracy: 0.0925\n",
      "Epoch 23/50\n",
      "691/691 [==============================] - 0s 561us/step - loss: 2.3835 - accuracy: 0.1491 - val_loss: 2.7270 - val_accuracy: 0.0925\n",
      "Epoch 24/50\n",
      "691/691 [==============================] - 0s 563us/step - loss: 2.4075 - accuracy: 0.1548 - val_loss: 2.7811 - val_accuracy: 0.0925\n",
      "Epoch 25/50\n",
      "691/691 [==============================] - 0s 561us/step - loss: 2.4037 - accuracy: 0.1708 - val_loss: 2.6512 - val_accuracy: 0.0751\n",
      "Epoch 26/50\n",
      "691/691 [==============================] - 0s 565us/step - loss: 2.3434 - accuracy: 0.1679 - val_loss: 2.6993 - val_accuracy: 0.0694\n",
      "Epoch 27/50\n",
      "691/691 [==============================] - 0s 562us/step - loss: 2.3689 - accuracy: 0.1693 - val_loss: 2.6861 - val_accuracy: 0.0925\n",
      "Epoch 28/50\n",
      "691/691 [==============================] - 0s 568us/step - loss: 2.4109 - accuracy: 0.2026 - val_loss: 2.7958 - val_accuracy: 0.0983\n",
      "Epoch 29/50\n",
      "691/691 [==============================] - 0s 565us/step - loss: 2.3053 - accuracy: 0.2417 - val_loss: 2.7007 - val_accuracy: 0.1156\n",
      "Epoch 30/50\n",
      "691/691 [==============================] - 0s 568us/step - loss: 2.2732 - accuracy: 0.2200 - val_loss: 2.7454 - val_accuracy: 0.0925\n",
      "Epoch 31/50\n",
      "691/691 [==============================] - 0s 563us/step - loss: 2.2558 - accuracy: 0.2272 - val_loss: 2.7197 - val_accuracy: 0.1387\n",
      "Epoch 32/50\n",
      "691/691 [==============================] - 0s 563us/step - loss: 2.2187 - accuracy: 0.2446 - val_loss: 2.7378 - val_accuracy: 0.1272\n",
      "Epoch 33/50\n",
      "691/691 [==============================] - 0s 559us/step - loss: 2.2303 - accuracy: 0.2388 - val_loss: 2.7329 - val_accuracy: 0.1214\n",
      "Epoch 34/50\n",
      "691/691 [==============================] - 0s 559us/step - loss: 2.1759 - accuracy: 0.2446 - val_loss: 2.6751 - val_accuracy: 0.1214\n",
      "Epoch 35/50\n",
      "691/691 [==============================] - 0s 559us/step - loss: 2.1369 - accuracy: 0.2605 - val_loss: 2.8684 - val_accuracy: 0.0751\n",
      "Epoch 36/50\n",
      "691/691 [==============================] - 0s 559us/step - loss: 2.1374 - accuracy: 0.2721 - val_loss: 2.7672 - val_accuracy: 0.1329\n",
      "Epoch 37/50\n",
      "691/691 [==============================] - 0s 561us/step - loss: 2.1145 - accuracy: 0.2721 - val_loss: 2.7715 - val_accuracy: 0.0867\n",
      "Epoch 38/50\n",
      "691/691 [==============================] - 0s 561us/step - loss: 2.0668 - accuracy: 0.2779 - val_loss: 2.8027 - val_accuracy: 0.1445\n",
      "Epoch 39/50\n",
      "691/691 [==============================] - 0s 562us/step - loss: 2.0605 - accuracy: 0.2865 - val_loss: 2.7458 - val_accuracy: 0.1272\n",
      "Epoch 40/50\n",
      "691/691 [==============================] - 0s 563us/step - loss: 2.0742 - accuracy: 0.3039 - val_loss: 3.0998 - val_accuracy: 0.1214\n",
      "Epoch 41/50\n",
      "691/691 [==============================] - 0s 563us/step - loss: 2.1864 - accuracy: 0.3010 - val_loss: 2.7748 - val_accuracy: 0.1156\n",
      "Epoch 42/50\n",
      "691/691 [==============================] - 0s 562us/step - loss: 2.0472 - accuracy: 0.3227 - val_loss: 2.8336 - val_accuracy: 0.0983\n",
      "Epoch 43/50\n",
      "691/691 [==============================] - 0s 562us/step - loss: 2.0140 - accuracy: 0.3314 - val_loss: 2.8327 - val_accuracy: 0.1329\n",
      "Epoch 44/50\n",
      "691/691 [==============================] - 0s 559us/step - loss: 1.9778 - accuracy: 0.3878 - val_loss: 2.8670 - val_accuracy: 0.1387\n",
      "Epoch 45/50\n",
      "691/691 [==============================] - 0s 561us/step - loss: 1.9429 - accuracy: 0.3864 - val_loss: 2.8216 - val_accuracy: 0.1214\n",
      "Epoch 46/50\n",
      "691/691 [==============================] - 0s 556us/step - loss: 1.9192 - accuracy: 0.3994 - val_loss: 2.9784 - val_accuracy: 0.0925\n",
      "Epoch 47/50\n",
      "691/691 [==============================] - 0s 562us/step - loss: 1.8796 - accuracy: 0.4197 - val_loss: 2.8842 - val_accuracy: 0.1156\n",
      "Epoch 48/50\n",
      "691/691 [==============================] - 0s 562us/step - loss: 1.8138 - accuracy: 0.4284 - val_loss: 2.8337 - val_accuracy: 0.1040\n",
      "Epoch 49/50\n",
      "691/691 [==============================] - 0s 559us/step - loss: 1.8054 - accuracy: 0.4718 - val_loss: 2.8299 - val_accuracy: 0.1503\n",
      "Epoch 50/50\n",
      "691/691 [==============================] - 0s 558us/step - loss: 1.7738 - accuracy: 0.4790 - val_loss: 2.7982 - val_accuracy: 0.1329\n",
      "173/173 [==============================] - 0s 243us/step\n",
      "173/173 [==============================] - 0s 162us/step\n",
      " \n",
      "Train on 691 samples, validate on 173 samples\n",
      "Epoch 1/50\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 3.3167 - accuracy: 0.0695 - val_loss: 2.8178 - val_accuracy: 0.0867\n",
      "Epoch 2/50\n",
      "691/691 [==============================] - 0s 598us/step - loss: 2.7894 - accuracy: 0.0781 - val_loss: 2.8744 - val_accuracy: 0.0867\n",
      "Epoch 3/50\n",
      "691/691 [==============================] - 0s 559us/step - loss: 2.6894 - accuracy: 0.0984 - val_loss: 2.6301 - val_accuracy: 0.1040\n",
      "Epoch 4/50\n",
      "691/691 [==============================] - 0s 568us/step - loss: 2.6149 - accuracy: 0.1274 - val_loss: 2.6307 - val_accuracy: 0.0983\n",
      "Epoch 5/50\n",
      "691/691 [==============================] - 0s 553us/step - loss: 2.6310 - accuracy: 0.1259 - val_loss: 2.5987 - val_accuracy: 0.0983\n",
      "Epoch 6/50\n",
      "691/691 [==============================] - 0s 553us/step - loss: 2.5599 - accuracy: 0.1302 - val_loss: 2.7672 - val_accuracy: 0.1040\n",
      "Epoch 7/50\n",
      "691/691 [==============================] - 0s 559us/step - loss: 2.6010 - accuracy: 0.1548 - val_loss: 2.6202 - val_accuracy: 0.1156\n",
      "Epoch 8/50\n",
      "691/691 [==============================] - 0s 555us/step - loss: 2.5499 - accuracy: 0.1693 - val_loss: 2.7207 - val_accuracy: 0.1214\n",
      "Epoch 9/50\n",
      "691/691 [==============================] - 0s 555us/step - loss: 2.5476 - accuracy: 0.1737 - val_loss: 2.6415 - val_accuracy: 0.0983\n",
      "Epoch 10/50\n",
      "691/691 [==============================] - 0s 558us/step - loss: 2.5204 - accuracy: 0.1910 - val_loss: 2.6494 - val_accuracy: 0.1098\n",
      "Epoch 11/50\n",
      "691/691 [==============================] - 0s 556us/step - loss: 2.4810 - accuracy: 0.1867 - val_loss: 2.6848 - val_accuracy: 0.1098\n",
      "Epoch 12/50\n",
      "691/691 [==============================] - 0s 556us/step - loss: 2.5033 - accuracy: 0.2055 - val_loss: 2.7148 - val_accuracy: 0.1272\n",
      "Epoch 13/50\n",
      "691/691 [==============================] - 0s 556us/step - loss: 2.4865 - accuracy: 0.2142 - val_loss: 2.7692 - val_accuracy: 0.1329\n",
      "Epoch 14/50\n",
      "691/691 [==============================] - 0s 556us/step - loss: 2.4786 - accuracy: 0.2344 - val_loss: 2.7657 - val_accuracy: 0.1214\n",
      "Epoch 15/50\n",
      "691/691 [==============================] - 0s 556us/step - loss: 2.4972 - accuracy: 0.2402 - val_loss: 2.7985 - val_accuracy: 0.1040\n",
      "Epoch 16/50\n",
      "691/691 [==============================] - 0s 555us/step - loss: 2.4232 - accuracy: 0.2894 - val_loss: 2.7901 - val_accuracy: 0.1040\n",
      "Epoch 17/50\n",
      "691/691 [==============================] - 0s 556us/step - loss: 2.4524 - accuracy: 0.3025 - val_loss: 2.8077 - val_accuracy: 0.1561\n",
      "Epoch 18/50\n",
      "691/691 [==============================] - 0s 558us/step - loss: 2.3465 - accuracy: 0.3343 - val_loss: 2.7299 - val_accuracy: 0.1734\n",
      "Epoch 19/50\n",
      "691/691 [==============================] - 0s 555us/step - loss: 2.2660 - accuracy: 0.3893 - val_loss: 3.9054 - val_accuracy: 0.1445\n",
      "Epoch 20/50\n",
      "691/691 [==============================] - 0s 559us/step - loss: 2.2739 - accuracy: 0.3907 - val_loss: 2.7345 - val_accuracy: 0.1792\n",
      "Epoch 21/50\n",
      "691/691 [==============================] - 0s 555us/step - loss: 2.1447 - accuracy: 0.4399 - val_loss: 3.3266 - val_accuracy: 0.1272\n",
      "Epoch 22/50\n",
      "691/691 [==============================] - 0s 553us/step - loss: 2.1023 - accuracy: 0.4544 - val_loss: 2.9559 - val_accuracy: 0.1734\n",
      "Epoch 23/50\n",
      "691/691 [==============================] - 0s 552us/step - loss: 2.0529 - accuracy: 0.4920 - val_loss: 2.8298 - val_accuracy: 0.1965\n",
      "Epoch 24/50\n",
      "691/691 [==============================] - 0s 553us/step - loss: 1.9626 - accuracy: 0.5181 - val_loss: 2.9742 - val_accuracy: 0.1850\n",
      "Epoch 25/50\n",
      "691/691 [==============================] - 0s 558us/step - loss: 1.9341 - accuracy: 0.5210 - val_loss: 2.8965 - val_accuracy: 0.1618\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "691/691 [==============================] - 0s 563us/step - loss: 1.8552 - accuracy: 0.5456 - val_loss: 2.9084 - val_accuracy: 0.1561\n",
      "Epoch 27/50\n",
      "691/691 [==============================] - 0s 555us/step - loss: 1.8137 - accuracy: 0.5601 - val_loss: 2.8698 - val_accuracy: 0.1850\n",
      "Epoch 28/50\n",
      "691/691 [==============================] - 0s 555us/step - loss: 1.7457 - accuracy: 0.5861 - val_loss: 2.8433 - val_accuracy: 0.1734\n",
      "Epoch 29/50\n",
      "691/691 [==============================] - 0s 556us/step - loss: 1.7759 - accuracy: 0.5630 - val_loss: 2.9715 - val_accuracy: 0.1965\n",
      "Epoch 30/50\n",
      "691/691 [==============================] - 0s 556us/step - loss: 1.7003 - accuracy: 0.5919 - val_loss: 2.9709 - val_accuracy: 0.1908\n",
      "Epoch 31/50\n",
      "691/691 [==============================] - 0s 556us/step - loss: 2.0427 - accuracy: 0.5861 - val_loss: 3.1267 - val_accuracy: 0.1272\n",
      "Epoch 32/50\n",
      "691/691 [==============================] - 0s 553us/step - loss: 1.7383 - accuracy: 0.6049 - val_loss: 3.0984 - val_accuracy: 0.1792\n",
      "Epoch 33/50\n",
      "691/691 [==============================] - 0s 555us/step - loss: 1.6955 - accuracy: 0.6498 - val_loss: 3.0184 - val_accuracy: 0.1792\n",
      "Epoch 34/50\n",
      "691/691 [==============================] - 0s 556us/step - loss: 1.5753 - accuracy: 0.6918 - val_loss: 3.0849 - val_accuracy: 0.1850\n",
      "Epoch 35/50\n",
      "691/691 [==============================] - 0s 553us/step - loss: 1.5181 - accuracy: 0.6918 - val_loss: 3.0284 - val_accuracy: 0.1734\n",
      "Epoch 36/50\n",
      "691/691 [==============================] - 0s 555us/step - loss: 1.6810 - accuracy: 0.7120 - val_loss: 2.9761 - val_accuracy: 0.1445\n",
      "Epoch 37/50\n",
      "691/691 [==============================] - 0s 559us/step - loss: 1.5815 - accuracy: 0.7221 - val_loss: 3.0313 - val_accuracy: 0.1561\n",
      "Epoch 38/50\n",
      "691/691 [==============================] - 0s 555us/step - loss: 1.4367 - accuracy: 0.7424 - val_loss: 3.1620 - val_accuracy: 0.1618\n",
      "Epoch 39/50\n",
      "691/691 [==============================] - 0s 553us/step - loss: 1.3688 - accuracy: 0.7496 - val_loss: 3.0909 - val_accuracy: 0.1445\n",
      "Epoch 40/50\n",
      "691/691 [==============================] - 0s 553us/step - loss: 1.3257 - accuracy: 0.7554 - val_loss: 3.1273 - val_accuracy: 0.1676\n",
      "Epoch 41/50\n",
      "691/691 [==============================] - 0s 555us/step - loss: 1.3295 - accuracy: 0.7511 - val_loss: 3.2065 - val_accuracy: 0.1792\n",
      "Epoch 42/50\n",
      "691/691 [==============================] - 0s 556us/step - loss: 1.2629 - accuracy: 0.7815 - val_loss: 2.9864 - val_accuracy: 0.1503\n",
      "Epoch 43/50\n",
      "691/691 [==============================] - 0s 559us/step - loss: 1.3286 - accuracy: 0.7482 - val_loss: 3.0821 - val_accuracy: 0.1445\n",
      "Epoch 44/50\n",
      "691/691 [==============================] - 0s 555us/step - loss: 1.3107 - accuracy: 0.7612 - val_loss: 3.1458 - val_accuracy: 0.1503\n",
      "Epoch 45/50\n",
      "691/691 [==============================] - 0s 556us/step - loss: 1.2458 - accuracy: 0.7931 - val_loss: 3.1413 - val_accuracy: 0.1503\n",
      "Epoch 46/50\n",
      "691/691 [==============================] - 0s 558us/step - loss: 1.2923 - accuracy: 0.7656 - val_loss: 3.1051 - val_accuracy: 0.1329\n",
      "Epoch 47/50\n",
      "691/691 [==============================] - 0s 556us/step - loss: 1.2611 - accuracy: 0.7771 - val_loss: 2.9873 - val_accuracy: 0.1329\n",
      "Epoch 48/50\n",
      "691/691 [==============================] - 0s 552us/step - loss: 1.2303 - accuracy: 0.7757 - val_loss: 3.2636 - val_accuracy: 0.1387\n",
      "Epoch 49/50\n",
      "691/691 [==============================] - 0s 556us/step - loss: 1.2109 - accuracy: 0.7800 - val_loss: 3.2015 - val_accuracy: 0.1387\n",
      "Epoch 50/50\n",
      "691/691 [==============================] - 0s 555us/step - loss: 1.2169 - accuracy: 0.7815 - val_loss: 3.3213 - val_accuracy: 0.1734\n",
      "173/173 [==============================] - 0s 249us/step\n",
      "173/173 [==============================] - 0s 162us/step\n",
      " \n",
      "Train on 691 samples, validate on 173 samples\n",
      "Epoch 1/50\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 3.2856 - accuracy: 0.0666 - val_loss: 2.8459 - val_accuracy: 0.0867\n",
      "Epoch 2/50\n",
      "691/691 [==============================] - 0s 559us/step - loss: 2.7891 - accuracy: 0.0854 - val_loss: 2.7059 - val_accuracy: 0.0983\n",
      "Epoch 3/50\n",
      "691/691 [==============================] - 0s 558us/step - loss: 2.6752 - accuracy: 0.1331 - val_loss: 2.6536 - val_accuracy: 0.1040\n",
      "Epoch 4/50\n",
      "691/691 [==============================] - 0s 559us/step - loss: 2.6239 - accuracy: 0.1259 - val_loss: 2.6163 - val_accuracy: 0.1040\n",
      "Epoch 5/50\n",
      "691/691 [==============================] - 0s 561us/step - loss: 2.5904 - accuracy: 0.1606 - val_loss: 2.6658 - val_accuracy: 0.0867\n",
      "Epoch 6/50\n",
      "691/691 [==============================] - 0s 562us/step - loss: 2.5738 - accuracy: 0.1896 - val_loss: 2.6402 - val_accuracy: 0.1503\n",
      "Epoch 7/50\n",
      "691/691 [==============================] - 0s 558us/step - loss: 2.5384 - accuracy: 0.2344 - val_loss: 2.7204 - val_accuracy: 0.1156\n",
      "Epoch 8/50\n",
      "691/691 [==============================] - 0s 556us/step - loss: 2.4727 - accuracy: 0.2793 - val_loss: 2.8276 - val_accuracy: 0.0925\n",
      "Epoch 9/50\n",
      "691/691 [==============================] - 0s 558us/step - loss: 2.4190 - accuracy: 0.3386 - val_loss: 2.7674 - val_accuracy: 0.1214\n",
      "Epoch 10/50\n",
      "691/691 [==============================] - 0s 561us/step - loss: 2.2755 - accuracy: 0.4269 - val_loss: 2.9409 - val_accuracy: 0.1329\n",
      "Epoch 11/50\n",
      "691/691 [==============================] - 0s 559us/step - loss: 2.2175 - accuracy: 0.4805 - val_loss: 2.9634 - val_accuracy: 0.1272\n",
      "Epoch 12/50\n",
      "691/691 [==============================] - 0s 561us/step - loss: 2.0979 - accuracy: 0.5355 - val_loss: 2.9803 - val_accuracy: 0.1561\n",
      "Epoch 13/50\n",
      "691/691 [==============================] - 0s 556us/step - loss: 1.9968 - accuracy: 0.6020 - val_loss: 3.1435 - val_accuracy: 0.1272\n",
      "Epoch 14/50\n",
      "691/691 [==============================] - 0s 561us/step - loss: 1.9341 - accuracy: 0.6151 - val_loss: 3.0522 - val_accuracy: 0.1098\n",
      "Epoch 15/50\n",
      "691/691 [==============================] - 0s 558us/step - loss: 1.8103 - accuracy: 0.6816 - val_loss: 3.2504 - val_accuracy: 0.1272\n",
      "Epoch 16/50\n",
      "691/691 [==============================] - 0s 559us/step - loss: 1.7373 - accuracy: 0.7178 - val_loss: 3.2452 - val_accuracy: 0.1445\n",
      "Epoch 17/50\n",
      "691/691 [==============================] - 0s 559us/step - loss: 1.6574 - accuracy: 0.7569 - val_loss: 3.1956 - val_accuracy: 0.1908\n",
      "Epoch 18/50\n",
      "691/691 [==============================] - 0s 558us/step - loss: 1.5945 - accuracy: 0.7916 - val_loss: 3.2587 - val_accuracy: 0.1618\n",
      "Epoch 19/50\n",
      "691/691 [==============================] - 0s 558us/step - loss: 1.4919 - accuracy: 0.7959 - val_loss: 3.3436 - val_accuracy: 0.1387\n",
      "Epoch 20/50\n",
      "691/691 [==============================] - 0s 559us/step - loss: 1.4709 - accuracy: 0.8263 - val_loss: 3.1651 - val_accuracy: 0.1792\n",
      "Epoch 21/50\n",
      "691/691 [==============================] - 0s 558us/step - loss: 1.3907 - accuracy: 0.8466 - val_loss: 3.1864 - val_accuracy: 0.1561\n",
      "Epoch 22/50\n",
      "691/691 [==============================] - 0s 559us/step - loss: 1.3018 - accuracy: 0.8452 - val_loss: 3.3162 - val_accuracy: 0.1445\n",
      "Epoch 23/50\n",
      "691/691 [==============================] - 0s 561us/step - loss: 1.3060 - accuracy: 0.8466 - val_loss: 3.1984 - val_accuracy: 0.1503\n",
      "Epoch 24/50\n",
      "691/691 [==============================] - 0s 558us/step - loss: 1.2005 - accuracy: 0.8871 - val_loss: 3.1808 - val_accuracy: 0.1965\n",
      "Epoch 25/50\n",
      "691/691 [==============================] - 0s 558us/step - loss: 1.1432 - accuracy: 0.8813 - val_loss: 3.2395 - val_accuracy: 0.1445\n",
      "Epoch 26/50\n",
      "691/691 [==============================] - 0s 561us/step - loss: 1.1217 - accuracy: 0.8828 - val_loss: 3.2890 - val_accuracy: 0.1272\n",
      "Epoch 27/50\n",
      "691/691 [==============================] - 0s 559us/step - loss: 1.1434 - accuracy: 0.8915 - val_loss: 3.1945 - val_accuracy: 0.1561\n",
      "Epoch 28/50\n",
      "691/691 [==============================] - 0s 555us/step - loss: 1.0888 - accuracy: 0.8900 - val_loss: 3.2462 - val_accuracy: 0.1445\n",
      "Epoch 29/50\n",
      "691/691 [==============================] - 0s 558us/step - loss: 1.0643 - accuracy: 0.9088 - val_loss: 3.3196 - val_accuracy: 0.1618\n",
      "Epoch 30/50\n",
      "691/691 [==============================] - 0s 563us/step - loss: 1.0033 - accuracy: 0.9190 - val_loss: 3.1695 - val_accuracy: 0.1387\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "691/691 [==============================] - 0s 563us/step - loss: 0.9697 - accuracy: 0.9291 - val_loss: 3.0690 - val_accuracy: 0.1676\n",
      "Epoch 32/50\n",
      "691/691 [==============================] - 0s 558us/step - loss: 0.9465 - accuracy: 0.9132 - val_loss: 3.2403 - val_accuracy: 0.1792\n",
      "Epoch 33/50\n",
      "691/691 [==============================] - 0s 558us/step - loss: 0.9443 - accuracy: 0.9161 - val_loss: 3.1337 - val_accuracy: 0.1850\n",
      "Epoch 34/50\n",
      "691/691 [==============================] - 0s 556us/step - loss: 0.9252 - accuracy: 0.9305 - val_loss: 3.2592 - val_accuracy: 0.1618\n",
      "Epoch 35/50\n",
      "691/691 [==============================] - 0s 559us/step - loss: 0.9023 - accuracy: 0.9407 - val_loss: 3.2207 - val_accuracy: 0.1503\n",
      "Epoch 36/50\n",
      "691/691 [==============================] - 0s 558us/step - loss: 0.9316 - accuracy: 0.9305 - val_loss: 3.2083 - val_accuracy: 0.1734\n",
      "Epoch 37/50\n",
      "691/691 [==============================] - 0s 558us/step - loss: 0.8600 - accuracy: 0.9349 - val_loss: 3.2426 - val_accuracy: 0.1676\n",
      "Epoch 38/50\n",
      "691/691 [==============================] - 0s 556us/step - loss: 0.8281 - accuracy: 0.9479 - val_loss: 3.2791 - val_accuracy: 0.1503\n",
      "Epoch 39/50\n",
      "691/691 [==============================] - 0s 566us/step - loss: 0.8471 - accuracy: 0.9450 - val_loss: 3.4660 - val_accuracy: 0.1272\n",
      "Epoch 40/50\n",
      "691/691 [==============================] - 0s 559us/step - loss: 0.8583 - accuracy: 0.9262 - val_loss: 3.3286 - val_accuracy: 0.1503\n",
      "Epoch 41/50\n",
      "691/691 [==============================] - 0s 561us/step - loss: 0.8454 - accuracy: 0.9305 - val_loss: 3.1888 - val_accuracy: 0.2023\n",
      "Epoch 42/50\n",
      "691/691 [==============================] - 0s 558us/step - loss: 0.8249 - accuracy: 0.9305 - val_loss: 3.2487 - val_accuracy: 0.2139\n",
      "Epoch 43/50\n",
      "691/691 [==============================] - 0s 559us/step - loss: 0.8393 - accuracy: 0.9378 - val_loss: 3.2973 - val_accuracy: 0.1561\n",
      "Epoch 44/50\n",
      "691/691 [==============================] - 0s 559us/step - loss: 0.7919 - accuracy: 0.9522 - val_loss: 3.2091 - val_accuracy: 0.1792\n",
      "Epoch 45/50\n",
      "691/691 [==============================] - 0s 561us/step - loss: 0.7477 - accuracy: 0.9595 - val_loss: 3.2783 - val_accuracy: 0.1850\n",
      "Epoch 46/50\n",
      "691/691 [==============================] - 0s 562us/step - loss: 0.7249 - accuracy: 0.9682 - val_loss: 3.2325 - val_accuracy: 0.2023\n",
      "Epoch 47/50\n",
      "691/691 [==============================] - 0s 563us/step - loss: 0.7093 - accuracy: 0.9566 - val_loss: 3.1222 - val_accuracy: 0.1792\n",
      "Epoch 48/50\n",
      "691/691 [==============================] - 0s 559us/step - loss: 0.7059 - accuracy: 0.9551 - val_loss: 3.1911 - val_accuracy: 0.1792\n",
      "Epoch 49/50\n",
      "691/691 [==============================] - 0s 559us/step - loss: 0.6879 - accuracy: 0.9624 - val_loss: 3.2130 - val_accuracy: 0.1618\n",
      "Epoch 50/50\n",
      "691/691 [==============================] - 0s 559us/step - loss: 0.7073 - accuracy: 0.9508 - val_loss: 3.1336 - val_accuracy: 0.1792\n",
      "173/173 [==============================] - 0s 260us/step\n",
      "173/173 [==============================] - 0s 162us/step\n",
      " \n",
      "Train on 691 samples, validate on 173 samples\n",
      "Epoch 1/50\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 3.2587 - accuracy: 0.0753 - val_loss: 2.7911 - val_accuracy: 0.0809\n",
      "Epoch 2/50\n",
      "691/691 [==============================] - 0s 556us/step - loss: 2.7676 - accuracy: 0.1013 - val_loss: 2.6945 - val_accuracy: 0.0809\n",
      "Epoch 3/50\n",
      "691/691 [==============================] - 0s 562us/step - loss: 2.6678 - accuracy: 0.1071 - val_loss: 2.6439 - val_accuracy: 0.0983\n",
      "Epoch 4/50\n",
      "691/691 [==============================] - 0s 556us/step - loss: 2.5966 - accuracy: 0.1548 - val_loss: 2.7099 - val_accuracy: 0.0983\n",
      "Epoch 5/50\n",
      "691/691 [==============================] - 0s 561us/step - loss: 2.6003 - accuracy: 0.1751 - val_loss: 2.7677 - val_accuracy: 0.0809\n",
      "Epoch 6/50\n",
      "691/691 [==============================] - 0s 559us/step - loss: 2.5577 - accuracy: 0.2171 - val_loss: 2.7877 - val_accuracy: 0.0925\n",
      "Epoch 7/50\n",
      "691/691 [==============================] - 0s 562us/step - loss: 2.5318 - accuracy: 0.2981 - val_loss: 2.8370 - val_accuracy: 0.1445\n",
      "Epoch 8/50\n",
      "691/691 [==============================] - 0s 565us/step - loss: 2.4725 - accuracy: 0.3690 - val_loss: 2.8731 - val_accuracy: 0.1387\n",
      "Epoch 9/50\n",
      "691/691 [==============================] - 0s 559us/step - loss: 2.4255 - accuracy: 0.4443 - val_loss: 3.1160 - val_accuracy: 0.0925\n",
      "Epoch 10/50\n",
      "691/691 [==============================] - 0s 561us/step - loss: 2.2718 - accuracy: 0.5774 - val_loss: 3.1682 - val_accuracy: 0.0925\n",
      "Epoch 11/50\n",
      "691/691 [==============================] - 0s 562us/step - loss: 2.0836 - accuracy: 0.6614 - val_loss: 3.4156 - val_accuracy: 0.0983\n",
      "Epoch 12/50\n",
      "691/691 [==============================] - 0s 561us/step - loss: 1.9786 - accuracy: 0.7482 - val_loss: 3.8033 - val_accuracy: 0.1040\n",
      "Epoch 13/50\n",
      "691/691 [==============================] - 0s 558us/step - loss: 1.8806 - accuracy: 0.8234 - val_loss: 3.7210 - val_accuracy: 0.0636\n",
      "Epoch 14/50\n",
      "691/691 [==============================] - 0s 558us/step - loss: 1.7059 - accuracy: 0.8611 - val_loss: 3.7078 - val_accuracy: 0.0751\n",
      "Epoch 15/50\n",
      "691/691 [==============================] - 0s 559us/step - loss: 1.5730 - accuracy: 0.8958 - val_loss: 3.6905 - val_accuracy: 0.0983\n",
      "Epoch 16/50\n",
      "691/691 [==============================] - 0s 561us/step - loss: 1.4575 - accuracy: 0.9103 - val_loss: 3.9333 - val_accuracy: 0.0925\n",
      "Epoch 17/50\n",
      "691/691 [==============================] - 0s 559us/step - loss: 1.4522 - accuracy: 0.9175 - val_loss: 3.6556 - val_accuracy: 0.0578\n",
      "Epoch 18/50\n",
      "691/691 [==============================] - 0s 562us/step - loss: 1.3540 - accuracy: 0.9465 - val_loss: 3.7246 - val_accuracy: 0.0694\n",
      "Epoch 19/50\n",
      "691/691 [==============================] - 0s 558us/step - loss: 1.3049 - accuracy: 0.9551 - val_loss: 3.9564 - val_accuracy: 0.0809\n",
      "Epoch 20/50\n",
      "691/691 [==============================] - 0s 561us/step - loss: 1.2493 - accuracy: 0.9595 - val_loss: 3.7483 - val_accuracy: 0.0983\n",
      "Epoch 21/50\n",
      "691/691 [==============================] - 0s 561us/step - loss: 1.1856 - accuracy: 0.9465 - val_loss: 3.7257 - val_accuracy: 0.0809\n",
      "Epoch 22/50\n",
      "691/691 [==============================] - 0s 556us/step - loss: 1.1198 - accuracy: 0.9522 - val_loss: 4.0869 - val_accuracy: 0.0925\n",
      "Epoch 23/50\n",
      "691/691 [==============================] - 0s 559us/step - loss: 1.0862 - accuracy: 0.9580 - val_loss: 3.8888 - val_accuracy: 0.0983\n",
      "Epoch 24/50\n",
      "691/691 [==============================] - 0s 559us/step - loss: 1.0744 - accuracy: 0.9653 - val_loss: 3.8449 - val_accuracy: 0.1098\n",
      "Epoch 25/50\n",
      "691/691 [==============================] - 0s 562us/step - loss: 0.9754 - accuracy: 0.9740 - val_loss: 3.6968 - val_accuracy: 0.0578\n",
      "Epoch 26/50\n",
      "691/691 [==============================] - 0s 555us/step - loss: 1.0259 - accuracy: 0.9653 - val_loss: 3.7048 - val_accuracy: 0.1040\n",
      "Epoch 27/50\n",
      "691/691 [==============================] - 0s 562us/step - loss: 1.0613 - accuracy: 0.9768 - val_loss: 3.6739 - val_accuracy: 0.0925\n",
      "Epoch 28/50\n",
      "691/691 [==============================] - 0s 559us/step - loss: 0.9291 - accuracy: 0.9812 - val_loss: 3.7863 - val_accuracy: 0.1156\n",
      "Epoch 29/50\n",
      "691/691 [==============================] - 0s 559us/step - loss: 0.8765 - accuracy: 0.9841 - val_loss: 3.7112 - val_accuracy: 0.1098\n",
      "Epoch 30/50\n",
      "691/691 [==============================] - 0s 558us/step - loss: 0.8401 - accuracy: 0.9754 - val_loss: 3.8386 - val_accuracy: 0.1098\n",
      "Epoch 31/50\n",
      "691/691 [==============================] - 0s 558us/step - loss: 0.8597 - accuracy: 0.9797 - val_loss: 3.7567 - val_accuracy: 0.0983\n",
      "Epoch 32/50\n",
      "691/691 [==============================] - 0s 555us/step - loss: 0.8247 - accuracy: 0.9725 - val_loss: 3.7809 - val_accuracy: 0.1040\n",
      "Epoch 33/50\n",
      "691/691 [==============================] - 0s 559us/step - loss: 0.7961 - accuracy: 0.9812 - val_loss: 3.5955 - val_accuracy: 0.0983\n",
      "Epoch 34/50\n",
      "691/691 [==============================] - 0s 559us/step - loss: 0.7694 - accuracy: 0.9870 - val_loss: 3.6504 - val_accuracy: 0.0867\n",
      "Epoch 35/50\n",
      "691/691 [==============================] - 0s 553us/step - loss: 0.7937 - accuracy: 0.9826 - val_loss: 3.6071 - val_accuracy: 0.1098\n",
      "Epoch 36/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "691/691 [==============================] - 0s 561us/step - loss: 0.7714 - accuracy: 0.9870 - val_loss: 3.7393 - val_accuracy: 0.1040\n",
      "Epoch 37/50\n",
      "691/691 [==============================] - 0s 559us/step - loss: 0.7306 - accuracy: 0.9884 - val_loss: 3.6680 - val_accuracy: 0.1156\n",
      "Epoch 38/50\n",
      "691/691 [==============================] - 0s 553us/step - loss: 0.7357 - accuracy: 0.9870 - val_loss: 3.8586 - val_accuracy: 0.0867\n",
      "Epoch 39/50\n",
      "691/691 [==============================] - 0s 556us/step - loss: 0.7470 - accuracy: 0.9870 - val_loss: 3.6177 - val_accuracy: 0.0983\n",
      "Epoch 40/50\n",
      "691/691 [==============================] - 0s 559us/step - loss: 0.7431 - accuracy: 0.9855 - val_loss: 3.7543 - val_accuracy: 0.0925\n",
      "Epoch 41/50\n",
      "691/691 [==============================] - 0s 559us/step - loss: 0.6715 - accuracy: 0.9884 - val_loss: 3.6453 - val_accuracy: 0.0867\n",
      "Epoch 42/50\n",
      "691/691 [==============================] - 0s 559us/step - loss: 0.6558 - accuracy: 0.9870 - val_loss: 3.7076 - val_accuracy: 0.0694\n",
      "Epoch 43/50\n",
      "691/691 [==============================] - 0s 559us/step - loss: 0.6613 - accuracy: 0.9899 - val_loss: 3.8494 - val_accuracy: 0.0578\n",
      "Epoch 44/50\n",
      "691/691 [==============================] - 0s 559us/step - loss: 0.7292 - accuracy: 0.9812 - val_loss: 4.1072 - val_accuracy: 0.0867\n",
      "Epoch 45/50\n",
      "691/691 [==============================] - 0s 555us/step - loss: 0.6961 - accuracy: 0.9768 - val_loss: 3.8176 - val_accuracy: 0.0867\n",
      "Epoch 46/50\n",
      "691/691 [==============================] - 0s 559us/step - loss: 0.6555 - accuracy: 0.9841 - val_loss: 3.7471 - val_accuracy: 0.0983\n",
      "Epoch 47/50\n",
      "691/691 [==============================] - 0s 559us/step - loss: 0.6228 - accuracy: 0.9913 - val_loss: 3.7562 - val_accuracy: 0.0983\n",
      "Epoch 48/50\n",
      "691/691 [==============================] - 0s 555us/step - loss: 0.6217 - accuracy: 0.9826 - val_loss: 3.6916 - val_accuracy: 0.0925\n",
      "Epoch 49/50\n",
      "691/691 [==============================] - 0s 556us/step - loss: 0.6226 - accuracy: 0.9913 - val_loss: 4.0589 - val_accuracy: 0.0925\n",
      "Epoch 50/50\n",
      "691/691 [==============================] - 0s 555us/step - loss: 0.6181 - accuracy: 0.9870 - val_loss: 3.9397 - val_accuracy: 0.1040\n",
      "173/173 [==============================] - 0s 249us/step\n",
      "173/173 [==============================] - 0s 156us/step\n",
      " \n",
      "Train on 691 samples, validate on 173 samples\n",
      "Epoch 1/50\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 3.3983 - accuracy: 0.0912 - val_loss: 2.8339 - val_accuracy: 0.1272\n",
      "Epoch 2/50\n",
      "691/691 [==============================] - 0s 561us/step - loss: 2.7826 - accuracy: 0.1230 - val_loss: 3.0580 - val_accuracy: 0.0751\n",
      "Epoch 3/50\n",
      "691/691 [==============================] - 0s 561us/step - loss: 2.6743 - accuracy: 0.1491 - val_loss: 2.9134 - val_accuracy: 0.1850\n",
      "Epoch 4/50\n",
      "691/691 [==============================] - 0s 568us/step - loss: 2.6092 - accuracy: 0.1823 - val_loss: 3.1747 - val_accuracy: 0.0925\n",
      "Epoch 5/50\n",
      "691/691 [==============================] - 0s 558us/step - loss: 2.5623 - accuracy: 0.2475 - val_loss: 3.5757 - val_accuracy: 0.1387\n",
      "Epoch 6/50\n",
      "691/691 [==============================] - 0s 561us/step - loss: 2.4949 - accuracy: 0.2590 - val_loss: 4.1607 - val_accuracy: 0.1387\n",
      "Epoch 7/50\n",
      "691/691 [==============================] - 0s 562us/step - loss: 2.4370 - accuracy: 0.3140 - val_loss: 4.5243 - val_accuracy: 0.1272\n",
      "Epoch 8/50\n",
      "691/691 [==============================] - 0s 561us/step - loss: 2.4082 - accuracy: 0.4110 - val_loss: 4.7219 - val_accuracy: 0.1503\n",
      "Epoch 9/50\n",
      "691/691 [==============================] - 0s 561us/step - loss: 2.3016 - accuracy: 0.4501 - val_loss: 6.2337 - val_accuracy: 0.1503\n",
      "Epoch 10/50\n",
      "691/691 [==============================] - 0s 561us/step - loss: 2.2013 - accuracy: 0.5716 - val_loss: 6.9835 - val_accuracy: 0.1734\n",
      "Epoch 11/50\n",
      "691/691 [==============================] - 0s 561us/step - loss: 2.0545 - accuracy: 0.6324 - val_loss: 6.2001 - val_accuracy: 0.1214\n",
      "Epoch 12/50\n",
      "691/691 [==============================] - 0s 562us/step - loss: 2.0366 - accuracy: 0.6715 - val_loss: 6.1018 - val_accuracy: 0.1676\n",
      "Epoch 13/50\n",
      "691/691 [==============================] - 0s 562us/step - loss: 1.8352 - accuracy: 0.7381 - val_loss: 6.5410 - val_accuracy: 0.1445\n",
      "Epoch 14/50\n",
      "691/691 [==============================] - 0s 561us/step - loss: 1.7240 - accuracy: 0.7713 - val_loss: 8.6633 - val_accuracy: 0.1329\n",
      "Epoch 15/50\n",
      "691/691 [==============================] - 0s 563us/step - loss: 1.6585 - accuracy: 0.8046 - val_loss: 8.7543 - val_accuracy: 0.1676\n",
      "Epoch 16/50\n",
      "691/691 [==============================] - 0s 559us/step - loss: 1.5393 - accuracy: 0.8119 - val_loss: 8.7139 - val_accuracy: 0.1503\n",
      "Epoch 17/50\n",
      "691/691 [==============================] - 0s 561us/step - loss: 1.4948 - accuracy: 0.8307 - val_loss: 8.7404 - val_accuracy: 0.1561\n",
      "Epoch 18/50\n",
      "691/691 [==============================] - 0s 563us/step - loss: 1.4205 - accuracy: 0.8625 - val_loss: 8.1682 - val_accuracy: 0.1618\n",
      "Epoch 19/50\n",
      "691/691 [==============================] - 0s 561us/step - loss: 1.4602 - accuracy: 0.8582 - val_loss: 8.5552 - val_accuracy: 0.1445\n",
      "Epoch 20/50\n",
      "691/691 [==============================] - 0s 559us/step - loss: 1.3611 - accuracy: 0.8726 - val_loss: 7.0501 - val_accuracy: 0.1329\n",
      "Epoch 21/50\n",
      "691/691 [==============================] - 0s 559us/step - loss: 1.3373 - accuracy: 0.8799 - val_loss: 8.0756 - val_accuracy: 0.1503\n",
      "Epoch 22/50\n",
      "691/691 [==============================] - 0s 565us/step - loss: 1.2991 - accuracy: 0.8669 - val_loss: 7.2994 - val_accuracy: 0.1618\n",
      "Epoch 23/50\n",
      "691/691 [==============================] - 0s 563us/step - loss: 1.2510 - accuracy: 0.8871 - val_loss: 8.4221 - val_accuracy: 0.1445\n",
      "Epoch 24/50\n",
      "691/691 [==============================] - 0s 563us/step - loss: 1.2349 - accuracy: 0.8813 - val_loss: 8.6064 - val_accuracy: 0.1561\n",
      "Epoch 25/50\n",
      "691/691 [==============================] - 0s 561us/step - loss: 1.1910 - accuracy: 0.9030 - val_loss: 8.0384 - val_accuracy: 0.1561\n",
      "Epoch 26/50\n",
      "691/691 [==============================] - 0s 566us/step - loss: 1.1224 - accuracy: 0.8987 - val_loss: 7.8905 - val_accuracy: 0.1387\n",
      "Epoch 27/50\n",
      "691/691 [==============================] - 0s 563us/step - loss: 1.1053 - accuracy: 0.9291 - val_loss: 7.3017 - val_accuracy: 0.1387\n",
      "Epoch 28/50\n",
      "691/691 [==============================] - 0s 566us/step - loss: 1.0942 - accuracy: 0.9001 - val_loss: 6.6770 - val_accuracy: 0.1387\n",
      "Epoch 29/50\n",
      "691/691 [==============================] - 0s 562us/step - loss: 1.0670 - accuracy: 0.9262 - val_loss: 7.1630 - val_accuracy: 0.1792\n",
      "Epoch 30/50\n",
      "691/691 [==============================] - 0s 563us/step - loss: 1.0973 - accuracy: 0.9103 - val_loss: 6.7041 - val_accuracy: 0.1272\n",
      "Epoch 31/50\n",
      "691/691 [==============================] - 0s 562us/step - loss: 1.1221 - accuracy: 0.9190 - val_loss: 6.0568 - val_accuracy: 0.1503\n",
      "Epoch 32/50\n",
      "691/691 [==============================] - 0s 568us/step - loss: 1.0154 - accuracy: 0.9378 - val_loss: 6.5096 - val_accuracy: 0.1387\n",
      "Epoch 33/50\n",
      "691/691 [==============================] - 0s 569us/step - loss: 0.9855 - accuracy: 0.9334 - val_loss: 6.1589 - val_accuracy: 0.1503\n",
      "Epoch 34/50\n",
      "691/691 [==============================] - 0s 565us/step - loss: 0.9939 - accuracy: 0.9233 - val_loss: 6.0516 - val_accuracy: 0.1387\n",
      "Epoch 35/50\n",
      "691/691 [==============================] - 0s 565us/step - loss: 0.9424 - accuracy: 0.9392 - val_loss: 6.2010 - val_accuracy: 0.1503\n",
      "Epoch 36/50\n",
      "691/691 [==============================] - 0s 563us/step - loss: 0.9472 - accuracy: 0.9291 - val_loss: 5.8581 - val_accuracy: 0.1676\n",
      "Epoch 37/50\n",
      "691/691 [==============================] - 0s 563us/step - loss: 0.9399 - accuracy: 0.9349 - val_loss: 7.1086 - val_accuracy: 0.1329\n",
      "Epoch 38/50\n",
      "691/691 [==============================] - 0s 559us/step - loss: 0.8968 - accuracy: 0.9493 - val_loss: 7.4412 - val_accuracy: 0.1387\n",
      "Epoch 39/50\n",
      "691/691 [==============================] - 0s 556us/step - loss: 0.9067 - accuracy: 0.9334 - val_loss: 6.3916 - val_accuracy: 0.1561\n",
      "Epoch 40/50\n",
      "691/691 [==============================] - 0s 558us/step - loss: 0.9096 - accuracy: 0.9291 - val_loss: 5.6485 - val_accuracy: 0.1561\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "691/691 [==============================] - 0s 559us/step - loss: 0.8898 - accuracy: 0.9349 - val_loss: 6.3318 - val_accuracy: 0.1561\n",
      "Epoch 42/50\n",
      "691/691 [==============================] - 0s 561us/step - loss: 0.8976 - accuracy: 0.9276 - val_loss: 6.5169 - val_accuracy: 0.1329\n",
      "Epoch 43/50\n",
      "691/691 [==============================] - 0s 563us/step - loss: 0.8598 - accuracy: 0.9551 - val_loss: 5.7456 - val_accuracy: 0.1329\n",
      "Epoch 44/50\n",
      "691/691 [==============================] - 0s 562us/step - loss: 0.9373 - accuracy: 0.9276 - val_loss: 5.4849 - val_accuracy: 0.1040\n",
      "Epoch 45/50\n",
      "691/691 [==============================] - 0s 553us/step - loss: 0.8670 - accuracy: 0.9378 - val_loss: 5.7633 - val_accuracy: 0.0925\n",
      "Epoch 46/50\n",
      "691/691 [==============================] - 0s 558us/step - loss: 0.7963 - accuracy: 0.9653 - val_loss: 5.4977 - val_accuracy: 0.1272\n",
      "Epoch 47/50\n",
      "691/691 [==============================] - 0s 558us/step - loss: 0.7633 - accuracy: 0.9522 - val_loss: 5.0162 - val_accuracy: 0.1561\n",
      "Epoch 48/50\n",
      "691/691 [==============================] - 0s 555us/step - loss: 0.7877 - accuracy: 0.9580 - val_loss: 5.2992 - val_accuracy: 0.1272\n",
      "Epoch 49/50\n",
      "691/691 [==============================] - 0s 561us/step - loss: 0.7840 - accuracy: 0.9566 - val_loss: 5.1537 - val_accuracy: 0.1618\n",
      "Epoch 50/50\n",
      "691/691 [==============================] - 0s 558us/step - loss: 0.7685 - accuracy: 0.9551 - val_loss: 4.8515 - val_accuracy: 0.1561\n",
      "173/173 [==============================] - 0s 255us/step\n",
      "173/173 [==============================] - 0s 150us/step\n",
      " \n",
      "Train on 691 samples, validate on 173 samples\n",
      "Epoch 1/50\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 3.3729 - accuracy: 0.0680 - val_loss: 2.8701 - val_accuracy: 0.0867\n",
      "Epoch 2/50\n",
      "691/691 [==============================] - 0s 552us/step - loss: 2.8363 - accuracy: 0.0709 - val_loss: 2.9475 - val_accuracy: 0.0809\n",
      "Epoch 3/50\n",
      "691/691 [==============================] - 0s 556us/step - loss: 2.7486 - accuracy: 0.0666 - val_loss: 2.6807 - val_accuracy: 0.0867\n",
      "Epoch 4/50\n",
      "691/691 [==============================] - 0s 555us/step - loss: 2.6612 - accuracy: 0.0984 - val_loss: 2.6420 - val_accuracy: 0.0751\n",
      "Epoch 5/50\n",
      "691/691 [==============================] - 0s 556us/step - loss: 2.6538 - accuracy: 0.1143 - val_loss: 2.6417 - val_accuracy: 0.0809\n",
      "Epoch 6/50\n",
      "691/691 [==============================] - 0s 555us/step - loss: 2.6266 - accuracy: 0.1172 - val_loss: 2.6980 - val_accuracy: 0.0983\n",
      "Epoch 7/50\n",
      "691/691 [==============================] - 0s 552us/step - loss: 2.5889 - accuracy: 0.1505 - val_loss: 2.7180 - val_accuracy: 0.0925\n",
      "Epoch 8/50\n",
      "691/691 [==============================] - 0s 552us/step - loss: 2.5570 - accuracy: 0.1664 - val_loss: 2.7223 - val_accuracy: 0.1272\n",
      "Epoch 9/50\n",
      "691/691 [==============================] - 0s 556us/step - loss: 2.5070 - accuracy: 0.1809 - val_loss: 2.7345 - val_accuracy: 0.1618\n",
      "Epoch 10/50\n",
      "691/691 [==============================] - 0s 552us/step - loss: 2.4632 - accuracy: 0.2156 - val_loss: 2.7971 - val_accuracy: 0.1445\n",
      "Epoch 11/50\n",
      "691/691 [==============================] - 0s 556us/step - loss: 2.4383 - accuracy: 0.2330 - val_loss: 2.8038 - val_accuracy: 0.1445\n",
      "Epoch 12/50\n",
      "691/691 [==============================] - 0s 553us/step - loss: 2.3723 - accuracy: 0.2504 - val_loss: 2.7498 - val_accuracy: 0.1387\n",
      "Epoch 13/50\n",
      "691/691 [==============================] - 0s 555us/step - loss: 2.3305 - accuracy: 0.2750 - val_loss: 2.8253 - val_accuracy: 0.1618\n",
      "Epoch 14/50\n",
      "691/691 [==============================] - 0s 550us/step - loss: 2.2875 - accuracy: 0.3213 - val_loss: 2.9114 - val_accuracy: 0.1618\n",
      "Epoch 15/50\n",
      "691/691 [==============================] - 0s 553us/step - loss: 2.2188 - accuracy: 0.4023 - val_loss: 3.3453 - val_accuracy: 0.1387\n",
      "Epoch 16/50\n",
      "691/691 [==============================] - 0s 555us/step - loss: 2.1174 - accuracy: 0.4602 - val_loss: 2.9844 - val_accuracy: 0.1908\n",
      "Epoch 17/50\n",
      "691/691 [==============================] - 0s 553us/step - loss: 2.0357 - accuracy: 0.5166 - val_loss: 3.3097 - val_accuracy: 0.1214\n",
      "Epoch 18/50\n",
      "691/691 [==============================] - 0s 555us/step - loss: 2.0845 - accuracy: 0.5485 - val_loss: 3.4445 - val_accuracy: 0.1387\n",
      "Epoch 19/50\n",
      "691/691 [==============================] - 0s 553us/step - loss: 1.8636 - accuracy: 0.6368 - val_loss: 3.2449 - val_accuracy: 0.1618\n",
      "Epoch 20/50\n",
      "691/691 [==============================] - 0s 549us/step - loss: 1.7394 - accuracy: 0.7091 - val_loss: 3.1872 - val_accuracy: 0.1503\n",
      "Epoch 21/50\n",
      "691/691 [==============================] - 0s 552us/step - loss: 1.6586 - accuracy: 0.7511 - val_loss: 3.2560 - val_accuracy: 0.1214\n",
      "Epoch 22/50\n",
      "691/691 [==============================] - 0s 553us/step - loss: 1.6197 - accuracy: 0.7337 - val_loss: 3.3386 - val_accuracy: 0.1329\n",
      "Epoch 23/50\n",
      "691/691 [==============================] - 0s 555us/step - loss: 1.4801 - accuracy: 0.7931 - val_loss: 3.3883 - val_accuracy: 0.1329\n",
      "Epoch 24/50\n",
      "691/691 [==============================] - 0s 552us/step - loss: 1.4377 - accuracy: 0.7974 - val_loss: 3.3776 - val_accuracy: 0.1503\n",
      "Epoch 25/50\n",
      "691/691 [==============================] - 0s 559us/step - loss: 1.3618 - accuracy: 0.8148 - val_loss: 3.3962 - val_accuracy: 0.1214\n",
      "Epoch 26/50\n",
      "691/691 [==============================] - 0s 550us/step - loss: 1.3120 - accuracy: 0.8234 - val_loss: 3.3034 - val_accuracy: 0.1734\n",
      "Epoch 27/50\n",
      "691/691 [==============================] - 0s 550us/step - loss: 1.2956 - accuracy: 0.8234 - val_loss: 3.2987 - val_accuracy: 0.1329\n",
      "Epoch 28/50\n",
      "691/691 [==============================] - 0s 552us/step - loss: 1.2344 - accuracy: 0.8466 - val_loss: 3.7217 - val_accuracy: 0.1445\n",
      "Epoch 29/50\n",
      "691/691 [==============================] - 0s 550us/step - loss: 1.1830 - accuracy: 0.8654 - val_loss: 3.4248 - val_accuracy: 0.1272\n",
      "Epoch 30/50\n",
      "691/691 [==============================] - 0s 553us/step - loss: 1.1355 - accuracy: 0.8871 - val_loss: 3.6164 - val_accuracy: 0.1445\n",
      "Epoch 31/50\n",
      "691/691 [==============================] - 0s 553us/step - loss: 1.1238 - accuracy: 0.8770 - val_loss: 3.3941 - val_accuracy: 0.1503\n",
      "Epoch 32/50\n",
      "691/691 [==============================] - 0s 553us/step - loss: 1.0686 - accuracy: 0.8755 - val_loss: 3.6468 - val_accuracy: 0.1040\n",
      "Epoch 33/50\n",
      "691/691 [==============================] - 0s 555us/step - loss: 1.0158 - accuracy: 0.8929 - val_loss: 3.4376 - val_accuracy: 0.0925\n",
      "Epoch 34/50\n",
      "691/691 [==============================] - 0s 550us/step - loss: 0.9380 - accuracy: 0.9190 - val_loss: 3.4116 - val_accuracy: 0.1503\n",
      "Epoch 35/50\n",
      "691/691 [==============================] - 0s 555us/step - loss: 0.9231 - accuracy: 0.9132 - val_loss: 3.5759 - val_accuracy: 0.1445\n",
      "Epoch 36/50\n",
      "691/691 [==============================] - 0s 548us/step - loss: 0.8903 - accuracy: 0.9175 - val_loss: 3.4902 - val_accuracy: 0.1387\n",
      "Epoch 37/50\n",
      "691/691 [==============================] - 0s 553us/step - loss: 0.9122 - accuracy: 0.9059 - val_loss: 3.7795 - val_accuracy: 0.1503\n",
      "Epoch 38/50\n",
      "691/691 [==============================] - 0s 553us/step - loss: 0.9126 - accuracy: 0.9247 - val_loss: 3.3681 - val_accuracy: 0.1214\n",
      "Epoch 39/50\n",
      "691/691 [==============================] - 0s 556us/step - loss: 0.8712 - accuracy: 0.9219 - val_loss: 3.6236 - val_accuracy: 0.1618\n",
      "Epoch 40/50\n",
      "691/691 [==============================] - 0s 553us/step - loss: 0.8430 - accuracy: 0.9219 - val_loss: 3.3694 - val_accuracy: 0.1156\n",
      "Epoch 41/50\n",
      "691/691 [==============================] - 0s 552us/step - loss: 0.8500 - accuracy: 0.9291 - val_loss: 3.4349 - val_accuracy: 0.0925\n",
      "Epoch 42/50\n",
      "691/691 [==============================] - 0s 556us/step - loss: 0.8314 - accuracy: 0.9247 - val_loss: 3.4139 - val_accuracy: 0.1445\n",
      "Epoch 43/50\n",
      "691/691 [==============================] - 0s 555us/step - loss: 0.7935 - accuracy: 0.9378 - val_loss: 3.4743 - val_accuracy: 0.1098\n",
      "Epoch 44/50\n",
      "691/691 [==============================] - 0s 556us/step - loss: 0.7822 - accuracy: 0.9334 - val_loss: 3.3808 - val_accuracy: 0.1561\n",
      "Epoch 45/50\n",
      "691/691 [==============================] - 0s 552us/step - loss: 0.7784 - accuracy: 0.9276 - val_loss: 3.4122 - val_accuracy: 0.1445\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "691/691 [==============================] - 0s 558us/step - loss: 0.7491 - accuracy: 0.9421 - val_loss: 3.3706 - val_accuracy: 0.1445\n",
      "Epoch 47/50\n",
      "691/691 [==============================] - 0s 555us/step - loss: 0.7339 - accuracy: 0.9407 - val_loss: 3.4233 - val_accuracy: 0.1040\n",
      "Epoch 48/50\n",
      "691/691 [==============================] - 0s 553us/step - loss: 0.7053 - accuracy: 0.9624 - val_loss: 3.6285 - val_accuracy: 0.1503\n",
      "Epoch 49/50\n",
      "691/691 [==============================] - 0s 555us/step - loss: 0.7284 - accuracy: 0.9421 - val_loss: 3.3864 - val_accuracy: 0.1387\n",
      "Epoch 50/50\n",
      "691/691 [==============================] - 0s 553us/step - loss: 0.7147 - accuracy: 0.9436 - val_loss: 3.3153 - val_accuracy: 0.1445\n",
      "173/173 [==============================] - 0s 243us/step\n",
      "173/173 [==============================] - 0s 145us/step\n",
      " \n",
      "Accuracy: 14.34\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 468x468 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "keep_accuracy = np.zeros((10))\n",
    "j = 0\n",
    "\n",
    "for participant in files:\n",
    "    mat = loadmat(participant)\n",
    "    X = np.array(mat[\"X_2D\"])\n",
    "    y = np.array(mat[\"exemplarLabels\"]).ravel()     # get labels (exemplar)\n",
    "\n",
    "    y_hf =[]\n",
    "    X_hf = []\n",
    "    for i in range(0,len(X)):                       # keep only the hf category\n",
    "        if (12 < y[i] < 25):\n",
    "            y_hf.append(y[i])\n",
    "            X_hf.append(X[i])\n",
    "\n",
    "    X_hf = np.array(X_hf)\n",
    "    y_hf = np.array(y_hf).ravel()\n",
    "\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(y_hf)\n",
    "    y_hf = le.transform(y_hf)\n",
    "\n",
    "    X_training = X_hf[:int(0.8*len(X_hf))]          # create the train and test sets\n",
    "    X_validation = X_hf[int(0.8*len(X_hf)):]\n",
    "\n",
    "    y_training = y_hf[:int(0.8*len(X_hf))]\n",
    "    y_validation = y_hf[int(0.8*len(X_hf)):]\n",
    "\n",
    "    num_classes = 12                                # we have 12 classes\n",
    "    \n",
    "    y_training1hot = keras.utils.to_categorical(y_training - 1, num_classes)      # subtract 1 to convert to 0-index\n",
    "    y_validation1hot = keras.utils.to_categorical(y_validation - 1, num_classes)\n",
    "\n",
    "    # reshape to treat the data like images (124x32)\n",
    "    X_training = np.reshape(X_training, (-1, electrodes, N, 1))\n",
    "    X_validation = np.reshape(X_validation, (-1, electrodes, N, 1))\n",
    "\n",
    "    # cnn model\n",
    "    model = Sequential()                            \n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=X_training.shape[1:], activation = \"relu\"))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=128,kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "                    bias_regularizer=regularizers.l2(1e-3),\n",
    "                    activity_regularizer=regularizers.l2(1e-3),\n",
    "                    activation = \"relu\"))\n",
    "    model.add(Dropout(0.15))\n",
    "    model.add(Dense(units=num_classes,activity_regularizer=regularizers.l2(1e-5), activation = \"softmax\"))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='nadam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_training, y_training1hot,                                # train the model\n",
    "              epochs=50, \n",
    "              validation_data=(X_validation, y_validation1hot), \n",
    "              shuffle=True)\n",
    "\n",
    "    y_validation_predictions = model.predict(X_validation, verbose=1)    # make predictions\n",
    "\n",
    "    # create the confusion matrex\n",
    "    cnf_matrix6 = confusion_matrix(y_validation+1, np.argmax(y_validation_predictions, axis=1)+1)\n",
    "    cm_cv6 += cnf_matrix6                                                # add together all the confusion matrices\n",
    "    \n",
    "    _, accuracy = model.evaluate(X_validation, y_validation1hot)         # find accuracy\n",
    "    keep_accuracy[j] = accuracy\n",
    "    j = j + 1\n",
    "    print(\" \")\n",
    "    \n",
    "print('Accuracy: %.2f' % (np.mean(keep_accuracy)*100))                   # print mean accuracy\n",
    "\n",
    "sum_by_row = np.sum(cm_cv6, 1)                                           # normalize the final confusion matrix\n",
    "for i in range(0,12):\n",
    "    cm_cv6[i,:] = cm_cv6[i,:] / sum_by_row[i]\n",
    "        \n",
    "plot_cm(np.round(cm_cv6, 2),12)                                          # plot the final confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.11347518, 0.10638298, 0.04964539, 0.09929078, 0.07801418,\n",
       "        0.05673759, 0.12765957, 0.05673759, 0.03546099, 0.10638298,\n",
       "        0.08510638, 0.08510638],\n",
       "       [0.17808219, 0.10958904, 0.03424658, 0.06164384, 0.04794521,\n",
       "        0.05479452, 0.12328767, 0.04109589, 0.06164384, 0.07534247,\n",
       "        0.06849315, 0.14383562],\n",
       "       [0.11034483, 0.32413793, 0.02758621, 0.08965517, 0.00689655,\n",
       "        0.04137931, 0.05517241, 0.06206897, 0.05517241, 0.11724138,\n",
       "        0.03448276, 0.07586207],\n",
       "       [0.08965517, 0.13103448, 0.07586207, 0.02758621, 0.06206897,\n",
       "        0.13103448, 0.08275862, 0.04827586, 0.06206897, 0.08275862,\n",
       "        0.08965517, 0.11724138],\n",
       "       [0.09589041, 0.0890411 , 0.04794521, 0.0890411 , 0.06164384,\n",
       "        0.10958904, 0.06849315, 0.0890411 , 0.09589041, 0.08219178,\n",
       "        0.09589041, 0.07534247],\n",
       "       [0.0915493 , 0.11971831, 0.01408451, 0.09859155, 0.16197183,\n",
       "        0.12676056, 0.04929577, 0.06338028, 0.03521127, 0.07746479,\n",
       "        0.04929577, 0.11267606],\n",
       "       [0.04895105, 0.11188811, 0.04895105, 0.1048951 , 0.09090909,\n",
       "        0.1048951 , 0.08391608, 0.06293706, 0.05594406, 0.16083916,\n",
       "        0.06993007, 0.05594406],\n",
       "       [0.16666667, 0.08333333, 0.04166667, 0.0625    , 0.07638889,\n",
       "        0.06944444, 0.13194444, 0.0625    , 0.09027778, 0.04166667,\n",
       "        0.09722222, 0.07638889],\n",
       "       [0.12676056, 0.11971831, 0.04225352, 0.09859155, 0.05633803,\n",
       "        0.08450704, 0.03521127, 0.09859155, 0.04929577, 0.08450704,\n",
       "        0.11267606, 0.0915493 ],\n",
       "       [0.0625    , 0.15277778, 0.02777778, 0.125     , 0.11111111,\n",
       "        0.04166667, 0.0625    , 0.08333333, 0.14583333, 0.0625    ,\n",
       "        0.04166667, 0.08333333],\n",
       "       [0.09589041, 0.16438356, 0.04109589, 0.06849315, 0.06849315,\n",
       "        0.06849315, 0.04794521, 0.08219178, 0.08219178, 0.16438356,\n",
       "        0.06849315, 0.04794521],\n",
       "       [0.11643836, 0.04109589, 0.04794521, 0.03424658, 0.06164384,\n",
       "        0.14383562, 0.10273973, 0.06849315, 0.06849315, 0.08219178,\n",
       "        0.15753425, 0.07534247]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_cv6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep CNN, exemplar\n",
    "\n",
    "Εφαρμόζουμε το Deep cnn για τις exemplar κατηγορίες από όλες τις κλάσεις, δηλαδή κάνουμε ταξινόμηση για 72 κατηγορίες (12 κατηγορίες από κάθε κλάση)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4150 samples, validate on 1038 samples\n",
      "Epoch 1/50\n",
      "4150/4150 [==============================] - 3s 761us/step - loss: 4.3178 - accuracy: 0.0094 - val_loss: 5.9176 - val_accuracy: 0.0135\n",
      "Epoch 2/50\n",
      "4150/4150 [==============================] - 2s 430us/step - loss: 4.2834 - accuracy: 0.0125 - val_loss: 15.4058 - val_accuracy: 0.0135\n",
      "Epoch 3/50\n",
      "4150/4150 [==============================] - 2s 429us/step - loss: 4.2438 - accuracy: 0.0229 - val_loss: 4.5235 - val_accuracy: 0.0231\n",
      "Epoch 4/50\n",
      "4150/4150 [==============================] - 2s 433us/step - loss: 4.1628 - accuracy: 0.0272 - val_loss: 4.2465 - val_accuracy: 0.0250\n",
      "Epoch 5/50\n",
      "4150/4150 [==============================] - 2s 428us/step - loss: 4.1032 - accuracy: 0.0354 - val_loss: 4.2151 - val_accuracy: 0.0366\n",
      "Epoch 6/50\n",
      "4150/4150 [==============================] - 2s 476us/step - loss: 4.0448 - accuracy: 0.0439 - val_loss: 4.1182 - val_accuracy: 0.0405\n",
      "Epoch 7/50\n",
      "4150/4150 [==============================] - 2s 462us/step - loss: 3.9683 - accuracy: 0.0458 - val_loss: 4.2989 - val_accuracy: 0.0395\n",
      "Epoch 8/50\n",
      "4150/4150 [==============================] - 2s 469us/step - loss: 3.9081 - accuracy: 0.0542 - val_loss: 4.1162 - val_accuracy: 0.0405\n",
      "Epoch 9/50\n",
      "4150/4150 [==============================] - 2s 472us/step - loss: 3.8566 - accuracy: 0.0602 - val_loss: 4.1129 - val_accuracy: 0.0318\n",
      "Epoch 10/50\n",
      "4150/4150 [==============================] - 2s 471us/step - loss: 3.7427 - accuracy: 0.0687 - val_loss: 4.1834 - val_accuracy: 0.0472\n",
      "Epoch 11/50\n",
      "4150/4150 [==============================] - 2s 506us/step - loss: 3.6256 - accuracy: 0.0865 - val_loss: 4.3493 - val_accuracy: 0.0395\n",
      "Epoch 12/50\n",
      "4150/4150 [==============================] - 2s 470us/step - loss: 3.5273 - accuracy: 0.0983 - val_loss: 4.1613 - val_accuracy: 0.0472\n",
      "Epoch 13/50\n",
      "4150/4150 [==============================] - 2s 495us/step - loss: 3.4098 - accuracy: 0.1157 - val_loss: 4.2746 - val_accuracy: 0.0501\n",
      "Epoch 14/50\n",
      "4150/4150 [==============================] - 2s 486us/step - loss: 3.2696 - accuracy: 0.1333 - val_loss: 4.2598 - val_accuracy: 0.0520\n",
      "Epoch 15/50\n",
      "4150/4150 [==============================] - 2s 455us/step - loss: 3.1244 - accuracy: 0.1595 - val_loss: 4.4063 - val_accuracy: 0.0443\n",
      "Epoch 16/50\n",
      "4150/4150 [==============================] - 2s 512us/step - loss: 3.0162 - accuracy: 0.1798 - val_loss: 4.7213 - val_accuracy: 0.0491\n",
      "Epoch 17/50\n",
      "4150/4150 [==============================] - 2s 448us/step - loss: 2.8914 - accuracy: 0.1971 - val_loss: 4.5843 - val_accuracy: 0.0414\n",
      "Epoch 18/50\n",
      "4150/4150 [==============================] - 2s 484us/step - loss: 2.7551 - accuracy: 0.2316 - val_loss: 4.7979 - val_accuracy: 0.0520\n",
      "Epoch 19/50\n",
      "4150/4150 [==============================] - 2s 422us/step - loss: 2.6066 - accuracy: 0.2492 - val_loss: 5.1082 - val_accuracy: 0.0539\n",
      "Epoch 20/50\n",
      "4150/4150 [==============================] - 2s 437us/step - loss: 2.5118 - accuracy: 0.2802 - val_loss: 5.1306 - val_accuracy: 0.0501\n",
      "Epoch 21/50\n",
      "4150/4150 [==============================] - 2s 431us/step - loss: 2.3850 - accuracy: 0.3051 - val_loss: 5.1325 - val_accuracy: 0.0491\n",
      "Epoch 22/50\n",
      "4150/4150 [==============================] - 2s 427us/step - loss: 2.2660 - accuracy: 0.3318 - val_loss: 5.3692 - val_accuracy: 0.0539\n",
      "Epoch 23/50\n",
      "4150/4150 [==============================] - 2s 426us/step - loss: 2.2248 - accuracy: 0.3467 - val_loss: 5.5024 - val_accuracy: 0.0655\n",
      "Epoch 24/50\n",
      "4150/4150 [==============================] - 2s 428us/step - loss: 2.1484 - accuracy: 0.3614 - val_loss: 5.9218 - val_accuracy: 0.0530\n",
      "Epoch 25/50\n",
      "4150/4150 [==============================] - 2s 429us/step - loss: 2.0211 - accuracy: 0.4029 - val_loss: 5.6531 - val_accuracy: 0.0491\n",
      "Epoch 26/50\n",
      "4150/4150 [==============================] - 2s 430us/step - loss: 1.9838 - accuracy: 0.4161 - val_loss: 5.8798 - val_accuracy: 0.0511\n",
      "Epoch 27/50\n",
      "4150/4150 [==============================] - 2s 426us/step - loss: 1.8952 - accuracy: 0.4349 - val_loss: 6.2642 - val_accuracy: 0.0491\n",
      "Epoch 28/50\n",
      "4150/4150 [==============================] - 2s 429us/step - loss: 1.8145 - accuracy: 0.4624 - val_loss: 6.2670 - val_accuracy: 0.0501\n",
      "Epoch 29/50\n",
      "4150/4150 [==============================] - 2s 427us/step - loss: 1.8060 - accuracy: 0.4581 - val_loss: 6.3693 - val_accuracy: 0.0472\n",
      "Epoch 30/50\n",
      "4150/4150 [==============================] - 2s 427us/step - loss: 1.7247 - accuracy: 0.4865 - val_loss: 6.8562 - val_accuracy: 0.0588\n",
      "Epoch 31/50\n",
      "4150/4150 [==============================] - 2s 426us/step - loss: 1.6821 - accuracy: 0.4981 - val_loss: 7.0178 - val_accuracy: 0.0434\n",
      "Epoch 32/50\n",
      "4150/4150 [==============================] - 2s 426us/step - loss: 1.6253 - accuracy: 0.5219 - val_loss: 6.6304 - val_accuracy: 0.0539\n",
      "Epoch 33/50\n",
      "4150/4150 [==============================] - 2s 420us/step - loss: 1.6009 - accuracy: 0.5173 - val_loss: 7.0701 - val_accuracy: 0.0530\n",
      "Epoch 34/50\n",
      "4150/4150 [==============================] - 2s 423us/step - loss: 1.5809 - accuracy: 0.5388 - val_loss: 7.0650 - val_accuracy: 0.0568\n",
      "Epoch 35/50\n",
      "4150/4150 [==============================] - 2s 424us/step - loss: 1.4873 - accuracy: 0.5499 - val_loss: 7.6526 - val_accuracy: 0.0482\n",
      "Epoch 36/50\n",
      "4150/4150 [==============================] - 2s 424us/step - loss: 1.4435 - accuracy: 0.5658 - val_loss: 7.7799 - val_accuracy: 0.0559\n",
      "Epoch 37/50\n",
      "4150/4150 [==============================] - 2s 422us/step - loss: 1.4128 - accuracy: 0.5798 - val_loss: 8.3285 - val_accuracy: 0.0482\n",
      "Epoch 38/50\n",
      "4150/4150 [==============================] - 2s 424us/step - loss: 1.4182 - accuracy: 0.5704 - val_loss: 7.6293 - val_accuracy: 0.0453\n",
      "Epoch 39/50\n",
      "4150/4150 [==============================] - 2s 422us/step - loss: 1.3991 - accuracy: 0.5805 - val_loss: 8.0086 - val_accuracy: 0.0568\n",
      "Epoch 40/50\n",
      "4150/4150 [==============================] - 2s 422us/step - loss: 1.3682 - accuracy: 0.5923 - val_loss: 8.3248 - val_accuracy: 0.0511\n",
      "Epoch 41/50\n",
      "4150/4150 [==============================] - 2s 420us/step - loss: 1.3759 - accuracy: 0.5913 - val_loss: 8.1059 - val_accuracy: 0.0462\n",
      "Epoch 42/50\n",
      "4150/4150 [==============================] - 2s 422us/step - loss: 1.2463 - accuracy: 0.6318 - val_loss: 8.5721 - val_accuracy: 0.0617\n",
      "Epoch 43/50\n",
      "4150/4150 [==============================] - 2s 420us/step - loss: 1.2167 - accuracy: 0.6429 - val_loss: 8.7293 - val_accuracy: 0.0520\n",
      "Epoch 44/50\n",
      "4150/4150 [==============================] - 2s 423us/step - loss: 1.2249 - accuracy: 0.6371 - val_loss: 8.8777 - val_accuracy: 0.0511\n",
      "Epoch 45/50\n",
      "4150/4150 [==============================] - 2s 423us/step - loss: 1.1875 - accuracy: 0.6417 - val_loss: 9.1522 - val_accuracy: 0.0472\n",
      "Epoch 46/50\n",
      "4150/4150 [==============================] - 2s 428us/step - loss: 1.1745 - accuracy: 0.6530 - val_loss: 9.3716 - val_accuracy: 0.0491\n",
      "Epoch 47/50\n",
      "4150/4150 [==============================] - 2s 426us/step - loss: 1.2019 - accuracy: 0.6434 - val_loss: 9.0418 - val_accuracy: 0.0424\n",
      "Epoch 48/50\n",
      "4150/4150 [==============================] - 2s 425us/step - loss: 1.1892 - accuracy: 0.6530 - val_loss: 8.7286 - val_accuracy: 0.0376\n",
      "Epoch 49/50\n",
      "4150/4150 [==============================] - 2s 427us/step - loss: 1.1104 - accuracy: 0.6788 - val_loss: 9.4691 - val_accuracy: 0.0405\n",
      "Epoch 50/50\n",
      "4150/4150 [==============================] - 2s 423us/step - loss: 1.0901 - accuracy: 0.6858 - val_loss: 8.8893 - val_accuracy: 0.0424\n",
      "1038/1038 [==============================] - 0s 240us/step\n",
      "1038/1038 [==============================] - 0s 148us/step\n",
      " \n",
      "Train on 4148 samples, validate on 1037 samples\n",
      "Epoch 1/50\n",
      "4148/4148 [==============================] - 3s 776us/step - loss: 4.3228 - accuracy: 0.0137 - val_loss: 4.2813 - val_accuracy: 0.0164\n",
      "Epoch 2/50\n",
      "4148/4148 [==============================] - 2s 478us/step - loss: 4.2819 - accuracy: 0.0147 - val_loss: 4.7070 - val_accuracy: 0.0125\n",
      "Epoch 3/50\n",
      "4148/4148 [==============================] - 2s 474us/step - loss: 4.2570 - accuracy: 0.0198 - val_loss: 4.4172 - val_accuracy: 0.0106\n",
      "Epoch 4/50\n",
      "4148/4148 [==============================] - 2s 456us/step - loss: 4.2060 - accuracy: 0.0284 - val_loss: 4.2458 - val_accuracy: 0.0318\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4148/4148 [==============================] - 2s 448us/step - loss: 4.1203 - accuracy: 0.0436 - val_loss: 4.3379 - val_accuracy: 0.0280\n",
      "Epoch 6/50\n",
      "4148/4148 [==============================] - 2s 438us/step - loss: 4.0182 - accuracy: 0.0559 - val_loss: 4.1952 - val_accuracy: 0.0347\n",
      "Epoch 7/50\n",
      "4148/4148 [==============================] - 2s 440us/step - loss: 3.8591 - accuracy: 0.0740 - val_loss: 4.2947 - val_accuracy: 0.0260\n",
      "Epoch 8/50\n",
      "4148/4148 [==============================] - 2s 439us/step - loss: 3.6971 - accuracy: 0.0882 - val_loss: 4.2433 - val_accuracy: 0.0280\n",
      "Epoch 9/50\n",
      "4148/4148 [==============================] - 2s 470us/step - loss: 3.5000 - accuracy: 0.1230 - val_loss: 4.4333 - val_accuracy: 0.0434\n",
      "Epoch 10/50\n",
      "4148/4148 [==============================] - 2s 487us/step - loss: 3.2823 - accuracy: 0.1562 - val_loss: 4.2322 - val_accuracy: 0.0473\n",
      "Epoch 11/50\n",
      "4148/4148 [==============================] - 2s 466us/step - loss: 3.0930 - accuracy: 0.1946 - val_loss: 4.4145 - val_accuracy: 0.0376\n",
      "Epoch 12/50\n",
      "4148/4148 [==============================] - 2s 457us/step - loss: 2.8925 - accuracy: 0.2283 - val_loss: 4.8266 - val_accuracy: 0.0434\n",
      "Epoch 13/50\n",
      "4148/4148 [==============================] - 2s 451us/step - loss: 2.7112 - accuracy: 0.2676 - val_loss: 4.7629 - val_accuracy: 0.0376\n",
      "Epoch 14/50\n",
      "4148/4148 [==============================] - 2s 455us/step - loss: 2.5400 - accuracy: 0.3069 - val_loss: 4.7901 - val_accuracy: 0.0357\n",
      "Epoch 15/50\n",
      "4148/4148 [==============================] - 2s 475us/step - loss: 2.3770 - accuracy: 0.3433 - val_loss: 5.0740 - val_accuracy: 0.0569\n",
      "Epoch 16/50\n",
      "4148/4148 [==============================] - 2s 474us/step - loss: 2.2262 - accuracy: 0.3751 - val_loss: 5.0291 - val_accuracy: 0.0482\n",
      "Epoch 17/50\n",
      "4148/4148 [==============================] - 2s 452us/step - loss: 2.0548 - accuracy: 0.4183 - val_loss: 5.7160 - val_accuracy: 0.0366\n",
      "Epoch 18/50\n",
      "4148/4148 [==============================] - 2s 433us/step - loss: 1.9465 - accuracy: 0.4465 - val_loss: 6.5910 - val_accuracy: 0.0424\n",
      "Epoch 19/50\n",
      "4148/4148 [==============================] - 2s 443us/step - loss: 1.8758 - accuracy: 0.4629 - val_loss: 5.9614 - val_accuracy: 0.0386\n",
      "Epoch 20/50\n",
      "4148/4148 [==============================] - 2s 436us/step - loss: 1.7407 - accuracy: 0.5014 - val_loss: 6.2011 - val_accuracy: 0.0357\n",
      "Epoch 21/50\n",
      "4148/4148 [==============================] - 2s 432us/step - loss: 1.6413 - accuracy: 0.5345 - val_loss: 6.5478 - val_accuracy: 0.0444\n",
      "Epoch 22/50\n",
      "4148/4148 [==============================] - 2s 444us/step - loss: 1.5818 - accuracy: 0.5364 - val_loss: 6.8374 - val_accuracy: 0.0395\n",
      "Epoch 23/50\n",
      "4148/4148 [==============================] - 2s 437us/step - loss: 1.5190 - accuracy: 0.5514 - val_loss: 7.2730 - val_accuracy: 0.0376\n",
      "Epoch 24/50\n",
      "4148/4148 [==============================] - 2s 471us/step - loss: 1.4800 - accuracy: 0.5629 - val_loss: 7.4254 - val_accuracy: 0.0444\n",
      "Epoch 25/50\n",
      "4148/4148 [==============================] - 2s 478us/step - loss: 1.3731 - accuracy: 0.5899 - val_loss: 7.6264 - val_accuracy: 0.0395\n",
      "Epoch 26/50\n",
      "4148/4148 [==============================] - 2s 470us/step - loss: 1.2956 - accuracy: 0.6157 - val_loss: 8.4133 - val_accuracy: 0.0424\n",
      "Epoch 27/50\n",
      "4148/4148 [==============================] - 2s 449us/step - loss: 1.3136 - accuracy: 0.6109 - val_loss: 8.1663 - val_accuracy: 0.0501\n",
      "Epoch 28/50\n",
      "4148/4148 [==============================] - 2s 459us/step - loss: 1.2322 - accuracy: 0.6340 - val_loss: 7.2275 - val_accuracy: 0.0482\n",
      "Epoch 29/50\n",
      "4148/4148 [==============================] - 2s 438us/step - loss: 1.1722 - accuracy: 0.6569 - val_loss: 8.4632 - val_accuracy: 0.0444\n",
      "Epoch 30/50\n",
      "4148/4148 [==============================] - 2s 440us/step - loss: 1.1355 - accuracy: 0.6666 - val_loss: 7.9695 - val_accuracy: 0.0453\n",
      "Epoch 31/50\n",
      "4148/4148 [==============================] - 2s 462us/step - loss: 1.0905 - accuracy: 0.6806 - val_loss: 8.8177 - val_accuracy: 0.0434\n",
      "Epoch 32/50\n",
      "4148/4148 [==============================] - 2s 452us/step - loss: 1.0510 - accuracy: 0.6938 - val_loss: 7.9918 - val_accuracy: 0.0386\n",
      "Epoch 33/50\n",
      "4148/4148 [==============================] - 2s 449us/step - loss: 1.0395 - accuracy: 0.6880 - val_loss: 9.0780 - val_accuracy: 0.0424\n",
      "Epoch 34/50\n",
      "4148/4148 [==============================] - 2s 448us/step - loss: 0.9991 - accuracy: 0.7023 - val_loss: 8.3409 - val_accuracy: 0.0434\n",
      "Epoch 35/50\n",
      "4148/4148 [==============================] - 2s 450us/step - loss: 0.9690 - accuracy: 0.7177 - val_loss: 9.0163 - val_accuracy: 0.0473\n",
      "Epoch 36/50\n",
      "4148/4148 [==============================] - 2s 444us/step - loss: 0.9252 - accuracy: 0.7232 - val_loss: 8.6835 - val_accuracy: 0.0453\n",
      "Epoch 37/50\n",
      "4148/4148 [==============================] - 2s 438us/step - loss: 0.9127 - accuracy: 0.7365 - val_loss: 9.4442 - val_accuracy: 0.0424\n",
      "Epoch 38/50\n",
      "4148/4148 [==============================] - 2s 443us/step - loss: 0.8590 - accuracy: 0.7490 - val_loss: 9.4434 - val_accuracy: 0.0473\n",
      "Epoch 39/50\n",
      "4148/4148 [==============================] - 2s 438us/step - loss: 0.8481 - accuracy: 0.7527 - val_loss: 9.9527 - val_accuracy: 0.0453\n",
      "Epoch 40/50\n",
      "4148/4148 [==============================] - 2s 441us/step - loss: 0.8175 - accuracy: 0.7592 - val_loss: 9.3149 - val_accuracy: 0.0366\n",
      "Epoch 41/50\n",
      "4148/4148 [==============================] - 2s 442us/step - loss: 0.7813 - accuracy: 0.7741 - val_loss: 9.8981 - val_accuracy: 0.0550\n",
      "Epoch 42/50\n",
      "4148/4148 [==============================] - 2s 440us/step - loss: 0.7838 - accuracy: 0.7686 - val_loss: 10.0086 - val_accuracy: 0.0453\n",
      "Epoch 43/50\n",
      "4148/4148 [==============================] - 2s 441us/step - loss: 0.8051 - accuracy: 0.7707 - val_loss: 9.9108 - val_accuracy: 0.0347\n",
      "Epoch 44/50\n",
      "4148/4148 [==============================] - 2s 438us/step - loss: 0.7699 - accuracy: 0.7734 - val_loss: 11.2946 - val_accuracy: 0.0415\n",
      "Epoch 45/50\n",
      "4148/4148 [==============================] - 2s 436us/step - loss: 0.7837 - accuracy: 0.7705 - val_loss: 9.2913 - val_accuracy: 0.0434\n",
      "Epoch 46/50\n",
      "4148/4148 [==============================] - 2s 443us/step - loss: 0.7542 - accuracy: 0.7794 - val_loss: 10.1399 - val_accuracy: 0.0540\n",
      "Epoch 47/50\n",
      "4148/4148 [==============================] - 2s 440us/step - loss: 0.7785 - accuracy: 0.7797 - val_loss: 10.7916 - val_accuracy: 0.0559\n",
      "Epoch 48/50\n",
      "4148/4148 [==============================] - 2s 439us/step - loss: 0.7502 - accuracy: 0.7792 - val_loss: 9.8388 - val_accuracy: 0.0395\n",
      "Epoch 49/50\n",
      "4148/4148 [==============================] - 2s 438us/step - loss: 0.7253 - accuracy: 0.7956 - val_loss: 9.9996 - val_accuracy: 0.0530\n",
      "Epoch 50/50\n",
      "4148/4148 [==============================] - 2s 443us/step - loss: 0.6798 - accuracy: 0.8088 - val_loss: 10.7441 - val_accuracy: 0.0386\n",
      "1037/1037 [==============================] - 0s 232us/step\n",
      "1037/1037 [==============================] - 0s 145us/step\n",
      " \n",
      "Train on 4148 samples, validate on 1038 samples\n",
      "Epoch 1/50\n",
      "4148/4148 [==============================] - 3s 770us/step - loss: 4.3416 - accuracy: 0.0157 - val_loss: 4.4417 - val_accuracy: 0.0173\n",
      "Epoch 2/50\n",
      "4148/4148 [==============================] - 2s 465us/step - loss: 4.1405 - accuracy: 0.0321 - val_loss: 4.5308 - val_accuracy: 0.0125\n",
      "Epoch 3/50\n",
      "4148/4148 [==============================] - 2s 467us/step - loss: 3.9615 - accuracy: 0.0494 - val_loss: 4.6997 - val_accuracy: 0.0193\n",
      "Epoch 4/50\n",
      "4148/4148 [==============================] - 2s 468us/step - loss: 3.7936 - accuracy: 0.0689 - val_loss: 4.0353 - val_accuracy: 0.0356\n",
      "Epoch 5/50\n",
      "4148/4148 [==============================] - 2s 467us/step - loss: 3.5787 - accuracy: 0.0950 - val_loss: 3.9873 - val_accuracy: 0.0568\n",
      "Epoch 6/50\n",
      "4148/4148 [==============================] - 2s 468us/step - loss: 3.3575 - accuracy: 0.1280 - val_loss: 4.0783 - val_accuracy: 0.0472\n",
      "Epoch 7/50\n",
      "4148/4148 [==============================] - 2s 468us/step - loss: 3.1044 - accuracy: 0.1712 - val_loss: 4.1530 - val_accuracy: 0.0617\n",
      "Epoch 8/50\n",
      "4148/4148 [==============================] - 2s 467us/step - loss: 2.8495 - accuracy: 0.2194 - val_loss: 4.2027 - val_accuracy: 0.0703\n",
      "Epoch 9/50\n",
      "4148/4148 [==============================] - 2s 468us/step - loss: 2.5778 - accuracy: 0.2731 - val_loss: 4.3217 - val_accuracy: 0.0713\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50\n",
      "4148/4148 [==============================] - 2s 444us/step - loss: 2.3329 - accuracy: 0.3303 - val_loss: 4.3938 - val_accuracy: 0.0771\n",
      "Epoch 11/50\n",
      "4148/4148 [==============================] - 2s 449us/step - loss: 2.0894 - accuracy: 0.3824 - val_loss: 4.8569 - val_accuracy: 0.0723\n",
      "Epoch 12/50\n",
      "4148/4148 [==============================] - 2s 444us/step - loss: 1.8684 - accuracy: 0.4417 - val_loss: 4.9219 - val_accuracy: 0.0665\n",
      "Epoch 13/50\n",
      "4148/4148 [==============================] - 2s 445us/step - loss: 1.7263 - accuracy: 0.4822 - val_loss: 5.2632 - val_accuracy: 0.0857\n",
      "Epoch 14/50\n",
      "4148/4148 [==============================] - 2s 445us/step - loss: 1.4977 - accuracy: 0.5446 - val_loss: 5.6418 - val_accuracy: 0.0925\n",
      "Epoch 15/50\n",
      "4148/4148 [==============================] - 2s 440us/step - loss: 1.3439 - accuracy: 0.5865 - val_loss: 6.0097 - val_accuracy: 0.0819\n",
      "Epoch 16/50\n",
      "4148/4148 [==============================] - 2s 449us/step - loss: 1.2331 - accuracy: 0.6131 - val_loss: 6.0056 - val_accuracy: 0.0886\n",
      "Epoch 17/50\n",
      "4148/4148 [==============================] - 2s 451us/step - loss: 1.0996 - accuracy: 0.6579 - val_loss: 6.4107 - val_accuracy: 0.0771\n",
      "Epoch 18/50\n",
      "4148/4148 [==============================] - 2s 449us/step - loss: 1.0066 - accuracy: 0.6876 - val_loss: 6.9802 - val_accuracy: 0.0790\n",
      "Epoch 19/50\n",
      "4148/4148 [==============================] - 2s 448us/step - loss: 0.9287 - accuracy: 0.7093 - val_loss: 6.8711 - val_accuracy: 0.0809\n",
      "Epoch 20/50\n",
      "4148/4148 [==============================] - 2s 465us/step - loss: 0.8390 - accuracy: 0.7534 - val_loss: 7.5081 - val_accuracy: 0.0790\n",
      "Epoch 21/50\n",
      "4148/4148 [==============================] - 2s 448us/step - loss: 0.8004 - accuracy: 0.7498 - val_loss: 8.4972 - val_accuracy: 0.0617\n",
      "Epoch 22/50\n",
      "4148/4148 [==============================] - 2s 462us/step - loss: 0.7619 - accuracy: 0.7688 - val_loss: 7.4765 - val_accuracy: 0.0723\n",
      "Epoch 23/50\n",
      "4148/4148 [==============================] - 2s 435us/step - loss: 0.6758 - accuracy: 0.7900 - val_loss: 8.0264 - val_accuracy: 0.0809\n",
      "Epoch 24/50\n",
      "4148/4148 [==============================] - 2s 460us/step - loss: 0.6082 - accuracy: 0.8062 - val_loss: 8.8291 - val_accuracy: 0.0800\n",
      "Epoch 25/50\n",
      "4148/4148 [==============================] - 2s 470us/step - loss: 0.5688 - accuracy: 0.8269 - val_loss: 8.9289 - val_accuracy: 0.0829\n",
      "Epoch 26/50\n",
      "4148/4148 [==============================] - 2s 461us/step - loss: 0.5205 - accuracy: 0.8380 - val_loss: 9.4656 - val_accuracy: 0.0819\n",
      "Epoch 27/50\n",
      "4148/4148 [==============================] - 2s 486us/step - loss: 0.5287 - accuracy: 0.8351 - val_loss: 9.4683 - val_accuracy: 0.0809\n",
      "Epoch 28/50\n",
      "4148/4148 [==============================] - 2s 452us/step - loss: 0.5476 - accuracy: 0.8337 - val_loss: 9.5019 - val_accuracy: 0.0829\n",
      "Epoch 29/50\n",
      "4148/4148 [==============================] - 2s 499us/step - loss: 0.5502 - accuracy: 0.8305 - val_loss: 10.0730 - val_accuracy: 0.0703\n",
      "Epoch 30/50\n",
      "4148/4148 [==============================] - 2s 418us/step - loss: 0.4579 - accuracy: 0.8554 - val_loss: 10.5826 - val_accuracy: 0.0877\n",
      "Epoch 31/50\n",
      "4148/4148 [==============================] - 2s 427us/step - loss: 0.4203 - accuracy: 0.8742 - val_loss: 10.7955 - val_accuracy: 0.0694\n",
      "Epoch 32/50\n",
      "4148/4148 [==============================] - 2s 428us/step - loss: 0.3535 - accuracy: 0.8920 - val_loss: 10.1492 - val_accuracy: 0.0751\n",
      "Epoch 33/50\n",
      "4148/4148 [==============================] - 2s 455us/step - loss: 0.3357 - accuracy: 0.9031 - val_loss: 11.0664 - val_accuracy: 0.0703\n",
      "Epoch 34/50\n",
      "4148/4148 [==============================] - 2s 454us/step - loss: 0.3573 - accuracy: 0.8930 - val_loss: 11.1061 - val_accuracy: 0.0713\n",
      "Epoch 35/50\n",
      "4148/4148 [==============================] - 2s 477us/step - loss: 0.3874 - accuracy: 0.8809 - val_loss: 10.8767 - val_accuracy: 0.0780\n",
      "Epoch 36/50\n",
      "4148/4148 [==============================] - 2s 448us/step - loss: 0.4553 - accuracy: 0.8587 - val_loss: 10.9723 - val_accuracy: 0.0819\n",
      "Epoch 37/50\n",
      "4148/4148 [==============================] - 2s 430us/step - loss: 0.4829 - accuracy: 0.8614 - val_loss: 10.7749 - val_accuracy: 0.0790\n",
      "Epoch 38/50\n",
      "4148/4148 [==============================] - 2s 428us/step - loss: 0.3657 - accuracy: 0.8884 - val_loss: 11.1826 - val_accuracy: 0.0761\n",
      "Epoch 39/50\n",
      "4148/4148 [==============================] - 2s 432us/step - loss: 0.2868 - accuracy: 0.9156 - val_loss: 11.5730 - val_accuracy: 0.0751\n",
      "Epoch 40/50\n",
      "4148/4148 [==============================] - 2s 435us/step - loss: 0.2310 - accuracy: 0.9344 - val_loss: 11.3642 - val_accuracy: 0.0857\n",
      "Epoch 41/50\n",
      "4148/4148 [==============================] - 2s 435us/step - loss: 0.2310 - accuracy: 0.9354 - val_loss: 11.3920 - val_accuracy: 0.0906\n",
      "Epoch 42/50\n",
      "4148/4148 [==============================] - 2s 436us/step - loss: 0.2509 - accuracy: 0.9226 - val_loss: 11.3411 - val_accuracy: 0.0761\n",
      "Epoch 43/50\n",
      "4148/4148 [==============================] - 2s 434us/step - loss: 0.2966 - accuracy: 0.9151 - val_loss: 12.1300 - val_accuracy: 0.0877\n",
      "Epoch 44/50\n",
      "4148/4148 [==============================] - 2s 481us/step - loss: 0.3099 - accuracy: 0.9067 - val_loss: 12.4142 - val_accuracy: 0.0732\n",
      "Epoch 45/50\n",
      "4148/4148 [==============================] - 2s 455us/step - loss: 0.3445 - accuracy: 0.8954 - val_loss: 12.9441 - val_accuracy: 0.0723\n",
      "Epoch 46/50\n",
      "4148/4148 [==============================] - 2s 461us/step - loss: 0.3478 - accuracy: 0.8961 - val_loss: 11.2229 - val_accuracy: 0.0800\n",
      "Epoch 47/50\n",
      "4148/4148 [==============================] - 2s 452us/step - loss: 0.2982 - accuracy: 0.9106 - val_loss: 12.2179 - val_accuracy: 0.0800\n",
      "Epoch 48/50\n",
      "4148/4148 [==============================] - 2s 448us/step - loss: 0.2220 - accuracy: 0.9351 - val_loss: 12.5147 - val_accuracy: 0.0790\n",
      "Epoch 49/50\n",
      "4148/4148 [==============================] - 2s 464us/step - loss: 0.2174 - accuracy: 0.9339 - val_loss: 12.5486 - val_accuracy: 0.0829\n",
      "Epoch 50/50\n",
      "4148/4148 [==============================] - 2s 444us/step - loss: 0.1833 - accuracy: 0.9486 - val_loss: 12.6150 - val_accuracy: 0.0906\n",
      "1038/1038 [==============================] - 0s 264us/step\n",
      "1038/1038 [==============================] - 0s 158us/step\n",
      " \n",
      "Train on 4148 samples, validate on 1038 samples\n",
      "Epoch 1/50\n",
      "4148/4148 [==============================] - 3s 742us/step - loss: 4.3256 - accuracy: 0.0096 - val_loss: 4.5776 - val_accuracy: 0.0125\n",
      "Epoch 2/50\n",
      "4148/4148 [==============================] - 2s 438us/step - loss: 4.2866 - accuracy: 0.0130 - val_loss: 7.5992 - val_accuracy: 0.0125\n",
      "Epoch 3/50\n",
      "4148/4148 [==============================] - 2s 438us/step - loss: 4.2792 - accuracy: 0.0121 - val_loss: 4.7428 - val_accuracy: 0.0116\n",
      "Epoch 4/50\n",
      "4148/4148 [==============================] - 2s 434us/step - loss: 4.2836 - accuracy: 0.0123 - val_loss: 5.1349 - val_accuracy: 0.0145\n",
      "Epoch 5/50\n",
      "4148/4148 [==============================] - 2s 441us/step - loss: 4.2724 - accuracy: 0.0125 - val_loss: 4.3012 - val_accuracy: 0.0154\n",
      "Epoch 6/50\n",
      "4148/4148 [==============================] - 2s 433us/step - loss: 4.2522 - accuracy: 0.0181 - val_loss: 4.2889 - val_accuracy: 0.0193\n",
      "Epoch 7/50\n",
      "4148/4148 [==============================] - 2s 438us/step - loss: 4.2163 - accuracy: 0.0241 - val_loss: 4.2636 - val_accuracy: 0.0183\n",
      "Epoch 8/50\n",
      "4148/4148 [==============================] - 2s 436us/step - loss: 4.1561 - accuracy: 0.0229 - val_loss: 4.1687 - val_accuracy: 0.0270\n",
      "Epoch 9/50\n",
      "4148/4148 [==============================] - 2s 436us/step - loss: 4.0779 - accuracy: 0.0306 - val_loss: 4.4382 - val_accuracy: 0.0183\n",
      "Epoch 10/50\n",
      "4148/4148 [==============================] - 2s 436us/step - loss: 4.0260 - accuracy: 0.0350 - val_loss: 4.2780 - val_accuracy: 0.0299\n",
      "Epoch 11/50\n",
      "4148/4148 [==============================] - 2s 437us/step - loss: 3.9672 - accuracy: 0.0369 - val_loss: 4.4428 - val_accuracy: 0.0241\n",
      "Epoch 12/50\n",
      "4148/4148 [==============================] - 2s 437us/step - loss: 3.9079 - accuracy: 0.0403 - val_loss: 4.2448 - val_accuracy: 0.0222\n",
      "Epoch 13/50\n",
      "4148/4148 [==============================] - 2s 433us/step - loss: 3.8350 - accuracy: 0.0448 - val_loss: 4.1701 - val_accuracy: 0.0202\n",
      "Epoch 14/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4148/4148 [==============================] - 2s 430us/step - loss: 3.7702 - accuracy: 0.0470 - val_loss: 4.4030 - val_accuracy: 0.0231\n",
      "Epoch 15/50\n",
      "4148/4148 [==============================] - 2s 434us/step - loss: 3.7128 - accuracy: 0.0540 - val_loss: 4.1708 - val_accuracy: 0.0250\n",
      "Epoch 16/50\n",
      "4148/4148 [==============================] - 2s 428us/step - loss: 3.6098 - accuracy: 0.0615 - val_loss: 4.2715 - val_accuracy: 0.0241\n",
      "Epoch 17/50\n",
      "4148/4148 [==============================] - 2s 431us/step - loss: 3.5415 - accuracy: 0.0624 - val_loss: 4.4514 - val_accuracy: 0.0299\n",
      "Epoch 18/50\n",
      "4148/4148 [==============================] - 2s 429us/step - loss: 3.4971 - accuracy: 0.0733 - val_loss: 4.4280 - val_accuracy: 0.0202\n",
      "Epoch 19/50\n",
      "4148/4148 [==============================] - 2s 446us/step - loss: 3.4025 - accuracy: 0.0822 - val_loss: 4.4953 - val_accuracy: 0.0241\n",
      "Epoch 20/50\n",
      "4148/4148 [==============================] - 2s 484us/step - loss: 3.3423 - accuracy: 0.0875 - val_loss: 4.6232 - val_accuracy: 0.0337\n",
      "Epoch 21/50\n",
      "4148/4148 [==============================] - 2s 435us/step - loss: 3.2641 - accuracy: 0.1003 - val_loss: 4.8081 - val_accuracy: 0.0299\n",
      "Epoch 22/50\n",
      "4148/4148 [==============================] - 2s 426us/step - loss: 3.1825 - accuracy: 0.1078 - val_loss: 4.9119 - val_accuracy: 0.0328\n",
      "Epoch 23/50\n",
      "4148/4148 [==============================] - 2s 423us/step - loss: 3.1274 - accuracy: 0.1148 - val_loss: 4.9994 - val_accuracy: 0.0222\n",
      "Epoch 24/50\n",
      "4148/4148 [==============================] - 2s 423us/step - loss: 3.0506 - accuracy: 0.1307 - val_loss: 4.9888 - val_accuracy: 0.0250\n",
      "Epoch 25/50\n",
      "4148/4148 [==============================] - 2s 446us/step - loss: 2.9882 - accuracy: 0.1360 - val_loss: 5.1211 - val_accuracy: 0.0318\n",
      "Epoch 26/50\n",
      "4148/4148 [==============================] - 2s 438us/step - loss: 2.9094 - accuracy: 0.1509 - val_loss: 5.3897 - val_accuracy: 0.0250\n",
      "Epoch 27/50\n",
      "4148/4148 [==============================] - 2s 497us/step - loss: 2.8684 - accuracy: 0.1531 - val_loss: 5.5914 - val_accuracy: 0.0328\n",
      "Epoch 28/50\n",
      "4148/4148 [==============================] - 2s 454us/step - loss: 2.8264 - accuracy: 0.1685 - val_loss: 5.6469 - val_accuracy: 0.0289\n",
      "Epoch 29/50\n",
      "4148/4148 [==============================] - 2s 468us/step - loss: 2.7785 - accuracy: 0.1883 - val_loss: 5.7761 - val_accuracy: 0.0279\n",
      "Epoch 30/50\n",
      "4148/4148 [==============================] - 2s 465us/step - loss: 2.7655 - accuracy: 0.1917 - val_loss: 6.0485 - val_accuracy: 0.0318\n",
      "Epoch 31/50\n",
      "4148/4148 [==============================] - 2s 444us/step - loss: 2.7301 - accuracy: 0.1888 - val_loss: 5.9526 - val_accuracy: 0.0231\n",
      "Epoch 32/50\n",
      "4148/4148 [==============================] - 2s 429us/step - loss: 2.6501 - accuracy: 0.2126 - val_loss: 6.2676 - val_accuracy: 0.0279\n",
      "Epoch 33/50\n",
      "4148/4148 [==============================] - 2s 424us/step - loss: 2.6178 - accuracy: 0.2211 - val_loss: 6.2770 - val_accuracy: 0.0279\n",
      "Epoch 34/50\n",
      "4148/4148 [==============================] - 2s 429us/step - loss: 2.5752 - accuracy: 0.2264 - val_loss: 6.1680 - val_accuracy: 0.0328\n",
      "Epoch 35/50\n",
      "4148/4148 [==============================] - 2s 427us/step - loss: 2.5351 - accuracy: 0.2379 - val_loss: 6.7996 - val_accuracy: 0.0337\n",
      "Epoch 36/50\n",
      "4148/4148 [==============================] - 2s 425us/step - loss: 2.5086 - accuracy: 0.2488 - val_loss: 6.6910 - val_accuracy: 0.0289\n",
      "Epoch 37/50\n",
      "4148/4148 [==============================] - 2s 428us/step - loss: 2.4507 - accuracy: 0.2599 - val_loss: 6.7852 - val_accuracy: 0.0241\n",
      "Epoch 38/50\n",
      "4148/4148 [==============================] - 2s 425us/step - loss: 2.4373 - accuracy: 0.2628 - val_loss: 7.1129 - val_accuracy: 0.0260\n",
      "Epoch 39/50\n",
      "4148/4148 [==============================] - 2s 429us/step - loss: 2.4230 - accuracy: 0.2596 - val_loss: 7.1710 - val_accuracy: 0.0241\n",
      "Epoch 40/50\n",
      "4148/4148 [==============================] - 2s 427us/step - loss: 2.3517 - accuracy: 0.2799 - val_loss: 7.1002 - val_accuracy: 0.0279\n",
      "Epoch 41/50\n",
      "4148/4148 [==============================] - 2s 425us/step - loss: 2.3447 - accuracy: 0.2881 - val_loss: 7.4152 - val_accuracy: 0.0222\n",
      "Epoch 42/50\n",
      "4148/4148 [==============================] - 2s 429us/step - loss: 2.2985 - accuracy: 0.3091 - val_loss: 7.7993 - val_accuracy: 0.0308\n",
      "Epoch 43/50\n",
      "4148/4148 [==============================] - 2s 430us/step - loss: 2.2568 - accuracy: 0.3105 - val_loss: 7.7429 - val_accuracy: 0.0299\n",
      "Epoch 44/50\n",
      "4148/4148 [==============================] - 2s 427us/step - loss: 2.2380 - accuracy: 0.3214 - val_loss: 7.8509 - val_accuracy: 0.0289\n",
      "Epoch 45/50\n",
      "4148/4148 [==============================] - 2s 429us/step - loss: 2.2217 - accuracy: 0.3252 - val_loss: 7.9281 - val_accuracy: 0.0250\n",
      "Epoch 46/50\n",
      "4148/4148 [==============================] - 2s 430us/step - loss: 2.2137 - accuracy: 0.3194 - val_loss: 8.1687 - val_accuracy: 0.0328\n",
      "Epoch 47/50\n",
      "4148/4148 [==============================] - 2s 431us/step - loss: 2.1720 - accuracy: 0.3264 - val_loss: 8.2531 - val_accuracy: 0.0270\n",
      "Epoch 48/50\n",
      "4148/4148 [==============================] - 2s 429us/step - loss: 2.1602 - accuracy: 0.3310 - val_loss: 8.8472 - val_accuracy: 0.0241\n",
      "Epoch 49/50\n",
      "4148/4148 [==============================] - 2s 427us/step - loss: 2.1332 - accuracy: 0.3457 - val_loss: 8.6243 - val_accuracy: 0.0270\n",
      "Epoch 50/50\n",
      "4148/4148 [==============================] - 2s 422us/step - loss: 2.1318 - accuracy: 0.3464 - val_loss: 8.2032 - val_accuracy: 0.0328\n",
      "1038/1038 [==============================] - 0s 221us/step\n",
      "1038/1038 [==============================] - 0s 136us/step\n",
      " \n",
      "Train on 4148 samples, validate on 1037 samples\n",
      "Epoch 1/50\n",
      "4148/4148 [==============================] - 3s 751us/step - loss: 4.3115 - accuracy: 0.0108 - val_loss: 4.6309 - val_accuracy: 0.0145\n",
      "Epoch 2/50\n",
      "4148/4148 [==============================] - 2s 445us/step - loss: 4.2735 - accuracy: 0.0162 - val_loss: 12.9554 - val_accuracy: 0.0145\n",
      "Epoch 3/50\n",
      "4148/4148 [==============================] - 2s 447us/step - loss: 4.2346 - accuracy: 0.0222 - val_loss: 4.7406 - val_accuracy: 0.0087\n",
      "Epoch 4/50\n",
      "4148/4148 [==============================] - 2s 445us/step - loss: 4.1740 - accuracy: 0.0297 - val_loss: 4.2406 - val_accuracy: 0.0299\n",
      "Epoch 5/50\n",
      "4148/4148 [==============================] - 2s 446us/step - loss: 4.0641 - accuracy: 0.0371 - val_loss: 4.2648 - val_accuracy: 0.0328\n",
      "Epoch 6/50\n",
      "4148/4148 [==============================] - 2s 446us/step - loss: 3.9472 - accuracy: 0.0429 - val_loss: 4.2467 - val_accuracy: 0.0309\n",
      "Epoch 7/50\n",
      "4148/4148 [==============================] - 2s 443us/step - loss: 3.8533 - accuracy: 0.0562 - val_loss: 4.1548 - val_accuracy: 0.0289\n",
      "Epoch 8/50\n",
      "4148/4148 [==============================] - 2s 447us/step - loss: 3.7189 - accuracy: 0.0716 - val_loss: 4.1918 - val_accuracy: 0.0386\n",
      "Epoch 9/50\n",
      "4148/4148 [==============================] - 2s 445us/step - loss: 3.5480 - accuracy: 0.0914 - val_loss: 4.1340 - val_accuracy: 0.0511\n",
      "Epoch 10/50\n",
      "4148/4148 [==============================] - 2s 444us/step - loss: 3.3699 - accuracy: 0.1085 - val_loss: 4.1348 - val_accuracy: 0.0588\n",
      "Epoch 11/50\n",
      "4148/4148 [==============================] - 2s 444us/step - loss: 3.1913 - accuracy: 0.1367 - val_loss: 4.2728 - val_accuracy: 0.0627\n",
      "Epoch 12/50\n",
      "4148/4148 [==============================] - 2s 444us/step - loss: 3.0044 - accuracy: 0.1565 - val_loss: 4.6051 - val_accuracy: 0.0723\n",
      "Epoch 13/50\n",
      "4148/4148 [==============================] - 2s 438us/step - loss: 2.7894 - accuracy: 0.2032 - val_loss: 4.7417 - val_accuracy: 0.0511\n",
      "Epoch 14/50\n",
      "4148/4148 [==============================] - 2s 443us/step - loss: 2.5818 - accuracy: 0.2510 - val_loss: 4.9137 - val_accuracy: 0.0559\n",
      "Epoch 15/50\n",
      "4148/4148 [==============================] - 2s 441us/step - loss: 2.4007 - accuracy: 0.2878 - val_loss: 4.9123 - val_accuracy: 0.0665\n",
      "Epoch 16/50\n",
      "4148/4148 [==============================] - 2s 441us/step - loss: 2.1863 - accuracy: 0.3378 - val_loss: 4.9933 - val_accuracy: 0.0608\n",
      "Epoch 17/50\n",
      "4148/4148 [==============================] - 2s 441us/step - loss: 2.0178 - accuracy: 0.3927 - val_loss: 5.8864 - val_accuracy: 0.0617\n",
      "Epoch 18/50\n",
      "4148/4148 [==============================] - 2s 442us/step - loss: 1.8623 - accuracy: 0.4376 - val_loss: 5.6659 - val_accuracy: 0.0665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50\n",
      "4148/4148 [==============================] - 2s 438us/step - loss: 1.6954 - accuracy: 0.4701 - val_loss: 6.2597 - val_accuracy: 0.0771\n",
      "Epoch 20/50\n",
      "4148/4148 [==============================] - 2s 429us/step - loss: 1.5456 - accuracy: 0.5128 - val_loss: 5.8530 - val_accuracy: 0.0752\n",
      "Epoch 21/50\n",
      "4148/4148 [==============================] - 2s 426us/step - loss: 1.4706 - accuracy: 0.5350 - val_loss: 6.1557 - val_accuracy: 0.0588\n",
      "Epoch 22/50\n",
      "4148/4148 [==============================] - 2s 431us/step - loss: 1.3167 - accuracy: 0.5899 - val_loss: 6.8372 - val_accuracy: 0.0617\n",
      "Epoch 23/50\n",
      "4148/4148 [==============================] - 2s 427us/step - loss: 1.1890 - accuracy: 0.6261 - val_loss: 6.9522 - val_accuracy: 0.0675\n",
      "Epoch 24/50\n",
      "4148/4148 [==============================] - 2s 431us/step - loss: 1.1433 - accuracy: 0.6405 - val_loss: 7.0996 - val_accuracy: 0.0771\n",
      "Epoch 25/50\n",
      "4148/4148 [==============================] - 2s 441us/step - loss: 1.0585 - accuracy: 0.6733 - val_loss: 7.7704 - val_accuracy: 0.0752\n",
      "Epoch 26/50\n",
      "4148/4148 [==============================] - 2s 442us/step - loss: 0.9486 - accuracy: 0.6996 - val_loss: 8.1432 - val_accuracy: 0.0675\n",
      "Epoch 27/50\n",
      "4148/4148 [==============================] - 2s 440us/step - loss: 0.9208 - accuracy: 0.7182 - val_loss: 7.8649 - val_accuracy: 0.0675\n",
      "Epoch 28/50\n",
      "4148/4148 [==============================] - 2s 442us/step - loss: 0.8834 - accuracy: 0.7242 - val_loss: 8.3411 - val_accuracy: 0.0636\n",
      "Epoch 29/50\n",
      "4148/4148 [==============================] - 2s 444us/step - loss: 0.8453 - accuracy: 0.7389 - val_loss: 8.5051 - val_accuracy: 0.0723\n",
      "Epoch 30/50\n",
      "4148/4148 [==============================] - 2s 450us/step - loss: 0.7657 - accuracy: 0.7625 - val_loss: 8.5301 - val_accuracy: 0.0636\n",
      "Epoch 31/50\n",
      "4148/4148 [==============================] - 2s 445us/step - loss: 0.7099 - accuracy: 0.7760 - val_loss: 9.1654 - val_accuracy: 0.0704\n",
      "Epoch 32/50\n",
      "4148/4148 [==============================] - 2s 442us/step - loss: 0.6788 - accuracy: 0.8001 - val_loss: 9.7366 - val_accuracy: 0.0646\n",
      "Epoch 33/50\n",
      "4148/4148 [==============================] - 2s 444us/step - loss: 0.6260 - accuracy: 0.8112 - val_loss: 9.4688 - val_accuracy: 0.0694\n",
      "Epoch 34/50\n",
      "4148/4148 [==============================] - 2s 444us/step - loss: 0.6147 - accuracy: 0.8226 - val_loss: 8.8286 - val_accuracy: 0.0743\n",
      "Epoch 35/50\n",
      "4148/4148 [==============================] - 2s 443us/step - loss: 0.5975 - accuracy: 0.8250 - val_loss: 9.6174 - val_accuracy: 0.0820\n",
      "Epoch 36/50\n",
      "4148/4148 [==============================] - 2s 442us/step - loss: 0.5772 - accuracy: 0.8293 - val_loss: 10.0478 - val_accuracy: 0.0646\n",
      "Epoch 37/50\n",
      "4148/4148 [==============================] - 2s 444us/step - loss: 0.5309 - accuracy: 0.8423 - val_loss: 10.2157 - val_accuracy: 0.0752\n",
      "Epoch 38/50\n",
      "4148/4148 [==============================] - 2s 418us/step - loss: 0.5291 - accuracy: 0.8406 - val_loss: 9.8179 - val_accuracy: 0.0733\n",
      "Epoch 39/50\n",
      "4148/4148 [==============================] - 2s 418us/step - loss: 0.5075 - accuracy: 0.8503 - val_loss: 10.5495 - val_accuracy: 0.0665\n",
      "Epoch 40/50\n",
      "4148/4148 [==============================] - 2s 416us/step - loss: 0.4776 - accuracy: 0.8607 - val_loss: 10.6943 - val_accuracy: 0.0608\n",
      "Epoch 41/50\n",
      "4148/4148 [==============================] - 2s 424us/step - loss: 0.4621 - accuracy: 0.8607 - val_loss: 10.9991 - val_accuracy: 0.0714\n",
      "Epoch 42/50\n",
      "4148/4148 [==============================] - 2s 418us/step - loss: 0.4368 - accuracy: 0.8710 - val_loss: 10.6796 - val_accuracy: 0.0714\n",
      "Epoch 43/50\n",
      "4148/4148 [==============================] - 2s 421us/step - loss: 0.4086 - accuracy: 0.8795 - val_loss: 10.4203 - val_accuracy: 0.0733\n",
      "Epoch 44/50\n",
      "4148/4148 [==============================] - 2s 423us/step - loss: 0.4001 - accuracy: 0.8804 - val_loss: 11.3812 - val_accuracy: 0.0694\n",
      "Epoch 45/50\n",
      "4148/4148 [==============================] - 2s 423us/step - loss: 0.4212 - accuracy: 0.8792 - val_loss: 11.3475 - val_accuracy: 0.0646\n",
      "Epoch 46/50\n",
      "4148/4148 [==============================] - 2s 423us/step - loss: 0.4057 - accuracy: 0.8819 - val_loss: 11.0223 - val_accuracy: 0.0675\n",
      "Epoch 47/50\n",
      "4148/4148 [==============================] - 2s 433us/step - loss: 0.3767 - accuracy: 0.8872 - val_loss: 13.3939 - val_accuracy: 0.0579\n",
      "Epoch 48/50\n",
      "4148/4148 [==============================] - 2s 447us/step - loss: 0.3913 - accuracy: 0.8838 - val_loss: 10.7746 - val_accuracy: 0.0723\n",
      "Epoch 49/50\n",
      "4148/4148 [==============================] - 2s 450us/step - loss: 0.4091 - accuracy: 0.8780 - val_loss: 11.4165 - val_accuracy: 0.0743\n",
      "Epoch 50/50\n",
      "4148/4148 [==============================] - 2s 441us/step - loss: 0.3813 - accuracy: 0.8886 - val_loss: 12.0945 - val_accuracy: 0.0714\n",
      "1037/1037 [==============================] - 0s 246us/step\n",
      "1037/1037 [==============================] - 0s 154us/step\n",
      " \n",
      "Train on 4148 samples, validate on 1038 samples\n",
      "Epoch 1/50\n",
      "4148/4148 [==============================] - 3s 764us/step - loss: 4.3002 - accuracy: 0.0152 - val_loss: 4.3518 - val_accuracy: 0.0135\n",
      "Epoch 2/50\n",
      "4148/4148 [==============================] - 2s 436us/step - loss: 4.1532 - accuracy: 0.0212 - val_loss: 9.5707 - val_accuracy: 0.0164\n",
      "Epoch 3/50\n",
      "4148/4148 [==============================] - 2s 449us/step - loss: 3.9930 - accuracy: 0.0400 - val_loss: 4.5310 - val_accuracy: 0.0299\n",
      "Epoch 4/50\n",
      "4148/4148 [==============================] - 2s 451us/step - loss: 3.8262 - accuracy: 0.0545 - val_loss: 4.0446 - val_accuracy: 0.0356\n",
      "Epoch 5/50\n",
      "4148/4148 [==============================] - 2s 437us/step - loss: 3.6402 - accuracy: 0.0752 - val_loss: 3.9674 - val_accuracy: 0.0559\n",
      "Epoch 6/50\n",
      "4148/4148 [==============================] - 2s 433us/step - loss: 3.4759 - accuracy: 0.0853 - val_loss: 3.7915 - val_accuracy: 0.0645\n",
      "Epoch 7/50\n",
      "4148/4148 [==============================] - 2s 436us/step - loss: 3.2985 - accuracy: 0.1102 - val_loss: 4.1179 - val_accuracy: 0.0617\n",
      "Epoch 8/50\n",
      "4148/4148 [==============================] - 2s 443us/step - loss: 3.1555 - accuracy: 0.1222 - val_loss: 3.9077 - val_accuracy: 0.0684\n",
      "Epoch 9/50\n",
      "4148/4148 [==============================] - 2s 442us/step - loss: 2.9684 - accuracy: 0.1606 - val_loss: 4.0016 - val_accuracy: 0.0559\n",
      "Epoch 10/50\n",
      "4148/4148 [==============================] - 2s 434us/step - loss: 2.8466 - accuracy: 0.1779 - val_loss: 3.8995 - val_accuracy: 0.0896\n",
      "Epoch 11/50\n",
      "4148/4148 [==============================] - 2s 459us/step - loss: 2.6789 - accuracy: 0.2083 - val_loss: 4.0996 - val_accuracy: 0.0645\n",
      "Epoch 12/50\n",
      "4148/4148 [==============================] - 2s 521us/step - loss: 2.5364 - accuracy: 0.2281 - val_loss: 4.2469 - val_accuracy: 0.0829\n",
      "Epoch 13/50\n",
      "4148/4148 [==============================] - 2s 507us/step - loss: 2.3941 - accuracy: 0.2645 - val_loss: 4.5221 - val_accuracy: 0.0771\n",
      "Epoch 14/50\n",
      "4148/4148 [==============================] - 2s 441us/step - loss: 2.2600 - accuracy: 0.2813 - val_loss: 4.5638 - val_accuracy: 0.0829\n",
      "Epoch 15/50\n",
      "4148/4148 [==============================] - 2s 464us/step - loss: 2.1687 - accuracy: 0.3033 - val_loss: 5.0043 - val_accuracy: 0.0684\n",
      "Epoch 16/50\n",
      "4148/4148 [==============================] - 2s 455us/step - loss: 2.0592 - accuracy: 0.3257 - val_loss: 5.0570 - val_accuracy: 0.0636\n",
      "Epoch 17/50\n",
      "4148/4148 [==============================] - 2s 456us/step - loss: 1.9456 - accuracy: 0.3599 - val_loss: 4.9547 - val_accuracy: 0.0809\n",
      "Epoch 18/50\n",
      "4148/4148 [==============================] - 2s 509us/step - loss: 1.8592 - accuracy: 0.3809 - val_loss: 5.7763 - val_accuracy: 0.0723\n",
      "Epoch 19/50\n",
      "4148/4148 [==============================] - 2s 491us/step - loss: 1.7900 - accuracy: 0.3992 - val_loss: 5.5384 - val_accuracy: 0.0800\n",
      "Epoch 20/50\n",
      "4148/4148 [==============================] - 2s 442us/step - loss: 1.7273 - accuracy: 0.4192 - val_loss: 6.1324 - val_accuracy: 0.0829\n",
      "Epoch 21/50\n",
      "4148/4148 [==============================] - 2s 437us/step - loss: 1.5783 - accuracy: 0.4554 - val_loss: 6.4671 - val_accuracy: 0.0723\n",
      "Epoch 22/50\n",
      "4148/4148 [==============================] - 2s 437us/step - loss: 1.5266 - accuracy: 0.4675 - val_loss: 6.2606 - val_accuracy: 0.0790\n",
      "Epoch 23/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4148/4148 [==============================] - 2s 452us/step - loss: 1.4743 - accuracy: 0.4928 - val_loss: 6.1836 - val_accuracy: 0.0809\n",
      "Epoch 24/50\n",
      "4148/4148 [==============================] - 2s 435us/step - loss: 1.4345 - accuracy: 0.5084 - val_loss: 6.7403 - val_accuracy: 0.0829\n",
      "Epoch 25/50\n",
      "4148/4148 [==============================] - 2s 438us/step - loss: 1.3611 - accuracy: 0.5284 - val_loss: 7.2413 - val_accuracy: 0.0819\n",
      "Epoch 26/50\n",
      "4148/4148 [==============================] - 2s 429us/step - loss: 1.3064 - accuracy: 0.5514 - val_loss: 7.4100 - val_accuracy: 0.0607\n",
      "Epoch 27/50\n",
      "4148/4148 [==============================] - 2s 430us/step - loss: 1.2355 - accuracy: 0.5788 - val_loss: 6.9914 - val_accuracy: 0.0857\n",
      "Epoch 28/50\n",
      "4148/4148 [==============================] - 2s 426us/step - loss: 1.1973 - accuracy: 0.5945 - val_loss: 7.2774 - val_accuracy: 0.0809\n",
      "Epoch 29/50\n",
      "4148/4148 [==============================] - 2s 441us/step - loss: 1.1489 - accuracy: 0.6008 - val_loss: 7.6429 - val_accuracy: 0.0819\n",
      "Epoch 30/50\n",
      "4148/4148 [==============================] - 2s 429us/step - loss: 1.1187 - accuracy: 0.6152 - val_loss: 7.8609 - val_accuracy: 0.0684\n",
      "Epoch 31/50\n",
      "4148/4148 [==============================] - 2s 426us/step - loss: 1.0786 - accuracy: 0.6242 - val_loss: 7.7390 - val_accuracy: 0.0838\n",
      "Epoch 32/50\n",
      "4148/4148 [==============================] - 2s 426us/step - loss: 1.0428 - accuracy: 0.6533 - val_loss: 7.9070 - val_accuracy: 0.0848\n",
      "Epoch 33/50\n",
      "4148/4148 [==============================] - 2s 429us/step - loss: 0.9939 - accuracy: 0.6618 - val_loss: 8.5392 - val_accuracy: 0.0684\n",
      "Epoch 34/50\n",
      "4148/4148 [==============================] - 2s 428us/step - loss: 0.9653 - accuracy: 0.6813 - val_loss: 8.1481 - val_accuracy: 0.0819\n",
      "Epoch 35/50\n",
      "4148/4148 [==============================] - 2s 425us/step - loss: 0.9004 - accuracy: 0.6933 - val_loss: 8.6965 - val_accuracy: 0.0780\n",
      "Epoch 36/50\n",
      "4148/4148 [==============================] - 2s 431us/step - loss: 0.8940 - accuracy: 0.7131 - val_loss: 8.8715 - val_accuracy: 0.0848\n",
      "Epoch 37/50\n",
      "4148/4148 [==============================] - 2s 425us/step - loss: 0.8573 - accuracy: 0.7196 - val_loss: 9.4390 - val_accuracy: 0.0819\n",
      "Epoch 38/50\n",
      "4148/4148 [==============================] - 2s 425us/step - loss: 0.8528 - accuracy: 0.7232 - val_loss: 9.3454 - val_accuracy: 0.0761\n",
      "Epoch 39/50\n",
      "4148/4148 [==============================] - 2s 427us/step - loss: 0.8188 - accuracy: 0.7266 - val_loss: 9.2914 - val_accuracy: 0.0848\n",
      "Epoch 40/50\n",
      "4148/4148 [==============================] - 2s 423us/step - loss: 0.8509 - accuracy: 0.7244 - val_loss: 9.9956 - val_accuracy: 0.0703\n",
      "Epoch 41/50\n",
      "4148/4148 [==============================] - 2s 424us/step - loss: 0.7745 - accuracy: 0.7469 - val_loss: 10.0140 - val_accuracy: 0.0713\n",
      "Epoch 42/50\n",
      "4148/4148 [==============================] - 2s 426us/step - loss: 0.7350 - accuracy: 0.7746 - val_loss: 10.2273 - val_accuracy: 0.0723\n",
      "Epoch 43/50\n",
      "4148/4148 [==============================] - 2s 425us/step - loss: 0.6982 - accuracy: 0.7780 - val_loss: 9.7499 - val_accuracy: 0.0877\n",
      "Epoch 44/50\n",
      "4148/4148 [==============================] - 2s 427us/step - loss: 0.6772 - accuracy: 0.7857 - val_loss: 10.0493 - val_accuracy: 0.0703\n",
      "Epoch 45/50\n",
      "4148/4148 [==============================] - 2s 425us/step - loss: 0.6817 - accuracy: 0.7835 - val_loss: 10.7835 - val_accuracy: 0.0829\n",
      "Epoch 46/50\n",
      "4148/4148 [==============================] - 2s 425us/step - loss: 0.7291 - accuracy: 0.7715 - val_loss: 10.5576 - val_accuracy: 0.0819\n",
      "Epoch 47/50\n",
      "4148/4148 [==============================] - 2s 423us/step - loss: 0.7196 - accuracy: 0.7787 - val_loss: 10.4681 - val_accuracy: 0.0886\n",
      "Epoch 48/50\n",
      "4148/4148 [==============================] - 2s 428us/step - loss: 0.6857 - accuracy: 0.7883 - val_loss: 10.0006 - val_accuracy: 0.0780\n",
      "Epoch 49/50\n",
      "4148/4148 [==============================] - 2s 430us/step - loss: 0.6342 - accuracy: 0.7997 - val_loss: 10.7852 - val_accuracy: 0.0751\n",
      "Epoch 50/50\n",
      "4148/4148 [==============================] - 2s 419us/step - loss: 0.5778 - accuracy: 0.8141 - val_loss: 11.3539 - val_accuracy: 0.0723\n",
      "1038/1038 [==============================] - 0s 224us/step\n",
      "1038/1038 [==============================] - 0s 136us/step\n",
      " \n",
      "Train on 4150 samples, validate on 1038 samples\n",
      "Epoch 1/50\n",
      "4150/4150 [==============================] - 3s 785us/step - loss: 4.3249 - accuracy: 0.0113 - val_loss: 4.2767 - val_accuracy: 0.0154\n",
      "Epoch 2/50\n",
      "4150/4150 [==============================] - 2s 467us/step - loss: 4.2562 - accuracy: 0.0207 - val_loss: 4.2548 - val_accuracy: 0.0164\n",
      "Epoch 3/50\n",
      "4150/4150 [==============================] - 2s 450us/step - loss: 4.1469 - accuracy: 0.0320 - val_loss: 4.1341 - val_accuracy: 0.0279\n",
      "Epoch 4/50\n",
      "4150/4150 [==============================] - 2s 436us/step - loss: 3.9379 - accuracy: 0.0417 - val_loss: 4.0450 - val_accuracy: 0.0434\n",
      "Epoch 5/50\n",
      "4150/4150 [==============================] - 2s 451us/step - loss: 3.7076 - accuracy: 0.0701 - val_loss: 4.1240 - val_accuracy: 0.0655\n",
      "Epoch 6/50\n",
      "4150/4150 [==============================] - 2s 430us/step - loss: 3.4989 - accuracy: 0.0834 - val_loss: 4.0477 - val_accuracy: 0.0530\n",
      "Epoch 7/50\n",
      "4150/4150 [==============================] - 2s 442us/step - loss: 3.2608 - accuracy: 0.1161 - val_loss: 4.4869 - val_accuracy: 0.0453\n",
      "Epoch 8/50\n",
      "4150/4150 [==============================] - 2s 431us/step - loss: 3.0174 - accuracy: 0.1581 - val_loss: 4.5431 - val_accuracy: 0.0539\n",
      "Epoch 9/50\n",
      "4150/4150 [==============================] - 2s 445us/step - loss: 2.7365 - accuracy: 0.2101 - val_loss: 4.7891 - val_accuracy: 0.0684\n",
      "Epoch 10/50\n",
      "4150/4150 [==============================] - 2s 417us/step - loss: 2.4982 - accuracy: 0.2545 - val_loss: 4.9914 - val_accuracy: 0.0588\n",
      "Epoch 11/50\n",
      "4150/4150 [==============================] - 2s 440us/step - loss: 2.2364 - accuracy: 0.3063 - val_loss: 5.6811 - val_accuracy: 0.0588\n",
      "Epoch 12/50\n",
      "4150/4150 [==============================] - 2s 447us/step - loss: 2.0123 - accuracy: 0.3622 - val_loss: 5.9450 - val_accuracy: 0.0520\n",
      "Epoch 13/50\n",
      "4150/4150 [==============================] - 2s 450us/step - loss: 1.8226 - accuracy: 0.4108 - val_loss: 6.5265 - val_accuracy: 0.0511\n",
      "Epoch 14/50\n",
      "4150/4150 [==============================] - 2s 423us/step - loss: 1.6438 - accuracy: 0.4781 - val_loss: 6.3823 - val_accuracy: 0.0636\n",
      "Epoch 15/50\n",
      "4150/4150 [==============================] - 2s 447us/step - loss: 1.4526 - accuracy: 0.5323 - val_loss: 7.4497 - val_accuracy: 0.0578\n",
      "Epoch 16/50\n",
      "4150/4150 [==============================] - 2s 442us/step - loss: 1.3521 - accuracy: 0.5600 - val_loss: 8.1256 - val_accuracy: 0.0549\n",
      "Epoch 17/50\n",
      "4150/4150 [==============================] - 2s 430us/step - loss: 1.2440 - accuracy: 0.5916 - val_loss: 7.5059 - val_accuracy: 0.0482\n",
      "Epoch 18/50\n",
      "4150/4150 [==============================] - 2s 418us/step - loss: 1.1139 - accuracy: 0.6386 - val_loss: 8.5691 - val_accuracy: 0.0559\n",
      "Epoch 19/50\n",
      "4150/4150 [==============================] - 2s 426us/step - loss: 1.0290 - accuracy: 0.6742 - val_loss: 9.8586 - val_accuracy: 0.0520\n",
      "Epoch 20/50\n",
      "4150/4150 [==============================] - 2s 418us/step - loss: 0.9803 - accuracy: 0.6940 - val_loss: 9.8060 - val_accuracy: 0.0655\n",
      "Epoch 21/50\n",
      "4150/4150 [==============================] - 2s 437us/step - loss: 0.9223 - accuracy: 0.7087 - val_loss: 10.2240 - val_accuracy: 0.0607\n",
      "Epoch 22/50\n",
      "4150/4150 [==============================] - 2s 447us/step - loss: 0.7827 - accuracy: 0.7619 - val_loss: 10.6224 - val_accuracy: 0.0530\n",
      "Epoch 23/50\n",
      "4150/4150 [==============================] - 2s 463us/step - loss: 0.6826 - accuracy: 0.7930 - val_loss: 11.8277 - val_accuracy: 0.0472\n",
      "Epoch 24/50\n",
      "4150/4150 [==============================] - 2s 446us/step - loss: 0.6610 - accuracy: 0.7954 - val_loss: 11.5280 - val_accuracy: 0.0626\n",
      "Epoch 25/50\n",
      "4150/4150 [==============================] - 2s 442us/step - loss: 0.7015 - accuracy: 0.7846 - val_loss: 11.8993 - val_accuracy: 0.0645\n",
      "Epoch 26/50\n",
      "4150/4150 [==============================] - 2s 422us/step - loss: 0.6725 - accuracy: 0.7952 - val_loss: 12.6331 - val_accuracy: 0.0636\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4150/4150 [==============================] - 2s 426us/step - loss: 0.6347 - accuracy: 0.8014 - val_loss: 13.7482 - val_accuracy: 0.0665\n",
      "Epoch 28/50\n",
      "4150/4150 [==============================] - 2s 428us/step - loss: 0.5121 - accuracy: 0.8475 - val_loss: 12.4802 - val_accuracy: 0.0578\n",
      "Epoch 29/50\n",
      "4150/4150 [==============================] - 2s 427us/step - loss: 0.5120 - accuracy: 0.8424 - val_loss: 12.8588 - val_accuracy: 0.0655\n",
      "Epoch 30/50\n",
      "4150/4150 [==============================] - 2s 454us/step - loss: 0.4877 - accuracy: 0.8614 - val_loss: 13.9569 - val_accuracy: 0.0578\n",
      "Epoch 31/50\n",
      "4150/4150 [==============================] - 2s 442us/step - loss: 0.4675 - accuracy: 0.8598 - val_loss: 14.3155 - val_accuracy: 0.0539\n",
      "Epoch 32/50\n",
      "4150/4150 [==============================] - 2s 457us/step - loss: 0.4863 - accuracy: 0.8535 - val_loss: 13.6069 - val_accuracy: 0.0530\n",
      "Epoch 33/50\n",
      "4150/4150 [==============================] - 2s 415us/step - loss: 0.4631 - accuracy: 0.8612 - val_loss: 13.6654 - val_accuracy: 0.0549\n",
      "Epoch 34/50\n",
      "4150/4150 [==============================] - 2s 458us/step - loss: 0.4609 - accuracy: 0.8595 - val_loss: 15.3941 - val_accuracy: 0.0568\n",
      "Epoch 35/50\n",
      "4150/4150 [==============================] - 2s 485us/step - loss: 0.4896 - accuracy: 0.8569 - val_loss: 15.3243 - val_accuracy: 0.0462\n",
      "Epoch 36/50\n",
      "4150/4150 [==============================] - 2s 472us/step - loss: 0.5306 - accuracy: 0.8472 - val_loss: 13.7434 - val_accuracy: 0.0568\n",
      "Epoch 37/50\n",
      "4150/4150 [==============================] - 2s 461us/step - loss: 0.4854 - accuracy: 0.8564 - val_loss: 14.8959 - val_accuracy: 0.0559\n",
      "Epoch 38/50\n",
      "4150/4150 [==============================] - 2s 478us/step - loss: 0.4062 - accuracy: 0.8829 - val_loss: 15.8405 - val_accuracy: 0.0674\n",
      "Epoch 39/50\n",
      "4150/4150 [==============================] - 2s 473us/step - loss: 0.3074 - accuracy: 0.9104 - val_loss: 16.2207 - val_accuracy: 0.0607\n",
      "Epoch 40/50\n",
      "4150/4150 [==============================] - 2s 464us/step - loss: 0.2754 - accuracy: 0.9183 - val_loss: 16.3111 - val_accuracy: 0.0482\n",
      "Epoch 41/50\n",
      "4150/4150 [==============================] - 2s 447us/step - loss: 0.2882 - accuracy: 0.9120 - val_loss: 17.5119 - val_accuracy: 0.0559\n",
      "Epoch 42/50\n",
      "4150/4150 [==============================] - 2s 423us/step - loss: 0.3334 - accuracy: 0.9019 - val_loss: 17.3845 - val_accuracy: 0.0539\n",
      "Epoch 43/50\n",
      "4150/4150 [==============================] - 2s 425us/step - loss: 0.4266 - accuracy: 0.8764 - val_loss: 15.9686 - val_accuracy: 0.0539\n",
      "Epoch 44/50\n",
      "4150/4150 [==============================] - 2s 426us/step - loss: 0.3583 - accuracy: 0.8892 - val_loss: 17.0002 - val_accuracy: 0.0559\n",
      "Epoch 45/50\n",
      "4150/4150 [==============================] - 2s 425us/step - loss: 0.3246 - accuracy: 0.9012 - val_loss: 17.9853 - val_accuracy: 0.0549\n",
      "Epoch 46/50\n",
      "4150/4150 [==============================] - 2s 425us/step - loss: 0.2706 - accuracy: 0.9214 - val_loss: 17.7998 - val_accuracy: 0.0520\n",
      "Epoch 47/50\n",
      "4150/4150 [==============================] - 2s 429us/step - loss: 0.2448 - accuracy: 0.9294 - val_loss: 18.1056 - val_accuracy: 0.0568\n",
      "Epoch 48/50\n",
      "4150/4150 [==============================] - 2s 427us/step - loss: 0.2578 - accuracy: 0.9229 - val_loss: 18.2059 - val_accuracy: 0.0530\n",
      "Epoch 49/50\n",
      "4150/4150 [==============================] - 2s 502us/step - loss: 0.3814 - accuracy: 0.8928 - val_loss: 17.9360 - val_accuracy: 0.0578\n",
      "Epoch 50/50\n",
      "4150/4150 [==============================] - 2s 443us/step - loss: 0.3807 - accuracy: 0.8969 - val_loss: 16.4275 - val_accuracy: 0.0530\n",
      "1038/1038 [==============================] - 0s 233us/step\n",
      "1038/1038 [==============================] - 0s 161us/step\n",
      " \n",
      "Train on 4147 samples, validate on 1037 samples\n",
      "Epoch 1/50\n",
      "4147/4147 [==============================] - 3s 775us/step - loss: 4.3418 - accuracy: 0.0135 - val_loss: 4.2762 - val_accuracy: 0.0154\n",
      "Epoch 2/50\n",
      "4147/4147 [==============================] - 2s 475us/step - loss: 4.2682 - accuracy: 0.0186 - val_loss: 4.3218 - val_accuracy: 0.0222\n",
      "Epoch 3/50\n",
      "4147/4147 [==============================] - 2s 454us/step - loss: 4.2505 - accuracy: 0.0253 - val_loss: 5.3464 - val_accuracy: 0.0116\n",
      "Epoch 4/50\n",
      "4147/4147 [==============================] - 2s 446us/step - loss: 4.2153 - accuracy: 0.0294 - val_loss: 4.3127 - val_accuracy: 0.0241\n",
      "Epoch 5/50\n",
      "4147/4147 [==============================] - 2s 442us/step - loss: 4.1419 - accuracy: 0.0342 - val_loss: 4.2576 - val_accuracy: 0.0174\n",
      "Epoch 6/50\n",
      "4147/4147 [==============================] - 2s 440us/step - loss: 4.0471 - accuracy: 0.0449 - val_loss: 4.2482 - val_accuracy: 0.0231\n",
      "Epoch 7/50\n",
      "4147/4147 [==============================] - 2s 424us/step - loss: 3.9313 - accuracy: 0.0574 - val_loss: 4.3088 - val_accuracy: 0.0376\n",
      "Epoch 8/50\n",
      "4147/4147 [==============================] - 2s 435us/step - loss: 3.8153 - accuracy: 0.0680 - val_loss: 4.2636 - val_accuracy: 0.0299\n",
      "Epoch 9/50\n",
      "4147/4147 [==============================] - 2s 457us/step - loss: 3.6683 - accuracy: 0.0827 - val_loss: 4.2565 - val_accuracy: 0.0328\n",
      "Epoch 10/50\n",
      "4147/4147 [==============================] - 2s 441us/step - loss: 3.5261 - accuracy: 0.1071 - val_loss: 4.3005 - val_accuracy: 0.0260\n",
      "Epoch 11/50\n",
      "4147/4147 [==============================] - 2s 423us/step - loss: 3.3648 - accuracy: 0.1220 - val_loss: 4.3224 - val_accuracy: 0.0241\n",
      "Epoch 12/50\n",
      "4147/4147 [==============================] - 2s 423us/step - loss: 3.1932 - accuracy: 0.1488 - val_loss: 4.5385 - val_accuracy: 0.0328\n",
      "Epoch 13/50\n",
      "4147/4147 [==============================] - 2s 422us/step - loss: 3.0447 - accuracy: 0.1804 - val_loss: 4.7449 - val_accuracy: 0.0318\n",
      "Epoch 14/50\n",
      "4147/4147 [==============================] - 2s 423us/step - loss: 2.8926 - accuracy: 0.2018 - val_loss: 4.7217 - val_accuracy: 0.0376\n",
      "Epoch 15/50\n",
      "4147/4147 [==============================] - 2s 420us/step - loss: 2.7142 - accuracy: 0.2341 - val_loss: 5.2664 - val_accuracy: 0.0328\n",
      "Epoch 16/50\n",
      "4147/4147 [==============================] - 2s 431us/step - loss: 2.6273 - accuracy: 0.2592 - val_loss: 5.3039 - val_accuracy: 0.0318\n",
      "Epoch 17/50\n",
      "4147/4147 [==============================] - 2s 430us/step - loss: 2.4916 - accuracy: 0.2906 - val_loss: 5.6633 - val_accuracy: 0.0328\n",
      "Epoch 18/50\n",
      "4147/4147 [==============================] - 2s 421us/step - loss: 2.3397 - accuracy: 0.3217 - val_loss: 5.5846 - val_accuracy: 0.0357\n",
      "Epoch 19/50\n",
      "4147/4147 [==============================] - 2s 423us/step - loss: 2.2696 - accuracy: 0.3412 - val_loss: 5.9332 - val_accuracy: 0.0338\n",
      "Epoch 20/50\n",
      "4147/4147 [==============================] - 2s 424us/step - loss: 2.1819 - accuracy: 0.3569 - val_loss: 6.2594 - val_accuracy: 0.0386\n",
      "Epoch 21/50\n",
      "4147/4147 [==============================] - 2s 423us/step - loss: 2.0836 - accuracy: 0.3788 - val_loss: 6.5549 - val_accuracy: 0.0463\n",
      "Epoch 22/50\n",
      "4147/4147 [==============================] - 2s 422us/step - loss: 1.9416 - accuracy: 0.4155 - val_loss: 6.1635 - val_accuracy: 0.0318\n",
      "Epoch 23/50\n",
      "4147/4147 [==============================] - 2s 424us/step - loss: 1.8676 - accuracy: 0.4408 - val_loss: 6.4374 - val_accuracy: 0.0463\n",
      "Epoch 24/50\n",
      "4147/4147 [==============================] - 2s 419us/step - loss: 1.7884 - accuracy: 0.4613 - val_loss: 7.1789 - val_accuracy: 0.0386\n",
      "Epoch 25/50\n",
      "4147/4147 [==============================] - 2s 419us/step - loss: 1.7356 - accuracy: 0.4717 - val_loss: 7.2481 - val_accuracy: 0.0405\n",
      "Epoch 26/50\n",
      "4147/4147 [==============================] - 2s 419us/step - loss: 1.6685 - accuracy: 0.5018 - val_loss: 7.3360 - val_accuracy: 0.0415\n",
      "Epoch 27/50\n",
      "4147/4147 [==============================] - 2s 424us/step - loss: 1.5929 - accuracy: 0.5141 - val_loss: 6.7888 - val_accuracy: 0.0328\n",
      "Epoch 28/50\n",
      "4147/4147 [==============================] - 2s 468us/step - loss: 1.5646 - accuracy: 0.5264 - val_loss: 7.3172 - val_accuracy: 0.0347\n",
      "Epoch 29/50\n",
      "4147/4147 [==============================] - 2s 490us/step - loss: 1.4575 - accuracy: 0.5539 - val_loss: 8.2878 - val_accuracy: 0.0511\n",
      "Epoch 30/50\n",
      "4147/4147 [==============================] - 2s 504us/step - loss: 1.4110 - accuracy: 0.5756 - val_loss: 8.6035 - val_accuracy: 0.0376\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4147/4147 [==============================] - ETA: 0s - loss: 1.3731 - accuracy: 0.56 - 2s 453us/step - loss: 1.3763 - accuracy: 0.5686 - val_loss: 8.8473 - val_accuracy: 0.0424\n",
      "Epoch 32/50\n",
      "4147/4147 [==============================] - 2s 453us/step - loss: 1.3078 - accuracy: 0.5983 - val_loss: 8.2030 - val_accuracy: 0.0328\n",
      "Epoch 33/50\n",
      "4147/4147 [==============================] - 2s 475us/step - loss: 1.2771 - accuracy: 0.6089 - val_loss: 8.9944 - val_accuracy: 0.0289\n",
      "Epoch 34/50\n",
      "4147/4147 [==============================] - 2s 431us/step - loss: 1.2800 - accuracy: 0.6147 - val_loss: 9.6990 - val_accuracy: 0.0434\n",
      "Epoch 35/50\n",
      "4147/4147 [==============================] - 2s 439us/step - loss: 1.2572 - accuracy: 0.6166 - val_loss: 9.5137 - val_accuracy: 0.0424\n",
      "Epoch 36/50\n",
      "4147/4147 [==============================] - 2s 476us/step - loss: 1.1703 - accuracy: 0.6499 - val_loss: 9.2886 - val_accuracy: 0.0366\n",
      "Epoch 37/50\n",
      "4147/4147 [==============================] - 2s 454us/step - loss: 1.1188 - accuracy: 0.6612 - val_loss: 10.0977 - val_accuracy: 0.0318\n",
      "Epoch 38/50\n",
      "4147/4147 [==============================] - 2s 449us/step - loss: 1.0933 - accuracy: 0.6699 - val_loss: 10.6115 - val_accuracy: 0.0434\n",
      "Epoch 39/50\n",
      "4147/4147 [==============================] - 2s 428us/step - loss: 1.0409 - accuracy: 0.6853 - val_loss: 9.9677 - val_accuracy: 0.0405\n",
      "Epoch 40/50\n",
      "4147/4147 [==============================] - 2s 456us/step - loss: 1.0300 - accuracy: 0.6899 - val_loss: 9.6965 - val_accuracy: 0.0386\n",
      "Epoch 41/50\n",
      "4147/4147 [==============================] - 2s 424us/step - loss: 1.0191 - accuracy: 0.6897 - val_loss: 9.6790 - val_accuracy: 0.0318\n",
      "Epoch 42/50\n",
      "4147/4147 [==============================] - 2s 427us/step - loss: 0.9894 - accuracy: 0.6991 - val_loss: 9.0429 - val_accuracy: 0.0415\n",
      "Epoch 43/50\n",
      "4147/4147 [==============================] - 2s 418us/step - loss: 0.9707 - accuracy: 0.7036 - val_loss: 10.8525 - val_accuracy: 0.0338\n",
      "Epoch 44/50\n",
      "4147/4147 [==============================] - 2s 454us/step - loss: 0.9546 - accuracy: 0.7106 - val_loss: 10.8797 - val_accuracy: 0.0357\n",
      "Epoch 45/50\n",
      "4147/4147 [==============================] - 2s 429us/step - loss: 0.9354 - accuracy: 0.7193 - val_loss: 9.6436 - val_accuracy: 0.0347\n",
      "Epoch 46/50\n",
      "4147/4147 [==============================] - 2s 437us/step - loss: 0.8994 - accuracy: 0.7251 - val_loss: 10.6651 - val_accuracy: 0.0338\n",
      "Epoch 47/50\n",
      "4147/4147 [==============================] - 2s 413us/step - loss: 0.8959 - accuracy: 0.7352 - val_loss: 10.5440 - val_accuracy: 0.0289\n",
      "Epoch 48/50\n",
      "4147/4147 [==============================] - 2s 421us/step - loss: 0.8486 - accuracy: 0.7468 - val_loss: 11.3032 - val_accuracy: 0.0386\n",
      "Epoch 49/50\n",
      "4147/4147 [==============================] - 2s 426us/step - loss: 0.8618 - accuracy: 0.7437 - val_loss: 11.0636 - val_accuracy: 0.0280\n",
      "Epoch 50/50\n",
      "4147/4147 [==============================] - 2s 448us/step - loss: 0.8465 - accuracy: 0.7422 - val_loss: 11.0143 - val_accuracy: 0.0434\n",
      "1037/1037 [==============================] - 0s 242us/step\n",
      "1037/1037 [==============================] - 0s 168us/step\n",
      " \n",
      "Train on 4148 samples, validate on 1037 samples\n",
      "Epoch 1/50\n",
      "4148/4148 [==============================] - 3s 816us/step - loss: 4.3462 - accuracy: 0.0094 - val_loss: 4.3237 - val_accuracy: 0.0145\n",
      "Epoch 2/50\n",
      "4148/4148 [==============================] - 2s 433us/step - loss: 4.2719 - accuracy: 0.0193 - val_loss: 5.9923 - val_accuracy: 0.0135\n",
      "Epoch 3/50\n",
      "4148/4148 [==============================] - 2s 443us/step - loss: 4.2473 - accuracy: 0.0260 - val_loss: 5.8573 - val_accuracy: 0.0135\n",
      "Epoch 4/50\n",
      "4148/4148 [==============================] - 2s 428us/step - loss: 4.1601 - accuracy: 0.0376 - val_loss: 8.1742 - val_accuracy: 0.0116\n",
      "Epoch 5/50\n",
      "4148/4148 [==============================] - 2s 441us/step - loss: 4.0450 - accuracy: 0.0482 - val_loss: 4.3790 - val_accuracy: 0.0260\n",
      "Epoch 6/50\n",
      "4148/4148 [==============================] - 2s 435us/step - loss: 3.8716 - accuracy: 0.0603 - val_loss: 5.0847 - val_accuracy: 0.0424\n",
      "Epoch 7/50\n",
      "4148/4148 [==============================] - 2s 430us/step - loss: 3.6616 - accuracy: 0.0880 - val_loss: 4.9609 - val_accuracy: 0.0395\n",
      "Epoch 8/50\n",
      "4148/4148 [==============================] - 2s 434us/step - loss: 3.4482 - accuracy: 0.1162 - val_loss: 4.8014 - val_accuracy: 0.0569\n",
      "Epoch 9/50\n",
      "4148/4148 [==============================] - 2s 425us/step - loss: 3.2097 - accuracy: 0.1569 - val_loss: 4.9806 - val_accuracy: 0.0463\n",
      "Epoch 10/50\n",
      "4148/4148 [==============================] - 2s 426us/step - loss: 2.9496 - accuracy: 0.2020 - val_loss: 5.5358 - val_accuracy: 0.0521\n",
      "Epoch 11/50\n",
      "4148/4148 [==============================] - 2s 422us/step - loss: 2.7404 - accuracy: 0.2449 - val_loss: 4.9458 - val_accuracy: 0.0550\n",
      "Epoch 12/50\n",
      "4148/4148 [==============================] - 2s 423us/step - loss: 2.5263 - accuracy: 0.2900 - val_loss: 5.3542 - val_accuracy: 0.0694\n",
      "Epoch 13/50\n",
      "4148/4148 [==============================] - 2s 430us/step - loss: 2.3161 - accuracy: 0.3332 - val_loss: 5.6250 - val_accuracy: 0.0627\n",
      "Epoch 14/50\n",
      "4148/4148 [==============================] - 2s 426us/step - loss: 2.1749 - accuracy: 0.3773 - val_loss: 5.4864 - val_accuracy: 0.0569\n",
      "Epoch 15/50\n",
      "4148/4148 [==============================] - 2s 427us/step - loss: 2.0071 - accuracy: 0.4147 - val_loss: 6.3210 - val_accuracy: 0.0569\n",
      "Epoch 16/50\n",
      "4148/4148 [==============================] - 2s 426us/step - loss: 1.8445 - accuracy: 0.4597 - val_loss: 6.6395 - val_accuracy: 0.0453\n",
      "Epoch 17/50\n",
      "4148/4148 [==============================] - 2s 432us/step - loss: 1.6877 - accuracy: 0.5084 - val_loss: 7.0300 - val_accuracy: 0.0646\n",
      "Epoch 18/50\n",
      "4148/4148 [==============================] - 2s 455us/step - loss: 1.5578 - accuracy: 0.5422 - val_loss: 7.9777 - val_accuracy: 0.0627\n",
      "Epoch 19/50\n",
      "4148/4148 [==============================] - 2s 479us/step - loss: 1.4779 - accuracy: 0.5579 - val_loss: 7.4520 - val_accuracy: 0.0501\n",
      "Epoch 20/50\n",
      "4148/4148 [==============================] - 2s 483us/step - loss: 1.4140 - accuracy: 0.5810 - val_loss: 7.7919 - val_accuracy: 0.0665\n",
      "Epoch 21/50\n",
      "4148/4148 [==============================] - 2s 484us/step - loss: 1.2788 - accuracy: 0.6217 - val_loss: 7.7473 - val_accuracy: 0.0550\n",
      "Epoch 22/50\n",
      "4148/4148 [==============================] - 2s 472us/step - loss: 1.1751 - accuracy: 0.6451 - val_loss: 8.5419 - val_accuracy: 0.0530\n",
      "Epoch 23/50\n",
      "4148/4148 [==============================] - 2s 476us/step - loss: 1.1707 - accuracy: 0.6548 - val_loss: 9.7080 - val_accuracy: 0.0588\n",
      "Epoch 24/50\n",
      "4148/4148 [==============================] - 2s 466us/step - loss: 1.0930 - accuracy: 0.6750 - val_loss: 9.7837 - val_accuracy: 0.0521\n",
      "Epoch 25/50\n",
      "4148/4148 [==============================] - 2s 472us/step - loss: 1.0300 - accuracy: 0.6970 - val_loss: 9.6743 - val_accuracy: 0.0540\n",
      "Epoch 26/50\n",
      "4148/4148 [==============================] - 2s 447us/step - loss: 1.0203 - accuracy: 0.6984 - val_loss: 8.5792 - val_accuracy: 0.0627\n",
      "Epoch 27/50\n",
      "4148/4148 [==============================] - 2s 447us/step - loss: 0.9607 - accuracy: 0.7129 - val_loss: 10.9830 - val_accuracy: 0.0482\n",
      "Epoch 28/50\n",
      "4148/4148 [==============================] - 2s 469us/step - loss: 0.8824 - accuracy: 0.7420 - val_loss: 9.9848 - val_accuracy: 0.0473\n",
      "Epoch 29/50\n",
      "4148/4148 [==============================] - 2s 440us/step - loss: 0.8312 - accuracy: 0.7514 - val_loss: 11.4747 - val_accuracy: 0.0598\n",
      "Epoch 30/50\n",
      "4148/4148 [==============================] - 2s 448us/step - loss: 0.8304 - accuracy: 0.7592 - val_loss: 10.8674 - val_accuracy: 0.0521\n",
      "Epoch 31/50\n",
      "4148/4148 [==============================] - 2s 433us/step - loss: 0.8011 - accuracy: 0.7582 - val_loss: 9.5061 - val_accuracy: 0.0588\n",
      "Epoch 32/50\n",
      "4148/4148 [==============================] - 2s 440us/step - loss: 0.7555 - accuracy: 0.7777 - val_loss: 11.2462 - val_accuracy: 0.0569\n",
      "Epoch 33/50\n",
      "4148/4148 [==============================] - 2s 455us/step - loss: 0.7360 - accuracy: 0.7792 - val_loss: 11.3513 - val_accuracy: 0.0434\n",
      "Epoch 34/50\n",
      "4148/4148 [==============================] - 2s 454us/step - loss: 0.7499 - accuracy: 0.7739 - val_loss: 10.7089 - val_accuracy: 0.0492\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4148/4148 [==============================] - 2s 450us/step - loss: 0.7169 - accuracy: 0.7845 - val_loss: 11.7972 - val_accuracy: 0.0444\n",
      "Epoch 36/50\n",
      "4148/4148 [==============================] - 2s 437us/step - loss: 0.7015 - accuracy: 0.7968 - val_loss: 10.8038 - val_accuracy: 0.0540\n",
      "Epoch 37/50\n",
      "4148/4148 [==============================] - 2s 449us/step - loss: 0.6549 - accuracy: 0.8158 - val_loss: 10.8968 - val_accuracy: 0.0540\n",
      "Epoch 38/50\n",
      "4148/4148 [==============================] - 2s 451us/step - loss: 0.6045 - accuracy: 0.8269 - val_loss: 10.8800 - val_accuracy: 0.0540\n",
      "Epoch 39/50\n",
      "4148/4148 [==============================] - 2s 436us/step - loss: 0.5769 - accuracy: 0.8346 - val_loss: 11.5410 - val_accuracy: 0.0588\n",
      "Epoch 40/50\n",
      "4148/4148 [==============================] - 2s 449us/step - loss: 0.5730 - accuracy: 0.8291 - val_loss: 10.6526 - val_accuracy: 0.0463\n",
      "Epoch 41/50\n",
      "4148/4148 [==============================] - 2s 443us/step - loss: 0.5834 - accuracy: 0.8271 - val_loss: 12.3151 - val_accuracy: 0.0511\n",
      "Epoch 42/50\n",
      "4148/4148 [==============================] - 2s 431us/step - loss: 0.5782 - accuracy: 0.8394 - val_loss: 12.2342 - val_accuracy: 0.0608\n",
      "Epoch 43/50\n",
      "4148/4148 [==============================] - 2s 438us/step - loss: 0.5717 - accuracy: 0.8411 - val_loss: 13.5270 - val_accuracy: 0.0627\n",
      "Epoch 44/50\n",
      "4148/4148 [==============================] - 2s 424us/step - loss: 0.5013 - accuracy: 0.8570 - val_loss: 12.9726 - val_accuracy: 0.0579\n",
      "Epoch 45/50\n",
      "4148/4148 [==============================] - 2s 427us/step - loss: 0.4966 - accuracy: 0.8539 - val_loss: 13.3165 - val_accuracy: 0.0482\n",
      "Epoch 46/50\n",
      "4148/4148 [==============================] - 2s 428us/step - loss: 0.4862 - accuracy: 0.8580 - val_loss: 13.6694 - val_accuracy: 0.0550\n",
      "Epoch 47/50\n",
      "4148/4148 [==============================] - 2s 425us/step - loss: 0.4800 - accuracy: 0.8578 - val_loss: 11.4437 - val_accuracy: 0.0434\n",
      "Epoch 48/50\n",
      "4148/4148 [==============================] - 2s 441us/step - loss: 0.4440 - accuracy: 0.8730 - val_loss: 12.8040 - val_accuracy: 0.0627\n",
      "Epoch 49/50\n",
      "4148/4148 [==============================] - 2s 427us/step - loss: 0.3950 - accuracy: 0.8802 - val_loss: 13.1210 - val_accuracy: 0.0530\n",
      "Epoch 50/50\n",
      "4148/4148 [==============================] - 2s 424us/step - loss: 0.4458 - accuracy: 0.8698 - val_loss: 13.4697 - val_accuracy: 0.0386\n",
      "1037/1037 [==============================] - 0s 238us/step\n",
      "1037/1037 [==============================] - 0s 151us/step\n",
      " \n",
      "Train on 4147 samples, validate on 1037 samples\n",
      "Epoch 1/50\n",
      "4147/4147 [==============================] - 3s 751us/step - loss: 4.3334 - accuracy: 0.0111 - val_loss: 4.3312 - val_accuracy: 0.0135\n",
      "Epoch 2/50\n",
      "4147/4147 [==============================] - 2s 444us/step - loss: 4.2763 - accuracy: 0.0169 - val_loss: 6.0290 - val_accuracy: 0.0125\n",
      "Epoch 3/50\n",
      "4147/4147 [==============================] - 2s 442us/step - loss: 4.2018 - accuracy: 0.0256 - val_loss: 4.1948 - val_accuracy: 0.0338\n",
      "Epoch 4/50\n",
      "4147/4147 [==============================] - 2s 442us/step - loss: 3.9804 - accuracy: 0.0468 - val_loss: 4.1297 - val_accuracy: 0.0405\n",
      "Epoch 5/50\n",
      "4147/4147 [==============================] - 2s 447us/step - loss: 3.7424 - accuracy: 0.0735 - val_loss: 3.8753 - val_accuracy: 0.0665\n",
      "Epoch 6/50\n",
      "4147/4147 [==============================] - 2s 455us/step - loss: 3.5133 - accuracy: 0.1032 - val_loss: 3.8532 - val_accuracy: 0.0646\n",
      "Epoch 7/50\n",
      "4147/4147 [==============================] - 2s 425us/step - loss: 3.2141 - accuracy: 0.1514 - val_loss: 4.0518 - val_accuracy: 0.0829\n",
      "Epoch 8/50\n",
      "4147/4147 [==============================] - 2s 426us/step - loss: 2.9094 - accuracy: 0.1956 - val_loss: 3.7883 - val_accuracy: 0.1003\n",
      "Epoch 9/50\n",
      "4147/4147 [==============================] - 2s 420us/step - loss: 2.5859 - accuracy: 0.2602 - val_loss: 3.9522 - val_accuracy: 0.1041\n",
      "Epoch 10/50\n",
      "4147/4147 [==============================] - 2s 435us/step - loss: 2.2396 - accuracy: 0.3345 - val_loss: 4.1569 - val_accuracy: 0.0897\n",
      "Epoch 11/50\n",
      "4147/4147 [==============================] - 2s 419us/step - loss: 1.9597 - accuracy: 0.4099 - val_loss: 4.5985 - val_accuracy: 0.0974\n",
      "Epoch 12/50\n",
      "4147/4147 [==============================] - 2s 417us/step - loss: 1.6688 - accuracy: 0.4806 - val_loss: 5.1564 - val_accuracy: 0.0887\n",
      "Epoch 13/50\n",
      "4147/4147 [==============================] - 2s 418us/step - loss: 1.4158 - accuracy: 0.5515 - val_loss: 5.3514 - val_accuracy: 0.0858\n",
      "Epoch 14/50\n",
      "4147/4147 [==============================] - 2s 416us/step - loss: 1.2446 - accuracy: 0.6113 - val_loss: 5.5595 - val_accuracy: 0.1041\n",
      "Epoch 15/50\n",
      "4147/4147 [==============================] - 2s 417us/step - loss: 1.0708 - accuracy: 0.6578 - val_loss: 6.3246 - val_accuracy: 0.0964\n",
      "Epoch 16/50\n",
      "4147/4147 [==============================] - 2s 420us/step - loss: 0.9697 - accuracy: 0.6981 - val_loss: 6.3586 - val_accuracy: 0.1022\n",
      "Epoch 17/50\n",
      "4147/4147 [==============================] - 2s 428us/step - loss: 0.8109 - accuracy: 0.7504 - val_loss: 6.8319 - val_accuracy: 0.1022\n",
      "Epoch 18/50\n",
      "4147/4147 [==============================] - 2s 416us/step - loss: 0.7304 - accuracy: 0.7683 - val_loss: 6.7837 - val_accuracy: 0.1022\n",
      "Epoch 19/50\n",
      "4147/4147 [==============================] - 2s 417us/step - loss: 0.7345 - accuracy: 0.7743 - val_loss: 7.6467 - val_accuracy: 0.0897\n",
      "Epoch 20/50\n",
      "4147/4147 [==============================] - 2s 416us/step - loss: 0.5990 - accuracy: 0.8136 - val_loss: 8.0433 - val_accuracy: 0.0964\n",
      "Epoch 21/50\n",
      "4147/4147 [==============================] - 2s 414us/step - loss: 0.5285 - accuracy: 0.8355 - val_loss: 7.9410 - val_accuracy: 0.1119\n",
      "Epoch 22/50\n",
      "4147/4147 [==============================] - 2s 421us/step - loss: 0.5099 - accuracy: 0.8416 - val_loss: 7.8678 - val_accuracy: 0.1022\n",
      "Epoch 23/50\n",
      "4147/4147 [==============================] - 2s 415us/step - loss: 0.4811 - accuracy: 0.8517 - val_loss: 9.4911 - val_accuracy: 0.0926\n",
      "Epoch 24/50\n",
      "4147/4147 [==============================] - 2s 417us/step - loss: 0.4357 - accuracy: 0.8618 - val_loss: 9.5815 - val_accuracy: 0.1013\n",
      "Epoch 25/50\n",
      "4147/4147 [==============================] - 2s 432us/step - loss: 0.4365 - accuracy: 0.8683 - val_loss: 9.0001 - val_accuracy: 0.0926\n",
      "Epoch 26/50\n",
      "4147/4147 [==============================] - 2s 438us/step - loss: 0.4134 - accuracy: 0.8688 - val_loss: 8.6079 - val_accuracy: 0.0897\n",
      "Epoch 27/50\n",
      "4147/4147 [==============================] - 2s 442us/step - loss: 0.3482 - accuracy: 0.8944 - val_loss: 9.3950 - val_accuracy: 0.0974\n",
      "Epoch 28/50\n",
      "4147/4147 [==============================] - 2s 417us/step - loss: 0.3069 - accuracy: 0.9050 - val_loss: 9.4996 - val_accuracy: 0.0993\n",
      "Epoch 29/50\n",
      "4147/4147 [==============================] - 2s 419us/step - loss: 0.2955 - accuracy: 0.9117 - val_loss: 10.0757 - val_accuracy: 0.0839\n",
      "Epoch 30/50\n",
      "4147/4147 [==============================] - 2s 417us/step - loss: 0.3234 - accuracy: 0.8982 - val_loss: 10.6878 - val_accuracy: 0.0916\n",
      "Epoch 31/50\n",
      "4147/4147 [==============================] - 2s 419us/step - loss: 0.3356 - accuracy: 0.9009 - val_loss: 10.3822 - val_accuracy: 0.0984\n",
      "Epoch 32/50\n",
      "4147/4147 [==============================] - 2s 426us/step - loss: 0.3226 - accuracy: 0.9103 - val_loss: 10.1066 - val_accuracy: 0.1041\n",
      "Epoch 33/50\n",
      "4147/4147 [==============================] - 2s 416us/step - loss: 0.2883 - accuracy: 0.9125 - val_loss: 10.6551 - val_accuracy: 0.0878\n",
      "Epoch 34/50\n",
      "4147/4147 [==============================] - 2s 417us/step - loss: 0.2449 - accuracy: 0.9293 - val_loss: 10.9093 - val_accuracy: 0.0878\n",
      "Epoch 35/50\n",
      "4147/4147 [==============================] - 2s 416us/step - loss: 0.2478 - accuracy: 0.9269 - val_loss: 10.9575 - val_accuracy: 0.0984\n",
      "Epoch 36/50\n",
      "4147/4147 [==============================] - 2s 416us/step - loss: 0.2346 - accuracy: 0.9308 - val_loss: 10.8102 - val_accuracy: 0.0974\n",
      "Epoch 37/50\n",
      "4147/4147 [==============================] - 2s 427us/step - loss: 0.2511 - accuracy: 0.9281 - val_loss: 11.1142 - val_accuracy: 0.0906\n",
      "Epoch 38/50\n",
      "4147/4147 [==============================] - 2s 442us/step - loss: 0.2690 - accuracy: 0.9173 - val_loss: 11.4087 - val_accuracy: 0.0829\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4147/4147 [==============================] - 2s 446us/step - loss: 0.2566 - accuracy: 0.9260 - val_loss: 11.5126 - val_accuracy: 0.0926\n",
      "Epoch 40/50\n",
      "4147/4147 [==============================] - 2s 441us/step - loss: 0.2411 - accuracy: 0.9265 - val_loss: 11.2758 - val_accuracy: 0.0810\n",
      "Epoch 41/50\n",
      "4147/4147 [==============================] - 2s 442us/step - loss: 0.2717 - accuracy: 0.9236 - val_loss: 11.0654 - val_accuracy: 0.0945\n",
      "Epoch 42/50\n",
      "4147/4147 [==============================] - 2s 445us/step - loss: 0.2560 - accuracy: 0.9226 - val_loss: 11.3876 - val_accuracy: 0.0906\n",
      "Epoch 43/50\n",
      "4147/4147 [==============================] - 2s 446us/step - loss: 0.2044 - accuracy: 0.9402 - val_loss: 11.5117 - val_accuracy: 0.0964\n",
      "Epoch 44/50\n",
      "4147/4147 [==============================] - 2s 444us/step - loss: 0.1687 - accuracy: 0.9484 - val_loss: 12.1239 - val_accuracy: 0.0839\n",
      "Epoch 45/50\n",
      "4147/4147 [==============================] - 2s 449us/step - loss: 0.1530 - accuracy: 0.9506 - val_loss: 12.4916 - val_accuracy: 0.1013\n",
      "Epoch 46/50\n",
      "4147/4147 [==============================] - 2s 444us/step - loss: 0.1783 - accuracy: 0.9494 - val_loss: 12.4570 - val_accuracy: 0.0781\n",
      "Epoch 47/50\n",
      "4147/4147 [==============================] - 2s 443us/step - loss: 0.1830 - accuracy: 0.9424 - val_loss: 12.6989 - val_accuracy: 0.1061\n",
      "Epoch 48/50\n",
      "4147/4147 [==============================] - 2s 445us/step - loss: 0.2597 - accuracy: 0.9308 - val_loss: 11.6215 - val_accuracy: 0.0839\n",
      "Epoch 49/50\n",
      "4147/4147 [==============================] - 2s 442us/step - loss: 0.2086 - accuracy: 0.9397 - val_loss: 11.9925 - val_accuracy: 0.1003\n",
      "Epoch 50/50\n",
      "4147/4147 [==============================] - 2s 435us/step - loss: 0.1561 - accuracy: 0.9513 - val_loss: 11.9984 - val_accuracy: 0.1051\n",
      "1037/1037 [==============================] - 0s 230us/step\n",
      "1037/1037 [==============================] - 0s 140us/step\n",
      " \n",
      "Accuracy: 5.88\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "keep_accuracy = np.zeros((10))\n",
    "j = 0\n",
    "\n",
    "for participant in files:\n",
    "    mat = loadmat(participant)\n",
    "    X_2D = np.array(mat[\"X_2D\"])\n",
    "\n",
    "    X = X_2D\n",
    "    y = np.array(mat[\"exemplarLabels\"]).ravel()      # get labels, exemplar, 72 classes\n",
    "\n",
    "    X_training = X[:int(0.8*len(X))]                 # create the train and test sets\n",
    "    X_validation = X[int(0.8*len(X)):]\n",
    "\n",
    "    y_training = y[:int(0.8*len(X))]\n",
    "    y_validation = y[int(0.8*len(X)):]\n",
    "\n",
    "    num_classes = 72\n",
    "    y_training1hot = keras.utils.to_categorical(y_training - 1, num_classes)      # subtract 1 to convert to 0-index\n",
    "    y_validation1hot = keras.utils.to_categorical(y_validation - 1, num_classes)\n",
    "\n",
    "    # reshape to treat the data like images (124x32)\n",
    "    X_training = np.reshape(X_training, (-1, electrodes, N, 1))\n",
    "    X_validation = np.reshape(X_validation, (-1, electrodes, N, 1))\n",
    "\n",
    "    # deep cnn\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(8, kernel_size=3,input_shape=(124,32, 1), activation = 'relu'))\n",
    "    model.add(Conv2D(8, kernel_size=3, activation = 'relu'))\n",
    "    model.add(MaxPool2D(2,2))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(16, kernel_size=2,activation = 'relu'))\n",
    "    model.add(Conv2D(16, kernel_size=2,activation = 'relu'))\n",
    "    model.add(MaxPool2D(2,2))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(64, kernel_size=3, activation = 'relu'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(32, activation = \"relu\"))\n",
    "    model.add(Dense(32, activation = \"relu\"))\n",
    "    model.add(Dense(72, activation = \"softmax\"))\n",
    "\n",
    "    optimizer=Nadam(lr=0.004)\n",
    "    model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    model.fit(X_training, y_training1hot,                                     # train model\n",
    "              epochs=50, \n",
    "              validation_data=(X_validation, y_validation1hot), \n",
    "              shuffle=True)\n",
    "\n",
    "\n",
    "    y_validation_predictions = model.predict(X_validation, verbose=1)         # make predictions\n",
    "\n",
    "    # create the confusion matrix\n",
    "    cnf_matrix7 = confusion_matrix(y_validation-1, np.argmax(y_validation_predictions, axis=1))\n",
    "    cm_cv7 += cnf_matrix7                                                     # add together all the confusion matrices\n",
    "    \n",
    "    _, accuracy = model.evaluate(X_validation, y_validation1hot)              # find accuracy\n",
    "    keep_accuracy[j] = accuracy\n",
    "    j = j + 1\n",
    "    print(\" \")\n",
    "    \n",
    "print('Accuracy: %.2f' % (np.mean(keep_accuracy)*100))                        # print mean accuracy\n",
    "\n",
    "sum_by_row = np.sum(cm_cv7, 1)                                                # normalize the final confusion matrix\n",
    "for i in range(0,72):\n",
    "    cm_cv7[i,:] = cm_cv7[i,:] / sum_by_row[i]\n",
    "        \n",
    "plot_cm(np.round(cm_cv7, 2),72)                                               # plot the final confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.02545455 0.00727273 0.01454545 0.01454545 0.01090909 0.02181818\n",
      "  0.01090909 0.02545455 0.00363636 0.04727273 0.01454545 0.02909091\n",
      "  0.00363636 0.00363636 0.00727273 0.01454545 0.01090909 0.\n",
      "  0.01090909 0.00727273 0.         0.01454545 0.02545455 0.01090909\n",
      "  0.02545455 0.02545455 0.02181818 0.01090909 0.01090909 0.02181818\n",
      "  0.00727273 0.01454545 0.00727273 0.02545455 0.01454545 0.00363636\n",
      "  0.01090909 0.01454545 0.00727273 0.00363636 0.02545455 0.01818182\n",
      "  0.00363636 0.00727273 0.01090909 0.01818182 0.01090909 0.01090909\n",
      "  0.01818182 0.02909091 0.01454545 0.00363636 0.01090909 0.00363636\n",
      "  0.00727273 0.01454545 0.01454545 0.02181818 0.00363636 0.00727273\n",
      "  0.00727273 0.01454545 0.01818182 0.01454545 0.01090909 0.00727273\n",
      "  0.00363636 0.03272727 0.03272727 0.01818182 0.00727273 0.01818182]\n",
      " [0.0070922  0.04255319 0.0035461  0.0070922  0.0141844  0.0070922\n",
      "  0.0070922  0.0106383  0.0106383  0.0035461  0.0248227  0.0177305\n",
      "  0.0106383  0.0070922  0.0141844  0.0070922  0.0177305  0.0035461\n",
      "  0.0177305  0.0070922  0.0070922  0.0035461  0.         0.0035461\n",
      "  0.0106383  0.0070922  0.0035461  0.0070922  0.0141844  0.0106383\n",
      "  0.0177305  0.0035461  0.0070922  0.03191489 0.0070922  0.0141844\n",
      "  0.03546099 0.03191489 0.0141844  0.0248227  0.0141844  0.03546099\n",
      "  0.03546099 0.0248227  0.04255319 0.02836879 0.03191489 0.0248227\n",
      "  0.0177305  0.0070922  0.0141844  0.0070922  0.0070922  0.0106383\n",
      "  0.03191489 0.0106383  0.0141844  0.0177305  0.0035461  0.0106383\n",
      "  0.0070922  0.0106383  0.0141844  0.0177305  0.0106383  0.0070922\n",
      "  0.0035461  0.0035461  0.0106383  0.0070922  0.0070922  0.0141844 ]\n",
      " [0.02554745 0.01824818 0.05839416 0.02554745 0.00364964 0.01459854\n",
      "  0.01094891 0.02189781 0.00729927 0.01824818 0.04379562 0.04014599\n",
      "  0.00364964 0.00364964 0.00729927 0.00364964 0.00729927 0.00364964\n",
      "  0.00364964 0.01459854 0.00729927 0.01459854 0.01094891 0.01094891\n",
      "  0.01459854 0.00729927 0.01459854 0.00729927 0.01824818 0.02189781\n",
      "  0.00364964 0.01824818 0.02189781 0.02554745 0.00364964 0.02189781\n",
      "  0.01824818 0.01094891 0.01094891 0.02554745 0.02189781 0.00729927\n",
      "  0.00364964 0.01094891 0.01824818 0.00729927 0.01459854 0.01094891\n",
      "  0.04379562 0.         0.01824818 0.         0.01094891 0.01094891\n",
      "  0.01459854 0.00364964 0.01459854 0.01459854 0.01824818 0.00364964\n",
      "  0.         0.00729927 0.00729927 0.01094891 0.01094891 0.01094891\n",
      "  0.         0.00364964 0.04379562 0.01824818 0.00364964 0.01094891]\n",
      " [0.         0.01838235 0.02573529 0.03308824 0.01102941 0.02941176\n",
      "  0.02573529 0.00735294 0.01470588 0.03308824 0.02573529 0.00735294\n",
      "  0.         0.00735294 0.00735294 0.00367647 0.00735294 0.02573529\n",
      "  0.01838235 0.01102941 0.02205882 0.01102941 0.01102941 0.02573529\n",
      "  0.01838235 0.02941176 0.         0.02205882 0.02205882 0.02205882\n",
      "  0.00367647 0.00367647 0.01102941 0.01102941 0.         0.00367647\n",
      "  0.00735294 0.01470588 0.01102941 0.01102941 0.01838235 0.00367647\n",
      "  0.01102941 0.00735294 0.00735294 0.01838235 0.01470588 0.00367647\n",
      "  0.01102941 0.01838235 0.02205882 0.01838235 0.00735294 0.01838235\n",
      "  0.01470588 0.00735294 0.01102941 0.01102941 0.00367647 0.02941176\n",
      "  0.01470588 0.02205882 0.01470588 0.01102941 0.01470588 0.01838235\n",
      "  0.00367647 0.00735294 0.02573529 0.01470588 0.00367647 0.01838235]\n",
      " [0.00719424 0.01438849 0.01079137 0.01438849 0.05035971 0.02158273\n",
      "  0.00719424 0.01079137 0.01079137 0.01798561 0.01438849 0.02517986\n",
      "  0.         0.         0.00359712 0.         0.         0.00359712\n",
      "  0.         0.00359712 0.02158273 0.         0.01079137 0.00719424\n",
      "  0.01798561 0.01438849 0.01079137 0.00719424 0.02517986 0.01438849\n",
      "  0.         0.         0.00719424 0.02517986 0.01798561 0.01079137\n",
      "  0.02158273 0.01438849 0.02517986 0.01798561 0.01079137 0.00719424\n",
      "  0.03597122 0.01798561 0.01438849 0.00719424 0.00719424 0.01079137\n",
      "  0.01798561 0.0323741  0.0323741  0.01798561 0.00719424 0.01438849\n",
      "  0.02158273 0.         0.02877698 0.02517986 0.00719424 0.01438849\n",
      "  0.01079137 0.02877698 0.01798561 0.01079137 0.01798561 0.01798561\n",
      "  0.00359712 0.01798561 0.02158273 0.01079137 0.01798561 0.00719424]\n",
      " [0.01858736 0.01115242 0.01115242 0.01115242 0.00743494 0.07806691\n",
      "  0.02230483 0.02973978 0.         0.0260223  0.01115242 0.00371747\n",
      "  0.01115242 0.01115242 0.00371747 0.00371747 0.01115242 0.00743494\n",
      "  0.01115242 0.01858736 0.00743494 0.00371747 0.00743494 0.01858736\n",
      "  0.02973978 0.01115242 0.00743494 0.01115242 0.01858736 0.0260223\n",
      "  0.01486989 0.00743494 0.0260223  0.01486989 0.04832714 0.\n",
      "  0.00743494 0.01486989 0.00371747 0.00743494 0.0260223  0.02973978\n",
      "  0.01115242 0.00743494 0.01486989 0.02230483 0.00743494 0.01486989\n",
      "  0.01115242 0.         0.01486989 0.00743494 0.00371747 0.01858736\n",
      "  0.01115242 0.01858736 0.01486989 0.01858736 0.00743494 0.00743494\n",
      "  0.00743494 0.00743494 0.0260223  0.00371747 0.00371747 0.03345725\n",
      "  0.         0.01858736 0.00743494 0.00743494 0.00743494 0.01486989]\n",
      " [0.00722022 0.00361011 0.01444043 0.0433213  0.01805054 0.02166065\n",
      "  0.05776173 0.02166065 0.         0.02527076 0.01083032 0.01444043\n",
      "  0.00722022 0.01444043 0.01083032 0.00722022 0.01444043 0.00722022\n",
      "  0.00361011 0.01444043 0.00722022 0.         0.03971119 0.00722022\n",
      "  0.01805054 0.03610108 0.00361011 0.01805054 0.00722022 0.00361011\n",
      "  0.         0.01444043 0.01083032 0.02888087 0.00361011 0.00361011\n",
      "  0.01444043 0.00722022 0.01083032 0.01805054 0.01444043 0.01805054\n",
      "  0.01444043 0.01083032 0.01805054 0.00361011 0.00361011 0.01444043\n",
      "  0.00361011 0.01444043 0.03249097 0.01083032 0.         0.02166065\n",
      "  0.01805054 0.00722022 0.02888087 0.00361011 0.01805054 0.00722022\n",
      "  0.00722022 0.00722022 0.01083032 0.00722022 0.00722022 0.01805054\n",
      "  0.00722022 0.01083032 0.03971119 0.02166065 0.00722022 0.02166065]\n",
      " [0.04029304 0.00732601 0.03296703 0.01831502 0.01465201 0.02930403\n",
      "  0.01098901 0.06227106 0.         0.01465201 0.03663004 0.04761905\n",
      "  0.01098901 0.003663   0.         0.         0.01465201 0.\n",
      "  0.00732601 0.003663   0.01465201 0.00732601 0.01098901 0.003663\n",
      "  0.003663   0.02930403 0.01098901 0.00732601 0.01098901 0.01098901\n",
      "  0.         0.01098901 0.00732601 0.02930403 0.01098901 0.00732601\n",
      "  0.         0.00732601 0.01831502 0.01098901 0.01465201 0.02564103\n",
      "  0.02197802 0.02564103 0.02197802 0.02197802 0.00732601 0.003663\n",
      "  0.01831502 0.003663   0.003663   0.00732601 0.003663   0.01465201\n",
      "  0.01465201 0.003663   0.01465201 0.01465201 0.         0.01098901\n",
      "  0.         0.01098901 0.00732601 0.01465201 0.02930403 0.01098901\n",
      "  0.00732601 0.01831502 0.04395604 0.01831502 0.00732601 0.01098901]\n",
      " [0.03985507 0.02536232 0.00724638 0.00362319 0.01086957 0.00724638\n",
      "  0.00362319 0.01086957 0.08333333 0.00724638 0.02173913 0.00724638\n",
      "  0.01086957 0.00362319 0.02898551 0.00362319 0.00362319 0.00362319\n",
      "  0.01086957 0.         0.01811594 0.01086957 0.00724638 0.01086957\n",
      "  0.02173913 0.01086957 0.00724638 0.01086957 0.00362319 0.00362319\n",
      "  0.01449275 0.00362319 0.02173913 0.02898551 0.00362319 0.00724638\n",
      "  0.01086957 0.0326087  0.00724638 0.0326087  0.03623188 0.02898551\n",
      "  0.03985507 0.01449275 0.0615942  0.01449275 0.02536232 0.\n",
      "  0.01811594 0.         0.00724638 0.01086957 0.01086957 0.\n",
      "  0.01811594 0.00724638 0.00362319 0.02173913 0.00362319 0.\n",
      "  0.00362319 0.00724638 0.00724638 0.00724638 0.01449275 0.01086957\n",
      "  0.         0.01811594 0.0326087  0.00724638 0.         0.00724638]\n",
      " [0.01102941 0.01102941 0.00735294 0.01102941 0.01102941 0.04411765\n",
      "  0.02941176 0.01470588 0.00367647 0.09926471 0.01470588 0.02573529\n",
      "  0.         0.00367647 0.01102941 0.00367647 0.02205882 0.00367647\n",
      "  0.01838235 0.00367647 0.02205882 0.02205882 0.01102941 0.00367647\n",
      "  0.00735294 0.02205882 0.         0.02573529 0.01102941 0.01470588\n",
      "  0.00367647 0.01838235 0.01838235 0.01102941 0.01470588 0.01102941\n",
      "  0.01102941 0.01838235 0.00367647 0.00735294 0.00367647 0.00735294\n",
      "  0.01470588 0.         0.00367647 0.01838235 0.00367647 0.00735294\n",
      "  0.02205882 0.00735294 0.00735294 0.00367647 0.00735294 0.01470588\n",
      "  0.02205882 0.00735294 0.04411765 0.01102941 0.00367647 0.00735294\n",
      "  0.00735294 0.01838235 0.01838235 0.00735294 0.02573529 0.02205882\n",
      "  0.01102941 0.01838235 0.02205882 0.01102941 0.         0.01470588]\n",
      " [0.01119403 0.01492537 0.0261194  0.01492537 0.01865672 0.01492537\n",
      "  0.00373134 0.04477612 0.01119403 0.0261194  0.05597015 0.04850746\n",
      "  0.00373134 0.         0.00746269 0.00373134 0.01492537 0.00373134\n",
      "  0.00373134 0.00373134 0.01119403 0.00746269 0.01492537 0.00373134\n",
      "  0.01492537 0.0261194  0.00373134 0.01119403 0.01492537 0.00746269\n",
      "  0.01492537 0.00373134 0.00373134 0.03358209 0.01119403 0.01492537\n",
      "  0.00746269 0.00746269 0.03731343 0.00746269 0.01492537 0.01865672\n",
      "  0.0261194  0.02238806 0.01492537 0.0261194  0.01119403 0.00746269\n",
      "  0.00746269 0.00373134 0.01865672 0.00373134 0.         0.01492537\n",
      "  0.01492537 0.00746269 0.02985075 0.00746269 0.01119403 0.00746269\n",
      "  0.01119403 0.00746269 0.00746269 0.01119403 0.00373134 0.01119403\n",
      "  0.00373134 0.0261194  0.01865672 0.00746269 0.00746269 0.0261194 ]\n",
      " [0.02166065 0.02527076 0.02888087 0.01805054 0.00722022 0.01444043\n",
      "  0.00722022 0.03249097 0.02527076 0.01805054 0.02527076 0.06859206\n",
      "  0.01083032 0.00722022 0.00361011 0.00722022 0.01444043 0.\n",
      "  0.         0.01083032 0.01083032 0.00361011 0.         0.00722022\n",
      "  0.02166065 0.03610108 0.01444043 0.01083032 0.01083032 0.00722022\n",
      "  0.00722022 0.         0.01083032 0.02166065 0.01083032 0.01444043\n",
      "  0.00722022 0.01444043 0.01444043 0.00722022 0.01805054 0.00722022\n",
      "  0.02527076 0.01805054 0.01444043 0.         0.         0.\n",
      "  0.00722022 0.02888087 0.02166065 0.00722022 0.00361011 0.01083032\n",
      "  0.02166065 0.02166065 0.02166065 0.01083032 0.         0.01444043\n",
      "  0.00722022 0.00722022 0.01444043 0.01444043 0.01083032 0.02527076\n",
      "  0.01805054 0.01444043 0.0433213  0.00722022 0.00361011 0.00361011]\n",
      " [0.01492537 0.00746269 0.01492537 0.01865672 0.00373134 0.0261194\n",
      "  0.00373134 0.         0.00373134 0.00746269 0.00373134 0.\n",
      "  0.05223881 0.05970149 0.04477612 0.0261194  0.07089552 0.03358209\n",
      "  0.03358209 0.05970149 0.03358209 0.03731343 0.04104478 0.02985075\n",
      "  0.01119403 0.00746269 0.         0.00746269 0.00373134 0.00746269\n",
      "  0.00746269 0.02238806 0.01492537 0.00746269 0.00746269 0.00746269\n",
      "  0.00746269 0.01119403 0.         0.00746269 0.01119403 0.00373134\n",
      "  0.00373134 0.01119403 0.01119403 0.01119403 0.01492537 0.04104478\n",
      "  0.00746269 0.         0.00373134 0.00746269 0.00373134 0.00746269\n",
      "  0.00373134 0.         0.01119403 0.00746269 0.00746269 0.\n",
      "  0.00746269 0.00373134 0.01492537 0.         0.00373134 0.01119403\n",
      "  0.         0.00373134 0.         0.01119403 0.00746269 0.01119403]\n",
      " [0.00722022 0.01083032 0.         0.01444043 0.00361011 0.01805054\n",
      "  0.00361011 0.         0.00722022 0.         0.         0.00722022\n",
      "  0.0866426  0.05776173 0.01805054 0.0433213  0.03971119 0.03249097\n",
      "  0.03249097 0.07220217 0.05415162 0.03971119 0.03249097 0.02527076\n",
      "  0.01444043 0.00722022 0.00722022 0.00361011 0.00722022 0.01083032\n",
      "  0.01444043 0.01083032 0.01805054 0.01083032 0.02888087 0.00722022\n",
      "  0.00361011 0.00722022 0.00361011 0.00722022 0.01805054 0.00722022\n",
      "  0.00361011 0.01444043 0.00722022 0.01444043 0.01444043 0.04693141\n",
      "  0.02166065 0.00361011 0.00722022 0.00722022 0.00361011 0.\n",
      "  0.00361011 0.00361011 0.         0.         0.00722022 0.\n",
      "  0.         0.         0.01805054 0.         0.         0.01083032\n",
      "  0.00722022 0.00361011 0.00361011 0.         0.         0.00361011]\n",
      " [0.02214022 0.02214022 0.01107011 0.         0.00369004 0.00369004\n",
      "  0.00369004 0.00738007 0.00369004 0.00738007 0.00738007 0.00738007\n",
      "  0.06273063 0.02583026 0.08487085 0.01845018 0.05535055 0.01845018\n",
      "  0.01476015 0.03690037 0.0295203  0.03690037 0.01476015 0.01845018\n",
      "  0.00369004 0.01476015 0.00738007 0.00369004 0.00738007 0.00738007\n",
      "  0.02214022 0.00738007 0.02214022 0.00369004 0.00738007 0.00738007\n",
      "  0.02214022 0.01107011 0.00369004 0.02214022 0.01476015 0.01476015\n",
      "  0.00369004 0.01845018 0.03690037 0.00369004 0.01476015 0.05904059\n",
      "  0.01476015 0.00369004 0.00738007 0.00369004 0.00738007 0.00369004\n",
      "  0.00369004 0.         0.01107011 0.         0.         0.\n",
      "  0.         0.00738007 0.00738007 0.01476015 0.01107011 0.00738007\n",
      "  0.00369004 0.01107011 0.00738007 0.00369004 0.         0.01476015]\n",
      " [0.01838235 0.         0.00367647 0.01102941 0.00367647 0.00735294\n",
      "  0.00367647 0.         0.         0.01102941 0.00367647 0.00367647\n",
      "  0.06985294 0.05147059 0.02941176 0.07352941 0.04044118 0.04411765\n",
      "  0.04411765 0.05882353 0.01470588 0.01470588 0.03676471 0.05514706\n",
      "  0.01470588 0.00367647 0.         0.00367647 0.00367647 0.00735294\n",
      "  0.01102941 0.01838235 0.01470588 0.00367647 0.01838235 0.00367647\n",
      "  0.00735294 0.01470588 0.00367647 0.01102941 0.01102941 0.02205882\n",
      "  0.01102941 0.01470588 0.00735294 0.00367647 0.00735294 0.05147059\n",
      "  0.01470588 0.         0.01470588 0.00367647 0.00367647 0.\n",
      "  0.         0.01102941 0.00735294 0.00367647 0.01102941 0.00367647\n",
      "  0.00367647 0.01102941 0.00367647 0.00735294 0.         0.00735294\n",
      "  0.00367647 0.         0.00367647 0.00367647 0.00735294 0.00735294]\n",
      " [0.01845018 0.00369004 0.01107011 0.00738007 0.01107011 0.01476015\n",
      "  0.00738007 0.00369004 0.00369004 0.01845018 0.00738007 0.00738007\n",
      "  0.03321033 0.01845018 0.0295203  0.02214022 0.06273063 0.04797048\n",
      "  0.03690037 0.04059041 0.04059041 0.03321033 0.02583026 0.03690037\n",
      "  0.01107011 0.00369004 0.00369004 0.01107011 0.00738007 0.00738007\n",
      "  0.         0.00738007 0.00369004 0.01476015 0.         0.00369004\n",
      "  0.00369004 0.00369004 0.00738007 0.01476015 0.01476015 0.02583026\n",
      "  0.01476015 0.02583026 0.01476015 0.00738007 0.00738007 0.04797048\n",
      "  0.01107011 0.00369004 0.00738007 0.00369004 0.00369004 0.00738007\n",
      "  0.01476015 0.00738007 0.00738007 0.00738007 0.00738007 0.\n",
      "  0.00369004 0.00738007 0.         0.01476015 0.00738007 0.02583026\n",
      "  0.00369004 0.00738007 0.01107011 0.00738007 0.01107011 0.01476015]\n",
      " [0.01107011 0.00369004 0.01476015 0.00369004 0.         0.01845018\n",
      "  0.01845018 0.         0.00369004 0.01107011 0.00738007 0.00738007\n",
      "  0.04428044 0.01845018 0.00738007 0.05535055 0.0701107  0.05166052\n",
      "  0.0701107  0.06273063 0.07380074 0.01476015 0.0295203  0.02214022\n",
      "  0.00738007 0.00369004 0.00738007 0.01107011 0.00738007 0.01107011\n",
      "  0.01476015 0.01107011 0.01107011 0.00738007 0.00738007 0.00738007\n",
      "  0.00738007 0.00369004 0.         0.00738007 0.00369004 0.01476015\n",
      "  0.00369004 0.01845018 0.00369004 0.00369004 0.01107011 0.01107011\n",
      "  0.01845018 0.00738007 0.         0.00369004 0.00369004 0.00369004\n",
      "  0.00738007 0.         0.00738007 0.00738007 0.01476015 0.\n",
      "  0.01107011 0.00738007 0.01107011 0.01476015 0.00738007 0.01476015\n",
      "  0.00369004 0.00738007 0.00738007 0.00369004 0.         0.02214022]\n",
      " [0.01486989 0.01486989 0.01115242 0.01486989 0.00743494 0.0260223\n",
      "  0.00743494 0.         0.00371747 0.02973978 0.00371747 0.00371747\n",
      "  0.04089219 0.01858736 0.01486989 0.02230483 0.01486989 0.05947955\n",
      "  0.07063197 0.04832714 0.04832714 0.01115242 0.05947955 0.03717472\n",
      "  0.00371747 0.00743494 0.00743494 0.00371747 0.00371747 0.01858736\n",
      "  0.         0.01115242 0.01486989 0.01486989 0.01115242 0.00371747\n",
      "  0.00743494 0.00371747 0.00371747 0.         0.00371747 0.00371747\n",
      "  0.00743494 0.00743494 0.00743494 0.         0.01858736 0.03345725\n",
      "  0.00743494 0.00371747 0.01486989 0.01115242 0.00371747 0.01115242\n",
      "  0.00371747 0.00743494 0.01115242 0.01115242 0.01858736 0.00371747\n",
      "  0.01115242 0.         0.01115242 0.00371747 0.00371747 0.01486989\n",
      "  0.01115242 0.00371747 0.00371747 0.00371747 0.00743494 0.03717472]\n",
      " [0.02919708 0.01824818 0.00729927 0.00729927 0.         0.01094891\n",
      "  0.00364964 0.         0.         0.         0.00364964 0.00729927\n",
      "  0.07664234 0.02189781 0.02554745 0.0620438  0.03649635 0.02919708\n",
      "  0.04744526 0.05839416 0.03284672 0.01824818 0.02919708 0.04379562\n",
      "  0.01094891 0.02919708 0.00729927 0.01459854 0.00364964 0.00364964\n",
      "  0.01459854 0.00729927 0.02189781 0.00729927 0.03649635 0.00729927\n",
      "  0.00729927 0.         0.00364964 0.         0.02189781 0.00364964\n",
      "  0.00729927 0.00364964 0.00364964 0.01824818 0.00729927 0.04014599\n",
      "  0.02189781 0.         0.01459854 0.00729927 0.00729927 0.\n",
      "  0.01824818 0.         0.         0.         0.00364964 0.00364964\n",
      "  0.         0.         0.01094891 0.         0.         0.01094891\n",
      "  0.00364964 0.00729927 0.01094891 0.01094891 0.00364964 0.01459854]\n",
      " [0.0037037  0.01481481 0.01111111 0.01481481 0.00740741 0.02592593\n",
      "  0.01481481 0.01481481 0.00740741 0.01111111 0.         0.0037037\n",
      "  0.05185185 0.01851852 0.01111111 0.02222222 0.02962963 0.00740741\n",
      "  0.05185185 0.02592593 0.07777778 0.02962963 0.01111111 0.01851852\n",
      "  0.01111111 0.0037037  0.00740741 0.00740741 0.0037037  0.01481481\n",
      "  0.0037037  0.01481481 0.01111111 0.01111111 0.00740741 0.00740741\n",
      "  0.01851852 0.         0.00740741 0.01481481 0.01851852 0.01111111\n",
      "  0.00740741 0.02592593 0.0037037  0.00740741 0.01111111 0.03703704\n",
      "  0.00740741 0.01111111 0.01481481 0.         0.00740741 0.01111111\n",
      "  0.02222222 0.         0.00740741 0.0037037  0.0037037  0.0037037\n",
      "  0.0037037  0.01111111 0.03333333 0.00740741 0.         0.01481481\n",
      "  0.         0.01111111 0.00740741 0.01851852 0.01481481 0.03333333]\n",
      " [0.02173913 0.01449275 0.00362319 0.00362319 0.         0.02173913\n",
      "  0.01811594 0.01086957 0.01086957 0.01086957 0.00724638 0.00724638\n",
      "  0.0326087  0.02536232 0.0326087  0.02536232 0.03623188 0.03985507\n",
      "  0.0326087  0.05434783 0.03623188 0.07971014 0.02898551 0.01449275\n",
      "  0.00724638 0.01086957 0.00362319 0.00362319 0.00724638 0.01086957\n",
      "  0.00724638 0.01086957 0.01811594 0.01086957 0.02536232 0.00362319\n",
      "  0.01086957 0.00724638 0.00362319 0.00724638 0.02173913 0.01086957\n",
      "  0.00724638 0.01449275 0.00724638 0.01811594 0.01086957 0.0326087\n",
      "  0.01449275 0.         0.00362319 0.00362319 0.00724638 0.00724638\n",
      "  0.         0.01086957 0.00362319 0.         0.00724638 0.01086957\n",
      "  0.         0.00362319 0.00362319 0.01449275 0.00724638 0.01086957\n",
      "  0.00724638 0.         0.01449275 0.01086957 0.         0.01811594]\n",
      " [0.00362319 0.00362319 0.00724638 0.02173913 0.         0.00724638\n",
      "  0.00724638 0.01449275 0.00362319 0.01086957 0.01086957 0.00362319\n",
      "  0.05797101 0.02173913 0.01449275 0.04710145 0.05797101 0.05434783\n",
      "  0.03623188 0.03985507 0.05072464 0.0326087  0.0615942  0.03623188\n",
      "  0.00724638 0.01449275 0.00724638 0.00724638 0.         0.00724638\n",
      "  0.00724638 0.01086957 0.01086957 0.01811594 0.01449275 0.00362319\n",
      "  0.         0.00362319 0.00362319 0.01086957 0.01086957 0.01449275\n",
      "  0.00724638 0.         0.00724638 0.00724638 0.00362319 0.02536232\n",
      "  0.00362319 0.00362319 0.01449275 0.00724638 0.00362319 0.00362319\n",
      "  0.00362319 0.00724638 0.00362319 0.00724638 0.01086957 0.01086957\n",
      "  0.         0.01086957 0.01811594 0.01811594 0.00362319 0.01449275\n",
      "  0.00362319 0.00362319 0.00362319 0.01449275 0.         0.02173913]\n",
      " [0.01090909 0.         0.         0.         0.         0.01454545\n",
      "  0.00363636 0.         0.00727273 0.         0.00363636 0.\n",
      "  0.05454545 0.05090909 0.00363636 0.04727273 0.05454545 0.05818182\n",
      "  0.05454545 0.09090909 0.02909091 0.01090909 0.02909091 0.06909091\n",
      "  0.01090909 0.01090909 0.00727273 0.01818182 0.00363636 0.01090909\n",
      "  0.00363636 0.01090909 0.00363636 0.01454545 0.01818182 0.\n",
      "  0.00363636 0.         0.00363636 0.01454545 0.02909091 0.01090909\n",
      "  0.00727273 0.00727273 0.00727273 0.         0.01090909 0.02181818\n",
      "  0.01454545 0.00363636 0.00363636 0.00727273 0.         0.01454545\n",
      "  0.00727273 0.00727273 0.00727273 0.01090909 0.00363636 0.\n",
      "  0.00363636 0.00363636 0.01090909 0.00727273 0.00363636 0.\n",
      "  0.         0.02181818 0.00727273 0.01454545 0.00727273 0.01818182]\n",
      " [0.01107011 0.         0.00738007 0.01476015 0.01476015 0.01107011\n",
      "  0.00738007 0.01107011 0.00738007 0.01845018 0.00738007 0.01107011\n",
      "  0.01107011 0.00369004 0.00369004 0.00738007 0.         0.00738007\n",
      "  0.00369004 0.00738007 0.00369004 0.00369004 0.         0.00369004\n",
      "  0.02583026 0.04059041 0.02583026 0.0295203  0.00369004 0.01476015\n",
      "  0.01845018 0.02214022 0.03321033 0.01476015 0.02214022 0.01107011\n",
      "  0.01107011 0.01845018 0.03321033 0.01107011 0.02214022 0.01476015\n",
      "  0.00738007 0.01845018 0.0295203  0.02214022 0.01476015 0.01107011\n",
      "  0.01107011 0.00738007 0.01476015 0.01845018 0.03690037 0.00738007\n",
      "  0.01845018 0.00738007 0.01845018 0.00738007 0.00738007 0.01476015\n",
      "  0.         0.00738007 0.04797048 0.00738007 0.01476015 0.02214022\n",
      "  0.         0.01107011 0.0295203  0.01476015 0.01476015 0.00738007]\n",
      " [0.02197802 0.003663   0.01465201 0.00732601 0.00732601 0.02197802\n",
      "  0.01465201 0.01465201 0.003663   0.003663   0.00732601 0.01465201\n",
      "  0.003663   0.         0.01465201 0.01098901 0.00732601 0.003663\n",
      "  0.01098901 0.01831502 0.003663   0.01465201 0.         0.00732601\n",
      "  0.02564103 0.05494505 0.01465201 0.02930403 0.01831502 0.01465201\n",
      "  0.01465201 0.01831502 0.01831502 0.03296703 0.02197802 0.01465201\n",
      "  0.01098901 0.02197802 0.01098901 0.003663   0.02197802 0.03296703\n",
      "  0.00732601 0.00732601 0.01098901 0.01831502 0.00732601 0.00732601\n",
      "  0.01098901 0.00732601 0.00732601 0.00732601 0.01098901 0.01098901\n",
      "  0.02930403 0.03296703 0.01098901 0.00732601 0.01831502 0.\n",
      "  0.01098901 0.01465201 0.01831502 0.01098901 0.003663   0.02930403\n",
      "  0.003663   0.02564103 0.02564103 0.00732601 0.00732601 0.01831502]\n",
      " [0.00724638 0.01086957 0.         0.         0.01086957 0.00724638\n",
      "  0.         0.00362319 0.00362319 0.00362319 0.00362319 0.00362319\n",
      "  0.         0.00362319 0.00362319 0.00362319 0.         0.\n",
      "  0.00362319 0.00362319 0.00724638 0.00724638 0.         0.00724638\n",
      "  0.03985507 0.02173913 0.06884058 0.01811594 0.06521739 0.02173913\n",
      "  0.06521739 0.00362319 0.04710145 0.02173913 0.03623188 0.0326087\n",
      "  0.01086957 0.00724638 0.02173913 0.00724638 0.01086957 0.02173913\n",
      "  0.02536232 0.01811594 0.00724638 0.00724638 0.01086957 0.00724638\n",
      "  0.02536232 0.         0.01086957 0.02173913 0.00724638 0.00724638\n",
      "  0.01811594 0.01811594 0.         0.04347826 0.00362319 0.00724638\n",
      "  0.         0.01086957 0.01086957 0.01086957 0.         0.02898551\n",
      "  0.00724638 0.02536232 0.01449275 0.02536232 0.00724638 0.00362319]\n",
      " [0.01824818 0.00729927 0.01824818 0.00729927 0.00729927 0.01459854\n",
      "  0.01094891 0.01094891 0.00364964 0.02554745 0.00729927 0.02189781\n",
      "  0.00364964 0.         0.00729927 0.00364964 0.         0.\n",
      "  0.         0.00364964 0.00729927 0.00364964 0.00364964 0.00729927\n",
      "  0.01459854 0.04014599 0.02189781 0.04014599 0.02189781 0.01824818\n",
      "  0.00364964 0.03284672 0.01459854 0.02554745 0.01824818 0.00729927\n",
      "  0.01459854 0.         0.00364964 0.00729927 0.         0.00729927\n",
      "  0.02919708 0.00364964 0.01459854 0.         0.00729927 0.00729927\n",
      "  0.00364964 0.01094891 0.04014599 0.01094891 0.01459854 0.01459854\n",
      "  0.02919708 0.01824818 0.03649635 0.00364964 0.02189781 0.01094891\n",
      "  0.00364964 0.02919708 0.02919708 0.00729927 0.02189781 0.03284672\n",
      "  0.02189781 0.01459854 0.02189781 0.04014599 0.00364964 0.01094891]\n",
      " [0.01433692 0.         0.00358423 0.03225806 0.00358423 0.01433692\n",
      "  0.01792115 0.00716846 0.00358423 0.00358423 0.00358423 0.01433692\n",
      "  0.00358423 0.         0.00358423 0.00358423 0.         0.\n",
      "  0.00716846 0.00716846 0.00716846 0.01433692 0.         0.\n",
      "  0.02508961 0.00716846 0.04659498 0.00716846 0.03942652 0.02508961\n",
      "  0.02150538 0.02508961 0.01075269 0.01792115 0.02150538 0.01433692\n",
      "  0.00716846 0.02867384 0.00358423 0.00358423 0.02508961 0.02150538\n",
      "  0.01075269 0.00716846 0.03584229 0.02150538 0.00716846 0.\n",
      "  0.02150538 0.         0.02508961 0.01792115 0.01075269 0.02508961\n",
      "  0.03584229 0.00358423 0.00716846 0.01433692 0.01792115 0.02508961\n",
      "  0.00358423 0.02867384 0.02150538 0.02150538 0.01433692 0.01433692\n",
      "  0.00358423 0.01792115 0.04659498 0.01433692 0.00358423 0.00716846]\n",
      " [0.02205882 0.00367647 0.01838235 0.00367647 0.01102941 0.02205882\n",
      "  0.00367647 0.02205882 0.         0.01102941 0.01470588 0.\n",
      "  0.01470588 0.00367647 0.00367647 0.00367647 0.         0.00735294\n",
      "  0.00735294 0.00367647 0.00735294 0.02205882 0.         0.01102941\n",
      "  0.05514706 0.03308824 0.01470588 0.01838235 0.01470588 0.03676471\n",
      "  0.01470588 0.01102941 0.02941176 0.04044118 0.02573529 0.01838235\n",
      "  0.01838235 0.01470588 0.00367647 0.01102941 0.01838235 0.00367647\n",
      "  0.00735294 0.00367647 0.03308824 0.01470588 0.00735294 0.\n",
      "  0.03308824 0.         0.03308824 0.01470588 0.00367647 0.01838235\n",
      "  0.01102941 0.00367647 0.         0.01470588 0.00735294 0.01838235\n",
      "  0.00367647 0.00735294 0.00367647 0.00735294 0.00367647 0.03308824\n",
      "  0.01102941 0.05147059 0.01470588 0.02573529 0.00367647 0.01102941]\n",
      " [0.01083032 0.00361011 0.00361011 0.00722022 0.         0.01083032\n",
      "  0.00361011 0.00361011 0.01083032 0.         0.01083032 0.01444043\n",
      "  0.00361011 0.00722022 0.00722022 0.         0.00722022 0.00361011\n",
      "  0.         0.01083032 0.         0.         0.00361011 0.00361011\n",
      "  0.00722022 0.02527076 0.0866426  0.00722022 0.02888087 0.01805054\n",
      "  0.15162455 0.04693141 0.0433213  0.02166065 0.03610108 0.01444043\n",
      "  0.01083032 0.01083032 0.00361011 0.00722022 0.02166065 0.01444043\n",
      "  0.00361011 0.01444043 0.0433213  0.00361011 0.00722022 0.01083032\n",
      "  0.02527076 0.         0.02888087 0.01444043 0.00361011 0.00722022\n",
      "  0.01444043 0.00361011 0.00361011 0.01444043 0.00722022 0.00361011\n",
      "  0.         0.00722022 0.01083032 0.01444043 0.00361011 0.02527076\n",
      "  0.         0.01444043 0.01805054 0.00361011 0.00722022 0.00361011]\n",
      " [0.02592593 0.0037037  0.01111111 0.         0.         0.01111111\n",
      "  0.01111111 0.01111111 0.0037037  0.0037037  0.         0.01111111\n",
      "  0.02222222 0.0037037  0.01111111 0.01481481 0.0037037  0.01481481\n",
      "  0.00740741 0.01851852 0.         0.00740741 0.01111111 0.01851852\n",
      "  0.02962963 0.02222222 0.02592593 0.00740741 0.01481481 0.00740741\n",
      "  0.04074074 0.0962963  0.05925926 0.02222222 0.03333333 0.02592593\n",
      "  0.02222222 0.0037037  0.0037037  0.00740741 0.01851852 0.0037037\n",
      "  0.0037037  0.01111111 0.02962963 0.0037037  0.00740741 0.\n",
      "  0.01481481 0.         0.01851852 0.01111111 0.         0.00740741\n",
      "  0.00740741 0.02222222 0.0037037  0.01111111 0.0037037  0.\n",
      "  0.         0.00740741 0.01851852 0.01481481 0.         0.03703704\n",
      "  0.         0.04814815 0.01111111 0.02592593 0.         0.01111111]\n",
      " [0.02573529 0.00367647 0.01102941 0.00735294 0.01470588 0.00735294\n",
      "  0.00367647 0.00735294 0.         0.00735294 0.00735294 0.01102941\n",
      "  0.00367647 0.01838235 0.01470588 0.00735294 0.00367647 0.\n",
      "  0.00735294 0.01838235 0.00735294 0.         0.00367647 0.00735294\n",
      "  0.03308824 0.04779412 0.05514706 0.02205882 0.01470588 0.02573529\n",
      "  0.01838235 0.04044118 0.07352941 0.01102941 0.04779412 0.02205882\n",
      "  0.00735294 0.00735294 0.         0.00735294 0.01102941 0.00735294\n",
      "  0.01838235 0.00735294 0.02941176 0.01838235 0.00367647 0.01102941\n",
      "  0.00367647 0.00367647 0.02205882 0.01838235 0.01470588 0.01838235\n",
      "  0.00735294 0.00735294 0.         0.01102941 0.00367647 0.00735294\n",
      "  0.         0.         0.02573529 0.01102941 0.00367647 0.02205882\n",
      "  0.00367647 0.02205882 0.00735294 0.03308824 0.00735294 0.00735294]\n",
      " [0.02173913 0.01086957 0.01086957 0.01449275 0.00724638 0.01449275\n",
      "  0.00362319 0.01086957 0.01086957 0.00362319 0.00724638 0.00724638\n",
      "  0.         0.00362319 0.00362319 0.00362319 0.         0.00362319\n",
      "  0.00362319 0.00362319 0.01449275 0.00724638 0.00362319 0.00362319\n",
      "  0.03985507 0.02536232 0.01086957 0.01449275 0.02173913 0.01811594\n",
      "  0.01086957 0.01086957 0.01449275 0.07971014 0.01449275 0.0326087\n",
      "  0.03985507 0.01449275 0.01086957 0.02898551 0.02898551 0.03985507\n",
      "  0.00724638 0.01086957 0.03623188 0.02898551 0.01449275 0.01449275\n",
      "  0.00724638 0.         0.01449275 0.0326087  0.00362319 0.00724638\n",
      "  0.01811594 0.00362319 0.01086957 0.02536232 0.00724638 0.00362319\n",
      "  0.00724638 0.01449275 0.00362319 0.01449275 0.01086957 0.00724638\n",
      "  0.00724638 0.00724638 0.02898551 0.01811594 0.         0.00362319]\n",
      " [0.02197802 0.01098901 0.00732601 0.         0.00732601 0.01831502\n",
      "  0.003663   0.003663   0.00732601 0.00732601 0.003663   0.01831502\n",
      "  0.003663   0.003663   0.         0.003663   0.003663   0.\n",
      "  0.003663   0.01831502 0.003663   0.01098901 0.01098901 0.02930403\n",
      "  0.02197802 0.03663004 0.03663004 0.01465201 0.03663004 0.01098901\n",
      "  0.02197802 0.04029304 0.06593407 0.02564103 0.06227106 0.01465201\n",
      "  0.01098901 0.01098901 0.003663   0.003663   0.01831502 0.01098901\n",
      "  0.         0.003663   0.01098901 0.02197802 0.003663   0.01465201\n",
      "  0.02564103 0.         0.01465201 0.01465201 0.00732601 0.02197802\n",
      "  0.02930403 0.00732601 0.00732601 0.003663   0.01098901 0.00732601\n",
      "  0.         0.01098901 0.01465201 0.01465201 0.00732601 0.03296703\n",
      "  0.00732601 0.01465201 0.00732601 0.02197802 0.003663   0.01098901]\n",
      " [0.02536232 0.02173913 0.         0.01086957 0.01449275 0.01449275\n",
      "  0.00362319 0.00362319 0.01086957 0.01086957 0.00724638 0.00362319\n",
      "  0.         0.01086957 0.00724638 0.01449275 0.00362319 0.00362319\n",
      "  0.00724638 0.01449275 0.00724638 0.         0.00362319 0.\n",
      "  0.0326087  0.00724638 0.04347826 0.01086957 0.0326087  0.00724638\n",
      "  0.01449275 0.01811594 0.01086957 0.04347826 0.01811594 0.06521739\n",
      "  0.0326087  0.02536232 0.01449275 0.01449275 0.02536232 0.02898551\n",
      "  0.02173913 0.02898551 0.05797101 0.01086957 0.00362319 0.02173913\n",
      "  0.02898551 0.00724638 0.00724638 0.02173913 0.01086957 0.01086957\n",
      "  0.00362319 0.         0.00724638 0.01811594 0.00362319 0.01086957\n",
      "  0.00362319 0.00724638 0.00724638 0.         0.         0.00724638\n",
      "  0.         0.00362319 0.02536232 0.01449275 0.         0.01086957]\n",
      " [0.01811594 0.03623188 0.00724638 0.00724638 0.         0.01449275\n",
      "  0.02173913 0.00724638 0.00362319 0.01086957 0.00362319 0.01811594\n",
      "  0.00362319 0.         0.02536232 0.         0.01449275 0.00724638\n",
      "  0.00362319 0.00362319 0.01449275 0.00724638 0.00362319 0.00362319\n",
      "  0.02536232 0.01449275 0.01449275 0.00724638 0.01086957 0.00724638\n",
      "  0.         0.00724638 0.01086957 0.0326087  0.00724638 0.02536232\n",
      "  0.03623188 0.03985507 0.01086957 0.02898551 0.03623188 0.04347826\n",
      "  0.01086957 0.01449275 0.02898551 0.05072464 0.01449275 0.01086957\n",
      "  0.0326087  0.00724638 0.01811594 0.02173913 0.00724638 0.01086957\n",
      "  0.00362319 0.00362319 0.01811594 0.02898551 0.00724638 0.00362319\n",
      "  0.         0.01449275 0.00724638 0.00362319 0.01811594 0.01086957\n",
      "  0.00362319 0.01811594 0.01811594 0.01449275 0.00362319 0.        ]\n",
      " [0.01824818 0.03284672 0.00364964 0.01094891 0.01459854 0.01459854\n",
      "  0.01824818 0.01459854 0.01094891 0.01459854 0.00729927 0.01459854\n",
      "  0.01459854 0.00364964 0.00729927 0.00729927 0.         0.00729927\n",
      "  0.00364964 0.00729927 0.01459854 0.00729927 0.00729927 0.00364964\n",
      "  0.01094891 0.01094891 0.02189781 0.00729927 0.02554745 0.01824818\n",
      "  0.01094891 0.00364964 0.01094891 0.01459854 0.01824818 0.01824818\n",
      "  0.01824818 0.05839416 0.01459854 0.01094891 0.01824818 0.02189781\n",
      "  0.03284672 0.01094891 0.02919708 0.02919708 0.01094891 0.03284672\n",
      "  0.00729927 0.00364964 0.02919708 0.00364964 0.01094891 0.01459854\n",
      "  0.01824818 0.00729927 0.01824818 0.02554745 0.00729927 0.00364964\n",
      "  0.00364964 0.01459854 0.01824818 0.00729927 0.00729927 0.01094891\n",
      "  0.00364964 0.01094891 0.02919708 0.01094891 0.00729927 0.00729927]\n",
      " [0.         0.02573529 0.01838235 0.01470588 0.02573529 0.02573529\n",
      "  0.         0.01838235 0.01838235 0.03676471 0.01102941 0.01470588\n",
      "  0.00367647 0.         0.00367647 0.00735294 0.00367647 0.\n",
      "  0.         0.00735294 0.01838235 0.00735294 0.         0.00735294\n",
      "  0.02941176 0.02205882 0.00367647 0.00735294 0.00367647 0.02205882\n",
      "  0.00735294 0.00367647 0.01102941 0.01838235 0.02941176 0.01838235\n",
      "  0.01102941 0.03308824 0.05882353 0.02205882 0.02205882 0.02573529\n",
      "  0.04411765 0.00735294 0.03676471 0.02205882 0.01838235 0.01470588\n",
      "  0.         0.02205882 0.01838235 0.01470588 0.01102941 0.00735294\n",
      "  0.01102941 0.00735294 0.00735294 0.00367647 0.         0.00367647\n",
      "  0.00367647 0.01470588 0.00367647 0.01102941 0.01470588 0.01838235\n",
      "  0.         0.01470588 0.03308824 0.00367647 0.00735294 0.00735294]\n",
      " [0.00357143 0.01785714 0.01071429 0.00357143 0.         0.01785714\n",
      "  0.00714286 0.01428571 0.03214286 0.01428571 0.00714286 0.00357143\n",
      "  0.00357143 0.         0.01785714 0.00357143 0.         0.\n",
      "  0.00357143 0.01428571 0.00714286 0.00714286 0.         0.00357143\n",
      "  0.01785714 0.00357143 0.01785714 0.01071429 0.02857143 0.01071429\n",
      "  0.00714286 0.         0.01071429 0.05357143 0.01071429 0.01071429\n",
      "  0.025      0.01071429 0.03214286 0.03214286 0.01785714 0.02857143\n",
      "  0.03928571 0.03571429 0.04285714 0.02142857 0.05       0.01428571\n",
      "  0.00714286 0.00714286 0.00357143 0.00714286 0.00714286 0.01071429\n",
      "  0.03571429 0.         0.01071429 0.02142857 0.00357143 0.01071429\n",
      "  0.00714286 0.01428571 0.01428571 0.00714286 0.01428571 0.02142857\n",
      "  0.00357143 0.00357143 0.025      0.025      0.00357143 0.01071429]\n",
      " [0.02962963 0.03703704 0.01481481 0.0037037  0.0037037  0.00740741\n",
      "  0.         0.0037037  0.01111111 0.00740741 0.01111111 0.0037037\n",
      "  0.         0.01111111 0.02962963 0.         0.00740741 0.00740741\n",
      "  0.0037037  0.01111111 0.01851852 0.00740741 0.0037037  0.02222222\n",
      "  0.03703704 0.0037037  0.01851852 0.00740741 0.01851852 0.00740741\n",
      "  0.01111111 0.         0.01851852 0.01111111 0.02592593 0.01481481\n",
      "  0.03703704 0.02962963 0.         0.03333333 0.04814815 0.04444444\n",
      "  0.01851852 0.01481481 0.05925926 0.03703704 0.02592593 0.01111111\n",
      "  0.01481481 0.0037037  0.00740741 0.01851852 0.01111111 0.00740741\n",
      "  0.0037037  0.01111111 0.         0.01481481 0.00740741 0.0037037\n",
      "  0.0037037  0.00740741 0.00740741 0.00740741 0.01481481 0.\n",
      "  0.         0.00740741 0.03333333 0.02592593 0.         0.        ]\n",
      " [0.02166065 0.01444043 0.01083032 0.00361011 0.01083032 0.02166065\n",
      "  0.01444043 0.00361011 0.01444043 0.01083032 0.00722022 0.00722022\n",
      "  0.00722022 0.00722022 0.01083032 0.         0.01805054 0.00361011\n",
      "  0.00361011 0.02166065 0.01444043 0.         0.         0.01444043\n",
      "  0.03249097 0.03971119 0.00361011 0.01083032 0.02527076 0.01444043\n",
      "  0.02166065 0.00722022 0.03249097 0.02527076 0.03249097 0.01083032\n",
      "  0.04693141 0.03610108 0.01444043 0.00722022 0.02527076 0.02888087\n",
      "  0.01805054 0.01805054 0.0433213  0.03249097 0.00361011 0.01805054\n",
      "  0.00722022 0.         0.01805054 0.01083032 0.         0.00361011\n",
      "  0.01444043 0.00361011 0.         0.01805054 0.00722022 0.00361011\n",
      "  0.         0.00722022 0.02527076 0.01083032 0.00722022 0.00722022\n",
      "  0.         0.00361011 0.02527076 0.02166065 0.00361011 0.01083032]\n",
      " [0.00740741 0.04074074 0.00740741 0.01481481 0.01481481 0.01111111\n",
      "  0.         0.01111111 0.02592593 0.01111111 0.00740741 0.01851852\n",
      "  0.         0.         0.0037037  0.         0.0037037  0.00740741\n",
      "  0.         0.00740741 0.         0.0037037  0.00740741 0.0037037\n",
      "  0.02222222 0.03703704 0.00740741 0.01851852 0.0037037  0.0037037\n",
      "  0.01111111 0.0037037  0.0037037  0.03703704 0.01851852 0.00740741\n",
      "  0.04074074 0.04814815 0.00740741 0.02962963 0.04444444 0.01851852\n",
      "  0.04814815 0.02592593 0.04444444 0.03333333 0.01851852 0.00740741\n",
      "  0.0037037  0.0037037  0.02222222 0.02592593 0.01481481 0.01851852\n",
      "  0.01851852 0.0037037  0.0037037  0.01851852 0.01111111 0.00740741\n",
      "  0.0037037  0.00740741 0.00740741 0.01111111 0.01481481 0.0037037\n",
      "  0.         0.02592593 0.00740741 0.0037037  0.00740741 0.00740741]\n",
      " [0.00367647 0.00735294 0.01102941 0.00735294 0.00367647 0.01470588\n",
      "  0.00735294 0.00367647 0.04044118 0.01470588 0.01102941 0.00367647\n",
      "  0.00735294 0.00367647 0.02573529 0.01102941 0.00735294 0.00367647\n",
      "  0.00735294 0.02941176 0.02573529 0.00367647 0.         0.00367647\n",
      "  0.01838235 0.01102941 0.01102941 0.         0.01102941 0.00367647\n",
      "  0.01838235 0.01102941 0.01470588 0.04411765 0.02573529 0.01838235\n",
      "  0.01470588 0.02573529 0.02941176 0.03308824 0.0625     0.03676471\n",
      "  0.02941176 0.02941176 0.03308824 0.01470588 0.03308824 0.03676471\n",
      "  0.02205882 0.         0.01102941 0.02941176 0.00367647 0.\n",
      "  0.01838235 0.         0.00735294 0.00735294 0.01102941 0.01102941\n",
      "  0.         0.         0.00735294 0.         0.00735294 0.01470588\n",
      "  0.00367647 0.00367647 0.01102941 0.         0.00367647 0.00367647]\n",
      " [0.00363636 0.01090909 0.00727273 0.00727273 0.00363636 0.02181818\n",
      "  0.         0.00727273 0.03272727 0.01090909 0.00727273 0.01818182\n",
      "  0.00363636 0.00363636 0.00363636 0.         0.         0.\n",
      "  0.00363636 0.00363636 0.00727273 0.         0.         0.00727273\n",
      "  0.01818182 0.01818182 0.02545455 0.         0.01818182 0.01454545\n",
      "  0.01818182 0.01090909 0.00727273 0.01818182 0.01818182 0.03636364\n",
      "  0.04363636 0.03636364 0.01090909 0.02181818 0.03636364 0.03272727\n",
      "  0.03272727 0.05090909 0.12       0.02909091 0.03272727 0.01454545\n",
      "  0.01818182 0.00727273 0.00727273 0.01090909 0.00363636 0.00363636\n",
      "  0.01090909 0.         0.00363636 0.01454545 0.00363636 0.\n",
      "  0.00363636 0.00363636 0.01454545 0.01454545 0.00727273 0.00727273\n",
      "  0.         0.00363636 0.01818182 0.00727273 0.         0.00727273]\n",
      " [0.00722022 0.02166065 0.00361011 0.00722022 0.00361011 0.02888087\n",
      "  0.01083032 0.         0.02166065 0.00722022 0.         0.00722022\n",
      "  0.00722022 0.00722022 0.00722022 0.00361011 0.         0.\n",
      "  0.00722022 0.00722022 0.00722022 0.         0.         0.00722022\n",
      "  0.03610108 0.01083032 0.01444043 0.01444043 0.         0.02527076\n",
      "  0.02527076 0.00361011 0.01083032 0.03249097 0.01805054 0.03249097\n",
      "  0.06498195 0.0433213  0.01083032 0.03249097 0.04693141 0.02166065\n",
      "  0.01083032 0.00722022 0.02527076 0.03971119 0.03610108 0.02166065\n",
      "  0.01444043 0.         0.01805054 0.01805054 0.00361011 0.00722022\n",
      "  0.01444043 0.00361011 0.00361011 0.02888087 0.00361011 0.00361011\n",
      "  0.         0.01444043 0.01444043 0.         0.01083032 0.00722022\n",
      "  0.00361011 0.00722022 0.02166065 0.01083032 0.01805054 0.01444043]\n",
      " [0.01805054 0.01805054 0.00361011 0.01083032 0.         0.01805054\n",
      "  0.00361011 0.01083032 0.03971119 0.00361011 0.01805054 0.00722022\n",
      "  0.00361011 0.00722022 0.02166065 0.00361011 0.01444043 0.00361011\n",
      "  0.01083032 0.00722022 0.01083032 0.01083032 0.00722022 0.01083032\n",
      "  0.02527076 0.00361011 0.01444043 0.         0.00722022 0.01083032\n",
      "  0.00722022 0.00722022 0.01444043 0.02888087 0.00722022 0.01805054\n",
      "  0.06859206 0.02888087 0.00722022 0.02166065 0.04693141 0.02166065\n",
      "  0.01805054 0.03971119 0.03971119 0.03610108 0.03971119 0.03971119\n",
      "  0.01083032 0.00722022 0.00722022 0.03249097 0.         0.00722022\n",
      "  0.00722022 0.         0.00361011 0.01805054 0.00722022 0.00361011\n",
      "  0.         0.01083032 0.00722022 0.00722022 0.01444043 0.01444043\n",
      "  0.         0.00361011 0.00722022 0.00361011 0.00361011 0.00722022]\n",
      " [0.01845018 0.01107011 0.         0.01476015 0.01107011 0.02214022\n",
      "  0.         0.00738007 0.00738007 0.         0.00369004 0.00738007\n",
      "  0.01476015 0.03321033 0.04428044 0.04059041 0.03321033 0.01107011\n",
      "  0.03321033 0.04428044 0.02583026 0.04797048 0.0295203  0.0295203\n",
      "  0.01476015 0.01107011 0.00738007 0.00369004 0.00369004 0.00369004\n",
      "  0.01107011 0.01845018 0.01107011 0.00369004 0.02583026 0.01476015\n",
      "  0.01476015 0.00738007 0.00738007 0.01845018 0.01845018 0.01476015\n",
      "  0.01476015 0.01476015 0.02214022 0.01476015 0.01107011 0.06642066\n",
      "  0.01845018 0.00369004 0.01107011 0.01107011 0.01107011 0.01107011\n",
      "  0.00369004 0.00369004 0.         0.00738007 0.00738007 0.00738007\n",
      "  0.         0.         0.01476015 0.00738007 0.00738007 0.\n",
      "  0.         0.01107011 0.         0.00738007 0.00369004 0.00738007]\n",
      " [0.01459854 0.01459854 0.00364964 0.00729927 0.00364964 0.00729927\n",
      "  0.00729927 0.01094891 0.         0.01094891 0.00364964 0.\n",
      "  0.00729927 0.01094891 0.00729927 0.00729927 0.00729927 0.00364964\n",
      "  0.01459854 0.01094891 0.         0.00729927 0.00729927 0.01094891\n",
      "  0.01094891 0.00729927 0.02189781 0.01459854 0.02554745 0.01094891\n",
      "  0.01824818 0.01094891 0.02554745 0.01094891 0.02554745 0.02554745\n",
      "  0.02189781 0.01824818 0.00729927 0.00729927 0.03284672 0.01824818\n",
      "  0.01459854 0.02189781 0.02189781 0.01459854 0.01459854 0.02554745\n",
      "  0.05474453 0.01094891 0.02554745 0.04014599 0.01824818 0.01094891\n",
      "  0.02189781 0.00364964 0.01094891 0.03284672 0.01824818 0.\n",
      "  0.00364964 0.00729927 0.02554745 0.01459854 0.02189781 0.01094891\n",
      "  0.00364964 0.01459854 0.00729927 0.01094891 0.01094891 0.01459854]\n",
      " [0.00362319 0.01086957 0.01086957 0.01086957 0.03623188 0.01811594\n",
      "  0.00724638 0.02173913 0.00362319 0.01811594 0.00724638 0.01449275\n",
      "  0.         0.         0.00362319 0.         0.00362319 0.00362319\n",
      "  0.00362319 0.00362319 0.00362319 0.         0.00724638 0.\n",
      "  0.00724638 0.0326087  0.00362319 0.00724638 0.01086957 0.00724638\n",
      "  0.         0.         0.00362319 0.02173913 0.01449275 0.01086957\n",
      "  0.01811594 0.02536232 0.         0.00724638 0.00362319 0.01086957\n",
      "  0.01811594 0.         0.         0.00362319 0.00362319 0.00362319\n",
      "  0.01811594 0.04710145 0.05797101 0.         0.01811594 0.01811594\n",
      "  0.03623188 0.01086957 0.04347826 0.02536232 0.05434783 0.03623188\n",
      "  0.01086957 0.02536232 0.01811594 0.01449275 0.0326087  0.02536232\n",
      "  0.02536232 0.00362319 0.02173913 0.01449275 0.00724638 0.02898551]\n",
      " [0.00359712 0.         0.         0.00719424 0.01079137 0.01079137\n",
      "  0.01079137 0.01079137 0.01079137 0.01079137 0.00359712 0.00359712\n",
      "  0.         0.00359712 0.00719424 0.         0.00359712 0.\n",
      "  0.00719424 0.00719424 0.00719424 0.         0.00359712 0.00359712\n",
      "  0.02877698 0.01438849 0.01798561 0.01079137 0.0323741  0.00719424\n",
      "  0.01798561 0.01798561 0.02158273 0.01438849 0.01079137 0.00719424\n",
      "  0.01438849 0.01438849 0.00359712 0.01079137 0.00359712 0.01079137\n",
      "  0.01438849 0.01079137 0.01798561 0.01438849 0.00359712 0.01438849\n",
      "  0.01438849 0.01079137 0.04676259 0.01798561 0.02517986 0.02158273\n",
      "  0.01079137 0.0323741  0.01079137 0.02158273 0.02158273 0.02158273\n",
      "  0.00719424 0.0323741  0.02877698 0.01079137 0.0323741  0.0323741\n",
      "  0.02158273 0.02877698 0.03956835 0.02517986 0.01798561 0.00719424]\n",
      " [0.01481481 0.01481481 0.0037037  0.         0.02222222 0.\n",
      "  0.         0.0037037  0.01481481 0.         0.0037037  0.01111111\n",
      "  0.0037037  0.0037037  0.         0.0037037  0.         0.0037037\n",
      "  0.0037037  0.0037037  0.0037037  0.0037037  0.00740741 0.00740741\n",
      "  0.02592593 0.01851852 0.02592593 0.00740741 0.04074074 0.01851852\n",
      "  0.01851852 0.0037037  0.00740741 0.02592593 0.01851852 0.02962963\n",
      "  0.02592593 0.01851852 0.01111111 0.00740741 0.00740741 0.03333333\n",
      "  0.02222222 0.03333333 0.03703704 0.01851852 0.01481481 0.01481481\n",
      "  0.02592593 0.01851852 0.02222222 0.04814815 0.01851852 0.01111111\n",
      "  0.04074074 0.00740741 0.0037037  0.04444444 0.01481481 0.0037037\n",
      "  0.01111111 0.01111111 0.03333333 0.0037037  0.01111111 0.01481481\n",
      "  0.         0.01111111 0.0037037  0.01481481 0.0037037  0.0037037 ]\n",
      " [0.00724638 0.         0.         0.01449275 0.02536232 0.01086957\n",
      "  0.00362319 0.00362319 0.         0.00724638 0.00724638 0.00724638\n",
      "  0.         0.         0.00362319 0.         0.         0.\n",
      "  0.00724638 0.00362319 0.00362319 0.         0.00362319 0.00362319\n",
      "  0.03623188 0.02173913 0.01449275 0.         0.02536232 0.02898551\n",
      "  0.00724638 0.00362319 0.00724638 0.03623188 0.02173913 0.01086957\n",
      "  0.01086957 0.01086957 0.         0.01086957 0.01086957 0.01086957\n",
      "  0.00362319 0.00724638 0.01086957 0.01086957 0.         0.00362319\n",
      "  0.01449275 0.02536232 0.05072464 0.01811594 0.06521739 0.02898551\n",
      "  0.01086957 0.02173913 0.00724638 0.03623188 0.02173913 0.02173913\n",
      "  0.02536232 0.01449275 0.03623188 0.01086957 0.01811594 0.01449275\n",
      "  0.02536232 0.01811594 0.0326087  0.01811594 0.02898551 0.01811594]\n",
      " [0.02189781 0.         0.01094891 0.01459854 0.00364964 0.01459854\n",
      "  0.01094891 0.         0.01094891 0.00364964 0.00729927 0.\n",
      "  0.00364964 0.00364964 0.00729927 0.00729927 0.00364964 0.00364964\n",
      "  0.00729927 0.00729927 0.         0.         0.         0.00729927\n",
      "  0.01459854 0.03284672 0.01459854 0.01459854 0.00364964 0.02919708\n",
      "  0.00364964 0.01824818 0.01094891 0.01459854 0.00364964 0.01459854\n",
      "  0.02554745 0.01459854 0.00364964 0.00729927 0.01824818 0.00729927\n",
      "  0.02919708 0.         0.01824818 0.02554745 0.         0.01094891\n",
      "  0.01094891 0.01094891 0.02554745 0.01459854 0.01094891 0.05839416\n",
      "  0.03284672 0.01824818 0.01459854 0.03649635 0.01459854 0.02189781\n",
      "  0.01094891 0.00364964 0.02554745 0.01824818 0.04014599 0.02919708\n",
      "  0.01824818 0.02919708 0.04744526 0.01094891 0.00729927 0.00364964]\n",
      " [0.00738007 0.01476015 0.01107011 0.01476015 0.05166052 0.01476015\n",
      "  0.00369004 0.00738007 0.00369004 0.02214022 0.01107011 0.00738007\n",
      "  0.00369004 0.01107011 0.         0.00738007 0.00369004 0.00738007\n",
      "  0.00738007 0.00369004 0.         0.         0.00738007 0.00738007\n",
      "  0.01107011 0.01845018 0.01845018 0.01845018 0.00738007 0.00369004\n",
      "  0.01845018 0.00369004 0.00738007 0.02583026 0.01476015 0.01107011\n",
      "  0.01107011 0.01476015 0.01107011 0.01107011 0.01107011 0.01107011\n",
      "  0.01476015 0.01107011 0.02583026 0.03321033 0.         0.01107011\n",
      "  0.01476015 0.01107011 0.01107011 0.0295203  0.01476015 0.02583026\n",
      "  0.03321033 0.01476015 0.02214022 0.01107011 0.0295203  0.01107011\n",
      "  0.00738007 0.02214022 0.01107011 0.01476015 0.01845018 0.02214022\n",
      "  0.02214022 0.01845018 0.0295203  0.00738007 0.00738007 0.03690037]\n",
      " [0.00743494 0.         0.01858736 0.01858736 0.01486989 0.00743494\n",
      "  0.00371747 0.01115242 0.         0.00371747 0.00743494 0.01115242\n",
      "  0.00371747 0.00371747 0.00371747 0.         0.00743494 0.\n",
      "  0.00743494 0.00371747 0.01115242 0.00371747 0.00743494 0.00743494\n",
      "  0.02230483 0.01858736 0.00743494 0.03345725 0.01486989 0.00743494\n",
      "  0.01115242 0.01115242 0.02230483 0.01486989 0.04089219 0.00371747\n",
      "  0.         0.         0.00743494 0.         0.         0.\n",
      "  0.01115242 0.01115242 0.01486989 0.01486989 0.00371747 0.\n",
      "  0.01486989 0.02973978 0.03345725 0.01858736 0.01486989 0.01115242\n",
      "  0.02230483 0.08178439 0.02230483 0.01115242 0.01486989 0.01858736\n",
      "  0.00371747 0.02230483 0.01486989 0.02230483 0.01486989 0.02973978\n",
      "  0.03345725 0.04089219 0.02230483 0.0260223  0.01115242 0.02973978]\n",
      " [0.01067616 0.00355872 0.01067616 0.02846975 0.03558719 0.01779359\n",
      "  0.00711744 0.01779359 0.00711744 0.03202847 0.00711744 0.01423488\n",
      "  0.         0.         0.         0.         0.01423488 0.\n",
      "  0.00355872 0.01067616 0.00355872 0.00355872 0.00355872 0.00711744\n",
      "  0.01067616 0.01423488 0.01779359 0.01067616 0.00711744 0.01067616\n",
      "  0.00355872 0.00711744 0.01423488 0.02846975 0.02135231 0.02135231\n",
      "  0.01067616 0.02846975 0.01779359 0.00355872 0.01423488 0.\n",
      "  0.01067616 0.         0.02491103 0.         0.01423488 0.02135231\n",
      "  0.02135231 0.02491103 0.02846975 0.00711744 0.00711744 0.02491103\n",
      "  0.02135231 0.01423488 0.01779359 0.02491103 0.01779359 0.02846975\n",
      "  0.02846975 0.01423488 0.02491103 0.01423488 0.01067616 0.03202847\n",
      "  0.01067616 0.00711744 0.03202847 0.01423488 0.00355872 0.01779359]\n",
      " [0.01831502 0.01098901 0.         0.00732601 0.01831502 0.01465201\n",
      "  0.003663   0.         0.00732601 0.00732601 0.         0.\n",
      "  0.00732601 0.003663   0.         0.003663   0.003663   0.003663\n",
      "  0.003663   0.003663   0.         0.00732601 0.00732601 0.003663\n",
      "  0.00732601 0.01831502 0.03296703 0.00732601 0.03296703 0.02197802\n",
      "  0.00732601 0.01831502 0.02197802 0.02197802 0.01098901 0.02564103\n",
      "  0.02930403 0.01831502 0.003663   0.01098901 0.03663004 0.02197802\n",
      "  0.02197802 0.01098901 0.02564103 0.01831502 0.003663   0.01465201\n",
      "  0.01465201 0.01098901 0.02564103 0.03296703 0.00732601 0.02564103\n",
      "  0.02930403 0.01831502 0.02197802 0.05128205 0.00732601 0.01098901\n",
      "  0.         0.003663   0.01098901 0.00732601 0.02197802 0.01831502\n",
      "  0.003663   0.02564103 0.02564103 0.01831502 0.00732601 0.02197802]\n",
      " [0.01094891 0.00364964 0.00364964 0.01824818 0.01824818 0.00729927\n",
      "  0.01094891 0.00729927 0.00729927 0.01459854 0.00364964 0.01824818\n",
      "  0.01094891 0.         0.00364964 0.00729927 0.00729927 0.00729927\n",
      "  0.01094891 0.00364964 0.01824818 0.         0.01094891 0.00364964\n",
      "  0.01824818 0.01094891 0.00364964 0.00729927 0.01094891 0.01094891\n",
      "  0.         0.01459854 0.01459854 0.00729927 0.00729927 0.00364964\n",
      "  0.00729927 0.01459854 0.00729927 0.         0.02189781 0.00364964\n",
      "  0.02189781 0.01459854 0.00729927 0.01094891 0.00364964 0.\n",
      "  0.02189781 0.04379562 0.04014599 0.00364964 0.01094891 0.01459854\n",
      "  0.02189781 0.01459854 0.03284672 0.02189781 0.08029197 0.02919708\n",
      "  0.02919708 0.03649635 0.02919708 0.01459854 0.04379562 0.00364964\n",
      "  0.         0.00729927 0.03649635 0.00364964 0.01824818 0.01094891]\n",
      " [0.01811594 0.01086957 0.00362319 0.00724638 0.0326087  0.01086957\n",
      "  0.01449275 0.         0.00362319 0.01086957 0.01086957 0.01811594\n",
      "  0.         0.00362319 0.00362319 0.         0.00724638 0.\n",
      "  0.00362319 0.00724638 0.01449275 0.00362319 0.00362319 0.00362319\n",
      "  0.01811594 0.01449275 0.02173913 0.02536232 0.01449275 0.01086957\n",
      "  0.00362319 0.00724638 0.01449275 0.01449275 0.02898551 0.00362319\n",
      "  0.00362319 0.02536232 0.00724638 0.00362319 0.         0.00724638\n",
      "  0.01811594 0.         0.02173913 0.00724638 0.         0.\n",
      "  0.01086957 0.01449275 0.02898551 0.01449275 0.01449275 0.03985507\n",
      "  0.01449275 0.01811594 0.02898551 0.02898551 0.0326087  0.04347826\n",
      "  0.00724638 0.03623188 0.01449275 0.01449275 0.01086957 0.02173913\n",
      "  0.02536232 0.03623188 0.02536232 0.02536232 0.01086957 0.01811594]\n",
      " [0.00743494 0.01115242 0.01486989 0.0260223  0.01858736 0.00743494\n",
      "  0.02973978 0.01115242 0.         0.01858736 0.01115242 0.01486989\n",
      "  0.00743494 0.00371747 0.00371747 0.         0.         0.00371747\n",
      "  0.00371747 0.         0.00743494 0.         0.00371747 0.00371747\n",
      "  0.01486989 0.         0.00371747 0.01858736 0.01115242 0.01115242\n",
      "  0.00743494 0.00371747 0.00371747 0.01486989 0.01115242 0.01115242\n",
      "  0.00371747 0.00371747 0.00371747 0.01858736 0.00371747 0.00743494\n",
      "  0.01115242 0.         0.00743494 0.01486989 0.         0.00371747\n",
      "  0.00371747 0.03717472 0.03345725 0.00743494 0.01486989 0.02230483\n",
      "  0.0260223  0.01486989 0.0260223  0.01858736 0.05204461 0.03345725\n",
      "  0.05947955 0.0260223  0.03717472 0.01858736 0.04832714 0.01115242\n",
      "  0.01115242 0.01115242 0.01486989 0.01858736 0.01858736 0.03717472]\n",
      " [0.02517986 0.         0.01079137 0.01079137 0.01079137 0.01079137\n",
      "  0.02158273 0.00359712 0.         0.02158273 0.00359712 0.02158273\n",
      "  0.00359712 0.         0.         0.         0.         0.00719424\n",
      "  0.01798561 0.00719424 0.01438849 0.01438849 0.00359712 0.00359712\n",
      "  0.01438849 0.01798561 0.02158273 0.01438849 0.00719424 0.02158273\n",
      "  0.00359712 0.00719424 0.00719424 0.01438849 0.01079137 0.\n",
      "  0.00719424 0.         0.         0.00359712 0.00359712 0.00719424\n",
      "  0.01798561 0.00719424 0.00359712 0.01079137 0.01079137 0.01079137\n",
      "  0.01438849 0.03597122 0.05035971 0.00719424 0.01438849 0.02158273\n",
      "  0.01438849 0.0323741  0.02877698 0.02158273 0.01798561 0.01798561\n",
      "  0.02877698 0.05395683 0.01438849 0.01438849 0.01079137 0.02158273\n",
      "  0.01438849 0.01079137 0.04676259 0.04316547 0.01798561 0.01079137]\n",
      " [0.01470588 0.00735294 0.00367647 0.00367647 0.02205882 0.00735294\n",
      "  0.00735294 0.00735294 0.01102941 0.00367647 0.00367647 0.00735294\n",
      "  0.00367647 0.00735294 0.         0.         0.00367647 0.00367647\n",
      "  0.02205882 0.         0.01838235 0.00367647 0.01470588 0.\n",
      "  0.02205882 0.01102941 0.01838235 0.01102941 0.02573529 0.01102941\n",
      "  0.01470588 0.00367647 0.01102941 0.04044118 0.01102941 0.01102941\n",
      "  0.01102941 0.00367647 0.01470588 0.01102941 0.00735294 0.01470588\n",
      "  0.00735294 0.01470588 0.02205882 0.00735294 0.00367647 0.00735294\n",
      "  0.01102941 0.01102941 0.04779412 0.01470588 0.03308824 0.00367647\n",
      "  0.01470588 0.00735294 0.03308824 0.02941176 0.03308824 0.01102941\n",
      "  0.01102941 0.01470588 0.06985294 0.01102941 0.03308824 0.01838235\n",
      "  0.         0.01470588 0.01102941 0.00735294 0.02573529 0.04044118]\n",
      " [0.00735294 0.00367647 0.02205882 0.01470588 0.00735294 0.01470588\n",
      "  0.00735294 0.01102941 0.         0.00735294 0.00735294 0.02941176\n",
      "  0.00367647 0.         0.01102941 0.01838235 0.         0.00735294\n",
      "  0.00367647 0.00735294 0.01470588 0.00367647 0.00735294 0.01102941\n",
      "  0.02205882 0.01838235 0.00367647 0.00367647 0.01838235 0.00367647\n",
      "  0.00735294 0.01838235 0.01102941 0.01838235 0.01102941 0.00735294\n",
      "  0.00735294 0.00367647 0.         0.01102941 0.01838235 0.00367647\n",
      "  0.01470588 0.         0.01470588 0.00367647 0.00367647 0.\n",
      "  0.01838235 0.02573529 0.0625     0.01102941 0.01102941 0.01470588\n",
      "  0.02573529 0.02941176 0.01838235 0.01838235 0.01838235 0.02573529\n",
      "  0.00735294 0.02573529 0.02205882 0.05147059 0.02205882 0.02205882\n",
      "  0.01470588 0.03676471 0.02573529 0.02941176 0.00367647 0.01470588]\n",
      " [0.01433692 0.00716846 0.02150538 0.00358423 0.02508961 0.01433692\n",
      "  0.02508961 0.02150538 0.01433692 0.01075269 0.         0.00716846\n",
      "  0.         0.         0.         0.00358423 0.         0.00716846\n",
      "  0.01433692 0.         0.00716846 0.         0.00358423 0.\n",
      "  0.02508961 0.01792115 0.01433692 0.01433692 0.01433692 0.02867384\n",
      "  0.00358423 0.00716846 0.00358423 0.01433692 0.00716846 0.02150538\n",
      "  0.01433692 0.01792115 0.00716846 0.00358423 0.00358423 0.\n",
      "  0.01433692 0.01075269 0.01075269 0.02508961 0.00358423 0.00358423\n",
      "  0.00358423 0.02508961 0.03584229 0.01433692 0.02867384 0.03225806\n",
      "  0.00358423 0.00358423 0.01433692 0.04659498 0.02508961 0.02150538\n",
      "  0.00716846 0.01433692 0.01792115 0.01433692 0.07526882 0.03584229\n",
      "  0.01433692 0.02150538 0.01075269 0.02150538 0.01792115 0.00716846]\n",
      " [0.02985075 0.         0.         0.00746269 0.01492537 0.02985075\n",
      "  0.01119403 0.01492537 0.00373134 0.01492537 0.00746269 0.00746269\n",
      "  0.00373134 0.00373134 0.00373134 0.00746269 0.         0.01119403\n",
      "  0.00373134 0.00373134 0.01119403 0.00746269 0.00373134 0.00373134\n",
      "  0.01865672 0.01865672 0.0261194  0.01492537 0.0261194  0.01492537\n",
      "  0.01492537 0.02238806 0.0261194  0.03731343 0.01492537 0.00373134\n",
      "  0.00746269 0.00746269 0.01119403 0.01119403 0.01865672 0.01119403\n",
      "  0.01492537 0.00373134 0.01865672 0.02238806 0.         0.01865672\n",
      "  0.02238806 0.00373134 0.02985075 0.00373134 0.00746269 0.01119403\n",
      "  0.01119403 0.02238806 0.00746269 0.0261194  0.00373134 0.01492537\n",
      "  0.00746269 0.         0.00373134 0.03731343 0.00746269 0.04850746\n",
      "  0.01865672 0.05223881 0.02238806 0.03358209 0.00373134 0.01119403]\n",
      " [0.00364964 0.00364964 0.01459854 0.01459854 0.00729927 0.01094891\n",
      "  0.01459854 0.02189781 0.00364964 0.02554745 0.00364964 0.01459854\n",
      "  0.         0.         0.00364964 0.         0.00729927 0.\n",
      "  0.00729927 0.         0.01824818 0.00364964 0.00729927 0.\n",
      "  0.01824818 0.02189781 0.01824818 0.01824818 0.00364964 0.01824818\n",
      "  0.         0.00729927 0.01459854 0.01094891 0.00729927 0.\n",
      "  0.00729927 0.00729927 0.00729927 0.00364964 0.         0.00364964\n",
      "  0.01459854 0.         0.00364964 0.00729927 0.01094891 0.\n",
      "  0.01824818 0.03649635 0.03649635 0.01094891 0.02189781 0.02189781\n",
      "  0.01824818 0.03284672 0.01459854 0.01459854 0.01459854 0.02919708\n",
      "  0.01094891 0.04744526 0.01459854 0.01824818 0.02189781 0.03284672\n",
      "  0.04744526 0.04014599 0.03649635 0.01459854 0.02554745 0.02919708]\n",
      " [0.01838235 0.00367647 0.01838235 0.01838235 0.01470588 0.01470588\n",
      "  0.         0.02205882 0.00735294 0.00735294 0.00367647 0.01102941\n",
      "  0.00367647 0.00367647 0.00735294 0.00367647 0.         0.01102941\n",
      "  0.01470588 0.00367647 0.         0.00367647 0.         0.01470588\n",
      "  0.01838235 0.03308824 0.01102941 0.01470588 0.02573529 0.01838235\n",
      "  0.01102941 0.01838235 0.02941176 0.02573529 0.01470588 0.00367647\n",
      "  0.00367647 0.00735294 0.00735294 0.         0.02941176 0.01102941\n",
      "  0.01102941 0.         0.02205882 0.00735294 0.00367647 0.\n",
      "  0.00735294 0.02205882 0.03676471 0.00735294 0.01102941 0.01838235\n",
      "  0.01470588 0.03308824 0.02205882 0.03308824 0.01102941 0.01470588\n",
      "  0.01102941 0.02573529 0.01470588 0.03308824 0.         0.02941176\n",
      "  0.01470588 0.03676471 0.02573529 0.02205882 0.00735294 0.01470588]\n",
      " [0.03321033 0.00738007 0.01107011 0.00738007 0.         0.00369004\n",
      "  0.01476015 0.00738007 0.00738007 0.0295203  0.00369004 0.00738007\n",
      "  0.00738007 0.         0.         0.         0.00369004 0.00369004\n",
      "  0.00369004 0.         0.01845018 0.01107011 0.00369004 0.\n",
      "  0.00738007 0.02583026 0.01476015 0.01845018 0.04059041 0.01845018\n",
      "  0.00738007 0.         0.00738007 0.01107011 0.00369004 0.0295203\n",
      "  0.01845018 0.         0.01107011 0.02214022 0.00738007 0.00369004\n",
      "  0.02583026 0.01476015 0.01107011 0.02583026 0.00738007 0.00369004\n",
      "  0.02214022 0.01107011 0.0295203  0.01107011 0.00738007 0.0295203\n",
      "  0.01107011 0.01476015 0.01476015 0.02583026 0.02583026 0.02583026\n",
      "  0.00369004 0.02214022 0.01107011 0.01845018 0.01476015 0.01845018\n",
      "  0.00738007 0.03321033 0.07749077 0.02214022 0.01476015 0.00738007]\n",
      " [0.02197802 0.003663   0.02197802 0.01465201 0.003663   0.01098901\n",
      "  0.003663   0.02564103 0.00732601 0.02197802 0.01465201 0.02564103\n",
      "  0.         0.003663   0.003663   0.003663   0.003663   0.00732601\n",
      "  0.003663   0.01098901 0.00732601 0.003663   0.003663   0.003663\n",
      "  0.02564103 0.01831502 0.01098901 0.         0.01465201 0.01098901\n",
      "  0.003663   0.01098901 0.02564103 0.02930403 0.01831502 0.003663\n",
      "  0.01831502 0.01465201 0.003663   0.01098901 0.         0.003663\n",
      "  0.00732601 0.01098901 0.         0.01098901 0.00732601 0.00732601\n",
      "  0.02197802 0.00732601 0.03663004 0.003663   0.01098901 0.02564103\n",
      "  0.01831502 0.02930403 0.01465201 0.02564103 0.00732601 0.01465201\n",
      "  0.00732601 0.01831502 0.00732601 0.02564103 0.01465201 0.04761905\n",
      "  0.003663   0.02564103 0.03296703 0.05860806 0.01465201 0.02930403]\n",
      " [0.00729927 0.00729927 0.00729927 0.         0.01094891 0.01094891\n",
      "  0.00729927 0.00729927 0.00364964 0.01459854 0.00364964 0.01094891\n",
      "  0.00364964 0.         0.00729927 0.         0.         0.00364964\n",
      "  0.00364964 0.         0.00729927 0.01094891 0.         0.01824818\n",
      "  0.03649635 0.01459854 0.00364964 0.01459854 0.01459854 0.01459854\n",
      "  0.01824818 0.00729927 0.00364964 0.01824818 0.01094891 0.00729927\n",
      "  0.00729927 0.01094891 0.00364964 0.00729927 0.01094891 0.\n",
      "  0.00364964 0.         0.01824818 0.01459854 0.00364964 0.00729927\n",
      "  0.02189781 0.03284672 0.06934307 0.01824818 0.01459854 0.03649635\n",
      "  0.01459854 0.01094891 0.00729927 0.02919708 0.02919708 0.02189781\n",
      "  0.03649635 0.02554745 0.02189781 0.03649635 0.02189781 0.01824818\n",
      "  0.00729927 0.01824818 0.01824818 0.01094891 0.04379562 0.03649635]\n",
      " [0.01086957 0.00724638 0.00724638 0.01086957 0.02173913 0.01086957\n",
      "  0.01086957 0.00724638 0.         0.00724638 0.00724638 0.00362319\n",
      "  0.01449275 0.00362319 0.01449275 0.00362319 0.01449275 0.01449275\n",
      "  0.00724638 0.01086957 0.01449275 0.00362319 0.01811594 0.01086957\n",
      "  0.00362319 0.02173913 0.01086957 0.01086957 0.01449275 0.01811594\n",
      "  0.00362319 0.03623188 0.01449275 0.02173913 0.01811594 0.\n",
      "  0.         0.00362319 0.         0.         0.01811594 0.\n",
      "  0.00724638 0.00362319 0.00724638 0.00362319 0.00362319 0.00724638\n",
      "  0.         0.02536232 0.0326087  0.00724638 0.01086957 0.00724638\n",
      "  0.02536232 0.01811594 0.01811594 0.02898551 0.05072464 0.02173913\n",
      "  0.00724638 0.02173913 0.01811594 0.02898551 0.01086957 0.02536232\n",
      "  0.01086957 0.05072464 0.02536232 0.01086957 0.00362319 0.07608696]]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "print(cm_cv7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
